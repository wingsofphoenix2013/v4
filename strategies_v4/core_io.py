# core_io.py

import asyncio
import logging
import json
from datetime import datetime
import time
from decimal import Decimal

from infra import infra

log = logging.getLogger("CORE_IO")

SIGNAL_LOG_STREAM = "signal_log_queue"
POSITIONS_STREAM = "positions_stream"

# üìå –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ –ø–æ–ª—è–º TP/SL —Ü–µ–ª–∏
def get_field(obj, field, default=None):
    return obj.get(field, default) if isinstance(obj, dict) else getattr(obj, field, default)

def set_field(obj, field, value):
    if isinstance(obj, dict):
        obj[field] = value
    else:
        setattr(obj, field, value)
        
# üî∏ –ó–∞–ø–∏—Å—å –ª–æ–≥–∞ —Å–∏–≥–Ω–∞–ª–∞
async def write_log_entry_batch(pool, records: list[dict]):
    query = """
        INSERT INTO signal_log_entries_v4
        (log_uid, strategy_id, status, position_uid, note, logged_at)
        VALUES ($1, $2, $3, $4, $5, $6)
    """
    async with pool.acquire() as conn:
        try:
            values_list = []
            for record in records:
                values_list.append((
                    record["log_uid"],
                    int(record["strategy_id"]),
                    record["status"],
                    record.get("position_uid"),
                    record.get("note"),
                    datetime.fromisoformat(record["logged_at"])
                ))

            await conn.executemany(query, values_list)
            log.info(f"üíæ –ó–∞–ø–∏—Å–∞–Ω–æ –ª–æ–≥–æ–≤ —Å–∏–≥–Ω–∞–ª–æ–≤: {len(values_list)}")
        except Exception as e:
            log.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –±–∞—Ç—á-–∑–∞–ø–∏—Å–∏ –ª–æ–≥–æ–≤ —Å–∏–≥–Ω–∞–ª–æ–≤: {e}")
# üî∏ –ó–∞–ø–∏—Å—å –ø–æ–∑–∏—Ü–∏–∏ –∏ —Ü–µ–ª–µ–π
async def write_position_and_targets_batch(pool, records: list[dict]):
    async with pool.acquire() as conn:
        tx = conn.transaction()
        await tx.start()
        try:
            position_values = []
            target_values = []

            for record in records:
                position_values.append((
                    record["position_uid"],
                    int(record["strategy_id"]),
                    record["symbol"],
                    record["direction"],
                    Decimal(record["entry_price"]),
                    Decimal(record["quantity"]),
                    Decimal(record["quantity_left"]),
                    record["status"],
                    datetime.fromisoformat(record["created_at"]),
                    None,  # exit_price
                    None,  # closed_at
                    record.get("close_reason"),
                    Decimal(record.get("pnl", "0")),
                    Decimal(record["planned_risk"]),
                    Decimal(record["notional_value"]),
                    record["route"],
                    record["log_uid"]
                ))

                for target in record.get("tp_targets", []) + record.get("sl_targets", []):
                    target_values.append((
                        record["position_uid"],
                        get_field(target, "type"),
                        int(get_field(target, "level")),
                        Decimal(get_field(target, "price")) if get_field(target, "price") is not None else None,
                        Decimal(get_field(target, "quantity")),
                        get_field(target, "hit"),
                        datetime.fromisoformat(get_field(target, "hit_at")) if get_field(target, "hit_at") else None,
                        get_field(target, "canceled"),
                        get_field(target, "source")
                    ))

            await conn.executemany(
                """
                INSERT INTO positions_v4 (
                    position_uid, strategy_id, symbol, direction, entry_price,
                    quantity, quantity_left, status, created_at,
                    exit_price, closed_at, close_reason, pnl,
                    planned_risk, notional_value, route, log_uid
                )
                VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14,$15,$16,$17)
                """,
                position_values
            )

            if target_values:
                await conn.executemany(
                    """
                    INSERT INTO position_targets_v4 (
                        position_uid, type, level, price, quantity,
                        hit, hit_at, canceled, source
                    )
                    VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9)
                    """,
                    target_values
                )

            await tx.commit()
            log.info(f"üíæ –ó–∞–ø–∏—Å–∞–Ω–æ –ø–æ–∑–∏—Ü–∏–π: {len(position_values)}, —Ü–µ–ª–µ–π: {len(target_values)}")
        except Exception as e:
            await tx.rollback()
            log.warning(f"‚ùå –û—à–∏–±–∫–∞ –±–∞—Ç—á-–∑–∞–ø–∏—Å–∏ –ø–æ–∑–∏—Ü–∏–π: {e}")
# üî∏ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏ –∏ —Ü–µ–ª–µ–π –≤ –ë–î –ø–æ –ø–æ—Ç–æ–∫—É –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π
async def update_position_and_targets_batch(pool, records: list[dict]):
    async with pool.acquire() as conn:
        tx = conn.transaction()
        await tx.start()
        try:
            for record in records:
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏
                await conn.execute(
                    """
                    UPDATE positions_v4
                    SET
                        quantity_left = $1,
                        status = $2,
                        exit_price = $3,
                        close_reason = $4,
                        pnl = $5,
                        closed_at = $6,
                        planned_risk = $7
                    WHERE position_uid = $8
                    """,
                    Decimal(record["quantity_left"]),
                    record["status"],
                    Decimal(record["exit_price"]) if record.get("exit_price") else None,
                    record.get("close_reason"),
                    Decimal(record["pnl"]),
                    datetime.fromisoformat(record["closed_at"]) if record.get("closed_at") else None,
                    Decimal(record["planned_risk"]),
                    record["position_uid"]
                )

                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–ª–∏ –≤—Å—Ç–∞–≤–∫–∞ TP/SL —Ü–µ–ª–µ–π
                for target in record.get("tp_targets", []) + record.get("sl_targets", []):
                    result = await conn.execute(
                        """
                        UPDATE position_targets_v4
                        SET
                            hit = $1,
                            hit_at = $2,
                            canceled = $3
                        WHERE position_uid = $4 AND level = $5 AND type = $6
                        """,
                        get_field(target, "hit"),
                        datetime.fromisoformat(get_field(target, "hit_at")) if get_field(target, "hit_at") else None,
                        get_field(target, "canceled"),
                        record["position_uid"],
                        int(get_field(target, "level")),
                        get_field(target, "type")
                    )

                    if result == "UPDATE 0":
                        await conn.execute(
                            """
                            INSERT INTO position_targets_v4 (
                                position_uid, type, level, price, quantity,
                                hit, hit_at, canceled, source
                            ) VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9)
                            """,
                            record["position_uid"],
                            get_field(target, "type"),
                            int(get_field(target, "level")),
                            Decimal(get_field(target, "price")) if get_field(target, "price") is not None else None,
                            Decimal(get_field(target, "quantity")),
                            get_field(target, "hit"),
                            datetime.fromisoformat(get_field(target, "hit_at")) if get_field(target, "hit_at") else None,
                            get_field(target, "canceled"),
                            get_field(target, "source")
                        )

            await tx.commit()
            log.info(f"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–∑–∏—Ü–∏–π: {len(records)}")
        except Exception as e:
            await tx.rollback()
            log.warning(f"‚ùå –û—à–∏–±–∫–∞ –±–∞—Ç—á-–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ–∑–∏—Ü–∏–π: {e}")
# üî∏ –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –∞–∫—Ç–∏–≤–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–∞ —Ä–µ–≤–µ—Ä—Å–∞ —á–µ—Ä–µ–∑ signals_stream
async def reverse_entry(payload: dict):
    position_uid = payload["position_uid"]
    redis = infra.redis_client
    pool = infra.pg_pool

    log.info(f"[REVERSE_ENTRY] –ó–∞–ø—É—Å–∫ —Ä–µ–≤–µ—Ä—Å–∞ –¥–ª—è –ø–æ–∑–∏—Ü–∏–∏ {position_uid}")

    async with pool.acquire() as conn:
        # –ü–æ–ª—É—á–∞–µ–º log_uid, closed_at –∏ symbol –∏–∑ –ø–æ–∑–∏—Ü–∏–∏
        row = await conn.fetchrow("""
            SELECT log_uid, closed_at, symbol
            FROM positions_v4
            WHERE position_uid = $1
        """, position_uid)

        if not row:
            log.warning(f"[REVERSE_ENTRY] –ü–æ–∑–∏—Ü–∏—è {position_uid} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –ë–î ‚Äî –≤—ã—Ö–æ–¥")
            return

        log_uid = row["log_uid"]
        closed_at = row["closed_at"]
        symbol = row["symbol"]

        if closed_at is None:
            log.warning(f"[REVERSE_ENTRY] closed_at is None ‚Äî –æ–∂–∏–¥–∞–Ω–∏–µ 1 —Å–µ–∫ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π")
            await asyncio.sleep(1)

            row_retry = await conn.fetchrow("""
                SELECT closed_at
                FROM positions_v4
                WHERE position_uid = $1
            """, position_uid)

            closed_at = row_retry["closed_at"] if row_retry else None

            if closed_at is None:
                closed_at = datetime.utcnow()
                log.warning(f"[REVERSE_ENTRY] closed_at –≤—Å—ë –µ—â—ë None ‚Äî –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ now(): {closed_at.isoformat()}")
            else:
                log.info(f"[REVERSE_ENTRY] closed_at —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω –ø–æ—Å–ª–µ –æ–∂–∏–¥–∞–Ω–∏—è: {closed_at.isoformat()}")

        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–∞, –æ—Ç–∫—Ä—ã–≤—à–µ–≥–æ –ø–æ–∑–∏—Ü–∏—é
        sig = await conn.fetchrow("""
            SELECT direction
            FROM signals_v4_log
            WHERE id = $1
        """, log_uid)

        if not sig or not sig["direction"]:
            log.warning(f"[REVERSE_ENTRY] –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å direction –ø–æ log_uid={log_uid}")
            return

        direction = sig["direction"]
        reverse_direction = "short" if direction == "long" else "long"

        # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–∏–≥–Ω–∞–ª –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–æ –∑–∞–∫—Ä—ã—Ç–∏—è –ø–æ–∑–∏—Ü–∏–∏
        counter_sig = await conn.fetchrow("""
            SELECT message, bar_time, sent_at
            FROM signals_v4_log
            WHERE symbol = $1
              AND direction = $2
              AND received_at <= $3
            ORDER BY received_at DESC
            LIMIT 1
        """, symbol, reverse_direction, closed_at)

        if not counter_sig:
            log.warning(f"[REVERSE_ENTRY] –ö–æ–Ω—Ç—Ä-—Å–∏–≥–Ω–∞–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è {symbol} ({reverse_direction}) –¥–æ {closed_at}")
            return

        message = counter_sig["message"]
        bar_time = counter_sig["bar_time"]
        sent_at = counter_sig["sent_at"]
        received_at = datetime.utcnow().isoformat()

        new_signal = {
            "symbol": symbol,
            "message": message,
            "bar_time": bar_time.isoformat(),
            "sent_at": sent_at.isoformat(),
            "received_at": received_at
        }

        log.info(f"[REVERSE_ENTRY] üì§ –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–∞ –≤ signals_stream: {json.dumps(new_signal)}")

        try:
            await redis.xadd("signals_stream", new_signal)
            log.info(f"üì® [REVERSE_ENTRY] –ö–æ–Ω—Ç—Ä-—Å–∏–≥–Ω–∞–ª –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –¥–ª—è {symbol}")
        except Exception as e:
            log.warning(f"[REVERSE_ENTRY] –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Redis: {e}")
# üî∏ –ß—Ç–µ–Ω–∏–µ –ª–æ–≥–æ–≤ —Å–∏–≥–Ω–∞–ª–æ–≤
async def run_signal_log_writer():
    log.info("üìù [CORE_IO] –ó–∞–ø—É—Å–∫ –ª–æ–≥–≥–µ—Ä–∞ —Å–∏–≥–Ω–∞–ª–æ–≤")

    redis = infra.redis_client
    pool = infra.pg_pool
    last_id = "$"
    buffer = []
    buffer_limit = 100

    while True:
        try:
            response = await redis.xread(
                streams={SIGNAL_LOG_STREAM: last_id},
                count=buffer_limit,
                block=1000
            )

            if not response:
                continue

            for stream_name, messages in response:
                for msg_id, msg_data in messages:
                    last_id = msg_id
                    try:
                        record = json.loads(msg_data["data"])
                        buffer.append(record)
                    except Exception as e:
                        log.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø–∏—Å–∏: {e}")

            if buffer:
                await write_log_entry_batch(pool, buffer)
                buffer.clear()

        except Exception:
            log.exception("‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∏–∑ Redis Stream")
            await asyncio.sleep(5)
# üî∏ –ß—Ç–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–π –∏–∑ Redis –∏ –∑–∞–ø–∏—Å—å –≤ –ë–î
async def run_position_writer():
    log.info("üìù [CORE_IO] –ó–∞–ø—É—Å–∫ –≤–æ—Ä–∫–µ—Ä–∞ –∑–∞–ø–∏—Å–∏ –ø–æ–∑–∏—Ü–∏–π")
    redis = infra.redis_client
    pool = infra.pg_pool
    last_id = "$"
    buffer = []
    buffer_limit = 100

    while True:
        try:
            response = await redis.xread(
                streams={POSITIONS_STREAM: last_id},
                count=buffer_limit,
                block=1000
            )
            if not response:
                continue

            for stream_name, messages in response:
                for msg_id, msg_data in messages:
                    last_id = msg_id
                    try:
                        record = json.loads(msg_data["data"])
                        buffer.append(record)
                    except Exception as e:
                        log.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ–∑–∏—Ü–∏–∏: {e}")

            if buffer:
                await write_position_and_targets_batch(pool, buffer)
                buffer.clear()

        except Exception:
            log.exception("‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∏–∑ Redis Stream (positions)")
            await asyncio.sleep(5)
# üî∏ –í–æ—Ä–∫–µ—Ä –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –ø–æ–∑–∏—Ü–∏–∏ –∏–∑ Redis-–ø–æ—Ç–æ–∫–∞
async def run_position_update_writer():
    log.info("üõ† [CORE_IO] –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –ø–æ–∑–∏—Ü–∏–π")

    redis = infra.redis_client
    pool = infra.pg_pool
    last_id = "$"
    buffer = []
    buffer_limit = 100

    while True:
        try:
            response = await redis.xread(
                streams={"positions_update_stream": last_id},
                count=buffer_limit,
                block=1000
            )

            if not response:
                continue

            for stream_name, messages in response:
                for msg_id, msg_data in messages:
                    last_id = msg_id
                    try:
                        record = json.loads(msg_data["data"])
                        buffer.append(record)
                    except Exception as e:
                        log.warning(f"‚ö†Ô∏è [CORE_IO] –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ–∑–∏—Ü–∏–∏: {e}")

            if buffer:
                await update_position_and_targets_batch(pool, buffer)
                buffer.clear()

        except Exception:
            log.exception("‚ùå [CORE_IO] –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∏–∑ Redis Stream (positions_update_stream)")
            await asyncio.sleep(5)
# üîÑ –í–æ—Ä–∫–µ—Ä: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–¥–∞—á–∏ —Ä–µ–≤–µ—Ä—Å–∞ –∏–∑ Redis Stream
async def run_reverse_trigger_loop():
    log.info("üåÄ [CORE_IO] –ó–∞–ø—É—Å–∫ –≤–æ—Ä–∫–µ—Ä–∞ —Ä–µ–≤–µ—Ä—Å–∞")

    redis = infra.redis_client
    last_id = "$"
    batch_size = 10

    while True:
        try:
            response = await redis.xread(
                streams={"reverse_trigger_stream": last_id},
                count=batch_size,
                block=1000
            )

            if not response:
                continue

            tasks = []

            for _, messages in response:
                for msg_id, msg_data in messages:
                    last_id = msg_id
                    try:
                        payload = json.loads(msg_data["data"])
                        position_uid = payload["position_uid"]
                        log.info(f"[REVERSE_TRIGGER] –ü–æ–ª—É—á–µ–Ω UID –ø–æ–∑–∏—Ü–∏–∏: {position_uid}")
                        tasks.append(reverse_entry({"position_uid": position_uid}))
                    except Exception as e:
                        log.warning(f"[REVERSE_TRIGGER] –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–¥–∞—á–∏: {e}")

            if tasks:
                await asyncio.gather(*tasks)

        except Exception:
            log.exception("‚ùå [REVERSE_TRIGGER] –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∏–∑ Redis Stream")
            await asyncio.sleep(5)