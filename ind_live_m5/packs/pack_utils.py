# packs/pack_utils.py â€” ÑƒÑ‚Ð¸Ð»Ð¸Ñ‚Ñ‹ Ð´Ð»Ñ on-demand Ð¿Ð°ÐºÐµÑ‚Ð¾Ð² (RSI/MFI/â€¦): Ð²Ñ€ÐµÐ¼Ñ Ð±Ð°Ñ€Ð°, Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° OHLCV Ð¸Ð· TS, ÐºÐ¾Ñ€Ð·Ð¸Ð½Ñ‹ Ð¸ Ñ‚Ñ€ÐµÐ½Ð´Ñ‹

import asyncio
import logging
from datetime import datetime
import pandas as pd

# ðŸ”¸ Ð›Ð¾Ð³Ð³ÐµÑ€ Ð¼Ð¾Ð´ÑƒÐ»Ñ
log = logging.getLogger("PACK_UTILS")

# ðŸ”¸ Ð¢Ð°Ð¹Ð¼ÑˆÐ°Ð³Ð¸ TF (Ð¼Ñ Ð¸ Ð¼Ð¸Ð½ÑƒÑ‚Ñ‹)
STEP_MIN = {"m5": 5, "m15": 15, "h1": 60}
STEP_MS  = {"m5": 300_000, "m15": 900_000, "h1": 3_600_000}

# ðŸ”¸ ÐŸÑ€ÐµÑ„Ð¸ÐºÑÑ‹ Redis
BB_TS_PREFIX = "bb:ts"  # bb:ts:{symbol}:{tf}:{field}
IND_KV_PREFIX = "ind"   # ind:{symbol}:{tf}:{param_name}

# ðŸ”¸ ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ Ðº Ð½Ð°Ñ‡Ð°Ð»Ñƒ Ð±Ð°Ñ€Ð°
def floor_to_bar(ts_ms: int, tf: str) -> int:
    step = STEP_MS[tf]
    return (ts_ms // step) * step

# ðŸ”¸ Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° OHLCV Ð¸Ð· Redis TS (Ð¾Ð´Ð½Ð¸Ð¼ Ð±Ð°Ñ‚Ñ‡ÐµÐ¼) Ð¸ ÑÐ±Ð¾Ñ€ÐºÐ° DataFrame
async def load_ohlcv_df(redis, symbol: str, tf: str, end_ts_ms: int, bars: int = 800):
    if tf not in STEP_MS:
        return None

    step = STEP_MS[tf]
    start_ts = end_ts_ms - (bars - 1) * step

    fields = ["o", "h", "l", "c", "v"]
    keys = {f: f"{BB_TS_PREFIX}:{symbol}:{tf}:{f}" for f in fields}

    # Ð¾Ð´Ð¸Ð½ Ð±Ð°Ñ‚Ñ‡ Ð½Ð° 5 TS.RANGE
    tasks = {f: redis.execute_command("TS.RANGE", keys[f], start_ts, end_ts_ms) for f in fields}
    results = await asyncio.gather(*tasks.values(), return_exceptions=True)

    series = {}
    for f, res in zip(tasks.keys(), results):
        if isinstance(res, Exception):
            log.warning(f"[TS] RANGE {keys[f]} error: {res}")
            continue
        if res:
            try:
                series[f] = {int(ts): float(val) for ts, val in res if val is not None}
            except Exception as e:
                log.warning(f"[TS] parse {keys[f]} error: {e}")

    if not series or "c" not in series or not series["c"]:
        return None

    # Ð¾Ð±Ñ‰Ð¸Ð¹ Ð¸Ð½Ð´ÐµÐºÑ Ð¿Ð¾ Ð¼ÐµÑ‚ÐºÐ°Ð¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ (Ð¿Ð¾ close)
    idx = sorted(series["c"].keys())
    df = None
    for f in fields:
        col_map = series.get(f, {})
        s = pd.Series({ts: col_map.get(ts) for ts in idx})
        s.index = pd.to_datetime(s.index, unit="ms")
        s.name = f
        df = s.to_frame() if df is None else df.join(s, how="outer")

    if df is None or df.empty:
        return None

    df.index.name = "open_time"
    return df.sort_index()

# ðŸ”¸ RSI: ÐºÐ¾Ñ€Ð·Ð¸Ð½Ð° (Ð½Ð¸Ð¶Ð½ÑÑ Ð³Ñ€Ð°Ð½Ð¸Ñ†Ð°, ÑˆÐ°Ð³ 5)
def rsi_bucket_low(value: float) -> int:
    x = max(0.0, min(99.9999, float(value)))
    return int((int(x) // 5) * 5)

# ðŸ”¸ RSI: Ð¿Ð¾Ñ€Ð¾Ð³Ð¸ Â«Ð¼ÐµÑ€Ñ‚Ð²Ð¾Ð³Ð¾ ÐºÐ¾Ñ€Ð¸Ð´Ð¾Ñ€Ð°Â» Ð¿Ð¾ TF (Ð°Ð±ÑÐ¾Ð»ÑŽÑ‚Ð½Ñ‹Ðµ Ð¿ÑƒÐ½ÐºÑ‚Ñ‹ RSI)
RSI_EPS = {"m5": 0.3, "m15": 0.4, "h1": 0.6}

# ðŸ”¸ RSI: ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ Ñ‚Ñ€ÐµÐ½Ð´Ð° Ð¿Ð¾ Ð°Ð±ÑÐ¾Ð»ÑŽÑ‚Ð½Ð¾Ð¹ Ð´ÐµÐ»ÑŒÑ‚Ðµ (up/flat/down)
def classify_abs_delta(delta: float, tf: str) -> str:
    eps = RSI_EPS.get(tf, 0.4)
    if delta >= eps:
        return "up"
    if delta <= -eps:
        return "down"
    return "flat"

# ðŸ”¸ ÐŸÑ€Ð¾Ñ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ Ð·Ð°ÐºÑ€Ñ‹Ñ‚Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ RSI Ð¸Ð· KV ind:{symbol}:{tf}:rsi{length}
async def get_closed_rsi(redis, symbol: str, tf: str, length: int) -> float | None:
    key = f"{IND_KV_PREFIX}:{symbol}:{tf}:rsi{length}"
    try:
        s = await redis.get(key)
        return float(s) if s is not None else None
    except Exception:
        return None

# ðŸ”¸ Ð’ÑÐ¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ: ISO-Ð²Ñ€ÐµÐ¼Ñ Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚Ð¸Ñ Ð±Ð°Ñ€Ð° Ð¿Ð¾ ms
def bar_open_iso(bar_open_ms: int) -> str:
    return datetime.utcfromtimestamp(bar_open_ms / 1000).isoformat()