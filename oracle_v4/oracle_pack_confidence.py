# oracle_pack_confidence.py ‚Äî –≤–æ—Ä–∫–µ—Ä PACK-confidence: –ø–∞–∫–µ—Ç–Ω—ã–π —Ä–∞—Å—á—ë—Ç R/P/C/S –ø–æ –∫–æ–º–ø–ª–µ–∫—Ç—É –æ–∫–æ–Ω (7d+14d+28d) —Å –±–∞—Ç—á-–∑–∞–ø—Ä–æ—Å–∞–º–∏ –∏ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–æ–º

# üî∏ –ò–º–ø–æ—Ä—Ç—ã
import asyncio
import logging
import json
import math
import time
from typing import Dict, List, Tuple, Optional
from datetime import datetime

import infra
# –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —É—Ç–∏–ª–∏—Ç—ã –∏–∑ MW-–≤–æ—Ä–∫–µ—Ä–∞ (–æ–Ω–∏ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã)
from oracle_mw_confidence import (
    WINDOW_STEPS, Z, BASELINE_WR,
    _wilson_lower_bound, _wilson_bounds,
    _ecdf_rank, _median, _mad, _iqr,
)

# üî∏ –õ–æ–≥–≥–µ—Ä
log = logging.getLogger("ORACLE_PACK_CONFIDENCE")

# üî∏ –°—Ç—Ä–∏–º—ã
PACK_REPORT_STREAM = "oracle:pack:reports_ready"
PACK_CONSUMER_GROUP = "oracle_pack_conf_group"
PACK_CONSUMER_NAME = "oracle_pack_conf_worker"

# (–≥–æ—Ç–æ–≤–∏–º –Ω–∞–ø–µ—Ä—ë–¥ –¥–ª—è sense-—ç—Ç–∞–ø–∞; —ç—Ç–æ—Ç –≤–æ—Ä–∫–µ—Ä –ª–∏—à—å –ø—É–±–ª–∏–∫—É–µ—Ç ¬´–≥–æ—Ç–æ–≤–æ –∫ sense¬ª –ø–æ –∫–∞–∂–¥–æ–º—É report_id –∫–æ–º–ø–ª–µ–∫—Ç–∞)
PACK_SENSE_REPORT_READY_STREAM = "oracle:pack_sense:reports_ready"
PACK_SENSE_REPORT_READY_MAXLEN = 10_000

# üî∏ –ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º
MAX_CONCURRENT_STRATEGIES = 4  # –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–æ 4 —Å—Ç—Ä–∞—Ç–µ–≥–∏–π (–∫–æ–º–ø–ª–µ–∫—Ç–æ–≤ window_end)

# üî∏ –ö—ç—à –≤–µ—Å–æ–≤ (strategy_id,time_frame) ‚Üí (weights, opts, ts)
_weights_cache: Dict[Tuple[Optional[int], Optional[str]], Tuple[Dict[str, float], Dict, float]] = {}
WEIGHTS_TTL_SEC = 15 * 60  # 15 –º–∏–Ω—É—Ç

# üî∏ –ü—É–±–ª–∏—á–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –≤–æ—Ä–∫–µ—Ä–∞ (–∑–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ run_safe_loop –∏–∑ main)
async def run_oracle_pack_confidence():
    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    if infra.pg_pool is None or infra.redis_client is None:
        log.debug("‚ùå –ü—Ä–æ–ø—É—Å–∫: PG/Redis –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
        return

    # —Å–æ–∑–¥–∞—ë–º consumer group (–∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ)
    try:
        await infra.redis_client.xgroup_create(
            name=PACK_REPORT_STREAM, groupname=PACK_CONSUMER_GROUP, id="$", mkstream=True
        )
        log.debug("üì° –°–æ–∑–¥–∞–Ω–∞ –≥—Ä—É–ø–ø–∞ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª–µ–π Redis Stream: %s", PACK_CONSUMER_GROUP)
    except Exception as e:
        if "BUSYGROUP" in str(e):
            pass
        else:
            log.exception("‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≥—Ä—É–ø–ø—ã Redis Stream")
            return

    sem = asyncio.Semaphore(MAX_CONCURRENT_STRATEGIES)
    log.info("üöÄ –°—Ç–∞—Ä—Ç –≤–æ—Ä–∫–µ—Ä–∞ PACK-confidence (max_parallel_strategies=%d)", MAX_CONCURRENT_STRATEGIES)

    # –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —á—Ç–µ–Ω–∏—è —Å—Ç—Ä–∏–º–∞
    while True:
        try:
            resp = await infra.redis_client.xreadgroup(
                groupname=PACK_CONSUMER_GROUP,
                consumername=PACK_CONSUMER_NAME,
                streams={PACK_REPORT_STREAM: ">"},
                count=128,
                block=30_000,
            )
            if not resp:
                continue

            # –≥—Ä—É–ø–ø–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ (strategy_id, window_end)
            batches: Dict[Tuple[int, str], List[Tuple[str, dict]]] = {}
            for stream_name, msgs in resp:
                for msg_id, fields in msgs:
                    try:
                        payload = json.loads(fields.get("data", "{}"))
                        sid = int(payload.get("strategy_id", 0))
                        window_end = payload.get("window_end")  # ISO-—Å—Ç—Ä–æ–∫–∞
                        if not (sid and window_end):
                            # –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Äî ACK –∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                            await infra.redis_client.xack(PACK_REPORT_STREAM, PACK_CONSUMER_GROUP, msg_id)
                            continue
                        batches.setdefault((sid, window_end), []).append((msg_id, payload))
                    except Exception:
                        log.exception("‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ PACK stream")

            # –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–æ–º–ø–ª–µ–∫—Ç—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º —Å–µ–º–∞—Ñ–æ—Ä–æ–º
            tasks = []
            for (sid, window_end), items in batches.items():
                # —Å–æ–±–∏—Ä–∞–µ–º –æ–∫–æ–Ω–Ω—ã–µ —Ç–µ–≥–∏ –∏–∑ –ø—Ä–∏—à–µ–¥—à–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π (–Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤—Å–µ 3)
                try:
                    tfs = sorted({str(item[1].get("time_frame")) for item in items if item[1].get("time_frame")})
                except Exception:
                    tfs = []
                tasks.append(_process_window_batch_guard(sem, items, sid, window_end, tfs))

            if tasks:
                await asyncio.gather(*tasks)

        except asyncio.CancelledError:
            log.debug("‚èπÔ∏è –í–æ—Ä–∫–µ—Ä PACK-confidence –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ —Å–∏–≥–Ω–∞–ª—É")
            raise
        except Exception:
            log.exception("‚ùå –û—à–∏–±–∫–∞ —Ü–∏–∫–ª–∞ PACK-confidence ‚Äî –ø–∞—É–∑–∞ 5 —Å–µ–∫—É–Ω–¥")
            await asyncio.sleep(5)


# —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏ + —Å–µ–º–∞—Ñ–æ—Ä
async def _process_window_batch_guard(sem: asyncio.Semaphore, items: List[Tuple[str, dict]], strategy_id: int, window_end_iso: str, tfs: List[str]):
    async with sem:
        try:
            await _process_window_batch(items, strategy_id, window_end_iso, tfs)
        except Exception:
            log.exception("‚ùå –°–±–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–º–ø–ª–µ–∫—Ç–∞ sid=%s window_end=%s", strategy_id, window_end_iso)


# üî∏ –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –∫–æ–º–ø–ª–µ–∫—Ç–∞ (–∫–ª—é—á = strategy_id + window_end)
async def _process_window_batch(items: List[Tuple[str, dict]], strategy_id: int, window_end_iso: str, tfs_from_msgs: List[str]):
    # –ø—Ä–∏–≤–µ—Å—Ç–∏ ISO-—Å—Ç—Ä–æ–∫—É –∫ datetime (UTC-naive)
    try:
        window_end_dt = datetime.fromisoformat(window_end_iso.replace("Z", ""))
    except Exception:
        log.exception("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç window_end: %r", window_end_iso)
        # ACK –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∫–æ–º–ø–ª–µ–∫—Ç–∞, —á—Ç–æ–±—ã –Ω–µ –∑–∞–≤–∏—Å–∞–ª–∏
        await infra.redis_client.xack(PACK_REPORT_STREAM, PACK_CONSUMER_GROUP, *[mid for (mid, _) in items])
        return

    async with infra.pg_pool.acquire() as conn:
        # –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–º–ø–ª–µ–∫—Ç 7d/14d/28d –≥–æ—Ç–æ–≤
        rows = await conn.fetch(
            """
            SELECT id, time_frame, created_at
            FROM oracle_report_stat
            WHERE strategy_id = $1
              AND window_end  = $2
              AND time_frame IN ('7d','14d','28d')
            """,
            int(strategy_id), window_end_dt
        )
        if len(rows) < 3:
            # –Ω–µ –≥–æ—Ç–æ–≤ –∫–æ–º–ø–ª–µ–∫—Ç ‚Äî ACK –≤—Å—ë –∏ –≤—ã–π—Ç–∏
            await infra.redis_client.xack(PACK_REPORT_STREAM, PACK_CONSUMER_GROUP, *[mid for (mid, _) in items])
            log.debug("‚åõ PACK –∫–æ–º–ø–ª–µ–∫—Ç –Ω–µ –≥–æ—Ç–æ–≤: sid=%s window_end=%s (–Ω–∞—à–ª–∏ %d –∏–∑ 3)", strategy_id, window_end_iso, len(rows))
            return

        # –∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å: –µ—Å–ª–∏ —É–∂–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–ª–∏ —ç—Ç–æ—Ç –∫–æ–º–ø–ª–µ–∫—Ç ‚Äî ACK –∏ –≤—ã—Ö–æ–¥–∏–º
        inserted = await conn.fetchrow(
            """
            INSERT INTO oracle_pack_conf_processed (strategy_id, window_end)
            VALUES ($1, $2)
            ON CONFLICT DO NOTHING
            RETURNING 1
            """,
            int(strategy_id), window_end_dt
        )
        if not inserted:
            await infra.redis_client.xack(PACK_REPORT_STREAM, PACK_CONSUMER_GROUP, *[mid for (mid, _) in items])
            log.debug("‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫ PACK –∫–æ–º–ø–ª–µ–∫—Ç–∞: —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω (sid=%s window_end=%s)", strategy_id, window_end_iso)
            return

        # —Ç—Ä–∏ report_id –ø–æ –æ–∫–Ω–∞–º
        report_ids: Dict[str, int] = {str(r["time_frame"]): int(r["id"]) for r in rows}  # {'7d': id7, '14d': id14, '28d': id28}

        # –≤ –≤–µ—Ä—Ö–Ω–µ–π —á–∞—Å—Ç–∏ ‚Äî –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤ –Ω–∞ –≤—Ä–µ–º—è –±–∞—Ç—á–∞ (—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å)
        weights_by_tf: Dict[str, Tuple[Dict[str, float], Dict]] = {}
        for tf in ("7d", "14d", "28d"):
            w, o = await _get_active_weights_pack(conn, strategy_id, tf)
            weights_by_tf[tf] = (w, o)

        # –∑–∞–±—Ä–∞—Ç—å –í–°–ï –∞–≥—Ä–µ–≥–∞—Ç—ã –ø–æ —Ç—Ä—ë–º –æ—Ç—á—ë—Ç–∞–º –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º
        agg_rows = await conn.fetch(
            """
            SELECT
              a.id,
              a.report_id,
              a.strategy_id,
              a.time_frame,
              a.direction,
              a.timeframe,
              a.pack_base,
              a.agg_type,
              a.agg_key,
              a.agg_value,
              a.trades_total,
              a.trades_wins,
              a.winrate,
              a.avg_pnl_per_trade,
              r.created_at AS report_created_at
            FROM oracle_pack_aggregated_stat a
            JOIN oracle_report_stat r ON r.id = a.report_id
            WHERE a.report_id = ANY($1::bigint[])
            """,
            list(report_ids.values())
        )
        if not agg_rows:
            await infra.redis_client.xack(PACK_REPORT_STREAM, PACK_CONSUMER_GROUP, *[mid for (mid, _) in items])
            log.debug("‚ÑπÔ∏è –ù–µ—Ç PACK-–∞–≥—Ä–µ–≥–∞—Ç–æ–≤ –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Ç–∞: sid=%s window_end=%s", strategy_id, window_end_iso)
            return

        # –ø–æ–¥–≥–æ—Ç–æ–≤–∏–º –∫–æ–≥–æ—Ä—Ç—ã: –∫–ª—é—á –∫–æ–≥–æ—Ä—Ç—ã = –±–µ–∑ agg_value, + report_created_at
        # (strategy_id, time_frame, direction, timeframe, pack_base, agg_type, agg_key, report_created_at)
        cohort_keys: List[Tuple] = []
        for r in agg_rows:
            cohort_keys.append((
                r["strategy_id"], r["time_frame"], r["direction"], r["timeframe"],
                r["pack_base"], r["agg_type"], r["agg_key"], r["report_created_at"]
            ))
        cohort_keys = list({ck for ck in cohort_keys})  # —É–Ω–∏–∫–∞–ª–∏–∑–∏—Ä—É–µ–º

        # –∑–∞–≥—Ä—É–∑–∏–º –≤—Å–µ –∫–æ–≥–æ—Ä—Ç—ã –±–∞—Ç—á–∞–º–∏ (—á—Ç–æ–±—ã –Ω–µ —Å—Ç—Ä–µ–ª—è—Ç—å –ø–æ –æ–¥–Ω–æ–π)
        cohort_cache: Dict[Tuple, List[dict]] = {}
        if cohort_keys:
            BATCH = 200
            for i in range(0, len(cohort_keys), BATCH):
                chunk = cohort_keys[i:i+BATCH]

                # –ø–æ–¥–≥–æ—Ç–æ–≤–∏–º —Å—Ç–æ–ª–±—Ü—ã –∫–∞–∫ –º–∞—Å—Å–∏–≤—ã –¥–ª—è UNNEST
                sid_a       = [ck[0] for ck in chunk]            # int[]
                tf_a        = [ck[1] for ck in chunk]            # text[]
                dir_a       = [ck[2] for ck in chunk]            # text[]
                timeframe_a = [ck[3] for ck in chunk]            # text[]
                pbase_a     = [ck[4] for ck in chunk]            # text[]
                atype_a     = [ck[5] for ck in chunk]            # text[]
                akey_a      = [ck[6] for ck in chunk]            # text[]
                rcat_a      = [ck[7] for ck in chunk]            # timestamp[]

                rows_coh = await conn.fetch(
                    """
                    WITH keys AS (
                      SELECT
                        unnest($1::int[])        AS k_sid,
                        unnest($2::text[])       AS k_tf,
                        unnest($3::text[])       AS k_dir,
                        unnest($4::text[])       AS k_timeframe,
                        unnest($5::text[])       AS k_pbase,
                        unnest($6::text[])       AS k_atype,
                        unnest($7::text[])       AS k_akey,
                        unnest($8::timestamp[])  AS k_rcat
                    )
                    SELECT
                      v.strategy_id, v.time_frame, v.direction, v.timeframe,
                      v.pack_base, v.agg_type, v.agg_key, v.report_created_at,
                      v.id, v.trades_total, v.trades_wins, v.winrate, v.avg_pnl_per_trade
                    FROM v_pack_aggregated_with_time v
                    JOIN keys k ON
                         v.strategy_id       = k.k_sid
                     AND v.time_frame        = k.k_tf
                     AND v.direction         = k.k_dir
                     AND v.timeframe         = k.k_timeframe
                     AND v.pack_base         = k.k_pbase
                     AND v.agg_type          = k.k_atype
                     AND v.agg_key           = k.k_akey
                     AND v.report_created_at = k.k_rcat
                    """,
                    sid_a, tf_a, dir_a, timeframe_a, pbase_a, atype_a, akey_a, rcat_a
                )

                for rr in rows_coh:
                    ck = (
                        rr["strategy_id"], rr["time_frame"], rr["direction"], rr["timeframe"],
                        rr["pack_base"], rr["agg_type"], rr["agg_key"], rr["report_created_at"]
                    )
                    cohort_cache.setdefault(ck, []).append(dict(rr))

        # –ø–æ–¥–≥–æ—Ç–æ–≤–∏–º persistence-–º–∞—Ç—Ä–∏—Ü—ã (–ø–æ—Å–ª–µ–¥–Ω–∏–µ L –æ—Ç—á—ë—Ç–æ–≤) –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–∫–Ω–∞
        # –∫–ª—é—á –¥–ª—è –º–∞—Ç—Ä–∏—Ü—ã: (direction,timeframe,pack_base,agg_type,agg_key,agg_value) ‚Üí —Å–ø–∏—Å–æ–∫ n –ø–æ –ø–æ—Å–ª–µ–¥–Ω–∏–º L –æ—Ç—á—ë—Ç–æ–≤
        persistence_by_tf: Dict[str, Dict[Tuple, List[int]]] = {}
        for tf in ("7d", "14d", "28d"):
            # –±–µ—Ä—ë–º created_at —Ç–µ–∫—É—â–µ–≥–æ –æ—Ç—á—ë—Ç–∞ —ç—Ç–æ–≥–æ –æ–∫–Ω–∞ (–æ–Ω–∏ —Ä–∞–∑–Ω—ã–µ)
            rep_created = None
            for r in rows:
                if str(r["time_frame"]) == tf:
                    rep_created = r["created_at"]
                    break
            if not rep_created:
                persistence_by_tf[tf] = {}
                continue
            L = int(WINDOW_STEPS.get(tf, 42))
            persistence_by_tf[tf] = await _persistence_matrix_pack(conn, strategy_id, tf, rep_created, L)

        # —Å–≥—Ä—É–ø–ø–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫–∏ –ø–æ –∫–ª—é—á—É –¥–ª—è C (–∫—Ä–æ—Å—Å-–æ–∫–æ–Ω–Ω–∞—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å)
        # –∫–ª—é—á C: (strategy_id, direction, timeframe, pack_base, agg_type, agg_key, agg_value)
        rows_by_key: Dict[Tuple, List[dict]] = {}
        agg_list = [dict(r) for r in agg_rows]
        for r in agg_list:
            kC = (
                r["strategy_id"], r["direction"], r["timeframe"],
                r["pack_base"], r["agg_type"], r["agg_key"], r["agg_value"]
            )
            rows_by_key.setdefault(kC, []).append(r)

        # –æ–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Å: —Å–æ–±–∏—Ä–∞–µ–º –±–∞—Ç—á –¥–ª—è UPDATE
        ids, confs, inputs = [], [], []
        updated_per_report: Dict[int, int] = {rid: 0 for rid in report_ids.values()}

        for r in agg_list:
            n = int(r["trades_total"] or 0)
            w = int(r["trades_wins"] or 0)
            wr = float(r["winrate"] or 0.0)

            # –≤–µ—Å–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –æ–∫–Ω–∞ —Å—Ç—Ä–æ–∫–∏
            weights, opts = weights_by_tf.get(str(r["time_frame"]), ({"wR": 0.4, "wP": 0.25, "wC": 0.2, "wS": 0.15}, {"baseline_mode": "neutral"}))

            # R
            R = _wilson_lower_bound(w, n, Z) if n > 0 else 0.0

            # P ‚Äî –∏–∑ –º–∞—Ç—Ä–∏—Ü—ã –ø–æ –æ–∫–Ω—É —Å—Ç—Ä–æ–∫–∏
            L = int(WINDOW_STEPS.get(str(r["time_frame"]), 42))
            keyP = (r["direction"], r["timeframe"], r["pack_base"], r["agg_type"], r["agg_key"], r["agg_value"])
            hist_n = persistence_by_tf.get(str(r["time_frame"]), {}).get(keyP, [])
            present_flags = [1 if v is not None and int(v) > 0 else 0 for v in hist_n]
            L_eff = len(present_flags)
            presence_rate = (sum(present_flags) / L_eff) if L_eff > 0 else 0.0
            growth_hist = _ecdf_rank(int(n), [int(v) for v in hist_n if v is not None]) if hist_n else 0.0
            P = 0.6 * presence_rate + 0.4 * growth_hist

            # C ‚Äî –∏–∑ rows_by_key (–ø–æ —Ç—Ä—ë–º –æ–∫–Ω–∞–º)
            C = _coherence_from_rows(rows_by_key.get((
                r["strategy_id"], r["direction"], r["timeframe"],
                r["pack_base"], r["agg_type"], r["agg_key"], r["agg_value"]
            ), []))

            # S ‚Äî —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –ø–æ –∫–æ–≥–æ—Ä—Ç–µ (–≤—Å–µ agg_value –≤ —ç—Ç–æ–π –æ—Å–∏ –Ω–∞ –æ–¥–Ω–æ–º report_created_at), –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è —à–∫–∞–ª–∞
            cohort_key = (
                r["strategy_id"], r["time_frame"], r["direction"], r["timeframe"],
                r["pack_base"], r["agg_type"], r["agg_key"], r["report_created_at"]
            )
            cohort_rows = cohort_cache.get(cohort_key, [])
            S, _hist_len, dyn_meta = _stability_key_dynamic_pack(r, L, cohort_rows)

            # –º–∞—Å—Å–∞ / N_effect (–∫–∞–∫ –≤ MW)
            cohort_n = [int(x["trades_total"] or 0) for x in cohort_rows]
            ecdf_cohort = _ecdf_rank(n, cohort_n) if cohort_n else 0.0
            # –∏—Å—Ç–æ—Ä–∏—è n –¥–ª—è —ç—Ç–æ–≥–æ –∫–ª—é—á–∞ (–¥–ª—è —Å–º–µ—à–∏–≤–∞–Ω–∏—è –ø—Ä–∏ –º–∞–ª–æ–π –∫–æ–≥–æ—Ä—Ç–µ)
            ecdf_hist = _ecdf_rank(n, [int(v) for v in hist_n]) if hist_n else 0.0
            if len(cohort_n) < 5:
                N_effect = 0.5 * ecdf_cohort + 0.5 * ecdf_hist
            else:
                N_effect = ecdf_cohort
            floor = 1.0 / float(max(2, len(cohort_n)) + 1)
            N_effect = max(N_effect, floor)
            N_effect = float(max(0.0, min(1.0, N_effect)))
            n_pos = [v for v in cohort_n if v > 0]
            n_med = _median([float(v) for v in n_pos]) if n_pos else 1.0
            abs_mass = math.sqrt(n / (n + n_med)) if (n_med > 0 and n >= 0) else 0.0
            N_effect = float(max(0.0, min(1.0, N_effect * abs_mass)))

            # –≤–µ—Å–∞
            wR = float(weights.get("wR", 0.4))
            wP = float(weights.get("wP", 0.25))
            wC = float(weights.get("wC", 0.2))
            wS = float(weights.get("wS", 0.15))

            raw = wR * R + wP * P + wC * C + wS * S
            confidence = round(max(0.0, min(1.0, raw * N_effect)), 4)

            inputs_json = {
                "R": round(R, 6),
                "P": round(P, 6),
                "C": round(C, 6),
                "S": round(S, 6),
                "N_effect": round(N_effect, 6),
                "weights": {"wR": wR, "wP": wP, "wC": wC, "wS": wS},
                "n": n,
                "wins": w,
                "wr": round(wr, 6),
                "presence_rate": round(presence_rate, 6),
                "growth_hist": round(growth_hist, 6),
                "hist_points": len(hist_n),
                "dyn_scale_used": dyn_meta,
                "baseline_wr": BASELINE_WR,
                "window_end": window_end_iso,
                "formula": "(wR*R + wP*P + wC*C + wS*S) * N_effect",
            }

            ids.append(int(r["id"]))
            confs.append(float(confidence))
            inputs.append(json.dumps(inputs_json, separators=(",", ":")))
            updated_per_report[int(r["report_id"])] = updated_per_report.get(int(r["report_id"]), 0) + 1

        # –ø–∞–∫–µ—Ç–Ω—ã–π UPDATE (executemany) ‚Äî –±—ã—Å—Ç—Ä–æ –∏ –ø—Ä–æ—Å—Ç–æ
        if ids:
            await conn.executemany(
                """
                UPDATE oracle_pack_aggregated_stat
                   SET confidence = $2,
                       confidence_inputs = $3,
                       confidence_updated_at = now()
                 WHERE id = $1
                """,
                list(zip(ids, confs, inputs))
            )

        # –ª–æ–≥
        log.info(
            "‚úÖ PACK-confidence –æ–±–Ω–æ–≤–ª—ë–Ω: sid=%s window_end=%s rows_total=%d rows_7d=%d rows_14d=%d rows_28d=%d",
            strategy_id,
            window_end_iso,
            len(ids),
            updated_per_report.get(report_ids.get("7d", -1), 0),
            updated_per_report.get(report_ids.get("14d", -1), 0),
            updated_per_report.get(report_ids.get("28d", -1), 0),
        )

        # –ø—É–±–ª–∏–∫—É–µ–º –¢–†–ò —Å–æ–±—ã—Ç–∏—è ‚Äî –ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ –∫–∞–∂–¥—ã–π –æ—Ç—á—ë—Ç (–¥–ª—è –±—É–¥—É—â–µ–≥–æ sense-–≤–æ—Ä–∫–µ—Ä–∞)
        try:
            for tf in ("7d", "14d", "28d"):
                rid = report_ids[tf]
                _rows = updated_per_report.get(rid, 0)
                payload = {
                    "report_id": int(rid),
                    "strategy_id": int(strategy_id),
                    "time_frame": tf,
                    "window_end": window_end_iso,
                    "generated_at": datetime.utcnow().replace(tzinfo=None).isoformat(),
                    "aggregate_rows": int(_rows),
                }
                await infra.redis_client.xadd(
                    name=PACK_SENSE_REPORT_READY_STREAM,
                    fields={"data": json.dumps(payload, separators=(",", ":"))},
                    maxlen=PACK_SENSE_REPORT_READY_MAXLEN,
                    approximate=True,
                )
            log.debug("[PACK_SENSE_REPORT_READY] sid=%s window_end=%s done", strategy_id, window_end_iso)
        except Exception:
            log.exception("‚ùå –û—à–∏–±–∫–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ —Å–æ–±—ã—Ç–∏–π –≤ %s", PACK_SENSE_REPORT_READY_STREAM)

        # ACK –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∫–æ–º–ø–ª–µ–∫—Ç–∞
        await infra.redis_client.xack(PACK_REPORT_STREAM, PACK_CONSUMER_GROUP, *[mid for (mid, _) in items])


# üî∏ –ó–∞–≥—Ä—É–∑–∫–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö –≤–µ—Å–æ–≤ –¥–ª—è PACK (—Å –ø—Ä–æ—Å—Ç—ã–º –∫—ç—à–µ–º; —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–∞–∫ —É MW)
async def _get_active_weights_pack(conn, strategy_id: int, time_frame: str) -> Tuple[Dict[str, float], Dict]:
    now = time.time()

    # –ø–æ–ø—ã—Ç–∫–∏ –∏–∑ –∫—ç—à–∞
    for key in [(strategy_id, time_frame), (strategy_id, None), (None, None)]:
        w = _weights_cache.get(key)
        if w and (now - w[2] < WEIGHTS_TTL_SEC):
            return w[0], w[1]

    row = await conn.fetchrow(
        """
        SELECT weights, COALESCE(opts,'{}'::jsonb) AS opts
          FROM oracle_pack_conf_model
         WHERE is_active = true
           AND (
                 (strategy_id = $1 AND time_frame = $2)
              OR (strategy_id = $1 AND time_frame IS NULL)
              OR (strategy_id IS NULL AND time_frame IS NULL)
           )
         ORDER BY
           CASE WHEN strategy_id = $1 AND time_frame = $2 THEN 1
                WHEN strategy_id = $1 AND time_frame IS NULL THEN 2
                ELSE 3 END,
           created_at DESC
         LIMIT 1
        """,
        strategy_id, time_frame
    )

    defaults_w = {"wR": 0.4, "wP": 0.25, "wC": 0.2, "wS": 0.15}
    defaults_o = {"baseline_mode": "neutral"}

    def _parse_json_like(x, default):
        if isinstance(x, dict):
            return x
        if isinstance(x, (bytes, bytearray, memoryview)):
            try:
                return json.loads(bytes(x).decode("utf-8"))
            except Exception:
                log.exception("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –∏–∑ bytes/memoryview")
                return default
        if isinstance(x, str):
            try:
                return json.loads(x)
            except Exception:
                log.exception("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –∏–∑ —Å—Ç—Ä–æ–∫–∏")
                return default
        return default

    if row:
        raw_w = row["weights"]; raw_o = row["opts"]
        weights = _parse_json_like(raw_w, defaults_w)
        opts = _parse_json_like(raw_o, defaults_o)
    else:
        weights = defaults_w
        opts = defaults_o

    # –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∏ –º—è–≥–∫–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è (–∫–∞–∫ –≤ MW)
    wR = float(weights.get("wR", defaults_w["wR"]))
    wP = float(weights.get("wP", defaults_w["wP"]))
    wC = float(weights.get("wC", defaults_w["wC"]))
    wS = float(weights.get("wS", defaults_w["wS"]))

    wC = min(wC, 0.35)
    wR = max(wR, 0.25)

    total = wR + wP + wC + wS
    if not math.isfinite(total) or total <= 0:
        wR, wP, wC, wS = defaults_w["wR"], defaults_w["wP"], defaults_w["wC"], defaults_w["wS"]
        total = wR + wP + wC + wS

    wR, wP, wC, wS = (wR / total, wP / total, wC / total, wS / total)
    weights_norm = {"wR": wR, "wP": wP, "wC": wC, "wS": wS}

    ts = time.time()
    _weights_cache[(strategy_id, time_frame)] = (weights_norm, opts, ts)
    _weights_cache[(strategy_id, None)] = (weights_norm, opts, ts)
    _weights_cache[(None, None)] = (weights_norm, opts, ts)

    return weights_norm, opts


# üî∏ –ú–∞—Ç—Ä–∏—Ü–∞ persistence –¥–ª—è PACK: –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª—é—á–∞ ‚Üí —Å–ø–∏—Å–æ–∫ n –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ L –æ—Ç—á—ë—Ç–æ–≤ –¥–æ cutoff
async def _persistence_matrix_pack(conn, strategy_id: int, time_frame: str, cutoff_created_at, L: int) -> Dict[Tuple, List[Optional[int]]]:
    # –±–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ L –æ—Ç—á—ë—Ç–æ–≤ (id, created_at) –¥–æ –∏ –≤–∫–ª—é—á–∞—è cutoff
    last_reports = await conn.fetch(
        """
        SELECT id, created_at
        FROM oracle_report_stat
        WHERE strategy_id = $1
          AND time_frame  = $2
          AND created_at <= $3
        ORDER BY created_at DESC
        LIMIT $4
        """,
        int(strategy_id), str(time_frame), cutoff_created_at, int(L)
    )
    if not last_reports:
        return {}

    rep_ids = [int(r["id"]) for r in last_reports]
    # –≤—ã–±–æ—Ä–∫–∞ –≤—Å–µ—Ö trades_total –¥–ª—è —ç—Ç–∏—Ö –æ—Ç—á—ë—Ç–æ–≤ –æ–¥–Ω–∏–º –∫–æ–≤—Ä–æ–º
    rows = await conn.fetch(
        """
        SELECT
          a.report_id,
          a.direction, a.timeframe, a.pack_base, a.agg_type, a.agg_key, a.agg_value,
          a.trades_total
        FROM oracle_pack_aggregated_stat a
        WHERE a.report_id = ANY($1::bigint[])
          AND a.strategy_id = $2
        """,
        rep_ids, int(strategy_id)
    )

    # —É–ø–æ—Ä—è–¥–æ—á–∏–º –æ—Ç—á—ë—Ç—ã –ø–æ created_at (DESC –≤ last_reports)
    rep_order = {int(r["id"]): idx for idx, r in enumerate(last_reports)}  # 0 ‚Äî —Å–∞–º—ã–π —Å–≤–µ–∂–∏–π

    # —Å–æ–±–∏—Ä–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É —Å–ø–∏—Å–∫–æ–≤ –¥–ª–∏–Ω–æ–π L (–º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ–Ω—å—à–µ, –µ—Å–ª–∏ –º–∞–ª–æ –æ—Ç—á—ë—Ç–æ–≤)
    mat: Dict[Tuple, List[Optional[int]]] = {}
    for r in rows:
        key = (r["direction"], r["timeframe"], r["pack_base"], r["agg_type"], r["agg_key"], r["agg_value"])
        arr = mat.setdefault(key, [None] * len(last_reports))
        pos = rep_order.get(int(r["report_id"]))
        if pos is not None:
            arr[pos] = int(r["trades_total"] or 0)

    return mat


# üî∏ Coherence C –∏–∑ –Ω–∞–±–æ—Ä–∞ —Å—Ç—Ä–æ–∫ (3 –æ–∫–Ω–∞) –ø–æ –æ–¥–Ω–æ–º—É –∫–ª—é—á—É
def _coherence_from_rows(rows: List[dict]) -> float:
    if not rows:
        return 0.0
    signs: List[int] = []
    weights: List[float] = []
    for r in rows:
        n = int(r["trades_total"] or 0)
        w = int(r["trades_wins"] or 0)
        if n <= 0:
            continue
        lb, ub = _wilson_bounds(w, n, Z)
        if lb > BASELINE_WR:
            dist = max(lb - BASELINE_WR, ub - BASELINE_WR)
            if dist > 0:
                signs.append(+1); weights.append(dist)
        elif ub < BASELINE_WR:
            dist = max(BASELINE_WR - lb, BASELINE_WR - ub)
            if dist > 0:
                signs.append(-1); weights.append(dist)
    total_weight = sum(weights)
    if total_weight <= 0.0 or len(weights) < 2:
        return 0.0
    signed_weight = sum(s * w for s, w in zip(signs, weights))
    C = abs(signed_weight) / total_weight
    return float(max(0.0, min(1.0, C)))


# üî∏ Stability S –¥–ª—è PACK (robust z –≤–æ–∫—Ä—É–≥ –º–µ–¥–∏–∞–Ω—ã –∫–æ–≥–æ—Ä—Ç—ã)
def _stability_key_dynamic_pack(row: dict, L: int, cohort_rows: List[dict]) -> Tuple[float, int, dict]:
    # –∏—Å—Ç–æ—Ä–∏—è winrate –ø–æ —ç—Ç–æ–º—É –∂–µ –∫–ª—é—á—É –¥–æ —Ç–µ–∫—É—â–µ–≥–æ report_created_at (—á–µ—Ä–µ–∑ cohort_rows ‚Äî —É–∂–µ –Ω–∞ —Ç–µ–∫—É—â–µ–º –æ—Ç—á—ë—Ç–µ)
    wr_hist = [float(r.get("winrate") or 0.0) for r in cohort_rows]
    wr_now = float(row.get("winrate") or 0.0)
    if len(wr_hist) < 2:
        return 1.0, len(wr_hist), {"mode": "short_hist", "scale": None}

    med = _median(wr_hist)
    mad = _mad(wr_hist, med)
    iqr = _iqr(wr_hist)

    # cohort MAD –ø–æ —Ç–æ–π –∂–µ –∫–æ–≥–æ—Ä—Ç–µ (–µ—Å–ª–∏ –µ—Å—Ç—å —Å–º—ã—Å–ª)
    cohort_mad = _mad(wr_hist, med) if len(wr_hist) >= 3 else 0.0

    cand = []
    if mad > 0:
        cand.append(mad / 0.6745)
    if iqr > 0:
        cand.append(iqr / 1.349)
    if cohort_mad > 0:
        cand.append(cohort_mad / 0.6745)

    n_hist = len(wr_hist)
    cand.append(1.0 / math.sqrt(max(1.0, float(n_hist))))

    if all(c <= 0 for c in cand[:-1]) and abs(wr_now - med) < 1e-12:
        return 1.0, n_hist, {"mode": "flat_hist", "scale": 0.0}

    scale = max(cand) if cand else 1e-6
    z = abs(wr_now - med) / (scale + 1e-12)
    S_key = 1.0 / (1.0 + z)

    return S_key, n_hist, {"mode": "dynamic", "scale": round(scale, 6), "median": round(med, 6)}