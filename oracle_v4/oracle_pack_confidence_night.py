# oracle_pack_confidence_night.py ‚Äî –Ω–æ—á–Ω–æ–π —Ç—é–Ω–µ—Ä PACK: –∞–≤—Ç–æ–∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ –≤–µ—Å–æ–≤ (wR,wP,wC,wS) per-strategy/per-window —Ä–∞–∑ –≤ —Å—É—Ç–∫–∏

# üî∏ –ò–º–ø–æ—Ä—Ç—ã
import asyncio
import logging
from typing import Dict, List, Tuple, Optional
import math
import time
import json

import infra
# üî∏ –±–∞–∑–æ–≤—ã–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã/—É—Ç–∏–ª–∏—Ç—ã –±–µ—Ä—ë–º –∏–∑ MW-–∫–æ–Ω—Ñ–∏–¥–µ–Ω—Å–∞ (—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã)
from oracle_mw_confidence import (
    WINDOW_STEPS, Z, BASELINE_WR,
    _wilson_lower_bound, _wilson_bounds,
    _ecdf_rank, _median, _mad, _iqr,
)
# üî∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å S –¥–ª—è PACK –±–µ—Ä—ë–º –∏–∑ —Ä–∞–Ω—Ç–∞–π–º-–≤–æ—Ä–∫–µ—Ä–∞ PACK-confidence
from oracle_pack_confidence import _stability_key_dynamic_pack

# üî∏ –õ–æ–≥–≥–µ—Ä
log = logging.getLogger("ORACLE_PACK_CONFIDENCE_NIGHT")

# üî∏ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—É—Å–∫–∞ –≤–æ—Ä–∫–µ—Ä–∞ (–∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ run_periodic –≤ oracle_v4_main)
INITIAL_DELAY_H = 25        # –ø–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ 24 —á–∞—Å–∞ –ø–æ—Å–ª–µ —Å—Ç–∞—Ä—Ç–∞ —Å–µ—Ä–≤–∏—Å–∞
INTERVAL_H      = 24        # –∑–∞—Ç–µ–º —Ä–∞–∑ –≤ 24 —á–∞—Å–∞

# üî∏ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è/–æ—Ç–±–æ—Ä–∞
MIN_SAMPLES_PER_STRATEGY = 200     # –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Å—Ç—Ä–æ–∫-–æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é/–æ–∫–Ω–æ
HOLDOUT_FRACTION         = 0.15    # –¥–æ–ª—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö ¬´–ø–∞—Ä –æ—Ç—á—ë—Ç–æ–≤¬ª –Ω–∞ holdout-–ø—Ä–æ–≤–µ—Ä–∫—É (–ø–æ –≤—Ä–µ–º–µ–Ω–∏)
WEIGHT_CLIP_MIN          = 0.05    # –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
WEIGHT_CLIP_MAX          = 0.35    # –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (–∂—ë—Å—Ç–∫–æ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º, —á—Ç–æ–±—ã C –Ω–µ –¥–æ–º–∏–Ω–∏—Ä–æ–≤–∞–ª)
WEIGHTS_TOLERANCE        = 1e-9    # –∑–∞—â–∏—Ç–∞ –æ—Ç –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å –ø—Ä–∏ –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–µ


# üî∏ –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –≤–æ—Ä–∫–µ—Ä–∞ (–≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –∏–∑ oracle_v4_main ‚Üí run_periodic(...))
async def run_oracle_pack_confidence_night():
    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏
    if infra.pg_pool is None:
        log.debug("‚ùå –ü—Ä–æ–ø—É—Å–∫ –Ω–æ—á–Ω–æ–≥–æ PACK-—Ç—é–Ω–µ—Ä–∞: –Ω–µ—Ç PG-–ø—É–ª–∞")
        return

    # —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –¥–ª—è —Ç—é–Ω–∏–Ω–≥–∞ (–∞–∫—Ç–∏–≤–Ω—ã–µ –∏ market_watcher=true)
    strategies = await _load_target_strategies()
    if not strategies:
        log.debug("‚ÑπÔ∏è –ù–µ—á–µ–≥–æ —Ç—é–Ω–∏—Ç—å: –Ω–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏–π —Å market_watcher=true")
        return

    # –ø–µ—Ä–µ–±–æ—Ä —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –∏ –æ–∫–æ–Ω (7d/14d/28d)
    updated_total = 0
    async with infra.pg_pool.acquire() as conn:
        for sid in strategies:
            for tf in ("7d", "14d", "28d"):
                try:
                    ok = await _train_and_activate_weights_pack(conn, strategy_id=sid, time_frame=tf)
                    if ok:
                        updated_total += 1
                except Exception:
                    log.exception("‚ùå –û—à–∏–±–∫–∞ PACK-—Ç—é–Ω–∏–Ω–≥–∞ –≤–µ—Å–æ–≤: strategy_id=%s, time_frame=%s", sid, tf)

    log.info("‚úÖ –ù–æ—á–Ω–æ–π PACK-—Ç—é–Ω–µ—Ä –∑–∞–≤–µ—Ä—à—ë–Ω: –æ–±–Ω–æ–≤–ª–µ–Ω–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –≤–µ—Å–æ–≤ –¥–ª—è %d –ø–∞—Ä (strategy_id √ó time_frame)", updated_total)


# üî∏ –ó–∞–≥—Ä—É–∑–∫–∞ —Ü–µ–ª–µ–≤—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
async def _load_target_strategies() -> List[int]:
    async with infra.pg_pool.acquire() as conn:
        rows = await conn.fetch(
            """
            SELECT id
            FROM strategies_v4
            WHERE enabled = true
              AND (archived IS NOT TRUE)
              AND market_watcher = true
            """
        )
    return [int(r["id"]) for r in rows]


# üî∏ –û–±—É—á–µ–Ω–∏–µ –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏—è –≤–µ—Å–æ–≤ –¥–ª—è –æ–¥–Ω–æ–π –ø–∞—Ä—ã (strategy_id, time_frame) ‚Äî PACK
async def _train_and_activate_weights_pack(conn, strategy_id: int, time_frame: str) -> bool:
    # –Ω–∞–±–∏—Ä–∞–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –ø–∞—Ä—ã –æ—Ç—á—ë—Ç–æ–≤ (t, t+1), –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º—Å—è ~2*L –¥–ª—è —Å–≤–µ–∂–µ—Å—Ç–∏
    limit_reports = int(WINDOW_STEPS.get(time_frame, 42) * 2)
    reports = await conn.fetch(
        """
        SELECT id, created_at
        FROM oracle_report_stat
        WHERE strategy_id = $1 AND time_frame = $2 AND source = 'pack'
        ORDER BY created_at ASC
        LIMIT $3
        """,
        strategy_id, time_frame, limit_reports
    )
    if len(reports) < 3:
        log.debug("‚ÑπÔ∏è PACK strategy=%s tf=%s: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ—Ç—á—ë—Ç–æ–≤ (%d < 3)", strategy_id, time_frame, len(reports))
        return False

    # –ø–∞—Ä—ã (t, t+1)
    pairs: List[Tuple[Tuple[int, str], Tuple[int, str]]] = []
    for i in range(len(reports) - 1):
        pairs.append(
            ((int(reports[i]["id"]), str(reports[i]["created_at"])),
             (int(reports[i+1]["id"]), str(reports[i+1]["created_at"])))
        )

    # –¥–∞—Ç–∞—Å–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –º–µ—Ç–æ–∫
    X: List[Tuple[float, float, float, float]] = []  # (R,P,C,S)
    Y: List[int] = []

    # –∫—ç—à –∫–æ–≥–æ—Ä—Ç (–Ω–∞ —É—Ä–æ–≤–Ω–µ –æ–¥–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞)
    cohort_cache: Dict[Tuple, List[dict]] = {}

    for (rep_id_t, created_t), (rep_id_n, created_n) in pairs:
        # —Å—Ç—Ä–æ–∫–∏ –æ—Ç—á—ë—Ç–∞ T
        rows_t = await conn.fetch(
            """
            SELECT
              id, report_id, strategy_id, time_frame, direction, timeframe,
              pack_base, agg_type, agg_key, agg_value,
              trades_total, trades_wins, winrate, avg_pnl_per_trade, report_created_at
            FROM v_pack_aggregated_with_time
            WHERE report_id = $1
            """,
            rep_id_t
        )
        if not rows_t:
            continue

        # —Å—Ç—Ä–æ–∫–∏ –æ—Ç—á—ë—Ç–∞ T+1 (–¥–ª—è —Ü–µ–ª–µ–≤–æ–π –º–µ—Ç–∫–∏)
        rows_n = await conn.fetch(
            """
            SELECT
              id, report_id, strategy_id, time_frame, direction, timeframe,
              pack_base, agg_type, agg_key, agg_value,
              trades_total, trades_wins, winrate, report_created_at
            FROM v_pack_aggregated_with_time
            WHERE report_id = $1
            """,
            rep_id_n
        )
        key2row_n: Dict[Tuple, dict] = {}
        for rn in rows_n:
            kn = (rn["direction"], rn["timeframe"], rn["pack_base"], rn["agg_type"], rn["agg_key"], rn["agg_value"])
            key2row_n[kn] = dict(rn)

        # –Ω–∞—Ö–æ–¥–∏–º ¬´—Ç—Ä–æ–π–∫—É –æ—Ç—á—ë—Ç–æ–≤¬ª (7d/14d/28d) —Å —Ç–µ–º –∂–µ window_end, —á—Ç–æ —É T ‚Äî –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ C
        hdr_t = await conn.fetchrow(
            "SELECT strategy_id, window_end FROM oracle_report_stat WHERE id = $1",
            rep_id_t
        )
        trio_rows = await conn.fetch(
            """
            SELECT id, time_frame
            FROM oracle_report_stat
            WHERE strategy_id = $1
              AND window_end  = $2
              AND time_frame  IN ('7d','14d','28d')
              AND source = 'pack'
            """,
            int(hdr_t["strategy_id"]), hdr_t["window_end"]
        )
        trio_ids = {str(r["time_frame"]): int(r["id"]) for r in trio_rows}

        for rt in rows_t:
            row_t = dict(rt)
            key = (row_t["direction"], row_t["timeframe"], row_t["pack_base"], row_t["agg_type"], row_t["agg_key"], row_t["agg_value"])
            row_next = key2row_n.get(key)
            if not row_next:
                continue

            # –∫–æ–≥–æ—Ä—Ç–∞ –¥–ª—è T (–≤—Å–µ agg_value –≤–Ω—É—Ç—Ä–∏ –æ—Å–∏ –Ω–∞ –æ–¥–Ω–æ–º –æ—Ç—á—ë—Ç–µ)
            cohort_key = (
                row_t["strategy_id"], row_t["time_frame"], row_t["direction"], row_t["timeframe"],
                row_t["pack_base"], row_t["agg_type"], row_t["agg_key"], row_t["report_created_at"]
            )
            if cohort_key not in cohort_cache:
                cohort_cache[cohort_key] = await _fetch_pack_cohort(conn, row_t)

            # R (–Ω–∞ t)
            n_t = int(row_t["trades_total"] or 0)
            w_t = int(row_t["trades_wins"] or 0)
            R_t = _wilson_lower_bound(w_t, n_t, Z) if n_t > 0 else 0.0

            # P (–Ω–∞ t)
            L = int(WINDOW_STEPS.get(time_frame, 42))
            presence_rate_t, growth_hist_t = await _persistence_metrics_pack(conn, row_t, L)
            P_t = 0.6 * presence_rate_t + 0.4 * growth_hist_t

            # C (–Ω–∞ t) ‚Äî –ø–æ —Ç—Ä—ë–º –æ—Ç—á—ë—Ç–∞–º —Å —Ç–µ–º –∂–µ window_end; –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ <2 –æ–∫–æ–Ω ‚Äî C=0.0
            if len(trio_ids) >= 2:
                C_t = await _cross_window_coherence_by_ids_pack(conn, row_t, trio_ids)
            else:
                C_t = 0.0

            # S (–Ω–∞ t) ‚Äî —Ä–æ–±–∞—Å—Ç–Ω–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å wr
            S_t, _len_hist, _meta = _stability_key_dynamic_pack(row_t, L, cohort_cache[cohort_key])

            # —Ü–µ–ª–µ–≤–∞—è –º–µ—Ç–∫–∞ y: –æ–±–∞ –∑–Ω–∞–∫–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ baseline —É–≤–µ—Ä–µ–Ω–Ω—ã–µ –∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç
            y = _target_same_sign_next_pack(row_t, row_next)

            X.append((R_t, P_t, C_t, S_t))
            Y.append(y)

    samples = len(Y)
    if samples < MIN_SAMPLES_PER_STRATEGY:
        log.debug("‚ÑπÔ∏è PACK strategy=%s tf=%s: –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç—é–Ω–∏–Ω–≥–∞ (samples=%d < %d)",
                 strategy_id, time_frame, samples, MIN_SAMPLES_PER_STRATEGY)
        return False

    # —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ train/holdout –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ –ø–∞—Ä—ã ‚Äî holdout)
    holdout = max(1, int(samples * HOLDOUT_FRACTION))
    train = samples - holdout
    X_train, Y_train = X[:train], Y[:train]
    # X_hold, Y_hold = X[train:], Y[train:]  # —Ä–µ–∑–µ—Ä–≤ –ø–æ–¥ –º–µ—Ç—Ä–∏–∫—É, –µ—Å–ª–∏ –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è

    # –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (point-biserial corr)
    imp = _feature_importance_corr(X_train, Y_train)

    # –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–∞ + –∫–ª–∏–ø–ø–∏–Ω–≥ + –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–∞
    weights = _normalize_weights(imp, clip_min=WEIGHT_CLIP_MIN, clip_max=WEIGHT_CLIP_MAX)

    # –ø–æ–ª–∏—Ç–∏–∫–∞: –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–æ–ª—é R –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º C —Å–≤–µ—Ä—Ö—É
    min_R = 0.25
    max_C = 0.35
    wR = max(weights["wR"], min_R)
    wC = min(weights["wC"], max_C)
    wP = weights["wP"]
    wS = weights["wS"]
    s = wR + wP + wC + wS
    weights = {"wR": wR / s, "wP": wP / s, "wC": wC / s, "wS": wS / s}

    log.debug("üìä PACK-—Ç—é–Ω–∏–Ω–≥ strategy=%s tf=%s: samples=%d (train=%d, holdout=%d) ‚Üí weights=%s",
             strategy_id, time_frame, samples, train, holdout, weights)

    # –∞–∫—Ç–∏–≤–∏—Ä—É–µ–º –Ω–æ–≤—ã–µ –≤–µ—Å–∞ (–¥–µ–∞–∫—Ç–∏–≤–∏—Ä—É–µ–º —Å—Ç–∞—Ä—ã–µ –¥–ª—è –ø–∞—Ä—ã strategy/tf)
    await conn.execute(
        """
        UPDATE oracle_pack_conf_model
           SET is_active = false
         WHERE is_active = true
           AND COALESCE(strategy_id, -1) = $1
           AND COALESCE(time_frame, '') = $2
        """,
        int(strategy_id), str(time_frame)
    )
    await conn.execute(
        """
        INSERT INTO oracle_pack_conf_model (name, strategy_id, time_frame, weights, opts, is_active)
        VALUES ($1, $2, $3, $4::jsonb, $5::jsonb, true)
        """,
        f"pack_auto_{time.strftime('%Y%m%d_%H%M%S')}",
        int(strategy_id),
        str(time_frame),
        json.dumps(weights),
        '{"baseline_mode":"neutral"}',
    )
    log.info("‚úÖ –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω—ã –Ω–æ–≤—ã–µ PACK-–≤–µ—Å–∞ –¥–ª—è strategy=%s tf=%s: %s", strategy_id, time_frame, weights)
    return True


# üî∏ –ö–æ–≥–æ—Ä—Ç–∞ (PACK) –¥–ª—è –æ–¥–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞: –≤—Å–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –≤–Ω—É—Ç—Ä–∏ –æ—Å–∏, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è S/ECDF
async def _fetch_pack_cohort(conn, row: dict) -> List[dict]:
    rows = await conn.fetch(
        """
        SELECT id, trades_total, trades_wins, winrate, avg_pnl_per_trade
        FROM v_pack_aggregated_with_time
        WHERE strategy_id = $1
          AND time_frame  = $2
          AND direction   = $3
          AND timeframe   = $4
          AND pack_base   = $5
          AND agg_type    = $6
          AND agg_key     = $7
          AND report_created_at = $8
        """,
        row["strategy_id"], row["time_frame"], row["direction"], row["timeframe"],
        row["pack_base"], row["agg_type"], row["agg_key"], row["report_created_at"]
    )
    return [dict(x) for x in rows]


# üî∏ Persistence-–º–µ—Ç—Ä–∏–∫–∏ (PACK): presence_rate –∏ growth_hist
async def _persistence_metrics_pack(conn, row: dict, L: int) -> Tuple[float, float]:
    last_rows = await conn.fetch(
        """
        WITH last_reports AS (
          SELECT id, created_at
          FROM oracle_report_stat
          WHERE strategy_id = $1
            AND time_frame  = $2
            AND created_at <= $3
            AND source = 'pack'
          ORDER BY created_at DESC
          LIMIT $4
        )
        SELECT lr.created_at,
               a.trades_total
        FROM last_reports lr
        LEFT JOIN oracle_pack_aggregated_stat a
          ON a.report_id = lr.id
         AND a.strategy_id = $1
         AND a.time_frame  = $2
         AND a.direction   = $5
         AND a.timeframe   = $6
         AND a.pack_base   = $7
         AND a.agg_type    = $8
         AND a.agg_key     = $9
         AND a.agg_value   = $10
        ORDER BY lr.created_at DESC
        """,
        row["strategy_id"],
        row["time_frame"],
        row["report_created_at"],
        int(L),
        row["direction"],
        row["timeframe"],
        row["pack_base"],
        row["agg_type"],
        row["agg_key"],
        row["agg_value"],
    )

    present_flags = [1 if r["trades_total"] is not None and int(r["trades_total"]) > 0 else 0 for r in last_rows]
    L_eff = len(present_flags) if present_flags else 0
    presence_rate = (sum(present_flags) / L_eff) if L_eff > 0 else 0.0

    hist_n = [int(r["trades_total"]) for r in last_rows if r["trades_total"] is not None]
    growth_hist = _ecdf_rank(int(row["trades_total"] or 0), hist_n) if hist_n else 0.0

    return presence_rate, growth_hist


# üî∏ C –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –∫–æ–º–ø–ª–µ–∫—Ç—É report_id (7d/14d/28d) –¥–ª—è PACK-–∫–ª—é—á–∞ —Å—Ç—Ä–æ–∫–∏
async def _cross_window_coherence_by_ids_pack(conn, row: dict, report_ids: Dict[str, int]) -> float:
    rows = await conn.fetch(
        """
        SELECT a.time_frame, a.trades_total, a.trades_wins
        FROM oracle_pack_aggregated_stat a
        WHERE a.report_id = ANY($1::bigint[])
          AND a.strategy_id = $2
          AND a.direction   = $3
          AND a.timeframe   = $4
          AND a.pack_base   = $5
          AND a.agg_type    = $6
          AND a.agg_key     = $7
          AND a.agg_value   = $8
        """,
        list(report_ids.values()),
        row["strategy_id"], row["direction"], row["timeframe"],
        row["pack_base"], row["agg_type"], row["agg_key"], row["agg_value"]
    )
    if not rows:
        return 0.0

    signs: List[int] = []
    weights: List[float] = []

    for r in rows:
        n = int(r["trades_total"] or 0)
        w = int(r["trades_wins"] or 0)
        if n <= 0:
            continue
        lb, ub = _wilson_bounds(w, n, Z)
        if lb > BASELINE_WR:
            dist = max(lb - BASELINE_WR, ub - BASELINE_WR)
            if dist > 0:
                signs.append(+1); weights.append(dist)
        elif ub < BASELINE_WR:
            dist = max(BASELINE_WR - lb, BASELINE_WR - ub)
            if dist > 0:
                signs.append(-1); weights.append(dist)

    total_weight = sum(weights)
    if total_weight <= 0.0 or len(weights) < 2:
        return 0.0

    signed_weight = sum(s * w for s, w in zip(signs, weights))
    C = abs(signed_weight) / total_weight
    return float(max(0.0, min(1.0, C)))


# üî∏ –¶–µ–ª–µ–≤–∞—è –º–µ—Ç–∫–∞: ¬´–ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –∑–Ω–∞–∫–∞ wr –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ baseline¬ª –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–º –æ—Ç—á—ë—Ç–µ (PACK)
def _target_same_sign_next_pack(row_t: dict, row_next: dict) -> int:
    # –∑–Ω–∞–∫ –≤ t
    n_t = int(row_t["trades_total"] or 0); w_t = int(row_t["trades_wins"] or 0)
    lb_t, ub_t = _wilson_bounds(w_t, n_t, Z) if n_t > 0 else (0.0, 0.0)
    sign_t = 0
    if lb_t > BASELINE_WR:
        sign_t = +1
    elif ub_t < BASELINE_WR:
        sign_t = -1

    # –∑–Ω–∞–∫ –≤ t+1
    n_n = int(row_next["trades_total"] or 0); w_n = int(row_next["trades_wins"] or 0)
    lb_n, ub_n = _wilson_bounds(w_n, n_n, Z) if n_n > 0 else (0.0, 0.0)
    sign_n = 0
    if lb_n > BASELINE_WR:
        sign_n = +1
    elif ub_n < BASELINE_WR:
        sign_n = -1

    # —Ü–µ–ª–µ–≤–∞—è –ª–æ–≥–∏–∫–∞: –æ–±–∞ –∑–Ω–∞–∫–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å ¬´—É–≤–µ—Ä–µ–Ω–Ω—ã–º–∏¬ª –∏ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏
    if sign_t == 0 or sign_n == 0:
        return 0
    return 1 if (sign_t == sign_n) else 0


# üî∏ –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: point-biserial correlation (—É–ø—Ä–æ—â—ë–Ω–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ü–∏—Ä—Å–æ–Ω–∞ —Å –±–∏–Ω–∞—Ä–Ω–æ–π –º–µ—Ç–∫–æ–π)
def _feature_importance_corr(X: List[Tuple[float, float, float, float]], Y: List[int]) -> Dict[str, float]:
    if not X or not Y or len(X) != len(Y):
        return {"wR": 0.25, "wP": 0.25, "wC": 0.25, "wS": 0.25}

    n = len(Y)
    mean_y = sum(Y) / n if n > 0 else 0.0

    # –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä—ã –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º
    sums = [0.0, 0.0, 0.0, 0.0]
    sums2 = [0.0, 0.0, 0.0, 0.0]
    covs = [0.0, 0.0, 0.0, 0.0]

    for i in range(n):
        xi = X[i]
        yi = Y[i]
        for j in range(4):
            x = float(xi[j])
            sums[j] += x
            sums2[j] += x * x
            covs[j] += x * yi

    imps: List[float] = []
    for j in range(4):
        mean_x = sums[j] / n
        var_x = max(0.0, (sums2[j] / n) - (mean_x * mean_x))
        std_x = math.sqrt(var_x)
        cov_xy = (covs[j] / n) - (mean_x * mean_y)
        std_y = math.sqrt(max(1e-12, mean_y * (1.0 - mean_y)))  # –¥–∏—Å–ø–µ—Ä—Å–∏—è –±–∏–Ω–∞—Ä–Ω–æ–π –º–µ—Ç–∫–∏ p(1-p)
        corr = 0.0 if std_x < 1e-12 else (cov_xy / (std_x * std_y))
        imps.append(abs(corr))

    return {"wR": imps[0], "wP": imps[1], "wC": imps[2], "wS": imps[3]}


# üî∏ –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∫–ª–∏–ø–ø–∏–Ω–≥ –≤–µ—Å–æ–≤ (—Å –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–æ–π)
def _normalize_weights(imp: Dict[str, float], clip_min: float, clip_max: float) -> Dict[str, float]:
    # –Ω–∞—á–∞–ª—å–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    total = sum(max(v, 0.0) for v in imp.values())
    if total <= WEIGHTS_TOLERANCE:
        base = {"wR": 0.4, "wP": 0.25, "wC": 0.2, "wS": 0.15}
        return base

    weights = {k: (max(v, 0.0) / total) for k, v in imp.items()}

    # –∫–ª–∏–ø–ø–∏–Ω–≥
    for k in weights:
        weights[k] = min(max(weights[k], clip_min), clip_max)

    # –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–∞ –¥–æ 1
    s2 = sum(weights.values())
    if s2 <= WEIGHTS_TOLERANCE:
        return {"wR": 0.4, "wP": 0.25, "wC": 0.2, "wS": 0.15}

    return {k: (v / s2) for k, v in weights.items()}