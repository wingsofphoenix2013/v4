# üî∏ oracle_mw_confidence.py ‚Äî –≤–æ—Ä–∫–µ—Ä confidence: –ø–∞–∫–µ—Ç–Ω—ã–π —Ä–∞—Å—á—ë—Ç –ø–æ –∫–æ–º–ø–ª–µ–∫—Ç—É –æ–∫–æ–Ω (7d+14d+28d) –¥–ª—è –æ–¥–Ω–æ–≥–æ window_end + –∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å

import asyncio
import logging
import json
import math
import time
from typing import Dict, List, Tuple, Optional
from datetime import datetime

import infra

log = logging.getLogger("ORACLE_CONFIDENCE")

# üî∏ –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –≤–æ—Ä–∫–µ—Ä–∞ (Redis Stream)
REPORT_STREAM = "oracle:mw:reports_ready"
REPORT_CONSUMER_GROUP = "oracle_confidence_group"
REPORT_CONSUMER_NAME = "oracle_confidence_worker"

# üî∏ –°—Ç—Ä–∏–º ¬´–≥–æ—Ç–æ–≤–æ –¥–ª—è sense¬ª
SENSE_REPORT_READY_STREAM = "oracle:mw_sense:reports_ready"
SENSE_REPORT_READY_MAXLEN = 10000

# üî∏ –ì–µ–æ–º–µ—Ç—Ä–∏—è –æ–∫–Ω–∞ (—à–∞–≥ 4 —á–∞—Å–∞ ‚Üí 6 –ø—Ä–æ–≥–æ–Ω–æ–≤ –≤ —Å—É—Ç–∫–∏)
WINDOW_STEPS = {"7d": 7 * 6, "14d": 14 * 6, "28d": 28 * 6}

# üî∏ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
Z = 1.96
BASELINE_WR = 0.5

# üî∏ –ö—ç—à –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏ (strategy_id,time_frame) ‚Üí (weights, opts, ts)
_weights_cache: Dict[Tuple[Optional[int], Optional[str]], Tuple[Dict[str, float], Dict, float]] = {}
WEIGHTS_TTL_SEC = 15 * 60  # 15 –º–∏–Ω—É—Ç


# üî∏ –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –≤–æ—Ä–∫–µ—Ä–∞ (–≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –∏–∑ oracle_v4_main —á–µ—Ä–µ–∑ run_safe_loop)
async def run_oracle_confidence():
    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    if infra.pg_pool is None or infra.redis_client is None:
        log.debug("‚ùå –ü—Ä–æ–ø—É—Å–∫: PG/Redis –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
        return

    # —Å–æ–∑–¥–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª–µ–π (–∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ)
    try:
        await infra.redis_client.xgroup_create(
            name=REPORT_STREAM, groupname=REPORT_CONSUMER_GROUP, id="$", mkstream=True
        )
        log.info("üì° –°–æ–∑–¥–∞–Ω–∞ –≥—Ä—É–ø–ø–∞ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª–µ–π –≤ Redis Stream: %s", REPORT_CONSUMER_GROUP)
    except Exception as e:
        if "BUSYGROUP" in str(e):
            pass
        else:
            log.exception("‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≥—Ä—É–ø–ø—ã Redis Stream")
            return

    log.info("üöÄ –°—Ç–∞—Ä—Ç –≤–æ—Ä–∫–µ—Ä–∞ confidence (–ø–∞–∫–µ—Ç –ø–æ window_end)")

    # –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —á—Ç–µ–Ω–∏—è —Å—Ç—Ä–∏–º–∞
    while True:
        try:
            resp = await infra.redis_client.xreadgroup(
                groupname=REPORT_CONSUMER_GROUP,
                consumername=REPORT_CONSUMER_NAME,
                streams={REPORT_STREAM: ">"},
                count=64,
                block=30_000,
            )
            if not resp:
                continue

            # –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π
            for stream_name, msgs in resp:
                for msg_id, fields in msgs:
                    try:
                        payload = json.loads(fields.get("data", "{}"))
                        # –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è –±–µ—Ä—ë–º strategy_id –∏ window_end ‚Äî —ç—Ç–æ –Ω–∞—à –∫–ª—é—á –∫–æ–º–ø–ª–µ–∫—Ç–∞
                        strategy_id = int(payload.get("strategy_id", 0))
                        window_end = payload.get("window_end")
                        if not (strategy_id and window_end):
                            log.debug("‚ÑπÔ∏è –ü—Ä–æ–ø—É—Å–∫ —Å–æ–æ–±—â–µ–Ω–∏—è: –Ω–µ—Ç strategy_id/window_end: %s", payload)
                            await infra.redis_client.xack(REPORT_STREAM, REPORT_CONSUMER_GROUP, msg_id)
                            continue

                        await _process_window_batch(strategy_id, window_end)
                        await infra.redis_client.xack(REPORT_STREAM, REPORT_CONSUMER_GROUP, msg_id)
                    except Exception:
                        log.exception("‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ Redis Stream")

        except asyncio.CancelledError:
            log.info("‚èπÔ∏è –í–æ—Ä–∫–µ—Ä confidence –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ —Å–∏–≥–Ω–∞–ª—É")
            raise
        except Exception:
            log.exception("‚ùå –û—à–∏–±–∫–∞ —Ü–∏–∫–ª–∞ confidence ‚Äî –ø–∞—É–∑–∞ 5 —Å–µ–∫—É–Ω–¥")
            await asyncio.sleep(5)


# üî∏ –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏—è ¬´–æ—Ç—á—ë—Ç –≥–æ—Ç–æ–≤ –¥–ª—è sense¬ª –≤ Redis Stream
async def _emit_sense_report_ready(
    *,
    report_ids: Dict[str, int],
    strategy_id: int,
    window_end: str,
    aggregate_rows: int,
):
    # —Å–æ–±–∏—Ä–∞–µ–º –ø–µ–π–ª–æ–∞–¥
    payload = {
        "strategy_id": int(strategy_id),
        "time_frames": {"7d": report_ids.get("7d"), "14d": report_ids.get("14d"), "28d": report_ids.get("28d")},
        "window_end": window_end,
        "generated_at": datetime.utcnow().replace(tzinfo=None).isoformat(),
        "aggregate_rows": int(aggregate_rows),
    }
    fields = {"data": json.dumps(payload, separators=(",", ":"))}
    await infra.redis_client.xadd(
        name=SENSE_REPORT_READY_STREAM,
        fields=fields,
        maxlen=SENSE_REPORT_READY_MAXLEN,
        approximate=True,
    )
    log.info("[SENSE_REPORT_READY] sid=%s window_end=%s rows=%d", strategy_id, window_end, aggregate_rows)


# üî∏ –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –∫–æ–º–ø–ª–µ–∫—Ç–∞ –æ–∫–æ–Ω (–∫–ª—é—á = strategy_id + window_end)
async def _process_window_batch(strategy_id: int, window_end_iso: str):
    # –∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å: –æ—Ç–º–µ—Ç–∏–º –∫–æ–º–ø–ª–µ–∫—Ç –∫–∞–∫ ¬´–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –≤–ø–µ—Ä–≤—ã–µ¬ª
    async with infra.pg_pool.acquire() as conn:
        # —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ –∫–æ–º–ø–ª–µ–∫—Ç (7d/14d/28d) –≤–æ–æ–±—â–µ —Å–æ–±—Ä–∞–Ω
        rows = await conn.fetch(
            """
            SELECT id, time_frame, created_at
            FROM oracle_report_stat
            WHERE strategy_id = $1
              AND window_end = $2::timestamp
              AND time_frame IN ('7d','14d','28d')
            """,
            int(strategy_id), str(window_end_iso)
        )
        if len(rows) < 3:
            log.debug("‚åõ –ö–æ–º–ø–ª–µ–∫—Ç –Ω–µ –≥–æ—Ç–æ–≤: sid=%s window_end=%s (–Ω–∞—à–ª–∏ %d –∏–∑ 3)", strategy_id, window_end_iso, len(rows))
            return

        # –≤—Å—Ç–∞–≤–∫–∞-–º–∞—Ä–∫–µ—Ä: –µ—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å –∑–∞–ø–∏—Å—å ‚Äî –≤—ã—Ö–æ–¥–∏–º (–∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å)
        inserted = await conn.fetchrow(
            """
            INSERT INTO oracle_conf_processed (strategy_id, window_end)
            VALUES ($1, $2::timestamp)
            ON CONFLICT DO NOTHING
            RETURNING 1
            """,
            int(strategy_id), str(window_end_iso)
        )
        if not inserted:
            log.info("‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫: –∫–æ–º–ø–ª–µ–∫—Ç —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω (sid=%s window_end=%s)", strategy_id, window_end_iso)
            return

        report_ids = {str(r["time_frame"]): int(r["id"]) for r in rows}

        # –ª–æ–∫–∞–ª—å–Ω—ã–π ¬´—Å–Ω—ç–ø—à–æ—Ç¬ª –≤–µ—Å–æ–≤ –Ω–∞ –≤—Ä–µ–º—è –±–∞—Ç—á–∞ (—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –∫–æ–º–ø–ª–µ–∫—Ç–∞)
        batch_weights: Dict[str, Tuple[Dict[str, float], Dict]] = {}
        for tf in ("7d", "14d", "28d"):
            w, o = await _get_active_weights(conn, strategy_id, tf)
            batch_weights[tf] = (w, o)

        # –±–µ—Ä—ë–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –∞–≥—Ä–µ–≥–∞—Ç–æ–≤ –ø–æ —Ç—Ä—ë–º –æ—Ç—á—ë—Ç–∞–º
        agg_rows = await conn.fetch(
            """
            SELECT
              a.id,
              a.report_id,
              a.strategy_id,
              a.time_frame,
              a.direction,
              a.timeframe,
              a.agg_type,
              a.agg_base,
              a.agg_state,
              a.trades_total,
              a.trades_wins,
              a.winrate,
              a.avg_pnl_per_trade,
              r.created_at AS report_created_at
            FROM oracle_mw_aggregated_stat a
            JOIN oracle_report_stat r ON r.id = a.report_id
            WHERE a.report_id = ANY($1::bigint[])
            """,
            list(report_ids.values())
        )
        if not agg_rows:
            log.debug("‚ÑπÔ∏è –ù–µ—Ç –∞–≥—Ä–µ–≥–∞—Ç–æ–≤ –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Ç–∞: sid=%s window_end=%s", strategy_id, window_end_iso)
            return

        # –∫—ç—à–∏ –∫–æ–≥–æ—Ä—Ç—ã –Ω–∞ –æ–¥–∏–Ω –æ—Ç—á—ë—Ç (—Å—Ä–µ–∑) ‚Äî –∫–ª—é—á –±–µ–∑ agg_state
        cohort_cache: Dict[Tuple, List[dict]] = {}

        updated = 0
        for r in agg_rows:
            row = dict(r)

            # –∫–ª—é—á –∫–æ–≥–æ—Ä—Ç—ã –¥–ª—è ECDF(n)/S (–Ω–∞ —É—Ä–æ–≤–Ω–µ –æ–¥–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞)
            cohort_key = (
                row["strategy_id"], row["time_frame"], row["direction"],
                row["timeframe"], row["agg_type"], row["agg_base"], row["report_created_at"]
            )
            if cohort_key not in cohort_cache:
                cohort_cache[cohort_key] = await _fetch_cohort(conn, row)

            # –±–µ—Ä—ë–º –≤–µ—Å–∞ –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Å–Ω—ç–ø—à–æ—Ç–∞ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –æ–∫–Ω–∞ —Å—Ç—Ä–æ–∫–∏
            weights, opts = batch_weights.get(row["time_frame"], ({"wR": 0.4, "wP": 0.25, "wC": 0.2, "wS": 0.15}, {"baseline_mode": "neutral"}))

            try:
                confidence, inputs = await _calc_confidence_by_window_end(
                    conn=conn,
                    row=row,
                    cohort_rows=cohort_cache[cohort_key],
                    weights=weights,
                    opts=opts,
                    window_end_iso=window_end_iso,
                    report_ids=report_ids,
                )
                await conn.execute(
                    """
                    UPDATE oracle_mw_aggregated_stat
                       SET confidence = $2,
                           confidence_inputs = $3,
                           confidence_updated_at = now()
                     WHERE id = $1
                    """,
                    int(row["id"]),
                    float(confidence),
                    json.dumps(inputs, separators=(",", ":")),
                )
                # –∞—É–¥–∏—Ç (best-effort)
                try:
                    await conn.execute(
                        """
                        INSERT INTO oracle_mw_confidence_audit (
                          aggregated_id, report_id, strategy_id, time_frame, direction, timeframe,
                          agg_type, agg_base, agg_state, confidence, components
                        ) VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11)
                        """,
                        int(row["id"]), int(row["report_id"]), int(row["strategy_id"]), str(row["time_frame"]),
                        str(row["direction"]), str(row["timeframe"]), str(row["agg_type"]), str(row["agg_base"]),
                        str(row["agg_state"]), float(confidence), json.dumps(inputs, separators=(",", ":"))
                    )
                except Exception:
                    log.debug("–ê—É–¥–∏—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –∏–ª–∏ –ø—Ä–æ–ø—É—â–µ–Ω (aggregated_id=%s)", row["id"])

                updated += 1
            except Exception:
                log.exception("‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è confidence –¥–ª—è aggregated_id=%s", row["id"])

        log.info("‚úÖ –û–±–Ω–æ–≤–ª—ë–Ω confidence (–ø–∞–∫–µ—Ç): sid=%s window_end=%s rows=%d", strategy_id, window_end_iso, updated)

    # –ø—É–±–ª–∏–∫–∞—Ü–∏—è ¬´–≥–æ—Ç–æ–≤–æ –¥–ª—è sense¬ª ‚Äî —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –º—ã —Ä–µ–∞–ª—å–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–ª–∏ –∫–æ–º–ø–ª–µ–∫—Ç (–∏ –¥–æ—à–ª–∏ —Å—é–¥–∞)
    try:
        await _emit_sense_report_ready(
            report_ids=report_ids,
            strategy_id=strategy_id,
            window_end=window_end_iso,
            aggregate_rows=updated,
        )
    except Exception:
        log.exception("‚ùå –û—à–∏–±–∫–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ —Å–æ–±—ã—Ç–∏—è –≤ %s (sid=%s window_end=%s)", SENSE_REPORT_READY_STREAM, strategy_id, window_end_iso)


# üî∏ –í—ã–±–æ—Ä–∫–∞ –∫–æ–≥–æ—Ä—Ç—ã (–≤—Å–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è agg_state –≤–Ω—É—Ç—Ä–∏ –æ–¥–Ω–æ–≥–æ —Å—Ä–µ–∑–∞ –∏ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç—á—ë—Ç–∞)
async def _fetch_cohort(conn, row: dict) -> List[dict]:
    rows = await conn.fetch(
        """
        SELECT
          id,
          trades_total,
          trades_wins,
          winrate,
          avg_pnl_per_trade
        FROM v_mw_aggregated_with_time
        WHERE strategy_id = $1
          AND time_frame  = $2
          AND direction   = $3
          AND timeframe   = $4
          AND agg_type    = $5
          AND agg_base    = $6
          AND report_created_at = $7
        """,
        row["strategy_id"], row["time_frame"], row["direction"], row["timeframe"],
        row["agg_type"], row["agg_base"], row["report_created_at"]
    )
    return [dict(x) for x in rows]


# üî∏ –ó–∞–≥—Ä—É–∑–∫–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö –≤–µ—Å–æ–≤ –∏–∑ –ë–î (—Å –ø—Ä–æ—Å—Ç—ã–º –∫—ç—à–µ–º –∏ –±–µ–∑–æ–ø–∞—Å–Ω—ã–º –ø–∞—Ä—Å–∏–Ω–≥–æ–º JSON)
async def _get_active_weights(conn, strategy_id: int, time_frame: str) -> Tuple[Dict[str, float], Dict]:
    now = time.time()

    # –ø–æ–ø—ã—Ç–∫–∞: (strategy_id,time_frame)
    key = (strategy_id, time_frame)
    w = _weights_cache.get(key)
    if w and (now - w[2] < WEIGHTS_TTL_SEC):
        return w[0], w[1]

    # –ø–æ–ø—ã—Ç–∫–∞: (strategy_id,NULL)
    key2 = (strategy_id, None)
    w2 = _weights_cache.get(key2)
    if w2 and (now - w2[2] < WEIGHTS_TTL_SEC):
        return w2[0], w2[1]

    # –ø–æ–ø—ã—Ç–∫–∞: (NULL,NULL)
    key3 = (None, None)
    w3 = _weights_cache.get(key3)
    if w3 and (now - w3[2] < WEIGHTS_TTL_SEC):
        return w3[0], w3[1]

    # –∑–∞–ø—Ä–æ—Å –≤ –ë–î: –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç ‚Äî —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, –∑–∞—Ç–µ–º –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏, –∑–∞—Ç–µ–º –≥–ª–æ–±–∞–ª—å–Ω–æ
    row = await conn.fetchrow(
        """
        SELECT weights, COALESCE(opts,'{}'::jsonb) AS opts
          FROM oracle_conf_model
         WHERE is_active = true
           AND (
                 (strategy_id = $1 AND time_frame = $2)
              OR (strategy_id = $1 AND time_frame IS NULL)
              OR (strategy_id IS NULL AND time_frame IS NULL)
           )
         ORDER BY
           CASE WHEN strategy_id = $1 AND time_frame = $2 THEN 1
                WHEN strategy_id = $1 AND time_frame IS NULL THEN 2
                ELSE 3 END,
           created_at DESC
         LIMIT 1
        """,
        strategy_id, time_frame
    )

    # –¥–µ—Ñ–æ–ª—Ç—ã
    defaults_w = {"wR": 0.4, "wP": 0.25, "wC": 0.2, "wS": 0.15}
    defaults_o = {"baseline_mode": "neutral"}

    def _parse_json_like(x, default):
        if isinstance(x, dict):
            return x
        if isinstance(x, (bytes, bytearray, memoryview)):
            try:
                return json.loads(bytes(x).decode("utf-8"))
            except Exception:
                log.exception("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –∏–∑ bytes/memoryview")
                return default
        if isinstance(x, str):
            try:
                return json.loads(x)
            except Exception:
                log.exception("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –∏–∑ —Å—Ç—Ä–æ–∫–∏")
                return default
        return default

    if row:
        raw_w = row["weights"]
        raw_o = row["opts"]
        weights = _parse_json_like(raw_w, defaults_w)
        opts = _parse_json_like(raw_o, defaults_o)
    else:
        weights = defaults_w
        opts = defaults_o

    # –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –≤–µ—Å–æ–≤ + –º—è–≥–∫–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
    wR = float(weights.get("wR", defaults_w["wR"]))
    wP = float(weights.get("wP", defaults_w["wP"]))
    wC = float(weights.get("wC", defaults_w["wC"]))
    wS = float(weights.get("wS", defaults_w["wS"]))

    # –∫–ª–∏–ø–ø–∏–Ω–≥, —á—Ç–æ–±—ã C –Ω–µ –¥–æ–º–∏–Ω–∏—Ä–æ–≤–∞–ª, –∞ R –Ω–µ –¥–µ–≥—Ä–∞–¥–∏—Ä–æ–≤–∞–ª
    wC = min(wC, 0.35)
    wR = max(wR, 0.25)

    total = wR + wP + wC + wS
    if not math.isfinite(total) or total <= 0:
        wR, wP, wC, wS = defaults_w["wR"], defaults_w["wP"], defaults_w["wC"], defaults_w["wS"]
        total = wR + wP + wC + wS

    wR, wP, wC, wS = (wR / total, wP / total, wC / total, wS / total)
    weights_norm = {"wR": wR, "wP": wP, "wC": wC, "wS": wS}

    ts = time.time()
    _weights_cache[(strategy_id, time_frame)] = (weights_norm, opts, ts)
    _weights_cache[(strategy_id, None)] = (weights_norm, opts, ts)
    _weights_cache[(None, None)] = (weights_norm, opts, ts)

    return weights_norm, opts


# üî∏ –†–∞—Å—á—ë—Ç confidence –¥–ª—è —Å—Ç—Ä–æ–∫–∏ (–ø–æ –∫–æ–º–ø–ª–µ–∫—Ç—É –æ–∫–æ–Ω —Å –æ–±—â–∏–º window_end)
async def _calc_confidence_by_window_end(
    *,
    conn,
    row: dict,
    cohort_rows: List[dict],
    weights: Dict[str, float],
    opts: Dict,
    window_end_iso: str,
    report_ids: Dict[str, int],
) -> Tuple[float, dict]:
    n = int(row["trades_total"] or 0)
    wins = int(row["trades_wins"] or 0)
    wr = float(row["winrate"] or 0.0)

    # Reliability (R)
    R = _wilson_lower_bound(wins, n, Z) if n > 0 else 0.0

    # Persistence (P): –ø–æ —Ç–µ–∫—É—â–µ–º—É –æ–∫–Ω—É —Å—Ç—Ä–æ–∫–∏
    L = WINDOW_STEPS.get(str(row["time_frame"]), 42)
    presence_rate, growth_hist, hist_n = await _persistence_metrics(conn, row, L)
    P = 0.6 * presence_rate + 0.4 * growth_hist

    # Cross-window coherence (C) –ø–æ —Ç—Ä—ë–º –æ—Ç—á—ë—Ç–∞–º –∏–∑ –æ–¥–Ω–æ–≥–æ window_end
    C = await _cross_window_coherence_by_ids(conn, row, report_ids)

    # Stability (S): —Ä–æ–±–∞—Å—Ç–Ω–∞—è —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å wr (–¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è —à–∫–∞–ª–∞)
    S_key, _len_hist, dyn_scale_used = await _stability_key_dynamic(conn, row, L, cohort_rows)

    # –ú–∞—Å—Å–∞ / N_effect: ECDF –ø–æ –∫–æ–≥–æ—Ä—Ç–µ + –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –º–∞—Å—Å–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –º–µ–¥–∏–∞–Ω—ã
    cohort_n = [int(x["trades_total"] or 0) for x in cohort_rows]
    ecdf_cohort = _ecdf_rank(n, cohort_n)
    ecdf_hist = _ecdf_rank(n, hist_n) if hist_n else 0.0
    if len(cohort_n) < 5:
        N_effect = 0.5 * ecdf_cohort + 0.5 * ecdf_hist
    else:
        N_effect = ecdf_cohort
    floor = 1.0 / float(max(2, len(cohort_n)) + 1)
    N_effect = max(N_effect, floor)
    N_effect = float(max(0.0, min(1.0, N_effect)))
    n_pos = [v for v in cohort_n if v > 0]
    n_med = _median([float(v) for v in n_pos]) if n_pos else 1.0
    abs_mass = math.sqrt(n / (n + n_med)) if (n_med > 0 and n >= 0) else 0.0
    N_effect = float(max(0.0, min(1.0, N_effect * abs_mass)))

    # –í–µ—Å–∞
    wR = float(weights.get("wR", 0.4))
    wP = float(weights.get("wP", 0.25))
    wC = float(weights.get("wC", 0.2))
    wS = float(weights.get("wS", 0.15))

    raw = wR * R + wP * P + wC * C + wS * S_key
    confidence = round(max(0.0, min(1.0, raw * N_effect)), 4)

    inputs = {
        "R": round(R, 6),
        "P": round(P, 6),
        "C": round(C, 6),
        "S": round(S_key, 6),
        "N_effect": round(N_effect, 6),
        "weights": {"wR": wR, "wP": wP, "wC": wC, "wS": wS},
        "n": n,
        "wins": wins,
        "wr": wr,
        "presence_rate": round(presence_rate, 6),
        "growth_hist": round(growth_hist, 6),
        "hist_points": len(hist_n),
        "dyn_scale_used": dyn_scale_used,
        "baseline_wr": BASELINE_WR,
        "window_end": window_end_iso,
        "formula": "(wR*R + wP*P + wC*C + wS*S) * N_effect",
    }
    return confidence, inputs


# üî∏ C –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –∫–æ–º–ø–ª–µ–∫—Ç—É report_id (7d/14d/28d) –¥–ª—è –∫–ª—é—á–∞ —Å—Ç—Ä–æ–∫–∏
async def _cross_window_coherence_by_ids(conn, row: dict, report_ids: Dict[str, int]) -> float:
    # —Å–æ–±–∏—Ä–∞–µ–º –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∫–ª—é—á–∞ —Å—Ç—Ä–æ–∫–∏ (direction/timeframe/agg_type/base/state) –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –ø–æ –∫–∞–∂–¥–æ–º—É report_id
    rows = await conn.fetch(
        """
        SELECT a.time_frame, a.trades_total, a.trades_wins
        FROM oracle_mw_aggregated_stat a
        WHERE a.report_id = ANY($1::bigint[])
          AND a.strategy_id = $2
          AND a.direction   = $3
          AND a.timeframe   = $4
          AND a.agg_type    = $5
          AND a.agg_base    = $6
          AND a.agg_state   = $7
        """,
        list(report_ids.values()),
        row["strategy_id"], row["direction"], row["timeframe"],
        row["agg_type"], row["agg_base"], row["agg_state"]
    )
    if not rows:
        return 0.0

    signs: List[int] = []
    weights: List[float] = []

    for r in rows:
        n = int(r["trades_total"] or 0)
        w = int(r["trades_wins"] or 0)
        if n <= 0:
            continue
        lb, ub = _wilson_bounds(w, n, Z)
        # —É–≤–µ—Ä–µ–Ω–Ω–æ –≤—ã—à–µ baseline ‚Üí +1
        if lb > BASELINE_WR:
            dist = max(lb - BASELINE_WR, ub - BASELINE_WR)
            if dist > 0:
                signs.append(+1); weights.append(dist)
        # —É–≤–µ—Ä–µ–Ω–Ω–æ –Ω–∏–∂–µ baseline ‚Üí -1
        elif ub < BASELINE_WR:
            dist = max(BASELINE_WR - lb, BASELINE_WR - ub)
            if dist > 0:
                signs.append(-1); weights.append(dist)
        # –∏–Ω–∞—á–µ –æ–∫–Ω–æ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–µ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º

    total_weight = sum(weights)
    # —Ç—Ä–µ–±—É–µ–º –º–∏–Ω–∏–º—É–º 2 —É–≤–µ—Ä–µ–Ω–Ω—ã—Ö –æ–∫–Ω–∞
    if total_weight <= 0.0 or len(weights) < 2:
        return 0.0

    signed_weight = sum(s * w for s, w in zip(signs, weights))
    C = abs(signed_weight) / total_weight
    return float(max(0.0, min(1.0, C)))


# üî∏ Persistence-–º–µ—Ç—Ä–∏–∫–∏: presence_rate –∏ growth_hist (ECDF –ø–æ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º n)
async def _persistence_metrics(conn, row: dict, L: int) -> Tuple[float, float, List[int]]:
    # –ø–æ—Å–ª–µ–¥–Ω–∏–µ L –æ—Ç—á—ë—Ç–æ–≤ (created_at) –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏/–æ–∫–Ω—É –¥–æ –∏ –≤–∫–ª—é—á–∞—è —Ç–µ–∫—É—â–∏–π –æ—Ç—á—ë—Ç
    last_rows = await conn.fetch(
        """
        WITH last_reports AS (
          SELECT id, created_at
          FROM oracle_report_stat
          WHERE strategy_id = $1
            AND time_frame  = $2
            AND created_at <= $3
          ORDER BY created_at DESC
          LIMIT $4
        )
        SELECT lr.created_at,
               a.trades_total
        FROM last_reports lr
        LEFT JOIN oracle_mw_aggregated_stat a
          ON a.report_id = lr.id
         AND a.strategy_id = $1
         AND a.time_frame  = $2
         AND a.direction   = $5
         AND a.timeframe   = $6
         AND a.agg_type    = $7
         AND a.agg_base    = $8
         AND a.agg_state   = $9
        ORDER BY lr.created_at DESC
        """,
        row["strategy_id"],
        row["time_frame"],
        row["report_created_at"],
        int(L),
        row["direction"],
        row["timeframe"],
        row["agg_type"],
        row["agg_base"],
        row["agg_state"],
    )

    present_flags = [1 if r["trades_total"] is not None else 0 for r in last_rows]
    L_eff = len(present_flags) if present_flags else 0
    presence_rate = (sum(present_flags) / L_eff) if L_eff > 0 else 0.0

    hist_n = [int(r["trades_total"]) for r in last_rows if r["trades_total"] is not None]
    growth_hist = _ecdf_rank(int(row["trades_total"] or 0), hist_n) if hist_n else 0.0

    return presence_rate, growth_hist, hist_n


# üî∏ –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –∫–ª—é—á–∞: —Ä–æ–±–∞—Å—Ç–Ω—ã–π z –ø–æ –∏—Å—Ç–æ—Ä–∏–∏ wr —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π —à–∫–∞–ª–æ–π
async def _stability_key_dynamic(
    conn,
    row: dict,
    L: int,
    cohort_rows: List[dict],
) -> Tuple[float, int, dict]:
    rows = await conn.fetch(
        """
        SELECT winrate
        FROM v_mw_aggregated_with_time
        WHERE strategy_id = $1
          AND time_frame  = $2
          AND direction   = $3
          AND timeframe   = $4
          AND agg_type    = $5
          AND agg_base    = $6
          AND agg_state   = $7
          AND report_created_at <= $8
        ORDER BY report_created_at DESC
        LIMIT $9
        """,
        row["strategy_id"], row["time_frame"], row["direction"], row["timeframe"],
        row["agg_type"], row["agg_base"], row["agg_state"],
        row["report_created_at"], int(L)
    )
    wr_hist = [float(r["winrate"] or 0.0) for r in rows]
    wr_now = float(row["winrate"] or 0.0)
    if len(wr_hist) < 2:
        return 1.0, len(wr_hist), {"mode": "short_hist", "scale": None}

    med = _median(wr_hist)
    mad = _mad(wr_hist, med)
    iqr = _iqr(wr_hist)

    wr_cohort = [float(x["winrate"] or 0.0) for x in cohort_rows] if cohort_rows else []
    cohort_mad = _mad(wr_cohort, _median(wr_cohort)) if len(wr_cohort) >= 3 else 0.0

    cand = []
    if mad > 0:
        cand.append(mad / 0.6745)
    if iqr > 0:
        cand.append(iqr / 1.349)
    if cohort_mad > 0:
        cand.append(cohort_mad / 0.6745)

    n_hist = len(wr_hist)
    cand.append(1.0 / math.sqrt(max(1.0, float(n_hist))))

    if all(c <= 0 for c in cand[:-1]) and abs(wr_now - med) < 1e-12:
        return 1.0, n_hist, {"mode": "flat_hist", "scale": 0.0}

    scale = max(cand) if cand else 1e-6
    z = abs(wr_now - med) / (scale + 1e-12)
    S_key = 1.0 / (1.0 + z)

    return S_key, n_hist, {"mode": "dynamic", "scale": round(scale, 6), "median": round(med, 6)}


# üî∏ Wilson lower bound / bounds
def _wilson_lower_bound(wins: int, n: int, z: float) -> float:
    if n <= 0:
        return 0.0
    p = wins / n
    denom = 1.0 + (z * z) / n
    center = p + (z * z) / (2.0 * n)
    adj = z * math.sqrt((p * (1.0 - p) / n) + (z * z) / (4.0 * n * n))
    lb = (center - adj) / denom
    return max(0.0, min(1.0, lb))


def _wilson_bounds(wins: int, n: int, z: float) -> tuple[float, float]:
    if n <= 0:
        return 0.0, 0.0
    p = wins / n
    denom = 1.0 + (z * z) / n
    center = p + (z * z) / (2.0 * n)
    adj = z * math.sqrt((p * (1.0 - p) / n) + (z * z) / (4.0 * n * n))
    lb = (center - adj) / denom
    ub = (center + adj) / denom
    return max(0.0, min(1.0, lb)), max(0.0, min(1.0, ub))


# üî∏ ECDF-—Ä–∞–Ω–≥ / –±–∞–∑–æ–≤—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
def _ecdf_rank(x: int, values: List[int]) -> float:
    if not values:
        return 0.0
    cnt = sum(1 for v in values if v <= x)
    return cnt / len(values)


def _median(arr: List[float]) -> float:
    n = len(arr)
    if n == 0:
        return 0.0
    s = sorted(arr)
    mid = n // 2
    if n % 2 == 1:
        return s[mid]
    return 0.5 * (s[mid - 1] + s[mid])


def _mad(arr: List[float], med: float) -> float:
    if not arr:
        return 0.0
    dev = [abs(x - med) for x in arr]
    return _median(dev)


def _iqr(arr: List[float]) -> float:
    n = len(arr)
    if n < 4:
        return 0.0
    s = sorted(arr)
    q1 = _percentile(s, 25.0)
    q3 = _percentile(s, 75.0)
    return max(0.0, q3 - q1)


def _percentile(sorted_arr: List[float], p: float) -> float:
    if not sorted_arr:
        return 0.0
    if p <= 0:
        return sorted_arr[0]
    if p >= 100:
        return sorted_arr[-1]
    k = (len(sorted_arr) - 1) * (p / 100.0)
    f = math.floor(k)
    c = math.ceil(k)
    if f == c:
        return sorted_arr[int(k)]
    d0 = sorted_arr[int(f)] * (c - k)
    d1 = sorted_arr[int(c)] * (k - f)
    return d0 + d1