# üî∏ oracle_mw_confidence.py ‚Äî –≤–æ—Ä–∫–µ—Ä confidence: –∞–¥–∞–ø—Ç–∏–≤–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–æ–≤–µ—Ä–∏—è (R, P, C, S) –±–µ–∑ —Ä—É—á–Ω—ã—Ö –ø–æ—Ä–æ–≥–æ–≤

import asyncio
import logging
import json
import math
from typing import List, Tuple

import infra

log = logging.getLogger("ORACLE_CONFIDENCE")

# üî∏ –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –≤–æ—Ä–∫–µ—Ä–∞ (—Å—Ç—Ä–∏–º –æ—Ç—á—ë—Ç–æ–≤)
REPORT_STREAM = "oracle:mw:reports_ready"
REPORT_CONSUMER_GROUP = "oracle_confidence_group"
REPORT_CONSUMER_NAME = "oracle_confidence_worker"

# üî∏ –ì–µ–æ–º–µ—Ç—Ä–∏—è –æ–∫–Ω–∞ (—à–∞–≥ 4 —á–∞—Å–∞ ‚Üí 6 –ø—Ä–æ–≥–æ–Ω–æ–≤ –≤ —Å—É—Ç–∫–∏)
WINDOW_STEPS = {"7d": 7 * 6, "14d": 14 * 6, "28d": 28 * 6}

# üî∏ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
Z = 1.96  # Wilson 95%


# üî∏ –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –≤–æ—Ä–∫–µ—Ä–∞ (–≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –∏–∑ oracle_v4_main —á–µ—Ä–µ–∑ run_safe_loop)
async def run_oracle_confidence():
    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    if infra.pg_pool is None or infra.redis_client is None:
        log.debug("‚ùå –ü—Ä–æ–ø—É—Å–∫: PG/Redis –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
        return

    # —Å–æ–∑–¥–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª–µ–π (–∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ)
    try:
        await infra.redis_client.xgroup_create(
            name=REPORT_STREAM, groupname=REPORT_CONSUMER_GROUP, id="$", mkstream=True
        )
        log.info("üì° –°–æ–∑–¥–∞–Ω–∞ –≥—Ä—É–ø–ø–∞ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª–µ–π –≤ Redis Stream: %s", REPORT_CONSUMER_GROUP)
    except Exception as e:
        if "BUSYGROUP" in str(e):
            pass
        else:
            log.exception("‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≥—Ä—É–ø–ø—ã Redis Stream")
            return

    log.info("üöÄ –°—Ç–∞—Ä—Ç –≤–æ—Ä–∫–µ—Ä–∞ confidence (–∞–¥–∞–ø—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å)")

    # –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —á—Ç–µ–Ω–∏—è —Å—Ç—Ä–∏–º–∞
    while True:
        try:
            resp = await infra.redis_client.xreadgroup(
                groupname=REPORT_CONSUMER_GROUP,
                consumername=REPORT_CONSUMER_NAME,
                streams={REPORT_STREAM: ">"},
                count=16,
                block=30_000,
            )
            if not resp:
                continue

            # –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π
            for stream_name, msgs in resp:
                for msg_id, fields in msgs:
                    try:
                        payload = json.loads(fields.get("data", "{}"))
                        report_id = int(payload.get("report_id", 0))
                        strategy_id = int(payload.get("strategy_id", 0))
                        time_frame = payload.get("time_frame")
                        await _process_report(report_id, strategy_id, time_frame)
                        await infra.redis_client.xack(REPORT_STREAM, REPORT_CONSUMER_GROUP, msg_id)
                    except Exception:
                        log.exception("‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ Redis Stream")

        except asyncio.CancelledError:
            log.info("‚èπÔ∏è –í–æ—Ä–∫–µ—Ä confidence –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ —Å–∏–≥–Ω–∞–ª—É")
            raise
        except Exception:
            log.exception("‚ùå –û—à–∏–±–∫–∞ —Ü–∏–∫–ª–∞ confidence ‚Äî –ø–∞—É–∑–∞ 5 —Å–µ–∫—É–Ω–¥")
            await asyncio.sleep(5)


# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ–≥–æ –æ—Ç—á—ë—Ç–∞ (–ø–æ report_id)
async def _process_report(report_id: int, strategy_id: int, time_frame: str):
    async with infra.pg_pool.acquire() as conn:
        rows = await conn.fetch(
            """
            SELECT
              id,
              report_id,
              strategy_id,
              time_frame,
              direction,
              timeframe,
              agg_type,
              agg_base,
              agg_state,
              trades_total,
              trades_wins,
              winrate,
              avg_pnl_per_trade,
              report_created_at
            FROM v_mw_aggregated_with_time
            WHERE report_id = $1
            """,
            report_id,
        )
        if not rows:
            log.info("‚ÑπÔ∏è –î–ª—è report_id=%s –Ω–µ—Ç –∞–≥—Ä–µ–≥–∞—Ç–æ–≤", report_id)
            return

        # –∫–æ–≥–æ—Ä—Ç—ã –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –Ω–æ—Ä–º–∏—Ä–æ–≤–æ–∫ —Å—á–∏—Ç–∞–µ–º –æ–¥–∏–Ω —Ä–∞–∑ –Ω–∞ –æ—Ç—á—ë—Ç –∏ —Å—Ä–µ–∑
        cohort_cache = {}

        updated = 0
        for r in rows:
            row = dict(r)
            # –∫–ª—é—á –∫–æ–≥–æ—Ä—Ç—ã: –≤—Å–µ –ø–æ–ª—è, –∫—Ä–æ–º–µ agg_state (–≤–Ω—É—Ç—Ä–∏ –Ω–µ–≥–æ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º—Å—è)
            cohort_key = (
                row["strategy_id"], row["time_frame"], row["direction"],
                row["timeframe"], row["agg_type"], row["agg_base"], row["report_created_at"]
            )
            if cohort_key not in cohort_cache:
                cohort_cache[cohort_key] = await _fetch_cohort(conn, row)

            try:
                confidence, inputs = await _calc_confidence(conn, row, cohort_cache[cohort_key])
                await conn.execute(
                    """
                    UPDATE oracle_mw_aggregated_stat
                       SET confidence = $2,
                           confidence_inputs = $3,
                           confidence_updated_at = now()
                     WHERE id = $1
                    """,
                    int(row["id"]),
                    float(confidence),
                    json.dumps(inputs, separators=(",", ":")),
                )
                updated += 1
            except Exception:
                log.exception("‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è confidence –¥–ª—è aggregated_id=%s", row["id"])

        log.info(
            "‚úÖ –û–±–Ω–æ–≤–ª—ë–Ω confidence –¥–ª—è report_id=%s (strategy_id=%s, time_frame=%s): %d —Å—Ç—Ä–æ–∫",
            report_id, strategy_id, time_frame, updated
        )


# üî∏ –í—ã–±–æ—Ä–∫–∞ –∫–æ–≥–æ—Ä—Ç—ã (–≤—Å–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è agg_state –≤–Ω—É—Ç—Ä–∏ –æ–¥–Ω–æ–≥–æ —Å—Ä–µ–∑–∞ –∏ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç—á—ë—Ç–∞)
async def _fetch_cohort(conn, row: dict) -> List[dict]:
    rows = await conn.fetch(
        """
        SELECT
          id,
          trades_total,
          trades_wins,
          winrate,
          avg_pnl_per_trade
        FROM v_mw_aggregated_with_time
        WHERE strategy_id = $1
          AND time_frame  = $2
          AND direction   = $3
          AND timeframe   = $4
          AND agg_type    = $5
          AND agg_base    = $6
          AND report_created_at = $7
        """,
        row["strategy_id"], row["time_frame"], row["direction"], row["timeframe"],
        row["agg_type"], row["agg_base"], row["report_created_at"]
    )
    return [dict(x) for x in rows]


# üî∏ –†–∞—Å—á—ë—Ç confidence (–∞–¥–∞–ø—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å)
async def _calc_confidence(conn, row: dict, cohort_rows: List[dict]) -> Tuple[float, dict]:
    n = int(row["trades_total"] or 0)
    wins = int(row["trades_wins"] or 0)
    wr = float(row["winrate"] or 0.0)
    pnl = float(row["avg_pnl_per_trade"] or 0.0)

    # Reliability (R): Wilson lower bound
    R = _wilson_lower_bound(wins, n, Z) if n > 0 else 0.0

    # Persistence (P): presence_rate –ø–æ –ø–æ—Å–ª–µ–¥–Ω–∏–º L –æ—Ç—á—ë—Ç–∞–º –∏ growth_hist —á–µ—Ä–µ–∑ ECDF –ø–æ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º n
    L = WINDOW_STEPS.get(str(row["time_frame"]), 42)
    presence_rate, growth_hist, hist_n = await _persistence_metrics(conn, row, L)
    P = 0.6 * presence_rate + 0.4 * growth_hist

    # Cross-window coherence (C): —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å 7d/14d/28d, –≤–µ—Å–∞ = R –æ–∫–Ω–∞
    C = await _cross_window_coherence(conn, row)

    # Stability (S): —Ä–æ–±–∞—Å—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ (MAD) –ø–æ –∏—Å—Ç–æ—Ä–∏–∏ –∫–ª—é—á–∞;
    # –ø—Ä–∏ –º–∞–ª–æ–π –∏—Å—Ç–æ—Ä–∏–∏ –¥–æ–±–∞–≤–ª—è–µ–º shrinkage –∫ ¬´–∫–æ–≥–æ—Ä—Ç–Ω–æ–π¬ª —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—É—â–µ–≥–æ –ø—Ä–æ–≥–æ–Ω–∞
    S_key, len_hist = await _stability_key(conn, row, L)
    S_cohort = _stability_cohort_now(row, cohort_rows)
    w = min(1.0, max(0.0, len_hist / max(1, L)))  # –≤–µ—Å –∏—Å—Ç–æ—Ä–∏–∏ –∫–ª—é—á–∞ –≤ [0..1]
    S = w * S_key + (1 - w) * S_cohort

    # –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–∞ –ø–æ ¬´–º–∞—Å—Å–µ¬ª –≤–Ω—É—Ç—Ä–∏ –∫–æ–≥–æ—Ä—Ç—ã: ECDF –ø–æ n
    N_effect = _ecdf_rank(n, [int(x["trades_total"] or 0) for x in cohort_rows])
    N_effect = 0.05 + 0.95 * N_effect  # –º—è–≥–∫–∞—è –ø—Ä—É–∂–∏–Ω–∞ –æ—Ç –Ω—É–ª—è

    # –ò—Ç–æ–≥–æ–≤—ã–π —Å–∫–æ—Ä
    raw = 0.4 * R + 0.25 * P + 0.2 * C + 0.15 * S
    confidence = round(max(0.0, min(1.0, raw * N_effect)), 4)

    inputs = {
        "R": round(R, 6),
        "P": round(P, 6),
        "C": round(C, 6),
        "S": round(S, 6),
        "N_effect": round(N_effect, 6),
        "n": n,
        "wins": wins,
        "wr": wr,
        "avg_pnl_per_trade": pnl,
        "presence_rate": round(presence_rate, 6),
        "growth_hist": round(growth_hist, 6),
        "hist_points": len(hist_n),
        "formula": "(0.4*R + 0.25*P + 0.2*C + 0.15*S) * N_effect",
    }
    return confidence, inputs


# üî∏ Persistence-–º–µ—Ç—Ä–∏–∫–∏: presence_rate –∏ growth_hist (ECDF –ø–æ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º n)
async def _persistence_metrics(conn, row: dict, L: int) -> Tuple[float, float, List[int]]:
    # –ø–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ L –æ—Ç—á—ë—Ç–æ–≤ (created_at) –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏/–æ–∫–Ω—É –¥–æ –∏ –≤–∫–ª—é—á–∞—è —Ç–µ–∫—É—â–∏–π –æ—Ç—á—ë—Ç
    last_rows = await conn.fetch(
        """
        WITH last_reports AS (
          SELECT id, created_at
          FROM oracle_report_stat
          WHERE strategy_id = $1
            AND time_frame  = $2
            AND created_at <= $3
          ORDER BY created_at DESC
          LIMIT $4
        )
        SELECT lr.created_at,
               a.trades_total
        FROM last_reports lr
        LEFT JOIN oracle_mw_aggregated_stat a
          ON a.report_id = lr.id
         AND a.strategy_id = $1
         AND a.time_frame  = $2
         AND a.direction   = $5
         AND a.timeframe   = $6
         AND a.agg_type    = $7
         AND a.agg_base    = $8
         AND a.agg_state   = $9
        ORDER BY lr.created_at DESC
        """,
        row["strategy_id"],
        row["time_frame"],
        row["report_created_at"],
        int(L),
        row["direction"],
        row["timeframe"],
        row["agg_type"],
        row["agg_base"],
        row["agg_state"],
    )

    # presence_rate: –¥–æ–ª—è –æ—Ç—á—ë—Ç–æ–≤, –≥–¥–µ –∫–ª—é—á –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–æ–≤–∞–ª
    present_flags = [1 if r["trades_total"] is not None else 0 for r in last_rows]
    L_eff = len(present_flags) if present_flags else 0
    presence_rate = (sum(present_flags) / L_eff) if L_eff > 0 else 0.0

    # growth_hist: ECDF —Ç–µ–∫—É—â–µ–≥–æ n –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∏—Å—Ç–æ—Ä–∏–∏ n (–≥–¥–µ –∫–ª—é—á –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–æ–≤–∞–ª)
    hist_n = [int(r["trades_total"]) for r in last_rows if r["trades_total"] is not None]
    growth_hist = _ecdf_rank(int(row["trades_total"] or 0), hist_n) if hist_n else 0.0

    return presence_rate, growth_hist, hist_n


# üî∏ Cross-window coherence: –≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å–æ–≥–ª–∞—Å–∏–µ –æ–∫–æ–Ω (–≤–µ—Å–∞ = R –æ–∫–Ω–∞)
async def _cross_window_coherence(conn, row: dict) -> float:
    rows = await conn.fetch(
        """
        SELECT time_frame, trades_total, trades_wins, winrate, avg_pnl_per_trade
        FROM v_mw_aggregated_with_time
        WHERE strategy_id = $1
          AND direction   = $2
          AND timeframe   = $3
          AND agg_type    = $4
          AND agg_base    = $5
          AND agg_state   = $6
          AND report_created_at = $7
        """,
        row["strategy_id"], row["direction"], row["timeframe"],
        row["agg_type"], row["agg_base"], row["agg_state"],
        row["report_created_at"],
    )
    if not rows:
        return 0.0

    num = 0.0
    den = 0.0
    for r in rows:
        n = int(r["trades_total"] or 0)
        w = int(r["trades_wins"] or 0)
        pnl = float(r["avg_pnl_per_trade"] or 0.0)
        if n <= 0:
            continue
        Rw = _wilson_lower_bound(w, n, Z)
        den += Rw
        aligned = 1.0 if (Rw > 0.5 and pnl > 0.0) else 0.0
        num += Rw * aligned

    return (num / den) if den > 0 else 0.0


# üî∏ –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –∫–ª—é—á–∞: —Ä–æ–±–∞—Å—Ç–Ω—ã–π z –Ω–∞ –∏—Å—Ç–æ—Ä–∏–∏ –∫–ª—é—á–∞ (median/MAD)
async def _stability_key(conn, row: dict, L: int) -> Tuple[float, int]:
    rows = await conn.fetch(
        """
        SELECT winrate
        FROM v_mw_aggregated_with_time
        WHERE strategy_id = $1
          AND time_frame  = $2
          AND direction   = $3
          AND timeframe   = $4
          AND agg_type    = $5
          AND agg_base    = $6
          AND agg_state   = $7
          AND report_created_at <= $8
        ORDER BY report_created_at DESC
        LIMIT $9
        """,
        row["strategy_id"], row["time_frame"], row["direction"], row["timeframe"],
        row["agg_type"], row["agg_base"], row["agg_state"],
        row["report_created_at"], int(L)
    )
    wr_hist = [float(r["winrate"] or 0.0) for r in rows]
    if len(wr_hist) < 2:
        return 1.0, len(wr_hist)

    wr_now = float(row["winrate"] or 0.0)
    med = _median(wr_hist)
    mad = _mad(wr_hist, med)
    scale = (mad / 0.6745) if mad > 0 else (abs(med) * 0.1 + 1e-6)
    robust_z = abs(wr_now - med) / (scale + 1e-12)
    S_key = 1.0 / (1.0 + robust_z)
    return S_key, len(wr_hist)


# üî∏ ¬´–ö–æ–≥–æ—Ä—Ç–Ω–∞—è¬ª —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å: –Ω–∞—Å–∫–æ–ª—å–∫–æ wr_now –≤—ã–±–∏–≤–∞–µ—Ç—Å—è –∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è wr –≤ —Ç–µ–∫—É—â–µ–º –ø—Ä–æ–≥–æ–Ω–µ
def _stability_cohort_now(row: dict, cohort_rows: List[dict]) -> float:
    wr_now = float(row["winrate"] or 0.0)
    wr_cohort = [float(x["winrate"] or 0.0) for x in cohort_rows]
    if len(wr_cohort) < 3:
        return 1.0
    med = _median(wr_cohort)
    mad = _mad(wr_cohort, med)
    scale = (mad / 0.6745) if mad > 0 else (abs(med) * 0.1 + 1e-6)
    robust_z = abs(wr_now - med) / (scale + 1e-12)
    return 1.0 / (1.0 + robust_z)


# üî∏ Wilson lower bound (–±–∏–Ω–æ–º–∏–∞–ª—å–Ω–∞—è –ø—Ä–æ–ø–æ—Ä—Ü–∏—è)
def _wilson_lower_bound(wins: int, n: int, z: float) -> float:
    if n <= 0:
        return 0.0
    p = wins / n
    denom = 1.0 + (z * z) / n
    center = p + (z * z) / (2.0 * n)
    adj = z * math.sqrt((p * (1.0 - p) / n) + (z * z) / (4.0 * n * n))
    lb = (center - adj) / denom
    return max(0.0, min(1.0, lb))


# üî∏ ECDF-—Ä–∞–Ω–≥: –¥–æ–ª—è –∑–Ω–∞—á–µ–Ω–∏–π ‚â§ x (–µ—Å–ª–∏ —Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç, 0.0)
def _ecdf_rank(x: int, values: List[int]) -> float:
    if not values:
        return 0.0
    cnt = sum(1 for v in values if v <= x)
    return cnt / len(values)


# üî∏ –ú–µ–¥–∏–∞–Ω–∞
def _median(arr: List[float]) -> float:
    n = len(arr)
    if n == 0:
        return 0.0
    s = sorted(arr)
    mid = n // 2
    if n % 2 == 1:
        return s[mid]
    return 0.5 * (s[mid - 1] + s[mid])


# üî∏ MAD (median absolute deviation)
def _mad(arr: List[float], med: float) -> float:
    if not arr:
        return 0.0
    dev = [abs(x - med) for x in arr]
    return _median(dev)