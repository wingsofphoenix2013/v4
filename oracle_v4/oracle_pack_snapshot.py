# oracle_pack_snapshot.py ‚Äî –≤–æ—Ä–∫–µ—Ä PACK-–æ—Ç—á—ë—Ç–æ–≤ (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–µ COMBO): –∞–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ PACK –∏ –ø—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏—è –≤ —Å—Ç—Ä–∏–º

# üî∏ –ò–º–ø–æ—Ä—Ç—ã
import asyncio
import logging
import json
from datetime import datetime, timedelta
from typing import Dict, List, Tuple

import infra

# üî∏ –õ–æ–≥–≥–µ—Ä
log = logging.getLogger("ORACLE_PACK_SNAPSHOT")

# üî∏ –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –≤–æ—Ä–∫–µ—Ä–∞ / –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è
INITIAL_DELAY_SEC = 90                    # –ø–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ 90 —Å–µ–∫—É–Ω–¥
INTERVAL_SEC = 6 * 60 * 60                # –ø–µ—Ä–∏–æ–¥–∏—á–Ω–æ—Å—Ç—å ‚Äî –∫–∞–∂–¥—ã–µ 6 —á–∞—Å–æ–≤
BATCH_SIZE = 500                          # —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –ø–æ –ø–æ–∑–∏—Ü–∏—è–º
WINDOW_TAGS = ("7d", "14d", "28d")
WINDOW_SIZES = {
    "7d": timedelta(days=7),
    "14d": timedelta(days=14),
    "28d": timedelta(days=28),
}
TF_ORDER = ("m5", "m15", "h1")

# üî∏ Whitelist –ø–æ–ª–µ–π –∏ –ö–û–ú–ë–ò–ù–ê–¶–ò–ô (solo –ù–ï –ø–∏—à–µ–º, —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω—ã–µ combo)
PACK_FIELDS = {
    "rsi":     ["bucket_low", "trend"],
    "mfi":     ["bucket_low", "trend"],
    "bb":      ["bucket", "bucket_delta", "bw_trend_smooth"],
    "lr":      ["bucket", "bucket_delta", "angle_trend"],
    "atr":     ["bucket", "bucket_delta"],
    "adx_dmi": ["adx_bucket_low", "gap_bucket_low", "adx_dynamic_smooth", "gap_dynamic_smooth"],
    "ema":     ["side", "dynamic", "dynamic_smooth"],
    "macd":    ["mode", "cross", "zero_side", "hist_bucket_low_pct", "hist_trend_smooth"],
}

# üî∏ –†–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–µ COMBO (—Å—Ç—Ä–æ–∫–∏ ‚Äî –∏–º–µ–Ω–∞ –ø–æ–ª–µ–π —á–µ—Ä–µ–∑ "|")
PACK_COMBOS = {
    "rsi": ["bucket_low|trend"],
    "mfi": ["bucket_low|trend"],
    "atr": ["bucket|bucket_delta"],

    "bb": [
        "bucket|bucket_delta",
        "bucket|bw_trend_smooth",
        "bucket_delta|bw_trend_smooth",
        "bucket|bucket_delta|bw_trend_smooth",
    ],

    "lr": [
        "bucket|bucket_delta",
        "bucket|angle_trend",
        "bucket_delta|angle_trend",
        "bucket|bucket_delta|angle_trend",
    ],

    "adx_dmi": [
        "adx_bucket_low|adx_dynamic_smooth",
        "gap_bucket_low|gap_dynamic_smooth",
        "adx_dynamic_smooth|gap_dynamic_smooth",
    ],

    "ema": [
        "side|dynamic_smooth",
        "side|dynamic",
    ],

    "macd": [
        "mode|cross",
        "mode|hist_trend_smooth",
        "mode|hist_bucket_low_pct",
        "cross|hist_trend_smooth",
        "mode|zero_side",
    ],
}

# üî∏ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Redis Stream (—Å–∏–≥–Ω–∞–ª ¬´–æ—Ç—á—ë—Ç –≥–æ—Ç–æ–≤¬ª –ø–æ PACK)
REPORT_READY_STREAM = "oracle:pack:reports_ready"
REPORT_READY_MAXLEN = 10_000  # XADD MAXLEN ~


# üî∏ –ü—É–±–ª–∏—á–Ω–∞—è —Ç–æ—á–∫–∞ –∑–∞–ø—É—Å–∫–∞ –≤–æ—Ä–∫–µ—Ä–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏–∑ oracle_v4_main.py ‚Üí run_periodic)
async def run_oracle_pack_snapshot():
    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏
    if infra.pg_pool is None or infra.redis_client is None:
        log.debug("‚ùå –ü—Ä–æ–ø—É—Å–∫: PG/Redis –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
        return

    # –Ω–∞–±–æ—Ä —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    strategies = sorted(infra.market_watcher_strategies or [])
    if not strategies:
        log.debug("‚ÑπÔ∏è –°—Ç—Ä–∞—Ç–µ–≥–∏–π —Å market_watcher=true –Ω–µ—Ç ‚Äî –Ω–µ—á–µ–≥–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å")
        return

    # –º–æ–º–µ–Ω—Ç –æ—Ç—Å—á—ë—Ç–∞ –æ–∫–Ω–∞
    t_ref = datetime.utcnow().replace(tzinfo=None)  # UTC-naive
    log.debug("üöÄ –°—Ç–∞—Ä—Ç PACK-–æ—Ç—á—ë—Ç–∞ t0=%s, —Å—Ç—Ä–∞—Ç–µ–≥–∏–π=%d", t_ref.isoformat(), len(strategies))

    # –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
    async with infra.pg_pool.acquire() as conn:
        for sid in strategies:
            try:
                await _process_strategy(conn, sid, t_ref)
            except Exception:
                log.exception("‚ùå –û—à–∏–±–∫–∞ PACK –æ–±—Ä–∞–±–æ—Ç–∫–∏ strategy_id=%s", sid)

    # –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ
    log.debug("‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ PACK-–æ—Ç—á—ë—Ç–æ–≤ (—Å—Ç—Ä–∞—Ç–µ–≥–∏–π=%d)", len(strategies))


# üî∏ –ü–æ–ª–Ω—ã–π –ø—Ä–æ—Ö–æ–¥ –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏: –≤—Å–µ –æ–∫–Ω–∞ ‚Üí –ø–æ –∫–∞–∂–¥–æ–º—É –æ–∫–Ω—É –≤—Å–µ TF –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ
async def _process_strategy(conn, strategy_id: int, t_ref: datetime):
    # —Ü–∏–∫–ª –ø–æ –æ–∫–Ω–∞–º (7d/14d/28d)
    for tag in WINDOW_TAGS:
        # —Ä–∞—Å—á—ë—Ç –≥—Ä–∞–Ω–∏—Ü –æ–∫–Ω–∞
        win_start = t_ref - WINDOW_SIZES[tag]
        win_end = t_ref

        # —à–∞–ø–∫–∞ –æ—Ç—á—ë—Ç–∞ (source='pack')
        report_id = await _create_report_header(conn, strategy_id, tag, win_start, win_end)

        # –º–µ—Ç—Ä–∏–∫–∏ ¬´—à–∞–ø–∫–∏¬ª (closed_total/wins/pnl/avg-*)
        closed_total, closed_wins, pnl_sum_total, pnl_sum_wins = await _calc_report_head_metrics(
            conn, strategy_id, win_start, win_end
        )
        days_in_window = WINDOW_SIZES[tag].total_seconds() / 86400.0
        winrate = round((closed_wins / closed_total) if closed_total else 0.0, 4)
        avg_pnl_per_trade = round((pnl_sum_total / closed_total) if closed_total else 0.0, 4)
        avg_trades_per_day = round(closed_total / days_in_window, 4)

        # —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è ¬´—à–∞–ø–∫–∏¬ª
        await _finalize_report_header(
            conn=conn,
            report_id=report_id,
            closed_total=closed_total,
            closed_wins=closed_wins,
            winrate=winrate,
            pnl_sum_total=pnl_sum_total,
            pnl_sum_wins=pnl_sum_wins,
            avg_pnl_per_trade=avg_pnl_per_trade,
            avg_trades_per_day=avg_trades_per_day,
        )

        # –µ—Å–ª–∏ —Å–¥–µ–ª–æ–∫ –Ω–µ—Ç ‚Äî —Å—Ä–∞–∑—É —É–≤–µ–¥–æ–º–ª—è–µ–º downstream
        if closed_total == 0:
            log.debug("[PACK REPORT] sid=%s win=%s total=0 ‚Äî –ø—Ä–æ–ø—É—Å–∫ TF/–∞–≥—Ä–µ–≥–∞—Ü–∏–∏", strategy_id, tag)
            try:
                await _emit_report_ready(
                    redis=infra.redis_client,
                    report_id=report_id,
                    strategy_id=strategy_id,
                    time_frame=tag,
                    window_start=win_start,
                    window_end=win_end,
                    aggregate_rows=0,
                    tf_done=[],
                    generated_at=datetime.utcnow().replace(tzinfo=None),
                )
            except Exception:
                log.exception("‚ùå –û—à–∏–±–∫–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ PACK REPORT_READY sid=%s win=%s (total=0)", strategy_id, tag)
            continue

        # –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ö–æ–¥ –ø–æ TF ‚Äî —Å—á–∏—Ç–∞–µ–º –ü–ê–ö–∏ –¢–û–õ–¨–ö–û –ø–æ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–º COMBO
        tf_done: List[str] = []
        for tf in TF_ORDER:
            # –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ TF –ø–æ –∫–∞–∂–¥–æ–º—É –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—É
            try:
                await _process_timeframe_rsi(conn, report_id, strategy_id, tag, tf, win_start, win_end, days_in_window)
                await _process_timeframe_mfi(conn, report_id, strategy_id, tag, tf, win_start, win_end, days_in_window)
                await _process_timeframe_bb(conn,  report_id, strategy_id, tag, tf, win_start, win_end, days_in_window)
                await _process_timeframe_lr(conn,  report_id, strategy_id, tag, tf, win_start, win_end, days_in_window)
                await _process_timeframe_atr(conn, report_id, strategy_id, tag, tf, win_start, win_end, days_in_window)
                await _process_timeframe_adx(conn, report_id, strategy_id, tag, tf, win_start, win_end, days_in_window)
                await _process_timeframe_ema(conn, report_id, strategy_id, tag, tf, win_start, win_end, days_in_window)
                await _process_timeframe_macd(conn,report_id, strategy_id, tag, tf, win_start, win_end, days_in_window)
                tf_done.append(tf)
            except Exception:
                log.exception("‚ùå –û—à–∏–±–∫–∞ PACK –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ sid=%s win=%s tf=%s", strategy_id, tag, tf)

        # –ø—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏—è ¬´–æ—Ç—á—ë—Ç –≥–æ—Ç–æ–≤¬ª (–¥–ª—è PACK-confidence)
        try:
            # —á–∏—Å–ª–æ –∞–≥—Ä–µ–≥–∞—Ç–Ω—ã—Ö —Å—Ç—Ä–æ–∫
            row_count = await conn.fetchval(
                "SELECT COUNT(*)::int FROM oracle_pack_aggregated_stat WHERE report_id = $1",
                report_id,
            )
            await _emit_report_ready(
                redis=infra.redis_client,
                report_id=report_id,
                strategy_id=strategy_id,
                time_frame=tag,
                window_start=win_start,
                window_end=win_end,
                aggregate_rows=int(row_count or 0),
                tf_done=tf_done,
                generated_at=datetime.utcnow().replace(tzinfo=None),
            )
        except Exception:
            log.exception("‚ùå –û—à–∏–±–∫–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ PACK REPORT_READY sid=%s win=%s", strategy_id, tag)

        # –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤ –ø–æ –æ–∫–Ω—É
        log.debug(
            "[PACK REPORT] sid=%s win=%s report_id=%s total=%d wins=%d wr=%.4f pnl_sum=%.4f avg_pnl=%.4f avg_tpd=%.4f",
            strategy_id, tag, report_id, closed_total, closed_wins, winrate, pnl_sum_total, avg_pnl_per_trade, avg_trades_per_day
        )


# üî∏ –°–æ–∑–¥–∞–Ω–∏–µ (–∏–ª–∏ –≤–æ–∑–≤—Ä–∞—Ç id) —à–∞–ø–∫–∏ –æ—Ç—á—ë—Ç–∞ (source='pack')
async def _create_report_header(conn, strategy_id: int, time_frame: str, win_start: datetime, win_end: datetime) -> int:
    # –≤—Å—Ç–∞–≤–∫–∞ —Å –∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å—é –ø–æ (sid, tf, window_start, window_end, source)
    row = await conn.fetchrow(
        """
        INSERT INTO oracle_report_stat (strategy_id, time_frame, window_start, window_end, source)
        VALUES ($1, $2, $3, $4, 'pack')
        ON CONFLICT (strategy_id, time_frame, window_start, window_end, source)
        DO UPDATE SET created_at = oracle_report_stat.created_at
        RETURNING id
        """,
        strategy_id, time_frame, win_start, win_end
    )
    # –≤–æ–∑–≤—Ä–∞—Ç id —Å–æ–∑–¥–∞–Ω–Ω–æ–π/–Ω–∞–π–¥–µ–Ω–Ω–æ–π —à–∞–ø–∫–∏
    return int(row["id"])


# üî∏ –†–∞—Å—á—ë—Ç –∞–≥—Ä–µ–≥–∞—Ç–æ–≤ –¥–ª—è —à–∞–ø–∫–∏ (–æ–¥–Ω–∏–º SQL)
async def _calc_report_head_metrics(conn, strategy_id: int, win_start: datetime, win_end: datetime):
    # —Å—É–º–º–∞—Ä–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –∑–∞–∫—Ä—ã—Ç—ã–º –ø–æ–∑–∏—Ü–∏—è–º –≤ –æ–∫–Ω–µ
    r = await conn.fetchrow(
        """
        SELECT
            COUNT(*)::int                            AS closed_total,
            COALESCE(SUM( (pnl > 0)::int ), 0)::int AS closed_wins,
            COALESCE(SUM(pnl), 0)::numeric(24,4)    AS pnl_sum_total,
            COALESCE(SUM(CASE WHEN pnl > 0 THEN pnl ELSE 0 END), 0)::numeric(24,4) AS pnl_sum_wins
        FROM positions_v4
        WHERE strategy_id = $1
          AND status = 'closed'
          AND closed_at >= $2
          AND closed_at <  $3
        """,
        strategy_id, win_start, win_end
    )
    # –≤–æ–∑–≤—Ä–∞—Ç –∫–æ—Ä—Ç–µ–∂–∞ –º–µ—Ç—Ä–∏–∫
    return int(r["closed_total"]), int(r["closed_wins"]), float(r["pnl_sum_total"]), float(r["pnl_sum_wins"])


# üî∏ –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è ¬´—à–∞–ø–∫–∏¬ª (update –º–µ—Ç—Ä–∏–∫)
async def _finalize_report_header(
    conn,
    report_id: int,
    closed_total: int,
    closed_wins: int,
    winrate: float,
    pnl_sum_total: float,
    pnl_sum_wins: float,
    avg_pnl_per_trade: float,
    avg_trades_per_day: float,
):
    # –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–ª–µ–π –æ—Ç—á—ë—Ç–∞
    await conn.execute(
        """
        UPDATE oracle_report_stat
           SET closed_total       = $2,
               closed_wins        = $3,
               winrate            = $4,
               pnl_sum_total      = $5,
               pnl_sum_wins       = $6,
               avg_pnl_per_trade  = $7,
               avg_trades_per_day = $8
         WHERE id = $1
        """,
        report_id,
        int(closed_total),
        int(closed_wins),
        round(float(winrate), 4),
        round(float(pnl_sum_total), 4),
        round(float(pnl_sum_wins), 4),
        round(float(avg_pnl_per_trade), 4),
        round(float(avg_trades_per_day), 4),
    )


# üî∏ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ combo-–∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞
def _emit_combo_inc(
    inc_map: Dict[Tuple, Dict[str, float]],
    *,
    report_id: int,
    strategy_id: int,
    time_frame: str,
    direction: str,
    timeframe: str,
    base: str,
    fields: Dict[str, str],
    combos: List[str],
    pnl: float,
):
    # –¥–æ–±–∞–≤–∏—Ç—å –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç—ã –¢–û–õ–¨–ö–û –ø–æ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–º combo ('field1|field2|...')
    is_win = pnl > 0.0
    for combo_str in combos:
        parts = combo_str.split("|")
        if not all(f in fields for f in parts):
            continue
        agg_key = combo_str
        agg_value = "|".join(f"{f}:{fields[f]}" for f in parts)
        k = (report_id, strategy_id, time_frame, direction, timeframe, base, "combo", agg_key, agg_value)
        inc = inc_map.setdefault(k, {"t": 0, "w": 0, "pt": 0.0, "pw": 0.0})
        inc["t"] += 1
        if is_win:
            inc["w"] += 1
            inc["pw"] = round(inc["pw"] + pnl, 4)
        inc["pt"] = round(inc["pt"] + pnl, 4)


# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ TF: PACK=RSI
async def _process_timeframe_rsi(conn, report_id, strategy_id, time_frame, timeframe, win_start, win_end, days_in_window):
    # –≤—ã–±–æ—Ä –∑–∞–∫—Ä—ã—Ç—ã—Ö –ø–æ–∑–∏—Ü–∏–π
    rows = await conn.fetch(
        """
        SELECT position_uid, direction, pnl
          FROM positions_v4
         WHERE strategy_id = $1 AND status = 'closed'
           AND closed_at >= $2 AND closed_at < $3
        """,
        strategy_id, win_start, win_end
    )
    # –Ω–µ—Ç –ø–æ–∑–∏—Ü–∏–π ‚Äî –≤—ã—Ö–æ–¥–∏–º
    positions = [dict(r) for r in rows]
    if not positions:
        log.debug("[PACK-RSI] sid=%s win=%s tf=%s total=0", strategy_id, time_frame, timeframe)
        return

    # –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è RSI
    total, ok_rows = len(positions), 0
    rsi_fields = PACK_FIELDS["rsi"]
    rsi_combos = PACK_COMBOS["rsi"]

    # –ø–æ –±–∞—Ç—á–∞–º
    for bi in range((total + BATCH_SIZE - 1) // BATCH_SIZE):
        # —Å—Ä–µ–∑ –±–∞—Ç—á–∞
        batch = positions[bi * BATCH_SIZE : (bi + 1) * BATCH_SIZE]
        uid_list = [p["position_uid"] for p in batch]
        uid_meta = {p["position_uid"]: (p["direction"], float(p["pnl"] or 0.0)) for p in batch}

        # —á—Ç–µ–Ω–∏–µ PACK-–∑–Ω–∞—á–µ–Ω–∏–π RSI
        rows_pack = await conn.fetch(
            """
            SELECT position_uid, param_base, param_name, value_num, value_text, status
              FROM indicator_position_stat
             WHERE position_uid = ANY($1::text[])
               AND param_type = 'pack' AND timeframe = $2
               AND param_base LIKE 'rsi%' AND param_name = ANY($3::text[])
            """,
            uid_list, timeframe, rsi_fields,
        )

        # –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∑–Ω–∞—á–µ–Ω–∏–π –ø–æ uid ‚Üí base ‚Üí {field: value}
        by_uid: Dict[str, Dict[str, Dict[str, str]]] = {}
        bad: Dict[str, set] = {}
        for r in rows_pack:
            uid, base, status = r["position_uid"], r["param_base"], r["status"]
            if status != "ok":
                bad.setdefault(uid, set()).add(base)
                continue
            name = r["param_name"]
            val = str(r["value_text"]) if r["value_text"] is not None else (
                f"{float(r['value_num'] or 0.0):.8f}".rstrip('0').rstrip('.')
            )
            by_uid.setdefault(uid, {}).setdefault(base, {})[name] = val

        # –Ω–∞–∫–∞–ø–ª–∏–≤–∞–µ–º –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç—ã —Ç–æ–ª—å–∫–æ –ø–æ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–º combo
        inc_map: Dict[Tuple, Dict[str, float]] = {}
        for uid, base_map in by_uid.items():
            direction, pnl = uid_meta.get(uid, ("long", 0.0))
            for base, fields in base_map.items():
                if base in bad.get(uid, set()):
                    continue
                _emit_combo_inc(
                    inc_map,
                    report_id=report_id, strategy_id=strategy_id, time_frame=time_frame,
                    direction=direction, timeframe=timeframe, base=base, fields=fields,
                    combos=rsi_combos, pnl=pnl,
                )

        # –∑–∞–ø–∏—Å—å –±–∞—Ç—á–∞
        if inc_map:
            await _upsert_aggregates_batch(conn, inc_map, days_in_window)
            ok_rows += sum(v["t"] for v in inc_map.values())

    # –ª–æ–≥ –ø–æ TF
    log.debug("[PACK-RSI] sid=%s win=%s tf=%s positions=%d agg_rows=%d", strategy_id, time_frame, timeframe, total, ok_rows)


# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ TF: PACK=MFI
async def _process_timeframe_mfi(conn, report_id, strategy_id, time_frame, timeframe, win_start, win_end, days_in_window):
    # –≤—ã–±–æ—Ä –∑–∞–∫—Ä—ã—Ç—ã—Ö –ø–æ–∑–∏—Ü–∏–π
    rows = await conn.fetch(
        """
        SELECT position_uid, direction, pnl
          FROM positions_v4
         WHERE strategy_id = $1 AND status = 'closed'
           AND closed_at >= $2 AND closed_at < $3
        """,
        strategy_id, win_start, win_end
    )
    # –Ω–µ—Ç –ø–æ–∑–∏—Ü–∏–π ‚Äî –≤—ã—Ö–æ–¥–∏–º
    positions = [dict(r) for r in rows]
    if not positions:
        log.debug("[PACK-MFI] sid=%s win=%s tf=%s total=0", strategy_id, time_frame, timeframe)
        return

    # –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è MFI
    total, ok_rows = len(positions), 0
    mfi_fields = PACK_FIELDS["mfi"]
    mfi_combos = PACK_COMBOS["mfi"]

    # –ø–æ –±–∞—Ç—á–∞–º
    for bi in range((total + BATCH_SIZE - 1) // BATCH_SIZE):
        # —Å—Ä–µ–∑ –±–∞—Ç—á–∞
        batch = positions[bi * BATCH_SIZE : (bi + 1) * BATCH_SIZE]
        uid_list = [p["position_uid"] for p in batch]
        uid_meta = {p["position_uid"]: (p["direction"], float(p["pnl"] or 0.0)) for p in batch}

        # —á—Ç–µ–Ω–∏–µ PACK-–∑–Ω–∞—á–µ–Ω–∏–π MFI
        rows_pack = await conn.fetch(
            """
            SELECT position_uid, param_base, param_name, value_num, value_text, status
              FROM indicator_position_stat
             WHERE position_uid = ANY($1::text[])
               AND param_type = 'pack' AND timeframe = $2
               AND param_base LIKE 'mfi%' AND param_name = ANY($3::text[])
            """,
            uid_list, timeframe, mfi_fields,
        )

        # –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∑–Ω–∞—á–µ–Ω–∏–π
        by_uid: Dict[str, Dict[str, Dict[str, str]]] = {}
        bad: Dict[str, set] = {}
        for r in rows_pack:
            uid, base, status = r["position_uid"], r["param_base"], r["status"]
            if status != "ok":
                bad.setdefault(uid, set()).add(base)
                continue
            name = r["param_name"]
            val = str(r["value_text"]) if r["value_text"] is not None else (
                f"{float(r['value_num'] or 0.0):.8f}".rstrip('0').rstrip('.')
            )
            by_uid.setdefault(uid, {}).setdefault(base, {})[name] = val

        # –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç—ã –ø–æ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–º combo
        inc_map: Dict[Tuple, Dict[str, float]] = {}
        for uid, base_map in by_uid.items():
            direction, pnl = uid_meta.get(uid, ("long", 0.0))
            for base, fields in base_map.items():
                if base in bad.get(uid, set()):
                    continue
                _emit_combo_inc(
                    inc_map,
                    report_id=report_id, strategy_id=strategy_id, time_frame=time_frame,
                    direction=direction, timeframe=timeframe, base=base, fields=fields,
                    combos=mfi_combos, pnl=pnl,
                )

        # –∑–∞–ø–∏—Å—å –±–∞—Ç—á–∞
        if inc_map:
            await _upsert_aggregates_batch(conn, inc_map, days_in_window)
            ok_rows += sum(v["t"] for v in inc_map.values())

    # –ª–æ–≥ –ø–æ TF
    log.debug("[PACK-MFI] sid=%s win=%s tf=%s positions=%d agg_rows=%d", strategy_id, time_frame, timeframe, total, ok_rows)


# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ TF: PACK=BB
async def _process_timeframe_bb(conn, report_id, strategy_id, time_frame, timeframe, win_start, win_end, days_in_window):
    # –≤—ã–±–æ—Ä –∑–∞–∫—Ä—ã—Ç—ã—Ö –ø–æ–∑–∏—Ü–∏–π
    rows = await conn.fetch(
        """
        SELECT position_uid, direction, pnl
          FROM positions_v4
         WHERE strategy_id = $1 AND status = 'closed'
           AND closed_at >= $2 AND closed_at < $3
        """,
        strategy_id, win_start, win_end
    )
    # –Ω–µ—Ç –ø–æ–∑–∏—Ü–∏–π ‚Äî –≤—ã—Ö–æ–¥–∏–º
    positions = [dict(r) for r in rows]
    if not positions:
        log.debug("[PACK-BB] sid=%s win=%s tf=%s total=0", strategy_id, time_frame, timeframe)
        return

    # –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è BB
    total, ok_rows = len(positions), 0
    bb_fields = PACK_FIELDS["bb"]
    bb_combos = PACK_COMBOS["bb"]

    # –ø–æ –±–∞—Ç—á–∞–º
    for bi in range((total + BATCH_SIZE - 1) // BATCH_SIZE):
        # —Å—Ä–µ–∑ –±–∞—Ç—á–∞
        batch = positions[bi * BATCH_SIZE : (bi + 1) * BATCH_SIZE]
        uid_list = [p["position_uid"] for p in batch]
        uid_meta = {p["position_uid"]: (p["direction"], float(p["pnl"] or 0.0)) for p in batch}

        # —á—Ç–µ–Ω–∏–µ PACK-–∑–Ω–∞—á–µ–Ω–∏–π BB
        rows_pack = await conn.fetch(
            """
            SELECT position_uid, param_base, param_name, value_num, value_text, status
              FROM indicator_position_stat
             WHERE position_uid = ANY($1::text[])
               AND param_type = 'pack' AND timeframe = $2
               AND param_base LIKE 'bb%' AND param_name = ANY($3::text[])
            """,
            uid_list, timeframe, bb_fields,
        )

        # –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∑–Ω–∞—á–µ–Ω–∏–π
        by_uid: Dict[str, Dict[str, Dict[str, str]]] = {}
        bad: Dict[str, set] = {}
        for r in rows_pack:
            uid, base, status = r["position_uid"], r["param_base"], r["status"]
            if status != "ok":
                bad.setdefault(uid, set()).add(base)
                continue
            name = r["param_name"]
            val = str(r["value_text"]) if r["value_text"] is not None else (
                f"{float(r['value_num'] or 0.0):.8f}".rstrip('0').rstrip('.')
            )
            by_uid.setdefault(uid, {}).setdefault(base, {})[name] = val

        # –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç—ã –ø–æ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–º combo
        inc_map: Dict[Tuple, Dict[str, float]] = {}
        for uid, base_map in by_uid.items():
            direction, pnl = uid_meta.get(uid, ("long", 0.0))
            for base, fields in base_map.items():
                if base in bad.get(uid, set()):
                    continue
                _emit_combo_inc(
                    inc_map,
                    report_id=report_id, strategy_id=strategy_id, time_frame=time_frame,
                    direction=direction, timeframe=timeframe, base=base, fields=fields,
                    combos=bb_combos, pnl=pnl,
                )

        # –∑–∞–ø–∏—Å—å –±–∞—Ç—á–∞
        if inc_map:
            await _upsert_aggregates_batch(conn, inc_map, days_in_window)
            ok_rows += sum(v["t"] for v in inc_map.values())

    # –ª–æ–≥ –ø–æ TF
    log.debug("[PACK-BB] sid=%s win=%s tf=%s positions=%d agg_rows=%d", strategy_id, time_frame, timeframe, total, ok_rows)


# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ TF: PACK=LR
async def _process_timeframe_lr(conn, report_id, strategy_id, time_frame, timeframe, win_start, win_end, days_in_window):
    # –≤—ã–±–æ—Ä –∑–∞–∫—Ä—ã—Ç—ã—Ö –ø–æ–∑–∏—Ü–∏–π
    rows = await conn.fetch(
        """
        SELECT position_uid, direction, pnl
          FROM positions_v4
         WHERE strategy_id = $1 AND status = 'closed'
           AND closed_at >= $2 AND closed_at < $3
        """,
        strategy_id, win_start, win_end
    )
    # –Ω–µ—Ç –ø–æ–∑–∏—Ü–∏–π ‚Äî –≤—ã—Ö–æ–¥–∏–º
    positions = [dict(r) for r in rows]
    if not positions:
        log.debug("[PACK-LR] sid=%s win=%s tf=%s total=0", strategy_id, time_frame, timeframe)
        return

    # –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è LR
    total, ok_rows = len(positions), 0
    lr_fields = PACK_FIELDS["lr"]
    lr_combos = PACK_COMBOS["lr"]

    # –ø–æ –±–∞—Ç—á–∞–º
    for bi in range((total + BATCH_SIZE - 1) // BATCH_SIZE):
        # —Å—Ä–µ–∑ –±–∞—Ç—á–∞
        batch = positions[bi * BATCH_SIZE : (bi + 1) * BATCH_SIZE]
        uid_list = [p["position_uid"] for p in batch]
        uid_meta = {p["position_uid"]: (p["direction"], float(p["pnl"] or 0.0)) for p in batch}

        # —á—Ç–µ–Ω–∏–µ PACK-–∑–Ω–∞—á–µ–Ω–∏–π LR
        rows_pack = await conn.fetch(
            """
            SELECT position_uid, param_base, param_name, value_num, value_text, status
              FROM indicator_position_stat
             WHERE position_uid = ANY($1::text[])
               AND param_type = 'pack' AND timeframe = $2
               AND param_base LIKE 'lr%' AND param_name = ANY($3::text[])
            """,
            uid_list, timeframe, lr_fields,
        )

        # –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∑–Ω–∞—á–µ–Ω–∏–π
        by_uid: Dict[str, Dict[str, Dict[str, str]]] = {}
        bad: Dict[str, set] = {}
        for r in rows_pack:
            uid, base, status = r["position_uid"], r["param_base"], r["status"]
            if status != "ok":
                bad.setdefault(uid, set()).add(base)
                continue
            name = r["param_name"]
            val = str(r["value_text"]) if r["value_text"] is not None else (
                f"{float(r['value_num'] or 0.0):.8f}".rstrip('0').rstrip('.')
            )
            by_uid.setdefault(uid, {}).setdefault(base, {})[name] = val

        # –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç—ã –ø–æ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–º combo
        inc_map: Dict[Tuple, Dict[str, float]] = {}
        for uid, base_map in by_uid.items():
            direction, pnl = uid_meta.get(uid, ("long", 0.0))
            for base, fields in base_map.items():
                if base in bad.get(uid, set()):
                    continue
                _emit_combo_inc(
                    inc_map,
                    report_id=report_id, strategy_id=strategy_id, time_frame=time_frame,
                    direction=direction, timeframe=timeframe, base=base, fields=fields,
                    combos=lr_combos, pnl=pnl,
                )

        # –∑–∞–ø–∏—Å—å –±–∞—Ç—á–∞
        if inc_map:
            await _upsert_aggregates_batch(conn, inc_map, days_in_window)
            ok_rows += sum(v["t"] for v in inc_map.values())

    # –ª–æ–≥ –ø–æ TF
    log.debug("[PACK-LR] sid=%s win=%s tf=%s positions=%d agg_rows=%d", strategy_id, time_frame, timeframe, total, ok_rows)


# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ TF: PACK=ATR
async def _process_timeframe_atr(conn, report_id, strategy_id, time_frame, timeframe, win_start, win_end, days_in_window):
    # –≤—ã–±–æ—Ä –∑–∞–∫—Ä—ã—Ç—ã—Ö –ø–æ–∑–∏—Ü–∏–π
    rows = await conn.fetch(
        """
        SELECT position_uid, direction, pnl
          FROM positions_v4
         WHERE strategy_id = $1 AND status = 'closed'
           AND closed_at >= $2 AND closed_at < $3
        """,
        strategy_id, win_start, win_end
    )
    # –Ω–µ—Ç –ø–æ–∑–∏—Ü–∏–π ‚Äî –≤—ã—Ö–æ–¥–∏–º
    positions = [dict(r) for r in rows]
    if not positions:
        log.debug("[PACK-ATR] sid=%s win=%s tf=%s total=0", strategy_id, time_frame, timeframe)
        return

    # –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è ATR
    total, ok_rows = len(positions), 0
    atr_fields = PACK_FIELDS["atr"]
    atr_combos = PACK_COMBOS["atr"]

    # –ø–æ –±–∞—Ç—á–∞–º
    for bi in range((total + BATCH_SIZE - 1) // BATCH_SIZE):
        # —Å—Ä–µ–∑ –±–∞—Ç—á–∞
        batch = positions[bi * BATCH_SIZE : (bi + 1) * BATCH_SIZE]
        uid_list = [p["position_uid"] for p in batch]
        uid_meta = {p["position_uid"]: (p["direction"], float(p["pnl"] or 0.0)) for p in batch}

        # —á—Ç–µ–Ω–∏–µ PACK-–∑–Ω–∞—á–µ–Ω–∏–π ATR
        rows_pack = await conn.fetch(
            """
            SELECT position_uid, param_base, param_name, value_num, value_text, status
              FROM indicator_position_stat
             WHERE position_uid = ANY($1::text[])
               AND param_type = 'pack' AND timeframe = $2
               AND param_base LIKE 'atr%' AND param_name = ANY($3::text[])
            """,
            uid_list, timeframe, atr_fields,
        )

        # –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∑–Ω–∞—á–µ–Ω–∏–π
        by_uid: Dict[str, Dict[str, Dict[str, str]]] = {}
        bad: Dict[str, set] = {}
        for r in rows_pack:
            uid, base, status = r["position_uid"], r["param_base"], r["status"]
            if status != "ok":
                bad.setdefault(uid, set()).add(base)
                continue
            name = r["param_name"]
            val = str(r["value_text"]) if r["value_text"] is not None else (
                f"{float(r['value_num'] or 0.0):.8f}".rstrip('0').rstrip('.')
            )
            by_uid.setdefault(uid, {}).setdefault(base, {})[name] = val

        # –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç—ã –ø–æ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–º combo
        inc_map: Dict[Tuple, Dict[str, float]] = {}
        for uid, base_map in by_uid.items():
            direction, pnl = uid_meta.get(uid, ("long", 0.0))
            for base, fields in base_map.items():
                if base in bad.get(uid, set()):
                    continue
                _emit_combo_inc(
                    inc_map,
                    report_id=report_id, strategy_id=strategy_id, time_frame=time_frame,
                    direction=direction, timeframe=timeframe, base=base, fields=fields,
                    combos=atr_combos, pnl=pnl,
                )

        # –∑–∞–ø–∏—Å—å –±–∞—Ç—á–∞
        if inc_map:
            await _upsert_aggregates_batch(conn, inc_map, days_in_window)
            ok_rows += sum(v["t"] for v in inc_map.values())

    # –ª–æ–≥ –ø–æ TF
    log.debug("[PACK-ATR] sid=%s win=%s tf=%s positions=%d agg_rows=%d", strategy_id, time_frame, timeframe, total, ok_rows)


# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ TF: PACK=ADX_DMI
async def _process_timeframe_adx(conn, report_id, strategy_id, time_frame, timeframe, win_start, win_end, days_in_window):
    # –≤—ã–±–æ—Ä –∑–∞–∫—Ä—ã—Ç—ã—Ö –ø–æ–∑–∏—Ü–∏–π
    rows = await conn.fetch(
        """
        SELECT position_uid, direction, pnl
          FROM positions_v4
         WHERE strategy_id = $1 AND status = 'closed'
           AND closed_at >= $2 AND closed_at < $3
        """,
        strategy_id, win_start, win_end
    )
    # –Ω–µ—Ç –ø–æ–∑–∏—Ü–∏–π ‚Äî –≤—ã—Ö–æ–¥–∏–º
    positions = [dict(r) for r in rows]
    if not positions:
        log.debug("[PACK-ADX_DMI] sid=%s win=%s tf=%s total=0", strategy_id, time_frame, timeframe)
        return

    # –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è ADX_DMI
    total, ok_rows = len(positions), 0
    adx_fields = PACK_FIELDS["adx_dmi"]
    adx_combos = PACK_COMBOS["adx_dmi"]

    # –ø–æ –±–∞—Ç—á–∞–º
    for bi in range((total + BATCH_SIZE - 1) // BATCH_SIZE):
        # —Å—Ä–µ–∑ –±–∞—Ç—á–∞
        batch = positions[bi * BATCH_SIZE : (bi + 1) * BATCH_SIZE]
        uid_list = [p["position_uid"] for p in batch]
        uid_meta = {p["position_uid"]: (p["direction"], float(p["pnl"] or 0.0)) for p in batch}

        # —á—Ç–µ–Ω–∏–µ PACK-–∑–Ω–∞—á–µ–Ω–∏–π ADX_DMI
        rows_pack = await conn.fetch(
            """
            SELECT position_uid, param_base, param_name, value_num, value_text, status
              FROM indicator_position_stat
             WHERE position_uid = ANY($1::text[])
               AND param_type = 'pack' AND timeframe = $2
               AND param_base LIKE 'adx_dmi%' AND param_name = ANY($3::text[])
            """,
            uid_list, timeframe, adx_fields,
        )

        # –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∑–Ω–∞—á–µ–Ω–∏–π
        by_uid: Dict[str, Dict[str, Dict[str, str]]] = {}
        bad: Dict[str, set] = {}
        for r in rows_pack:
            uid, base, status = r["position_uid"], r["param_base"], r["status"]
            if status != "ok":
                bad.setdefault(uid, set()).add(base)
                continue
            name = r["param_name"]
            val = str(r["value_text"]) if r["value_text"] is not None else (
                f"{float(r['value_num'] or 0.0):.8f}".rstrip('0').rstrip('.')
            )
            by_uid.setdefault(uid, {}).setdefault(base, {})[name] = val

        # –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç—ã –ø–æ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–º combo
        inc_map: Dict[Tuple, Dict[str, float]] = {}
        for uid, base_map in by_uid.items():
            direction, pnl = uid_meta.get(uid, ("long", 0.0))
            for base, fields in base_map.items():
                if base in bad.get(uid, set()):
                    continue
                _emit_combo_inc(
                    inc_map,
                    report_id=report_id, strategy_id=strategy_id, time_frame=time_frame,
                    direction=direction, timeframe=timeframe, base=base, fields=fields,
                    combos=adx_combos, pnl=pnl,
                )

        # –∑–∞–ø–∏—Å—å –±–∞—Ç—á–∞
        if inc_map:
            await _upsert_aggregates_batch(conn, inc_map, days_in_window)
            ok_rows += sum(v["t"] for v in inc_map.values())

    # –ª–æ–≥ –ø–æ TF
    log.debug("[PACK-ADX_DMI] sid=%s win=%s tf=%s positions=%d agg_rows=%d", strategy_id, time_frame, timeframe, total, ok_rows)


# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ TF: PACK=EMA
async def _process_timeframe_ema(conn, report_id, strategy_id, time_frame, timeframe, win_start, win_end, days_in_window):
    # –≤—ã–±–æ—Ä –∑–∞–∫—Ä—ã—Ç—ã—Ö –ø–æ–∑–∏—Ü–∏–π
    rows = await conn.fetch(
        """
        SELECT position_uid, direction, pnl
          FROM positions_v4
         WHERE strategy_id = $1 AND status = 'closed'
           AND closed_at >= $2 AND closed_at < $3
        """,
        strategy_id, win_start, win_end
    )
    # –Ω–µ—Ç –ø–æ–∑–∏—Ü–∏–π ‚Äî –≤—ã—Ö–æ–¥–∏–º
    positions = [dict(r) for r in rows]
    if not positions:
        log.debug("[PACK-EMA] sid=%s win=%s tf=%s total=0", strategy_id, time_frame, timeframe)
        return

    # –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è EMA
    total, ok_rows = len(positions), 0
    ema_fields = PACK_FIELDS["ema"]
    ema_combos = PACK_COMBOS["ema"]

    # –ø–æ –±–∞—Ç—á–∞–º
    for bi in range((total + BATCH_SIZE - 1) // BATCH_SIZE):
        # —Å—Ä–µ–∑ –±–∞—Ç—á–∞
        batch = positions[bi * BATCH_SIZE : (bi + 1) * BATCH_SIZE]
        uid_list = [p["position_uid"] for p in batch]
        uid_meta = {p["position_uid"]: (p["direction"], float(p["pnl"] or 0.0)) for p in batch}

        # —á—Ç–µ–Ω–∏–µ PACK-–∑–Ω–∞—á–µ–Ω–∏–π EMA
        rows_pack = await conn.fetch(
            """
            SELECT position_uid, param_base, param_name, value_num, value_text, status
              FROM indicator_position_stat
             WHERE position_uid = ANY($1::text[])
               AND param_type = 'pack' AND timeframe = $2
               AND param_base LIKE 'ema%' AND param_name = ANY($3::text[])
            """,
            uid_list, timeframe, ema_fields,
        )

        # –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∑–Ω–∞—á–µ–Ω–∏–π
        by_uid: Dict[str, Dict[str, Dict[str, str]]] = {}
        bad: Dict[str, set] = {}
        for r in rows_pack:
            uid, base, status = r["position_uid"], r["param_base"], r["status"]
            if status != "ok":
                bad.setdefault(uid, set()).add(base)
                continue
            name = r["param_name"]
            val = str(r["value_text"]) if r["value_text"] is not None else (
                f"{float(r['value_num'] or 0.0):.8f}".rstrip('0').rstrip('.')
            )
            by_uid.setdefault(uid, {}).setdefault(base, {})[name] = val

        # –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç—ã –ø–æ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–º combo
        inc_map: Dict[Tuple, Dict[str, float]] = {}
        for uid, base_map in by_uid.items():
            direction, pnl = uid_meta.get(uid, ("long", 0.0))
            for base, fields in base_map.items():
                if base in bad.get(uid, set()):
                    continue
                _emit_combo_inc(
                    inc_map,
                    report_id=report_id, strategy_id=strategy_id, time_frame=time_frame,
                    direction=direction, timeframe=timeframe, base=base, fields=fields,
                    combos=ema_combos, pnl=pnl,
                )

        # –∑–∞–ø–∏—Å—å –±–∞—Ç—á–∞
        if inc_map:
            await _upsert_aggregates_batch(conn, inc_map, days_in_window)
            ok_rows += sum(v["t"] for v in inc_map.values())

    # –ª–æ–≥ –ø–æ TF
    log.debug("[PACK-EMA] sid=%s win=%s tf=%s positions=%d agg_rows=%d", strategy_id, time_frame, timeframe, total, ok_rows)


# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ TF: PACK=MACD
async def _process_timeframe_macd(conn, report_id, strategy_id, time_frame, timeframe, win_start, win_end, days_in_window):
    # –≤—ã–±–æ—Ä –∑–∞–∫—Ä—ã—Ç—ã—Ö –ø–æ–∑–∏—Ü–∏–π
    rows = await conn.fetch(
        """
        SELECT position_uid, direction, pnl
          FROM positions_v4
         WHERE strategy_id = $1 AND status = 'closed'
           AND closed_at >= $2 AND closed_at < $3
        """,
        strategy_id, win_start, win_end
    )
    # –Ω–µ—Ç –ø–æ–∑–∏—Ü–∏–π ‚Äî –≤—ã—Ö–æ–¥–∏–º
    positions = [dict(r) for r in rows]
    if not positions:
        log.debug("[PACK-MACD] sid=%s win=%s tf=%s total=0", strategy_id, time_frame, timeframe)
        return

    # –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è MACD
    total, ok_rows = len(positions), 0
    macd_fields = PACK_FIELDS["macd"]
    macd_combos = PACK_COMBOS["macd"]

    # –ø–æ –±–∞—Ç—á–∞–º
    for bi in range((total + BATCH_SIZE - 1) // BATCH_SIZE):
        # —Å—Ä–µ–∑ –±–∞—Ç—á–∞
        batch = positions[bi * BATCH_SIZE : (bi + 1) * BATCH_SIZE]
        uid_list = [p["position_uid"] for p in batch]
        uid_meta = {p["position_uid"]: (p["direction"], float(p["pnl"] or 0.0)) for p in batch}

        # —á—Ç–µ–Ω–∏–µ PACK-–∑–Ω–∞—á–µ–Ω–∏–π MACD
        rows_pack = await conn.fetch(
            """
            SELECT position_uid, param_base, param_name, value_num, value_text, status
              FROM indicator_position_stat
             WHERE position_uid = ANY($1::text[])
               AND param_type = 'pack' AND timeframe = $2
               AND param_base LIKE 'macd%' AND param_name = ANY($3::text[])
            """,
            uid_list, timeframe, macd_fields,
        )

        # –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∑–Ω–∞—á–µ–Ω–∏–π
        by_uid: Dict[str, Dict[str, Dict[str, str]]] = {}
        bad: Dict[str, set] = {}
        for r in rows_pack:
            uid, base, status = r["position_uid"], r["param_base"], r["status"]
            if status != "ok":
                bad.setdefault(uid, set()).add(base)
                continue
            name = r["param_name"]
            val = str(r["value_text"]) if r["value_text"] is not None else (
                f"{float(r['value_num'] or 0.0):.8f}".rstrip('0').rstrip('.')
            )
            by_uid.setdefault(uid, {}).setdefault(base, {})[name] = val

        # –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç—ã –ø–æ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–º combo
        inc_map: Dict[Tuple, Dict[str, float]] = {}
        for uid, base_map in by_uid.items():
            direction, pnl = uid_meta.get(uid, ("long", 0.0))
            for base, fields in base_map.items():
                if base in bad.get(uid, set()):
                    continue
                _emit_combo_inc(
                    inc_map,
                    report_id=report_id, strategy_id=strategy_id, time_frame=time_frame,
                    direction=direction, timeframe=timeframe, base=base, fields=fields,
                    combos=macd_combos, pnl=pnl,
                )

        # –∑–∞–ø–∏—Å—å –±–∞—Ç—á–∞
        if inc_map:
            await _upsert_aggregates_batch(conn, inc_map, days_in_window)
            ok_rows += sum(v["t"] for v in inc_map.values())

    # –ª–æ–≥ –ø–æ TF
    log.debug("[PACK-MACD] sid=%s win=%s tf=%s positions=%d agg_rows=%d", strategy_id, time_frame, timeframe, total, ok_rows)


# üî∏ –ë–∞—Ç—á–µ–≤—ã–π UPSERT (UNNEST + ON CONFLICT) —Å –ø–µ—Ä–µ—Å—á—ë—Ç–æ–º –º–µ—Ç—Ä–∏–∫
async def _upsert_aggregates_batch(conn, inc_map: Dict[Tuple, Dict[str, float]], days_in_window: float):
    # –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–∞—Å—Å–∏–≤–æ–≤ –ø–æ–ª–µ–π –ø–æ–¥ UNNEST
    report_ids, strategy_ids, time_frames, directions = [], [], [], []
    timeframes, pack_bases, agg_types, agg_keys, agg_values = [], [], [], [], []
    trades_inc, wins_inc, pnl_total_inc, pnl_wins_inc = [], [], [], []

    # —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ inc_map
    for (report_id, strategy_id, time_frame, direction, timeframe, pack_base, agg_type, agg_key, agg_value), v in inc_map.items():
        report_ids.append(report_id)
        strategy_ids.append(strategy_id)
        time_frames.append(time_frame)
        directions.append(direction)
        timeframes.append(timeframe)
        pack_bases.append(pack_base)
        agg_types.append(agg_type)
        agg_keys.append(agg_key)
        agg_values.append(agg_value)
        trades_inc.append(int(v["t"]))
        wins_inc.append(int(v["w"]))
        pnl_total_inc.append(round(float(v["pt"]), 4))
        pnl_wins_inc.append(round(float(v["pw"]), 4))

    # UPSERT + –ø–µ—Ä–µ—Å—á—ë—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö
    await conn.execute(
        """
        WITH data AS (
          SELECT
            unnest($1::bigint[])   AS report_id,
            unnest($2::int[])      AS strategy_id,
            unnest($3::text[])     AS time_frame,
            unnest($4::text[])     AS direction,
            unnest($5::text[])     AS timeframe,
            unnest($6::text[])     AS pack_base,
            unnest($7::text[])     AS agg_type,
            unnest($8::text[])     AS agg_key,
            unnest($9::text[])     AS agg_value,
            unnest($10::int[])     AS t_inc,
            unnest($11::int[])     AS w_inc,
            unnest($12::numeric[]) AS pt_inc,
            unnest($13::numeric[]) AS pw_inc
        )
        INSERT INTO oracle_pack_aggregated_stat (
            report_id, strategy_id, time_frame, direction, timeframe, pack_base, agg_type, agg_key, agg_value,
            trades_total, trades_wins, winrate,
            pnl_sum_total, pnl_sum_wins,
            avg_pnl_per_trade, avg_trades_per_day
        )
        SELECT
            report_id, strategy_id, time_frame, direction, timeframe, pack_base, agg_type, agg_key, agg_value,
            t_inc, w_inc,
            ROUND(CASE WHEN t_inc > 0 THEN w_inc::numeric / t_inc::numeric ELSE 0 END, 4),
            pt_inc, pw_inc,
            ROUND(CASE WHEN t_inc > 0 THEN pt_inc::numeric / t_inc::numeric ELSE 0 END, 4),
            ROUND(t_inc::numeric / $14::numeric, 4)
        FROM data
        ON CONFLICT (report_id, strategy_id, time_frame, direction, timeframe, pack_base, agg_type, agg_key, agg_value)
        DO UPDATE SET
            trades_total       = oracle_pack_aggregated_stat.trades_total + EXCLUDED.trades_total,
            trades_wins        = oracle_pack_aggregated_stat.trades_wins  + EXCLUDED.trades_wins,
            pnl_sum_total      = ROUND(oracle_pack_aggregated_stat.pnl_sum_total + EXCLUDED.pnl_sum_total, 4),
            pnl_sum_wins       = ROUND(oracle_pack_aggregated_stat.pnl_sum_wins  + EXCLUDED.pnl_sum_wins,  4),
            winrate            = ROUND(
                                   CASE
                                     WHEN (oracle_pack_aggregated_stat.trades_total + EXCLUDED.trades_total) > 0
                                       THEN (oracle_pack_aggregated_stat.trades_wins + EXCLUDED.trades_wins)::numeric
                                            / (oracle_pack_aggregated_stat.trades_total + EXCLUDED.trades_total)::numeric
                                     ELSE 0
                                   END, 4),
            avg_pnl_per_trade  = ROUND(
                                   CASE
                                     WHEN (oracle_pack_aggregated_stat.trades_total + EXCLUDED.trades_total) > 0
                                       THEN (oracle_pack_aggregated_stat.pnl_sum_total + EXCLUDED.pnl_sum_total)::numeric
                                            / (oracle_pack_aggregated_stat.trades_total + EXCLUDED.trades_total)::numeric
                                     ELSE 0
                                   END, 4),
            avg_trades_per_day = ROUND(
                                   ( (oracle_pack_aggregated_stat.trades_total + EXCLUDED.trades_total)::numeric / $14::numeric ),
                                   4),
            updated_at         = now()
        """,
        report_ids, strategy_ids, time_frames, directions, timeframes, pack_bases, agg_types, agg_keys, agg_values,
        trades_inc, wins_inc, pnl_total_inc, pnl_wins_inc,
        days_in_window,
    )


# üî∏ –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏—è ¬´–æ—Ç—á—ë—Ç –≥–æ—Ç–æ–≤¬ª (PACK)
async def _emit_report_ready(
    redis,
    *,
    report_id: int,
    strategy_id: int,
    time_frame: str,
    window_start: datetime,
    window_end: datetime,
    aggregate_rows: int,
    tf_done: List[str],
    generated_at: datetime,
):
    # —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ payload
    payload = {
        "report_id": int(report_id),
        "strategy_id": int(strategy_id),
        "time_frame": str(time_frame),
        "window_start": window_start.isoformat(),
        "window_end": window_end.isoformat(),
        "generated_at": generated_at.isoformat(),
        "aggregate_rows": int(aggregate_rows),
        "tf_done": list(tf_done or []),
    }
    fields = {"data": json.dumps(payload, separators=(",", ":"))}

    # –æ—Ç–ø—Ä–∞–≤–∫–∞ –≤ Redis Stream
    await redis.xadd(
        name=REPORT_READY_STREAM,
        fields=fields,
        maxlen=REPORT_READY_MAXLEN,
        approximate=True,
    )

    # –ª–æ–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    log.debug(
        "[PACK_REPORT_READY] sid=%s win=%s report_id=%s rows=%d tf_done=%s",
        strategy_id, time_frame, report_id, aggregate_rows, ",".join(tf_done) if tf_done else "-",
    )