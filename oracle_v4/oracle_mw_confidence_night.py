# üî∏ oracle_mw_confidence_night.py ‚Äî –Ω–æ—á–Ω–æ–π —Ç—é–Ω–µ—Ä: –∞–≤—Ç–æ–∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ –≤–µ—Å–æ–≤ (wR,wP,wC,wS) per-strategy/per-window —Ä–∞–∑ –≤ —Å—É—Ç–∫–∏

import asyncio
import logging
from typing import Dict, List, Tuple, Optional
import math
import time
import json

import infra
# üî∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ—Ç–æ–≤—ã–µ —É—Ç–∏–ª–∏—Ç—ã/–∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –≤–æ—Ä–∫–µ—Ä–∞ confidence
from oracle_mw_confidence import (
    WINDOW_STEPS, Z, BASELINE_WR,
    _wilson_lower_bound, _wilson_bounds,
    _persistence_metrics, _cross_window_coherence_by_ids, _stability_key_dynamic,
    _ecdf_rank, _median, _mad, _iqr,
)

log = logging.getLogger("ORACLE_CONFIDENCE_NIGHT")

# üî∏ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—É—Å–∫–∞ –≤–æ—Ä–∫–µ—Ä–∞ (–∑–∞–¥–µ—Ä–∂–∫–∞ —Å—Ç–∞—Ä—Ç–∞ –∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª –≤ —á–∞—Å–∞—Ö ‚Äî –ø–æ–¥–∫–ª—é—á–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ run_periodic –≤ main)
INITIAL_DELAY_H = 24        # –ø–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ 24 —á–∞—Å–∞ –ø–æ—Å–ª–µ —Å—Ç–∞—Ä—Ç–∞ —Å–µ—Ä–≤–∏—Å–∞
INTERVAL_H      = 24        # –∑–∞—Ç–µ–º —Ä–∞–∑ –≤ 24 —á–∞—Å–∞

# üî∏ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è/–æ—Ç–±–æ—Ä–∞
MIN_SAMPLES_PER_STRATEGY = 200     # –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Å—Ç—Ä–æ–∫-–æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é/–æ–∫–Ω–æ
HOLDOUT_FRACTION         = 0.15    # –¥–æ–ª—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö ¬´–ø–∞—Ä –æ—Ç—á—ë—Ç–æ–≤¬ª –Ω–∞ holdout-–ø—Ä–æ–≤–µ—Ä–∫—É (–ø–æ –≤—Ä–µ–º–µ–Ω–∏)
WEIGHT_CLIP_MIN          = 0.05    # –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
WEIGHT_CLIP_MAX          = 0.35    # –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (–∂—ë—Å—Ç–∫–æ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º, —á—Ç–æ–±—ã C –Ω–µ –¥–æ–º–∏–Ω–∏—Ä–æ–≤–∞–ª)
WEIGHTS_TOLERANCE        = 1e-9    # –∑–∞—â–∏—Ç–∞ –æ—Ç –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å –ø—Ä–∏ –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–µ


# üî∏ –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –≤–æ—Ä–∫–µ—Ä–∞ (–≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –∏–∑ oracle_v4_main —á–µ—Ä–µ–∑ run_periodic(..., initial_delay=..., interval=...))
async def run_oracle_confidence_night():
    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏
    if infra.pg_pool is None:
        log.debug("‚ùå –ü—Ä–æ–ø—É—Å–∫ –Ω–æ—á–Ω–æ–≥–æ —Ç—é–Ω–µ—Ä–∞: –Ω–µ—Ç PG-–ø—É–ª–∞")
        return

    # –ø–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –¥–ª—è —Ç—é–Ω–∏–Ω–≥–∞ (–∞–∫—Ç–∏–≤–Ω—ã–µ –∏ market_watcher=true)
    strategies = await _load_target_strategies()
    if not strategies:
        log.debug("‚ÑπÔ∏è –ù–µ—á–µ–≥–æ —Ç—é–Ω–∏—Ç—å: –Ω–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏–π —Å market_watcher=true")
        return

    # –ø–µ—Ä–µ–±–æ—Ä —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –∏ –æ–∫–æ–Ω (7d/14d/28d)
    updated_total = 0
    for sid in strategies:
        for tf in ("7d", "14d", "28d"):
            try:
                ok = await _train_and_activate_weights(strategy_id=sid, time_frame=tf)
                if ok:
                    updated_total += 1
            except Exception:
                log.exception("‚ùå –û—à–∏–±–∫–∞ —Ç—é–Ω–∏–Ω–≥–∞ –≤–µ—Å–æ–≤: strategy_id=%s, time_frame=%s", sid, tf)

    log.debug("‚úÖ –ù–æ—á–Ω–æ–π —Ç—é–Ω–µ—Ä –∑–∞–≤–µ—Ä—à—ë–Ω: –æ–±–Ω–æ–≤–ª–µ–Ω–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –≤–µ—Å–æ–≤ –¥–ª—è %d –ø–∞—Ä (strategy_id √ó time_frame)", updated_total)


# üî∏ –ó–∞–≥—Ä—É–∑–∫–∞ —Ü–µ–ª–µ–≤—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
async def _load_target_strategies() -> List[int]:
    async with infra.pg_pool.acquire() as conn:
        rows = await conn.fetch(
            """
            SELECT id
            FROM strategies_v4
            WHERE enabled = true
              AND (archived IS NOT TRUE)
              AND market_watcher = true
            """
        )
    return [int(r["id"]) for r in rows]


# üî∏ –û–±—É—á–µ–Ω–∏–µ –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏—è –≤–µ—Å–æ–≤ –¥–ª—è –æ–¥–Ω–æ–π –ø–∞—Ä—ã (strategy_id, time_frame)
async def _train_and_activate_weights(strategy_id: int, time_frame: str) -> bool:
    async with infra.pg_pool.acquire() as conn:
        # –≤—ã–±–∏—Ä–∞–µ–º –æ—Ç—á—ë—Ç—ã –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏/–æ–∫–Ω—É –≤ –ø–æ—Ä—è–¥–∫–µ –≤—Ä–µ–º–µ–Ω–∏ (ASC)
        limit_reports = int(WINDOW_STEPS.get(time_frame, 42) * 2)
        reports = await conn.fetch(
            """
            SELECT id, created_at
            FROM oracle_report_stat
            WHERE strategy_id = $1 AND time_frame = $2
            ORDER BY created_at ASC
            LIMIT $3
            """,
            strategy_id, time_frame, limit_reports
        )
        if len(reports) < 3:
            log.debug("‚ÑπÔ∏è strategy=%s tf=%s: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ—Ç—á—ë—Ç–æ–≤ (%d < 3)", strategy_id, time_frame, len(reports))
            return False

        # –ø–∞—Ä—ã (t, t+1) –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        pairs: List[Tuple[Tuple[int, str], Tuple[int, str]]] = []
        for i in range(len(reports) - 1):
            pairs.append(
                ((int(reports[i]["id"]), str(reports[i]["created_at"])),
                 (int(reports[i+1]["id"]), str(reports[i+1]["created_at"])))
            )

        # –¥–∞—Ç–∞—Å–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –º–µ—Ç–æ–∫
        X: List[Tuple[float, float, float, float]] = []
        Y: List[int] = []

        # –∫—ç—à –∫–æ–≥–æ—Ä—Ç –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
        cohort_cache: Dict[Tuple, List[dict]] = {}

        for (rep_id_t, created_t), (rep_id_n, created_n) in pairs:
            # —Å—Ç—Ä–æ–∫–∏ T
            rows_t = await conn.fetch(
                """
                SELECT
                  id, report_id, strategy_id, time_frame, direction, timeframe,
                  agg_type, agg_base, agg_state, trades_total, trades_wins, winrate, avg_pnl_per_trade, report_created_at
                FROM v_mw_aggregated_with_time
                WHERE report_id = $1
                """,
                rep_id_t
            )
            if not rows_t:
                continue

            # —Å—Ç—Ä–æ–∫–∏ T+1 (–¥–ª—è —Ü–µ–ª–µ–≤–æ–π –º–µ—Ç–∫–∏)
            rows_n = await conn.fetch(
                """
                SELECT
                  id, report_id, strategy_id, time_frame, direction, timeframe,
                  agg_type, agg_base, agg_state, trades_total, trades_wins, winrate, report_created_at
                FROM v_mw_aggregated_with_time
                WHERE report_id = $1
                """,
                rep_id_n
            )
            key2row_n: Dict[Tuple, dict] = {}
            for rn in rows_n:
                kn = (rn["direction"], rn["timeframe"], rn["agg_type"], rn["agg_base"], rn["agg_state"])
                key2row_n[kn] = dict(rn)

            # window_end —Ç–µ–∫—É—â–µ–≥–æ —Ä–µ–ø–æ—Ä—Ç–∞ T –¥–ª—è –ø–æ–¥–±–æ—Ä–∞ —Ç—Ä—ë—Ö –æ–∫–æ–Ω
            hdr_t = await conn.fetchrow(
                "SELECT strategy_id, window_end FROM oracle_report_stat WHERE id = $1",
                rep_id_t
            )
            # —Ç—Ä–∏ report_id —Å —Ç–µ–º –∂–µ window_end
            trio_rows = await conn.fetch(
                """
                SELECT id, time_frame
                FROM oracle_report_stat
                WHERE strategy_id = $1
                  AND window_end  = $2
                  AND time_frame  IN ('7d','14d','28d')
                """,
                int(hdr_t["strategy_id"]), hdr_t["window_end"]
            )
            trio_ids = {str(r["time_frame"]): int(r["id"]) for r in trio_rows}

            for rt in rows_t:
                row_t = dict(rt)
                key = (row_t["direction"], row_t["timeframe"], row_t["agg_type"], row_t["agg_base"], row_t["agg_state"])
                row_next = key2row_n.get(key)
                if not row_next:
                    continue

                # –∫—ç—à –∫–æ–≥–æ—Ä—Ç—ã –¥–ª—è T
                cohort_key = (
                    row_t["strategy_id"], row_t["time_frame"], row_t["direction"],
                    row_t["timeframe"], row_t["agg_type"], row_t["agg_base"], row_t["report_created_at"]
                )
                if cohort_key not in cohort_cache:
                    cohort_cache[cohort_key] = await _fetch_cohort_for(conn, row_t)

                # R (–Ω–∞ t)
                n_t = int(row_t["trades_total"] or 0)
                w_t = int(row_t["trades_wins"] or 0)
                R_t = _wilson_lower_bound(w_t, n_t, Z) if n_t > 0 else 0.0

                # P (–Ω–∞ t)
                L = int(WINDOW_STEPS.get(time_frame, 42))
                presence_rate_t, growth_hist_t, _hist_n_t = await _persistence_metrics(conn, row_t, L)
                P_t = 0.6 * presence_rate_t + 0.4 * growth_hist_t

                # C (–Ω–∞ t) ‚Äî –ø–∞–∫–µ—Ç–Ω—ã–π —Ä–∞—Å—á—ë—Ç –ø–æ —Ç—Ä—ë–º report_id —Å —Ç–µ–º –∂–µ window_end; –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ <2 –æ–∫–æ–Ω ‚Äî C=0.0
                if len(trio_ids) >= 2:
                    C_t = await _cross_window_coherence_by_ids(conn, row_t, trio_ids)
                else:
                    C_t = 0.0

                # S (–Ω–∞ t)
                S_t, _len_hist, _meta = await _stability_key_dynamic(conn, row_t, L, cohort_cache[cohort_key])

                # —Ü–µ–ª—å y: –∑–Ω–∞–∫ wr –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ baseline –Ω–∞ t –∏ t+1 –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å, –∏ t+1 –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å ¬´—É–≤–µ—Ä–µ–Ω–Ω—ã–º¬ª
                y = _target_same_sign_next(row_t, row_next)

                X.append((R_t, P_t, C_t, S_t))
                Y.append(y)

        samples = len(Y)
        if samples < MIN_SAMPLES_PER_STRATEGY:
            log.debug("‚ÑπÔ∏è strategy=%s tf=%s: –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç—é–Ω–∏–Ω–≥–∞ (samples=%d < %d)",
                     strategy_id, time_frame, samples, MIN_SAMPLES_PER_STRATEGY)
            return False

        # —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ train/holdout
        holdout = max(1, int(samples * HOLDOUT_FRACTION))
        train = samples - holdout
        X_train, Y_train = X[:train], Y[:train]
        X_hold, Y_hold = X[train:], Y[train:]

        # –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (point-biserial corr)
        imp = _feature_importance_corr(X_train, Y_train)

        # –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–∞ + –∫–ª–∏–ø–ø–∏–Ω–≥ + –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–∞
        weights = _normalize_weights(imp, clip_min=WEIGHT_CLIP_MIN, clip_max=WEIGHT_CLIP_MAX)

        # –¥–æ–ø. –ø–æ–ª–∏—Ç–∏–∫–∞: –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–æ–ª—é R –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º C —Å–≤–µ—Ä—Ö—É
        min_R = 0.25
        max_C = 0.35
        wR = max(weights["wR"], min_R)
        wC = min(weights["wC"], max_C)
        wP = weights["wP"]
        wS = weights["wS"]
        s = wR + wP + wC + wS
        weights = {"wR": wR / s, "wP": wP / s, "wC": wC / s, "wS": wS / s}

        log.debug("üìä –¢—é–Ω–∏–Ω–≥ strategy=%s tf=%s: samples=%d (train=%d, holdout=%d) ‚Üí weights=%s",
                 strategy_id, time_frame, samples, train, holdout, weights)

        # –∞–∫—Ç–∏–≤–∏—Ä—É–µ–º –Ω–æ–≤—ã–µ –≤–µ—Å–∞ (–¥–µ–∞–∫—Ç–∏–≤–∏—Ä—É–µ–º —Å—Ç–∞—Ä—ã–µ –¥–ª—è –ø–∞—Ä—ã strategy/tf)
        await conn.execute(
            """
            UPDATE oracle_conf_model
               SET is_active = false
             WHERE is_active = true
               AND COALESCE(strategy_id, -1) = $1
               AND COALESCE(time_frame, '') = $2
            """,
            int(strategy_id), str(time_frame)
        )
        await conn.execute(
            """
            INSERT INTO oracle_conf_model (name, strategy_id, time_frame, weights, opts, is_active)
            VALUES ($1, $2, $3, $4::jsonb, $5::jsonb, true)
            """,
            f"auto_{time.strftime('%Y%m%d_%H%M%S')}",
            int(strategy_id),
            str(time_frame),
            json.dumps(weights),
            '{"baseline_mode":"neutral"}',
        )
        log.debug("‚úÖ –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω—ã –Ω–æ–≤—ã–µ –≤–µ—Å–∞ –¥–ª—è strategy=%s tf=%s: %s", strategy_id, time_frame, weights)
        return True


# üî∏ –ö–æ–≥–æ—Ä—Ç–∞ –¥–ª—è –æ–¥–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞ (–≤—Å–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –≤–Ω—É—Ç—Ä–∏ —Å—Ä–µ–∑–∞; –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è S –∏ ECDF(n) –ø—Ä–∏ —Ä–∞—Å—á—ë—Ç–∞—Ö –≤ –æ–±—É—á–µ–Ω–∏–∏)
async def _fetch_cohort_for(conn, row: dict) -> List[dict]:
    rows = await conn.fetch(
        """
        SELECT id, trades_total, trades_wins, winrate, avg_pnl_per_trade
        FROM v_mw_aggregated_with_time
        WHERE strategy_id = $1
          AND time_frame  = $2
          AND direction   = $3
          AND timeframe   = $4
          AND agg_type    = $5
          AND agg_base    = $6
          AND report_created_at = $7
        """,
        row["strategy_id"], row["time_frame"], row["direction"], row["timeframe"],
        row["agg_type"], row["agg_base"], row["report_created_at"]
    )
    return [dict(x) for x in rows]


# üî∏ –¶–µ–ª–µ–≤–∞—è –º–µ—Ç–∫–∞: ¬´–ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –∑–Ω–∞–∫–∞ wr –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ baseline¬ª –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–º –æ—Ç—á—ë—Ç–µ
def _target_same_sign_next(row_t: dict, row_next: dict) -> int:
    # –∑–Ω–∞–∫ –≤ t
    n_t = int(row_t["trades_total"] or 0); w_t = int(row_t["trades_wins"] or 0)
    lb_t, ub_t = _wilson_bounds(w_t, n_t, Z) if n_t > 0 else (0.0, 0.0)
    sign_t = 0
    if lb_t > BASELINE_WR:
        sign_t = +1
    elif ub_t < BASELINE_WR:
        sign_t = -1

    # –∑–Ω–∞–∫ –≤ t+1
    n_n = int(row_next["trades_total"] or 0); w_n = int(row_next["trades_wins"] or 0)
    lb_n, ub_n = _wilson_bounds(w_n, n_n, Z) if n_n > 0 else (0.0, 0.0)
    sign_n = 0
    if lb_n > BASELINE_WR:
        sign_n = +1
    elif ub_n < BASELINE_WR:
        sign_n = -1

    # —Ü–µ–ª–µ–≤–∞—è –ª–æ–≥–∏–∫–∞: –æ–±–∞ –∑–Ω–∞–∫–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å ¬´—É–≤–µ—Ä–µ–Ω–Ω—ã–º–∏¬ª –∏ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏
    if sign_t == 0 or sign_n == 0:
        return 0
    return 1 if (sign_t == sign_n) else 0


# üî∏ –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: point-biserial correlation (—É–ø—Ä–æ—â—ë–Ω–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ü–∏—Ä—Å–æ–Ω–∞ —Å –±–∏–Ω–∞—Ä–Ω–æ–π –º–µ—Ç–∫–æ–π)
def _feature_importance_corr(X: List[Tuple[float, float, float, float]], Y: List[int]) -> Dict[str, float]:
    if not X or not Y or len(X) != len(Y):
        return {"wR": 0.25, "wP": 0.25, "wC": 0.25, "wS": 0.25}

    n = len(Y)
    mean_y = sum(Y) / n if n > 0 else 0.0

    # –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä—ã –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º
    sums = [0.0, 0.0, 0.0, 0.0]
    sums2 = [0.0, 0.0, 0.0, 0.0]
    covs = [0.0, 0.0, 0.0, 0.0]

    for i in range(n):
        xi = X[i]
        yi = Y[i]
        for j in range(4):
            x = float(xi[j])
            sums[j] += x
            sums2[j] += x * x
            covs[j] += x * yi

    imps: List[float] = []
    for j in range(4):
        mean_x = sums[j] / n
        var_x = max(0.0, (sums2[j] / n) - (mean_x * mean_x))
        std_x = math.sqrt(var_x)
        cov_xy = (covs[j] / n) - (mean_x * mean_y)
        # –¥–∏—Å–ø–µ—Ä—Å–∏—è –±–∏–Ω–∞—Ä–Ω–æ–π –º–µ—Ç–∫–∏: p*(1-p)
        std_y = math.sqrt(max(1e-12, mean_y * (1.0 - mean_y)))
        corr = 0.0 if std_x < 1e-12 else (cov_xy / (std_x * std_y))
        imps.append(abs(corr))

    # –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–µ –≤–∞–∂–Ω–æ—Å—Ç–∏
    return {"wR": imps[0], "wP": imps[1], "wC": imps[2], "wS": imps[3]}


# üî∏ –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∫–ª–∏–ø–ø–∏–Ω–≥ –≤–µ—Å–æ–≤ (—Å –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–æ–π)
def _normalize_weights(imp: Dict[str, float], clip_min: float, clip_max: float) -> Dict[str, float]:
    # –Ω–∞—á–∞–ª—å–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    total = sum(max(v, 0.0) for v in imp.values())
    if total <= WEIGHTS_TOLERANCE:
        base = {"wR": 0.4, "wP": 0.25, "wC": 0.2, "wS": 0.15}
        return base

    weights = {k: (max(v, 0.0) / total) for k, v in imp.items()}

    # –∫–ª–∏–ø–ø–∏–Ω–≥
    for k in weights:
        weights[k] = min(max(weights[k], clip_min), clip_max)

    # –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–∞ –¥–æ 1
    s2 = sum(weights.values())
    if s2 <= WEIGHTS_TOLERANCE:
        return {"wR": 0.4, "wP": 0.25, "wC": 0.2, "wS": 0.15}

    return {k: (v / s2) for k, v in weights.items()}