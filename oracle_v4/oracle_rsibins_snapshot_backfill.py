# oracle_rsibins_snapshot_backfill.py ‚Äî RSI-bins backfill: –≠—Ç–∞–ø 3 (–∑–∞–¥–µ—Ä–∂–∫–∞ —Å—Ç–∞—Ä—Ç–∞ + –ø–æ–ª–∏—Ä–æ–≤–∫–∞ –ª–æ–≥–æ–≤)

import os
import asyncio
import logging

import infra
from oracle_rsibins_snapshot_aggregator import (
    _load_position_and_strategy,
    _load_rsi_bins,
    _update_aggregates,
)

log = logging.getLogger("ORACLE_RSIBINS_BF")

# üî∏ –ö–æ–Ω—Ñ–∏–≥ backfill'–∞
BATCH_SIZE        = int(os.getenv("RSI_BF_BATCH_SIZE", "200"))
MAX_CONCURRENCY   = int(os.getenv("RSI_BF_MAX_CONCURRENCY", "8"))
SLEEP_MS          = int(os.getenv("RSI_BF_SLEEP_MS", "200"))
START_DELAY_SEC   = int(os.getenv("RSI_BF_START_DELAY_SEC", "120"))

_CANDIDATES_SQL = """
SELECT p.position_uid
FROM positions_v4 p
JOIN strategies_v4 s ON s.id = p.strategy_id
WHERE p.status = 'closed'
  AND COALESCE(p.rsi_checked, false) = false
  AND s.enabled = true
  AND COALESCE(s.market_watcher, false) = true
ORDER BY p.closed_at NULLS LAST, p.id
LIMIT $1
"""

# üî∏ –í—ã–±—Ä–∞—Ç—å –ø–∞—á–∫—É UID'–æ–≤ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
async def _fetch_candidates(batch_size: int):
    pg = infra.pg_pool
    async with pg.acquire() as conn:
        rows = await conn.fetch(_CANDIDATES_SQL, batch_size)
    return [r["position_uid"] for r in rows]

# üî∏ –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ–¥–∏–Ω UID
async def _process_uid(uid: str):
    try:
        pos, strat, verdict = await _load_position_and_strategy(uid)
        v_code, v_reason = verdict
        if v_code != "ok":
            return ("skip", v_reason, uid)

        bins = await _load_rsi_bins(uid)
        if not bins:
            return ("skip", "no_rsi14", uid)

        await _update_aggregates(pos, strat, bins)
        return ("updated", bins, uid)

    except Exception as e:
        log.exception("‚ùå BF uid=%s error: %s", uid, e)
        return ("error", "exception", uid)

# üî∏ –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª backfill'–∞
async def run_oracle_rsibins_snapshot_backfill():
    # –∑–∞–¥–µ—Ä–∂–∫–∞ —Å—Ç–∞—Ä—Ç–∞, —á—Ç–æ–±—ã –Ω–µ –∫–æ–Ω–∫—É—Ä–∏—Ä–æ–≤–∞—Ç—å —Å –¥—Ä—É–≥–∏–º–∏ –∏–Ω—Å—Ç–∞–Ω—Å–∞–º–∏
    if START_DELAY_SEC > 0:
        log.info("‚è≥ RSI-BINS BF: –∑–∞–¥–µ—Ä–∂–∫–∞ —Å—Ç–∞—Ä—Ç–∞ %d —Å–µ–∫", START_DELAY_SEC)
        await asyncio.sleep(START_DELAY_SEC)

    log.info("üöÄ RSI-BINS BF: —Å—Ç–∞—Ä—Ç, batch=%d, max_conc=%d, sleep=%dms",
             BATCH_SIZE, MAX_CONCURRENCY, SLEEP_MS)

    gate = asyncio.Semaphore(MAX_CONCURRENCY)

    while True:
        try:
            uids = await _fetch_candidates(BATCH_SIZE)
            if not uids:
                await asyncio.sleep(SLEEP_MS / 1000)
                continue

            # –ø–ª–∞–Ω –ø–∞—á–∫–∏ ‚Äî —Ç–µ–ø–µ—Ä—å –≤ DEBUG
            log.debug("[RSI-BINS BF] planned uids=%d (–ø—Ä–∏–º–µ—Ä: %s)", len(uids), uids[:3])

            results = []
            async def worker(uid: str):
                async with gate:
                    res = await _process_uid(uid)
                    results.append(res)

            await asyncio.gather(*[asyncio.create_task(worker(uid)) for uid in uids])

            # —Å–≤–æ–¥–∫–∞ ‚Äî INFO
            updated = sum(1 for r in results if r[0] == "updated")
            skipped = sum(1 for r in results if r[0] == "skip")
            errors  = sum(1 for r in results if r[0] == "error")

            log.info("[RSI-BINS BF] batch_done total=%d updated=%d skipped=%d errors=%d",
                     len(results), updated, skipped, errors)

        except asyncio.CancelledError:
            log.info("‚èπÔ∏è RSI-BINS backfill –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            raise
        except Exception as e:
            log.exception("‚ùå RSI-BINS BF loop error: %s", e)
            await asyncio.sleep(1)