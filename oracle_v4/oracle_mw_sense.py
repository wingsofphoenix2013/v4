# oracle_mw_sense.py â€” Ñ€Ð°ÑÑ‡Ñ‘Ñ‚ Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð¿Ð¾Ð»ÐµÐ·Ð½Ð¾ÑÑ‚Ð¸ agg_base (Coverage / Discrimination / Net Effect) + Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð°ÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Whitelist

# ðŸ”¸ Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ñ‹
import asyncio
import json
import logging
import math
from collections import defaultdict
from typing import Dict, List, Tuple

import infra

# ðŸ”¸ Ð›Ð¾Ð³Ð³ÐµÑ€
log = logging.getLogger("ORACLE_MW_SENSE")

# ðŸ”¸ ÐšÐ¾Ð½ÑÑ‚Ð°Ð½Ñ‚Ñ‹ Redis Stream (Ñ‡Ð¸Ñ‚Ð°ÐµÑ‚ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ Ð¾ Ð³Ð¾Ñ‚Ð¾Ð²Ð½Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð² Ð´Ð»Ñ sense)
SENSE_REPORT_READY_STREAM = "oracle:mw_sense:reports_ready"
SENSE_GROUP = "oracle_mw_sense_group"
SENSE_CONSUMER = "oracle_mw_sense_worker"

# ðŸ”¸ ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹
BASELINE_WR = 0.535  # Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ winrate (Ð¿Ð»Ð°Ð½ÐºÐ°); Ð¼Ð¾Ð¶Ð½Ð¾ Ð¿Ð¾Ð´Ð½ÑÑ‚ÑŒ, Ð¸ Ð²ÑÑ‘ Ð¿Ð¾Ð´ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑÑ
Z = 1.96             # Wilson 95%

# ðŸ”¸ ÐŸÐ¾Ñ€Ð¾Ð³Ð¸ Â«ÑÐ±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð³Ð¾Â» Ð¿Ñ€Ð¾Ñ„Ð¸Ð»Ñ Ð´Ð»Ñ Allowlist Ð±Ð°Ð· (Ñ€ÐµÑˆÐ°ÑŽÑ‚, ÐºÐ°ÐºÐ¸Ðµ agg_base Ð²Ð¾Ð¾Ð±Ñ‰Ðµ Ð³Ð¾Ð´ÑÑ‚ÑÑ)
ALLOWLIST_MIN_NE_STRICT = 0.0
ALLOWLIST_MIN_CRAMERS_V = 0.15
ALLOWLIST_MIN_COVERAGE_INCLUDED_STRICT = 0.20
ALLOWLIST_MIN_TRADES = 300
ALLOWLIST_MIN_STATES_USED = 4
ALLOWLIST_MIN_ENTROPY_NORM = 0.60


# ðŸ”¸ ÐŸÑƒÐ±Ð»Ð¸Ñ‡Ð½Ð°Ñ Ñ‚Ð¾Ñ‡ÐºÐ° Ð²Ñ…Ð¾Ð´Ð° Ð²Ð¾Ñ€ÐºÐµÑ€Ð° (Ð·Ð°Ð¿ÑƒÑÐºÐ°Ñ‚ÑŒ Ñ‡ÐµÑ€ÐµÐ· oracle_v4_main.py â†’ run_safe_loop)
async def run_oracle_mw_sense():
    # ÑƒÑÐ»Ð¾Ð²Ð¸Ñ Ð´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸
    if infra.pg_pool is None or infra.redis_client is None:
        log.info("âŒ ÐŸÑ€Ð¾Ð¿ÑƒÑÐº ORACLE_MW_SENSE: PG/Redis Ð½Ðµ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹")
        return

    # ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹ Ð¿Ð¾Ñ‚Ñ€ÐµÐ±Ð¸Ñ‚ÐµÐ»ÐµÐ¹ (Ð¸Ð´ÐµÐ¼Ð¿Ð¾Ñ‚ÐµÐ½Ñ‚Ð½Ð¾)
    try:
        await infra.redis_client.xgroup_create(
            name=SENSE_REPORT_READY_STREAM, groupname=SENSE_GROUP, id="$", mkstream=True
        )
        log.info("ðŸ“¡ Ð¡Ð¾Ð·Ð´Ð°Ð½Ð° Ð³Ñ€ÑƒÐ¿Ð¿Ð° Ð¿Ð¾Ñ‚Ñ€ÐµÐ±Ð¸Ñ‚ÐµÐ»ÐµÐ¹ Ð² Redis Stream: %s", SENSE_GROUP)
    except Exception as e:
        if "BUSYGROUP" in str(e):
            pass
        else:
            log.exception("âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹ Redis Stream")
            return

    log.info("ðŸš€ Ð¡Ñ‚Ð°Ñ€Ñ‚ Ð²Ð¾Ñ€ÐºÐµÑ€Ð° ORACLE_MW_SENSE (Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ agg_base + whitelist)")

    # Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ñ†Ð¸ÐºÐ» Ñ‡Ñ‚ÐµÐ½Ð¸Ñ ÑÑ‚Ñ€Ð¸Ð¼Ð°
    while True:
        try:
            resp = await infra.redis_client.xreadgroup(
                groupname=SENSE_GROUP,
                consumername=SENSE_CONSUMER,
                streams={SENSE_REPORT_READY_STREAM: ">"},
                count=64,
                block=30_000,
            )
            if not resp:
                continue

            # Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹
            for stream_name, msgs in resp:
                for msg_id, fields in msgs:
                    try:
                        # Ñ€Ð°ÑÐ¿Ð°ÐºÐ¾Ð²ÐºÐ° payload
                        data_raw = fields.get("data", "{}")
                        payload = json.loads(data_raw) if isinstance(data_raw, str) else {}
                        report_id = int(payload.get("report_id") or 0)
                        strategy_id = int(payload.get("strategy_id") or 0)
                        time_frame = str(payload.get("time_frame") or "")  # '7d' | '14d' | '28d'
                        if not (report_id and strategy_id and time_frame):
                            log.info("â„¹ï¸ ÐŸÑ€Ð¾Ð¿ÑƒÑÐº ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ: Ð½ÐµÐ¿Ð¾Ð»Ð½Ñ‹Ð¹ payload: %s", payload)
                            await infra.redis_client.xack(SENSE_REPORT_READY_STREAM, SENSE_GROUP, msg_id)
                            continue

                        # Ñ€Ð°ÑÑ‡Ñ‘Ñ‚ Ð¿Ð¾ Ð¾Ð´Ð½Ð¾Ð¼Ñƒ report_id
                        await _process_report(report_id=report_id, strategy_id=strategy_id, time_frame=time_frame)

                        # ack ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ
                        await infra.redis_client.xack(SENSE_REPORT_READY_STREAM, SENSE_GROUP, msg_id)

                    except Exception:
                        log.exception("âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ ORACLE_MW_SENSE")

        except asyncio.CancelledError:
            log.info("â¹ï¸ Ð’Ð¾Ñ€ÐºÐµÑ€ ORACLE_MW_SENSE Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½ Ð¿Ð¾ ÑÐ¸Ð³Ð½Ð°Ð»Ñƒ")
            raise
        except Exception:
            log.exception("âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ñ†Ð¸ÐºÐ»Ð° ORACLE_MW_SENSE â€” Ð¿Ð°ÑƒÐ·Ð° 5 ÑÐµÐºÑƒÐ½Ð´")
            await asyncio.sleep(5)


# ðŸ”¸ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð°: Ñ€Ð°ÑÑ‡Ñ‘Ñ‚ Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð¿Ð¾ Ð±Ð°Ð·Ð°Ð¼ + Ð¿Ð¾ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ðµ Whitelist (Ð´Ð»Ñ 7d)
async def _process_report(*, report_id: int, strategy_id: int, time_frame: str):
    # Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼ Ð²ÑÐµ Ð°Ð³Ñ€ÐµÐ³Ð°Ñ‚Ñ‹ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð° (Ð¿Ð¾ Ð²ÑÐµÐ¼ TF, Ð±Ð°Ð·Ð°Ð¼, ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸ÑÐ¼, Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸ÑÐ¼)
    async with infra.pg_pool.acquire() as conn:
        rows = await conn.fetch(
            """
            SELECT
              timeframe,
              direction,
              agg_type,
              agg_base,
              agg_state,
              trades_total,
              trades_wins,
              winrate
            FROM oracle_mw_aggregated_stat
            WHERE report_id = $1
            """,
            int(report_id),
        )
        if not rows:
            log.info("[SENSE] report_id=%s sid=%s tf=%s: Ð°Ð³Ñ€ÐµÐ³Ð°Ñ‚Ð¾Ð² Ð½ÐµÑ‚ â€” Ð¿Ñ€Ð¾Ð¿ÑƒÑÐº", report_id, strategy_id, time_frame)
            return

        # Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€Ð¾Ð²ÐºÐ° Ð´Ð»Ñ Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð±Ð°Ð·: timeframe â†’ agg_base â†’ [state rows Ð±ÐµÐ· ÑƒÑ‡Ñ‘Ñ‚Ð° direction]
        groups_for_metrics: Dict[str, Dict[str, List[dict]]] = defaultdict(lambda: defaultdict(list))
        # Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€Ð¾Ð²ÐºÐ° Ð´Ð»Ñ whitelist: timeframe â†’ agg_base â†’ direction â†’ [state rows]
        groups_for_wl: Dict[str, Dict[str, Dict[str, List[dict]]]] = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))

        for r in rows:
            rec = {
                "state": str(r["agg_state"]),
                "n": int(r["trades_total"] or 0),
                "w": int(r["trades_wins"] or 0),
                "wr": float(r["winrate"] or 0.0),
                "direction": str(r["direction"]),
                "agg_type": str(r["agg_type"]),
            }
            tf = str(r["timeframe"])
            base = str(r["agg_base"])
            groups_for_metrics[tf][base].append(rec)
            groups_for_wl[tf][base][rec["direction"]].append(rec)

        total_bases_written = 0
        wl_rows_written_total = 0
        tf_count = 0

        # Ð¾Ð±Ñ…Ð¾Ð´ TF â†’ agg_base Ð´Ð»Ñ Ñ€Ð°ÑÑ‡Ñ‘Ñ‚Ð° Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð¸ Ð·Ð°Ð¿Ð¸ÑÐ¸ Ð² oracle_mw_sense
        for timeframe, base_map in groups_for_metrics.items():
            tf_count += 1
            allowlist_bases: List[str] = []

            for agg_base, state_rows in base_map.items():
                # Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð´Ð»Ñ Ð±Ð°Ð·Ñ‹
                metrics, inputs_json = _compute_metrics_for_base(state_rows)

                # Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³ Ð±Ð°Ð·Ñ‹ Ð½Ð° Ð°Ñ€Ð½Ð¾ÑÑ‚ÑŒ/ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ñ‹
                agg_arity, agg_components = _parse_base_components(agg_base)

                # UPSERT Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð² oracle_mw_sense
                await conn.execute(
                    """
                    INSERT INTO oracle_mw_sense (
                        report_id, strategy_id, time_frame, timeframe, agg_base,
                        coverage_entropy_norm, discrimination_cramers_v,
                        net_effect_loose, net_effect_strict,
                        coverage_included_loose, coverage_included_strict,
                        trades_total_all_states, states_used_count, baseline_wr,
                        inputs_json, agg_arity, agg_components,
                        created_at, updated_at
                    )
                    VALUES (
                        $1,$2,$3,$4,$5,
                        $6,$7,
                        $8,$9,
                        $10,$11,
                        $12,$13,$14,
                        $15,$16,$17,
                        now(), now()
                    )
                    ON CONFLICT (report_id, strategy_id, time_frame, timeframe, agg_base)
                    DO UPDATE SET
                        coverage_entropy_norm    = EXCLUDED.coverage_entropy_norm,
                        discrimination_cramers_v = EXCLUDED.discrimination_cramers_v,
                        net_effect_loose         = EXCLUDED.net_effect_loose,
                        net_effect_strict        = EXCLUDED.net_effect_strict,
                        coverage_included_loose  = EXCLUDED.coverage_included_loose,
                        coverage_included_strict = EXCLUDED.coverage_included_strict,
                        trades_total_all_states  = EXCLUDED.trades_total_all_states,
                        states_used_count        = EXCLUDED.states_used_count,
                        baseline_wr              = EXCLUDED.baseline_wr,
                        inputs_json              = EXCLUDED.inputs_json,
                        agg_arity                = EXCLUDED.agg_arity,
                        agg_components           = EXCLUDED.agg_components,
                        updated_at               = now()
                    """,
                    int(report_id),
                    int(strategy_id),
                    str(time_frame),
                    str(timeframe),
                    str(agg_base),
                    float(metrics["coverage_entropy_norm"]),
                    float(metrics["discrimination_cramers_v"]),
                    float(metrics["net_effect_loose"]),
                    float(metrics["net_effect_strict"]),
                    float(metrics["coverage_included_loose"]),
                    float(metrics["coverage_included_strict"]),
                    int(metrics["trades_total_all_states"]),
                    int(metrics["states_used_count"]),
                    float(BASELINE_WR),
                    json.dumps(inputs_json, separators=(",", ":")),
                    int(agg_arity),
                    agg_components,
                )
                total_bases_written += 1

                # Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Allowlist Ð¿Ð¾ Â«ÑÐ±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð¼ÑƒÂ» Ð¿Ñ€Ð¾Ñ„Ð¸Ð»ÑŽ
                if (
                    float(metrics["net_effect_strict"]) > ALLOWLIST_MIN_NE_STRICT
                    and float(metrics["discrimination_cramers_v"]) >= ALLOWLIST_MIN_CRAMERS_V
                    and float(metrics["coverage_included_strict"]) >= ALLOWLIST_MIN_COVERAGE_INCLUDED_STRICT
                    and int(metrics["trades_total_all_states"]) >= ALLOWLIST_MIN_TRADES
                    and int(metrics["states_used_count"]) >= ALLOWLIST_MIN_STATES_USED
                    and float(metrics["coverage_entropy_norm"]) >= ALLOWLIST_MIN_ENTROPY_NORM
                ):
                    allowlist_bases.append(agg_base)

            # ÐµÑÐ»Ð¸ Ð¾ÐºÐ½Ð¾ 7d â€” ÑÑ‚Ñ€Ð¾Ð¸Ð¼ Whitelist (Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð´Ð»Ñ 7d, Ð¿Ð¾ Ñ‚Ð²Ð¾Ð¸Ð¼ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°Ð¼)
            if time_frame == "7d":
                # Ð¿ÐµÑ€ÐµÐ´ Ð²ÑÑ‚Ð°Ð²ÐºÐ¾Ð¹ â€” Ñ‡Ð¸ÑÑ‚Ð¸Ð¼ ÑÑ‚Ð°Ñ€Ñ‹Ðµ WL Ð´Ð»Ñ ÑÑ‚Ð¾Ð¹ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ð¸/TF/Ð¾ÐºÐ½Ð°, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð° Ð±Ñ‹Ð»Ð° Ð²ÑÐµÐ³Ð´Ð° Ð°ÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð¾Ð¹
                await conn.execute(
                    """
                    DELETE FROM oracle_mw_sense_whitelist
                    WHERE strategy_id = $1 AND time_frame = $2 AND timeframe = $3
                    """,
                    int(strategy_id), str(time_frame), str(timeframe)
                )

                # Ð¿Ñ€Ð¾Ñ…Ð¾Ð´Ð¸Ð¼ Ð¿Ð¾ Ñ€Ð°Ð·Ñ€ÐµÑˆÑ‘Ð½Ð½Ñ‹Ð¼ Ð±Ð°Ð·Ð°Ð¼ Ð¸ ÑÐ¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ WL Ð¿Ð¾ Ð¾Ð±Ð¾Ð¸Ð¼ Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸ÑÐ¼
                wl_rows_written_tf = 0
                bases_map_for_tf = groups_for_wl.get(timeframe, {})
                for base in allowlist_bases:
                    dir_map = bases_map_for_tf.get(base, {})
                    for direction, rows_dir in dir_map.items():
                        # ÑÑƒÐ¼Ð¼Ð° ÑÐ´ÐµÐ»Ð¾Ðº Ð² Ð±Ð°Ð·Ðµ Ð´Ð»Ñ Ð´Ð°Ð½Ð½Ð¾Ð³Ð¾ Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ (Ð´Ð»Ñ p_share)
                        N_dir_base = sum(int(r["n"]) for r in rows_dir if int(r["n"]) > 0)
                        if N_dir_base <= 0:
                            continue

                        # Ñ‚Ð¸Ð¿ Ð±Ð°Ð·Ñ‹ â†’ Ð´Ð»Ñ agg_type (solo/combo)
                        agg_type = "solo" if _base_arity_from_name(base) == 1 else "combo"

                        # Ð¿Ð¾ Ð²ÑÐµÐ¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸ÑÐ¼ ÑÑ‚Ð¾Ð¹ Ð±Ð°Ð·Ñ‹+Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ â€” Ð¾Ñ‚Ð±Ð¸Ñ€Ð°ÐµÐ¼ LB > BASELINE_WR
                        for r in rows_dir:
                            n = int(r["n"])
                            w = int(r["w"])
                            if n <= 0:
                                continue
                            lb = _wilson_lower_bound(w, n, Z)
                            if lb <= BASELINE_WR:
                                continue

                            wr = float(r["wr"])
                            p_share = float(n) / float(N_dir_base) if N_dir_base > 0 else 0.0
                            delta_wr = wr - BASELINE_WR

                            # Ð²ÑÑ‚Ð°Ð²ÐºÐ° Ð² Whitelist
                            await conn.execute(
                                """
                                INSERT INTO oracle_mw_sense_whitelist (
                                    report_id, strategy_id, time_frame, timeframe, direction,
                                    agg_base, agg_state,
                                    trades_total, trades_wins, winrate, wilson_lb, delta_wr, p_share_in_base,
                                    agg_arity, agg_components, baseline_wr,
                                    created_at, updated_at
                                )
                                VALUES (
                                    $1,$2,$3,$4,$5,
                                    $6,$7,
                                    $8,$9,$10,$11,$12,$13,
                                    $14,$15,$16,
                                    now(), now()
                                )
                                ON CONFLICT (report_id, strategy_id, time_frame, timeframe, direction, agg_base, agg_state)
                                DO UPDATE SET
                                    trades_total    = EXCLUDED.trades_total,
                                    trades_wins     = EXCLUDED.trades_wins,
                                    winrate         = EXCLUDED.winrate,
                                    wilson_lb       = EXCLUDED.wilson_lb,
                                    delta_wr        = EXCLUDED.delta_wr,
                                    p_share_in_base = EXCLUDED.p_share_in_base,
                                    agg_arity       = EXCLUDED.agg_arity,
                                    agg_components  = EXCLUDED.agg_components,
                                    baseline_wr     = EXCLUDED.baseline_wr,
                                    updated_at      = now()
                                """,
                                int(report_id),
                                int(strategy_id),
                                str(time_frame),
                                str(timeframe),
                                str(direction),
                                str(base),
                                str(r["state"]),
                                int(n),
                                int(w),
                                float(_clip01(wr)),
                                float(_clip01(lb)),
                                float(round(delta_wr, 6)),
                                float(round(_clip01(p_share), 6)),
                                int(_base_arity_from_name(base)),
                                _base_components_from_name(base),
                                float(BASELINE_WR),
                            )
                            wl_rows_written_tf += 1

                wl_rows_written_total += wl_rows_written_tf
                log.info(
                    "âœ… [WL] sid=%s report=%s win=%s tf=%s: allowlist_bases=%d, wl_rows=%d",
                    strategy_id, report_id, time_frame, timeframe, len(allowlist_bases), wl_rows_written_tf
                )

        log.info(
            "âœ… [SENSE] report_id=%s sid=%s win=%s â†’ Ð·Ð°Ð¿Ð¸ÑÐ°Ð½Ð¾ Ð±Ð°Ð·: %d (TF=%d), WL_rows_total=%d",
            report_id, strategy_id, time_frame, total_bases_written, tf_count, wl_rows_written_total
        )


# ðŸ”¸ Ð Ð°ÑÑ‡Ñ‘Ñ‚ Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð¿Ð¾ Ð¾Ð´Ð½Ð¾Ð¼Ñƒ agg_base (Ð² Ñ€Ð°Ð¼ÐºÐ°Ñ… Ð¾Ð´Ð½Ð¾Ð³Ð¾ report_id Ã— timeframe, Ð±ÐµÐ· ÑƒÑ‡Ñ‘Ñ‚Ð° Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ)
def _compute_metrics_for_base(state_rows: List[dict]) -> Tuple[Dict[str, float], Dict[str, dict]]:
    # Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð²Ñ…Ð¾Ð´Ð¾Ð² â€” Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÑÐµÐ¼ Ð¿Ð¾ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸ÑÐ¼, Ð¸Ð³Ð½Ð¾Ñ€Ð¸Ñ€ÑƒÑ direction
    # ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð¸Ð´ÐµÐ½Ñ‚Ð¸Ñ„Ð¸Ñ†Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾ ÑÑ‚Ñ€Ð¾ÐºÐµ 'state'
    acc: Dict[str, Dict[str, float]] = {}
    for r in state_rows:
        s = r["state"]
        v = acc.setdefault(s, {"n": 0, "w": 0})
        v["n"] += int(r["n"])
        v["w"] += int(r["w"])

    rows = [{"state": s, "n": int(v["n"]), "w": int(v["w"]), "wr": (float(v["w"]) / float(v["n"])) if v["n"] > 0 else 0.0}
            for s, v in acc.items() if int(v["n"]) > 0]

    N = sum(r["n"] for r in rows)
    S = len(rows)

    inputs_json = {r["state"]: {"n": int(r["n"]), "w": int(r["w"]), "wr": float(round(_clip01(r["wr"]), 6))} for r in rows}

    if N <= 0 or S <= 0:
        return (
            {
                "coverage_entropy_norm": 0.0,
                "discrimination_cramers_v": 0.0,
                "net_effect_loose": 0.0,
                "net_effect_strict": 0.0,
                "coverage_included_loose": 0.0,
                "coverage_included_strict": 0.0,
                "trades_total_all_states": 0,
                "states_used_count": 0,
            },
            inputs_json,
        )

    # Coverage: Ð½Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ ÑÐ½Ñ‚Ñ€Ð¾Ð¿Ð¸Ñ
    ps = [r["n"] / N for r in rows]
    H = -sum(p * math.log(p) for p in ps if p > 0)
    Hmax = math.log(S) if S > 1 else 1.0
    coverage_entropy_norm = 0.0 if S <= 1 else (H / Hmax if Hmax > 0 else 0.0)
    coverage_entropy_norm = float(max(0.0, min(1.0, coverage_entropy_norm)))

    # Discrimination: CramÃ©râ€™s V Ð¿Ð¾ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ðµ |S|Ã—2 (win/loss)
    wins = [r["w"] for r in rows]
    losses = [r["n"] - r["w"] for r in rows]
    total_wins = sum(wins)
    total_losses = sum(losses)
    chi2 = 0.0
    for i in range(S):
        exp_w = (rows[i]["n"] * total_wins) / N if N > 0 else 0.0
        exp_l = (rows[i]["n"] * total_losses) / N if N > 0 else 0.0
        if exp_w > 0:
            chi2 += ((wins[i] - exp_w) ** 2) / exp_w
        if exp_l > 0:
            chi2 += ((losses[i] - exp_l) ** 2) / exp_l
    k = 1 if S > 1 else 0  # c-1 = 1 (win/loss)
    V = math.sqrt(chi2 / (N * k)) if (N > 0 and k > 0) else 0.0
    discrimination_cramers_v = float(max(0.0, min(1.0, V)))

    # Net Effect (loose/strict) Ð¸ coverage Ð²ÐºÐ»ÑŽÑ‡Ñ‘Ð½Ð½Ñ‹Ñ… (Ð¿Ð¾ ÑÑ‚Ñ€Ð¾ÐºÐ°Ð¼ Ð±ÐµÐ· Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ)
    ne_loose = 0.0
    ne_strict = 0.0
    cov_loose = 0.0
    cov_strict = 0.0
    for r in rows:
        p = r["n"] / N
        wr = r["wr"]
        # loose: Ð¿Ð¾ ÑÑ‹Ñ€Ð¾Ð¼Ñƒ WR
        if wr >= BASELINE_WR:
            ne_loose += p * (wr - BASELINE_WR)
            cov_loose += p
        # strict: Ð¿Ð¾ Ð½Ð¸Ð¶Ð½ÐµÐ¹ Ð³Ñ€Ð°Ð½Ð¸Ñ†Ðµ Wilson
        lb = _wilson_lower_bound(int(r["w"]), int(r["n"]), Z)
        if lb > BASELINE_WR:
            ne_strict += p * (wr - BASELINE_WR)
            cov_strict += p

    metrics = {
        "coverage_entropy_norm": coverage_entropy_norm,
        "discrimination_cramers_v": discrimination_cramers_v,
        "net_effect_loose": float(ne_loose),
        "net_effect_strict": float(ne_strict),
        "coverage_included_loose": float(min(1.0, max(0.0, cov_loose))),
        "coverage_included_strict": float(min(1.0, max(0.0, cov_strict))),
        "trades_total_all_states": int(N),
        "states_used_count": int(S),
    }
    return metrics, inputs_json


# ðŸ”¸ ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ð±Ð°Ð·Ñ‹ Ð² Ð°Ñ€Ð½Ð¾ÑÑ‚ÑŒ Ð¸ ÑÐ¿Ð¸ÑÐ¾Ðº ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚ (Ð´Ð»Ñ ÑƒÐ´Ð¾Ð±Ð½Ñ‹Ñ… ÑÑ€ÐµÐ·Ð¾Ð²)
def _parse_base_components(agg_base: str) -> Tuple[int, List[str]]:
    parts = [p for p in str(agg_base).split("_") if p]
    arity = max(1, len(parts))
    components = parts  # ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ ÐµÑÑ‚ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¹ Ð¿Ð¾Ñ€ÑÐ´Ð¾Ðº Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
    return arity, components


# ðŸ”¸ Ð’ÑÐ¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ: Ð°Ñ€Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ð¾ Ð¸Ð¼ÐµÐ½Ð¸ Ð±Ð°Ð·Ñ‹
def _base_arity_from_name(agg_base: str) -> int:
    parts = [p for p in str(agg_base).split("_") if p]
    return max(1, len(parts))


# ðŸ”¸ Ð’ÑÐ¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ: ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ñ‹ Ð¿Ð¾ Ð¸Ð¼ÐµÐ½Ð¸ Ð±Ð°Ð·Ñ‹
def _base_components_from_name(agg_base: str) -> List[str]:
    return [p for p in str(agg_base).split("_") if p]


# ðŸ”¸ Wilson lower bound (Ð´Ð»Ñ strict-Ð¾Ñ‚Ð±Ð¾Ñ€Ð°/Whitelist)
def _wilson_lower_bound(wins: int, n: int, z: float) -> float:
    if n <= 0:
        return 0.0
    p = wins / n
    denom = 1.0 + (z * z) / n
    center = p + (z * z) / (2.0 * n)
    adj = z * math.sqrt((p * (1.0 - p) / n) + (z * z) / (4.0 * n * n))
    lb = (center - adj) / denom
    return float(max(0.0, min(1.0, lb)))


# ðŸ”¸ Ð’ÑÐ¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ: ÐºÐ»Ð¸Ð¿ Ðº [0,1]
def _clip01(x: float) -> float:
    try:
        return float(max(0.0, min(1.0, x)))
    except Exception:
        return 0.0