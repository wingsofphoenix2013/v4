import asyncio
import logging
import json
import infra
from dateutil import parser
from collections import deque
from datetime import datetime
import json

# üî∏ –í—Å—Ç–∞–≤–∫–∞ –∑–∞–ø–∏—Å–∏ –≤ —Ç–∞–±–ª–∏—Ü—É signals_v4_log –∏ –ø—É–±–ª–∏–∫–∞—Ü–∏—è –≤ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
async def insert_signal_log(data: dict):
    log = logging.getLogger("CORE_IO")

    required_fields = [
        "signal_id", "symbol", "direction", "source", "message", "raw_message",
        "bar_time", "sent_at", "received_at", "status", "uid"
    ]
    for field in required_fields:
        if field not in data:
            log.warning(f"–ü—Ä–æ–ø—É—â–µ–Ω –ª–æ–≥: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ {field} –≤ {data}")
            return

    # üîπ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –±—É—Ñ–µ—Ä
    signal_log_buffer.append(data)

    # üîπ –†–∞—Å—Å—ã–ª–∫–∞ –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º
    if data["status"] == "dispatched":
        try:
            raw = json.loads(data["raw_message"])
            strategy_ids = raw.get("strategies", [])
        except Exception as e:
            log.warning(f"–û—à–∏–±–∫–∞ —Ä–∞–∑–±–æ—Ä–∞ raw_message: {e}")
            return

        for strategy_id in strategy_ids:
            try:
                await infra.REDIS.xadd(
                    "strategy_input_stream",
                    {
                        "strategy_id": str(strategy_id),
                        "signal_id": str(data["signal_id"]),
                        "symbol": data["symbol"],
                        "direction": data["direction"],
                        "time": data["bar_time"],
                        "received_at": data["received_at"],
                        "log_uid": data["uid"]  # –≤–º–µ—Å—Ç–æ log_id
                    }
                )
                await infra.record_counter("strategies_dispatched_total")
            except Exception as e:
                log.warning(f"xadd –≤ strategy_input_stream –Ω–µ —É–¥–∞–ª—Å—è: {e}")
# üî∏ –ë—É—Ñ–µ—Ä –ª–æ–≥–æ–≤ —Å–∏–≥–Ω–∞–ª–æ–≤
signal_log_buffer = deque()
BUFFER_SIZE = 25         # –ú–∞–∫—Å–∏–º—É–º –ª–æ–≥–æ–≤ –∑–∞ –æ–¥–Ω—É –≤—Å—Ç–∞–≤–∫—É
FLUSH_INTERVAL = 1.0     # –ò–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏ (—Å–µ–∫—É–Ω–¥—ã)

# üî∏ –ü–∞–∫–µ—Ç–Ω–∞—è –≤—Å—Ç–∞–≤–∫–∞ –ª–æ–≥–æ–≤ –≤ signals_v4_log
async def flush_signal_logs():
    if not signal_log_buffer:
        return

    log = logging.getLogger("CORE_IO")
    batch = []
    while signal_log_buffer and len(batch) < BUFFER_SIZE:
        batch.append(signal_log_buffer.popleft())

    try:
        # üîπ –ó–∞–¥–µ—Ä–∂–∫–∞: —Å—á–∏—Ç–∞–µ–º –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É —Å–∏–≥–Ω–∞–ª—É
        try:
            last_sent_at = parser.isoparse(batch[-1]["sent_at"]).replace(tzinfo=None)
            latency_ms = (datetime.utcnow() - last_sent_at).total_seconds() * 1000
            await infra.record_gauge("processing_latency_ms", latency_ms)
        except Exception:
            pass

        async with infra.PG_POOL.acquire() as conn:
            await conn.executemany("""
                INSERT INTO signals_v4_log (
                    signal_id, symbol, direction, source, message, raw_message,
                    bar_time, sent_at, received_at, status, uid
                ) VALUES (
                    $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11
                )
                ON CONFLICT (uid) DO NOTHING
            """, [
                (
                    int(d["signal_id"]),
                    d["symbol"],
                    d["direction"],
                    d["source"],
                    d["message"],
                    d["raw_message"],
                    parser.isoparse(d["bar_time"]).replace(tzinfo=None),
                    parser.isoparse(d["sent_at"]).replace(tzinfo=None),
                    parser.isoparse(d["received_at"]).replace(tzinfo=None),
                    d["status"],
                    d["uid"]
                ) for d in batch
            ])
        log.debug(f"–ó–∞–ø–∏—Å–∞–Ω batch –ª–æ–≥–æ–≤: {len(batch)}")
    except Exception as e:
        log.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ batch insert: {e}")
        
# üî∏ –§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞: —Ñ–ª–∞—à –ª–æ–≥–æ–≤ —Å–∏–≥–Ω–∞–ª–æ–≤
async def run_flusher():
    while True:
        try:
            await flush_signal_logs()
        except Exception as e:
            logging.getLogger("CORE_IO").warning(f"–û—à–∏–±–∫–∞ –≤–æ flusher: {e}")
        await asyncio.sleep(FLUSH_INTERVAL)
        
# üî∏ –ó–∞–ø—É—Å–∫ –ª–æ–≥–≥–µ—Ä–∞ —Å–∏–≥–Ω–∞–ª–æ–≤: —á—Ç–µ–Ω–∏–µ –∏–∑ Redis Stream –∏ –∑–∞–ø–∏—Å—å –≤ –ë–î
async def run_core_io():
    log = logging.getLogger("CORE_IO")
    stream = "signals_log_stream"
    group = "core_io"
    consumer = "writer-1"

    try:
        await infra.REDIS.xgroup_create(stream, group, id="0", mkstream=True)
        log.info(f"–ì—Ä—É–ø–ø–∞ {group} —Å–æ–∑–¥–∞–Ω–∞ –¥–ª—è {stream}")
    except Exception:
        pass  # –≥—Ä—É–ø–ø–∞ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç

    # üî∏ –§–æ–Ω–æ–≤—ã–π –∑–∞–ø—É—Å–∫ flusher
    asyncio.create_task(run_flusher())

    while True:
        try:
            messages = await infra.REDIS.xreadgroup(
                groupname=group,
                consumername=consumer,
                streams={stream: ">"},
                count=100,
                block=500
            )
            if messages:
                for _, entries in messages:
                    for entry_id, entry_data in entries:
                        await insert_signal_log(dict(entry_data))
                        await infra.REDIS.xack(stream, group, entry_id)
        except Exception as e:
            log.exception(f"–û—à–∏–±–∫–∞ –≤ run_core_io: {e}")
            await asyncio.sleep(1)