# feed_cleaner.py ‚Äî —Ç—Ä–∏–≥–≥–µ—Ä–Ω–∞—è —á–∏—Å—Ç–∫–∞ –ø–æ BTCUSDT h1: XTRIM —Å—Ç–∞—Ä—à–µ 24—á –≤ Streams + DELETE —Å—Ç–∞—Ä—ã—Ö healed_ts –≤ PG

# üî∏ –ò–º–ø–æ—Ä—Ç—ã –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
import os
import asyncio
import logging
from datetime import datetime, timezone, timedelta

log = logging.getLogger("BB_FEED_CLEANER")

# üî∏ –ö–æ–Ω—Ñ–∏–≥/ENV
STREAM_OHLCV = "bb:ohlcv_stream"
STREAM_PG_INS = "bb:pg_candle_inserted"
CLEAN_SYMBOL = os.getenv("BB_CLEANER_SYMBOL", "BTCUSDT")
CLEAN_INTERVAL = os.getenv("BB_CLEANER_INTERVAL", "h1")
GROUP_NAME = os.getenv("BB_CLEANER_GROUP", "bb_cleaner_group")
CONSUMER_NAME = os.getenv("BB_CLEANER_CONSUMER", "bb_cleaner")
BLOCK_MS = int(os.getenv("BB_CLEANER_BLOCK_MS", "5000"))
RETENTION_HOURS = int(os.getenv("BB_CLEANER_RETENTION_HOURS", "24"))

# üî∏ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–æ–µ: –ø–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è Redis (UTC) –∏ –ø–æ—Ä–æ–≥ –æ—Ç—Å–µ—á–∫–∏ (dt, ms)
async def _get_cutoff_utc(redis) -> tuple[datetime, int]:
    # Redis TIME ‚Üí [seconds, microseconds]
    sec, usec = await redis.execute_command("TIME")
    now_utc = datetime.fromtimestamp(int(sec) + int(usec) / 1_000_000, tz=timezone.utc)
    cutoff_utc = now_utc - timedelta(hours=RETENTION_HOURS)
    cutoff_ms = int(cutoff_utc.timestamp() * 1000)
    return cutoff_utc, cutoff_ms

# üî∏ –¢—Ä–∏–º —Å—Ç—Ä–∏–º–æ–≤ –ø–æ –ø–æ—Ä–æ–≥—É MINID
async def _trim_streams(redis, cutoff_ms: int) -> tuple[int, int]:
    cutoff_id = f"{cutoff_ms}-0"
    # –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–µ–∑–∫–∞ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏: MINID ~ <cutoff_id>
    try:
        trimmed_ohlcv = await redis.execute_command("XTRIM", STREAM_OHLCV, "MINID", "~", cutoff_id)
    except Exception as e:
        log.warning(f"[CLEAN] XTRIM MINID {STREAM_OHLCV} –æ—à–∏–±–∫–∞: {e}")
        trimmed_ohlcv = 0
    try:
        trimmed_pgins = await redis.execute_command("XTRIM", STREAM_PG_INS, "MINID", "~", cutoff_id)
    except Exception as e:
        log.warning(f"[CLEAN] XTRIM MINID {STREAM_PG_INS} –æ—à–∏–±–∫–∞: {e}")
        trimmed_pgins = 0
    return int(trimmed_ohlcv or 0), int(trimmed_pgins or 0)

# üî∏ –ß–∏—Å—Ç–∫–∞ –ë–î: —É–¥–∞–ª–∏—Ç—å healed_ts —Å—Ç–∞—Ä—à–µ –ø–æ—Ä–æ–≥–∞
async def _delete_old_gaps(pg_pool, cutoff_dt_utc: datetime) -> int:
    # —É–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ, —á—Ç–æ —Ä–µ–∞–ª—å–Ω–æ –¥–æ–∑–∞–ª–∏—Ç—ã –≤ TS (healed_ts_at IS NOT NULL)
    try:
        async with pg_pool.connection() as conn:
            async with conn.cursor() as cur:
                await cur.execute(
                    """
                    DELETE FROM ohlcv_bb_gap
                    WHERE healed_ts_at IS NOT NULL
                      AND healed_ts_at < %s
                    """,
                    (cutoff_dt_utc.replace(tzinfo=None),)  # –≤ –ë–î timestamp –±–µ–∑ TZ, –∫–æ–Ω—Ç—Ä–∞–∫—Ç ‚Äî UTC-naive
                )
                # cursor.rowcount –º–æ–∂–µ—Ç –±—ã—Ç—å -1 –¥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è; –ø–æ—Å–ª–µ execute –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —á–∏—Å–ª–æ–º
                deleted = cur.rowcount if cur.rowcount is not None else 0
        return int(deleted or 0)
    except Exception as e:
        log.warning(f"[CLEAN] DELETE ohlcv_bb_gap –æ—à–∏–±–∫–∞: {e}", exc_info=True)
        return 0

# üî∏ –û—Å–Ω–æ–≤–Ω–æ–π –≤–æ—Ä–∫–µ—Ä: –∂–¥—ë—Ç —Ç—Ä–∏–≥–≥–µ—Ä (BTCUSDT/h1) –∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç —á–∏—Å—Ç–∫—É
async def run_feed_cleaner_bb(pg_pool, redis):
    log.info(f"BB_FEED_CLEANER –∑–∞–ø—É—â–µ–Ω: trigger={CLEAN_SYMBOL}/{CLEAN_INTERVAL}, retention={RETENTION_HOURS}h")

    # —Å–æ–∑–¥–∞—Ç—å –≥—Ä—É–ø–ø—É –¥–ª—è ohlcv_stream (—á–∏—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è)
    try:
        await redis.xgroup_create(STREAM_OHLCV, GROUP_NAME, id="$", mkstream=True)
    except Exception:
        # –≥—Ä—É–ø–ø–∞ –º–æ–≥–ª–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å ‚Äî —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ
        pass

    while True:
        try:
            # —á–∏—Ç–∞–µ–º –Ω–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–π –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å
            resp = await redis.xreadgroup(
                GROUP_NAME,
                CONSUMER_NAME,
                streams={STREAM_OHLCV: ">"},
                count=100,
                block=BLOCK_MS
            )
            if not resp:
                continue

            to_ack = []
            trigger = False

            # –ø–µ—Ä–µ–±–∏—Ä–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è batched
            for _stream_key, messages in resp:
                for msg_id, data in messages:
                    to_ack.append(msg_id)
                    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏
                    if not isinstance(data, dict):
                        continue
                    sym = data.get("symbol")
                    iv = data.get("interval")
                    if sym == CLEAN_SYMBOL and iv == CLEAN_INTERVAL:
                        trigger = True

            # –µ—Å–ª–∏ —Ç—Ä–∏–≥–≥–µ—Ä –ø–æ–π–º–∞–Ω ‚Äî —á–∏—Å—Ç–∏–º
            if trigger:
                cutoff_dt_utc, cutoff_ms = await _get_cutoff_utc(redis)
                trimmed_ohlcv, trimmed_pgins = await _trim_streams(redis, cutoff_ms)
                deleted_rows = await _delete_old_gaps(pg_pool, cutoff_dt_utc)

                # –ª–æ–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                log.info(
                    "CLEAN OK: trigger=%s/%s at=%s cutoff=%s ‚Üí XTRIM(%s)=%d, XTRIM(%s)=%d, DELETE(gap)=%d",
                    CLEAN_SYMBOL, CLEAN_INTERVAL,
                    datetime.utcnow().replace(tzinfo=timezone.utc).isoformat(),
                    cutoff_dt_utc.isoformat(),
                    STREAM_OHLCV, trimmed_ohlcv,
                    STREAM_PG_INS, trimmed_pgins,
                    deleted_rows
                )

            # ACK –≤—Å–µ—Ö –ø—Ä–æ—á–∏—Ç–∞–Ω–Ω—ã—Ö (—á—Ç–æ–± –Ω–µ –∫–æ–ø–∏—Ç—å PEL)
            if to_ack:
                try:
                    await redis.xack(STREAM_OHLCV, GROUP_NAME, *to_ack)
                except Exception as e:
                    log.warning(f"[CLEAN] XACK –æ—à–∏–±–∫–∞: {e}")

        except Exception as e:
            log.error(f"BB_FEED_CLEANER –æ—à–∏–±–∫–∞: {e}", exc_info=True)
            await asyncio.sleep(2)