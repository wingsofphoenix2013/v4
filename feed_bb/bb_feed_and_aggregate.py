# bb_feed_and_aggregate.py â€” per-symbol Bybit WS (linear) â†’ Redis TS/Stream Ð´Ð»Ñ m5/m15/h1

# ðŸ”¸ Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ñ‹ Ð¸ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸
import os
import asyncio
import logging
import json
import time
import random
from decimal import Decimal, ROUND_DOWN, InvalidOperation

import websockets
from websockets.exceptions import ConnectionClosedError

log = logging.getLogger("BB_FEED_AGGR")

# ðŸ”¸ ÐšÐ¾Ð½Ñ„Ð¸Ð³/ENV
BYBIT_WS_URL = os.getenv("BYBIT_WS_PUBLIC_LINEAR", "wss://stream.bybit.com/v5/public/linear")
KEEPALIVE_SEC = int(os.getenv("BB_WS_KEEPALIVE_SEC", "60"))
ACTIVE_REFRESH_SEC = int(os.getenv("BB_ACTIVE_REFRESH_SEC", "60"))
NONCLOSED_THROTTLE_SEC = int(os.getenv("BB_NONCLOSED_THROTTLE_SEC", "10"))
TS_RETENTION_MS = int(os.getenv("BB_TS_RETENTION_MS", str(60 * 24 * 60 * 60 * 1000)))  # ~60 Ð´Ð½ÐµÐ¹

# ðŸ”¸ ÐœÐ°Ð¿Ð¿Ð¸Ð½Ð³Ð¸ Ð¸Ð½Ñ‚ÐµÑ€Ð²Ð°Ð»Ð¾Ð²
SUB_IV = {"m5": "5", "m15": "15", "h1": "60"}
ALL_TF = ("m5", "m15", "h1")

# ðŸ”¸ ÐšÐµÑˆ precision Ð¸Ð· tickers_bb
class PrecisionCache:
    def __init__(self):
        self.price = {}
        self.qty = {}

    async def get(self, pg_pool, symbol: str):
        if symbol in self.price and symbol in self.qty:
            return self.price[symbol], self.qty[symbol]
        async with pg_pool.connection() as conn:
            async with conn.cursor() as cur:
                await cur.execute(
                    "SELECT precision_price, precision_qty FROM tickers_bb WHERE symbol = %s",
                    (symbol,)
                )
                row = await cur.fetchone()
        pp = int(row[0]) if row and row[0] is not None else 0
        pq = int(row[1]) if row and row[1] is not None else 0
        self.price[symbol] = pp
        self.qty[symbol] = pq
        return pp, pq

prec_cache = PrecisionCache()

# ðŸ”¸ Ð£Ñ‚Ð¸Ð»Ð¸Ñ‚Ñ‹ Ð¾ÐºÑ€ÑƒÐ³Ð»ÐµÐ½Ð¸Ñ/Ñ‡Ñ‚ÐµÐ½Ð¸Ñ Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ…
def _round_down(value: float, digits: int) -> float:
    if digits <= 0:
        if digits == 0:
            try:
                return float(Decimal(value).to_integral_value(rounding=ROUND_DOWN))
            except Exception:
                return float(int(value))
        return value
    try:
        return float(Decimal(value).quantize(Decimal(f"1e-{digits}"), rounding=ROUND_DOWN))
    except (InvalidOperation, ValueError):
        return value

async def _load_active_symbols(pg_pool):
    try:
        async with pg_pool.connection() as conn:
            async with conn.cursor() as cur:
                await cur.execute(
                    "SELECT symbol FROM tickers_bb WHERE status='enabled' AND is_active=true ORDER BY symbol"
                )
                rows = await cur.fetchall()
        return [r[0] for r in rows] if rows else []
    except Exception as e:
        log.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ… Ñ‚Ð¸ÐºÐµÑ€Ð¾Ð²: {e}", exc_info=True)
        return []

# ðŸ”¸ Ð‘ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð°Ñ Ð·Ð°Ð¿Ð¸ÑÑŒ Ð¾Ð´Ð½Ð¾Ð¹ Ñ‚Ð¾Ñ‡ÐºÐ¸ Ð² Redis TS
async def _ts_safe_add(redis, key: str, ts_ms: int, value, labels: dict):
    try:
        try:
            await redis.execute_command("TS.INFO", key)
        except Exception:
            await redis.execute_command(
                "TS.CREATE", key,
                "RETENTION", TS_RETENTION_MS,
                "DUPLICATE_POLICY", "last",
                "LABELS", *sum(([k, str(v)] for k, v in labels.items()), [])
            )
        await redis.execute_command("TS.ADD", key, ts_ms, value)
    except Exception as e:
        log.warning(f"TS.ADD Ð¾ÑˆÐ¸Ð±ÐºÐ° {key}: {e}")

# ðŸ”¸ ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Bybit kline
def _parse_bybit_kline(msg: dict):
    topic = msg.get("topic") or ""
    if not topic.startswith("kline."):
        return []
    parts = topic.split(".")
    if len(parts) != 3:
        return []
    iv_bybit, symbol = parts[1], parts[2]
    iv_map = {"5": "m5", "15": "m15", "60": "h1"}
    interval_m = iv_map.get(iv_bybit)
    if not interval_m:
        return []
    data = msg.get("data") or []
    out = []
    for item in data:
        start = item.get("start")
        if start is None:
            continue
        try:
            o = float(item.get("open")); h = float(item.get("high"))
            l = float(item.get("low"));  c = float(item.get("close"))
            v = float(item.get("volume"))
        except Exception:
            continue
        is_closed = bool(item.get("confirm"))
        out.append((symbol, interval_m, int(start), o, h, l, c, v, is_closed))
    return out

# ðŸ”¸ per-symbol WS listener (ÐºÐ»Ð°Ð´Ñ‘Ñ‚ kline-ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ñ‹ Ð² Ð¾Ñ‡ÐµÑ€ÐµÐ´ÑŒ)
async def _listen_symbol_tf(symbol: str, bybit_iv: str, queue: asyncio.Queue):
    url = BYBIT_WS_URL
    topic = f"kline.{bybit_iv}.{symbol}"

    async def keepalive(ws):
        try:
            while True:
                try:
                    await ws.ping()                               # ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ñ‹Ð¹ WS ping
                    await ws.send(json.dumps({"op": "ping"}))     # Bybit ping
                except Exception:
                    return
                await asyncio.sleep(KEEPALIVE_SEC)                # Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð¾Ð². 20 c
        except asyncio.CancelledError:
            return

    backoff = 1.0  # ÑÐºÑÐ¿Ð¾Ð½ÐµÐ½Ñ†Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð±ÑÐºÐ¾Ñ„Ñ„ Ñ Ð´Ð¶Ð¸Ñ‚Ñ‚ÐµÑ€Ð¾Ð¼

    while True:
        try:
            # Ð¼ÑÐ³ÐºÐ¸Ð¹ ÑÑ‚Ð°Ñ€Ñ‚, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ð¾Ñ‚ÐºÑ€Ñ‹Ð²Ð°Ñ‚ÑŒ Ð´ÐµÑÑÑ‚ÐºÐ¸ ÐºÐ¾Ð½Ð½ÐµÐºÑ‚Ð¾Ð² Ð¾Ð´Ð½Ð¾Ð¼Ð¾Ð¼ÐµÐ½Ñ‚Ð½Ð¾
            await asyncio.sleep(random.uniform(0.05, 0.25))

            async with websockets.connect(
                url,
                ping_interval=None,       # ÑÐ²Ð¾Ð¹ keepalive
                close_timeout=5,
                max_queue=None,           # Ð½Ðµ Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ð¾Ñ‡ÐµÑ€ÐµÐ´ÑŒ ÐºÐ°Ð´Ñ€Ð¾Ð²
                open_timeout=10,
            ) as ws:
                # Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÐ°
                await ws.send(json.dumps({"op": "subscribe", "args": [topic]}))

                # Ð¼ÑÐ³ÐºÐ¸Ð¹ ack: Ð¿Ð¾Ð´Ð¾Ð¶Ð´Ð°Ñ‚ÑŒ Ð´Ð¾ 5Ñ, Ð½Ð¾ ÐÐ• Ñ€Ð²Ð°Ñ‚ÑŒ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¸ Ñ‚Ð°Ð¹Ð¼Ð°ÑƒÑ‚Ðµ
                try:
                    ack_raw = await asyncio.wait_for(ws.recv(), timeout=5.0)
                    try:
                        ack = json.loads(ack_raw)
                        if isinstance(ack, dict) and ack.get("op") == "subscribe":
                            pass  # Ð¾Ðº
                    except Exception:
                        pass
                except asyncio.TimeoutError:
                    pass  # Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð°ÐµÐ¼ Ð±ÐµÐ· ack

                # ÑƒÑÐ¿ÐµÑˆÐ½Ð¾Ðµ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ â†’ ÑÐ±Ñ€Ð°ÑÑ‹Ð²Ð°ÐµÐ¼ Ð±ÑÐºÐ¾Ñ„Ñ„ Ð¸ Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ keepalive
                backoff = 1.0
                ka = asyncio.create_task(keepalive(ws))
                try:
                    async for raw in ws:
                        try:
                            msg = json.loads(raw)
                        except Exception:
                            continue
                        if msg.get("topic") != topic:
                            continue

                        items = _parse_bybit_kline(msg)  # [(sym, iv_m, ts_ms, o,h,l,c,v,is_closed), ...]
                        for it in items:
                            await queue.put(it)
                finally:
                    ka.cancel()

        except (ConnectionClosedError, asyncio.IncompleteReadError, OSError) as e:
            # Ð¾Ð¶Ð¸Ð´Ð°ÐµÐ¼Ñ‹Ðµ ÑÐµÑ‚ÐµÐ²Ñ‹Ðµ Ð¾Ð±Ñ€Ñ‹Ð²Ñ‹ â€” Ð¿Ð»Ð°Ð²Ð½Ñ‹Ð¹ Ñ€ÐµÐºÐ¾Ð½Ð½ÐµÐºÑ‚ Ñ Ð´Ð¶Ð¸Ñ‚Ñ‚ÐµÑ€Ð¾Ð¼
            wait = min(30.0, backoff * (1.5 + random.random() * 0.5))
            log.info(f"[WS {bybit_iv}] {symbol} reconnect in {wait:.1f}s ({type(e).__name__})")
            await asyncio.sleep(wait)
            backoff = wait

        except Exception as e:
            # Ð½ÐµÐ¾Ð¶Ð¸Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ â€” ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¹ Ð±ÑÐºÐ¾Ñ„Ñ„
            log.error(f"[WS {bybit_iv}] {symbol} error: {e}", exc_info=True)
            await asyncio.sleep(3)
                        
# ðŸ”¸ worker: Ð±ÐµÑ€Ñ‘Ñ‚ Ð¸Ð· Ð¾Ñ‡ÐµÑ€ÐµÐ´Ð¸, Ð¿Ð¸ÑˆÐµÑ‚ TS/Stream (Ñ‚Ñ€Ð¾Ñ‚Ñ‚Ð»Ð¸Ñ‚ Ð½ÐµÐ·Ð°ÐºÑ€Ñ‹Ñ‚Ñ‹Ðµ)
async def _kline_worker_tf(queue: asyncio.Queue, pg_pool, redis, tf_name: str, throttle_map: dict):
    while True:
        sym, iv_m, ts_ms, o, h, l, c, v, is_closed = await queue.get()
        try:
            pp, pq = await prec_cache.get(pg_pool, sym)
            o_r = _round_down(o, pp); h_r = _round_down(h, pp)
            l_r = _round_down(l, pp); c_r = _round_down(c, pp)
            v_r = _round_down(v, pq)
            labels = {"symbol": sym, "interval": iv_m}

            # Ñ‚Ñ€Ð¾Ñ‚Ñ‚Ð»Ð¸Ð½Ð³ Ð½ÐµÐ·Ð°ÐºÑ€Ñ‹Ñ‚Ñ‹Ñ… Ð±Ð°Ñ€Ð¾Ð²
            if not is_closed:
                key = (sym, iv_m)
                now_s = int(time.monotonic())
                last_s = throttle_map.get(key, 0)
                if now_s - last_s < NONCLOSED_THROTTLE_SEC:
                    continue
                throttle_map[key] = now_s

            # Ð·Ð°Ð¿Ð¸ÑÑŒ Ð² TS (ÐºÐ°Ðº Ð² v4: Ð¾Ð´Ð¸Ð½ Ñ€ÑÐ´, last-Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿Ð¸ÑÑŒ)
            await asyncio.gather(
                _ts_safe_add(redis, f"bb:ts:{sym}:{iv_m}:o", ts_ms, o_r, {**labels, "field": "o"}),
                _ts_safe_add(redis, f"bb:ts:{sym}:{iv_m}:h", ts_ms, h_r, {**labels, "field": "h"}),
                _ts_safe_add(redis, f"bb:ts:{sym}:{iv_m}:l", ts_ms, l_r, {**labels, "field": "l"}),
                _ts_safe_add(redis, f"bb:ts:{sym}:{iv_m}:c", ts_ms, c_r, {**labels, "field": "c"}),
                _ts_safe_add(redis, f"bb:ts:{sym}:{iv_m}:v", ts_ms, v_r, {**labels, "field": "v"}),
            )

            # Ð·Ð°ÐºÑ€Ñ‹Ñ‚Ñ‹Ð¹ Ð±Ð°Ñ€ â†’ Ð² Stream + Pub/Sub
            if is_closed:
                await redis.xadd("bb:ohlcv_stream", {
                    "symbol": sym, "interval": iv_m, "timestamp": str(ts_ms),
                    "o": str(o_r), "h": str(h_r), "l": str(l_r), "c": str(c_r), "v": str(v_r),
                })
                await redis.publish("bb:ohlcv_channel", json.dumps({
                    "symbol": sym, "interval": iv_m, "timestamp": str(ts_ms)
                }))

        except Exception as e:
            log.warning(f"[{tf_name}] worker err {sym}: {e}", exc_info=True)
        finally:
            queue.task_done()

# ðŸ”¸ ÐœÐµÐ½ÐµÐ´Ð¶ÐµÑ€ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ñ‚Ð°Ð¹Ð¼Ñ„Ñ€ÐµÐ¹Ð¼Ð°: per-symbol WS + Ð¿ÑƒÐ» Ð²Ð¾Ñ€ÐºÐµÑ€Ð¾Ð²
async def _run_tf_manager(pg_pool, redis, interval_m: str, workers_num: int = 6):
    bybit_iv = SUB_IV[interval_m]
    tf_name = interval_m
    log.info(f"[{tf_name}] per-symbol WS mode")

    queue: asyncio.Queue = asyncio.Queue(maxsize=20000)
    throttle_map: dict = {}
    workers = [
        asyncio.create_task(_kline_worker_tf(queue, pg_pool, redis, tf_name, throttle_map))
        for _ in range(workers_num)
    ]

    tasks: dict[str, asyncio.Task] = {}

    while True:
        try:
            active = set(await _load_active_symbols(pg_pool))
            known = set(tasks.keys())

            # ÑÑ‚Ð°Ñ€Ñ‚ Ð½Ð¾Ð²Ñ‹Ñ… ÑÐ»ÑƒÑˆÐ°Ñ‚ÐµÐ»ÐµÐ¹
            for sym in active - known:
                tasks[sym] = asyncio.create_task(_listen_symbol_tf(sym, bybit_iv, queue))
                log.info(f"[{tf_name}] start WS {sym}")
                # Ð»Ñ‘Ð³ÐºÐ¸Ð¹ stagger, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ð»ÑƒÐ¿Ð¸Ñ‚ÑŒ Ð´ÐµÑÑÑ‚ÐºÐ¸ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ð¹ Ð² Ð¾Ð´Ð½Ñƒ Ð¼Ð¸Ð»Ð»Ð¸ÑÐµÐºÑƒÐ½Ð´Ñƒ
                await asyncio.sleep(0.05)

            # ÑÑ‚Ð¾Ð¿ Ð»Ð¸ÑˆÐ½Ð¸Ñ…
            for sym in known - active:
                t = tasks.pop(sym, None)
                if t:
                    t.cancel()
                    log.info(f"[{tf_name}] stop WS {sym}")

            await asyncio.sleep(ACTIVE_REFRESH_SEC)
        except Exception as e:
            log.error(f"[{tf_name}] manager err: {e}", exc_info=True)
            await asyncio.sleep(2)

# ðŸ”¸ ÐŸÑƒÐ±Ð»Ð¸Ñ‡Ð½Ñ‹Ðµ Ð²Ð¾Ñ€ÐºÐµÑ€Ñ‹ (Ð´Ð»Ñ main)
async def run_feed_and_aggregator_m5_bb(pg_pool, redis):
    await _run_tf_manager(pg_pool, redis, "m5", workers_num=int(os.getenv("BB_M5_WORKERS", "8")))

async def run_feed_and_aggregator_m15_bb(pg_pool, redis):
    await _run_tf_manager(pg_pool, redis, "m15", workers_num=int(os.getenv("BB_M15_WORKERS", "6")))

async def run_feed_and_aggregator_h1_bb(pg_pool, redis):
    await _run_tf_manager(pg_pool, redis, "h1", workers_num=int(os.getenv("BB_H1_WORKERS", "4")))