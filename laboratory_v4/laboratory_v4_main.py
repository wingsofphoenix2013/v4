# üî∏ –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏–∏: –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ, –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ —Ä–∞–Ω—ã (–ø–æ 10), –±–∞—Ç—á-–æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–∑–∏—Ü–∏–π (–ø–æ 500), —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã

import os
import asyncio
import logging
from datetime import datetime

import laboratory_v4_infra as infra
import laboratory_v4_loader as loader
import laboratory_v4_results_aggregator as results_agg
import laboratory_v4_adx_worker as adx
import laboratory_v4_bb_worker as bb
import laboratory_v4_rsi_worker as rsi
import laboratory_v4_dmigaptrend_worker as dmigt
import laboratory_v4_dmigap_worker as dmigap
import laboratory_v4_emastatus_worker as emastatus

import laboratory_v4_seeder as seeder

log = logging.getLogger("LAB_MAIN")

LAB_LOOP_SLEEP_SEC = int(os.getenv("LAB_LOOP_SLEEP_SEC", "21600"))

# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ä–∞–Ω–∞ (lab_id √ó strategy_id)
async def process_run(lab: dict, strategy_id: int):
    lab_id = int(lab["lab_id"])
    lock_key = f"lab:run:lock:{lab_id}:{strategy_id}"

    try:
        try:
            async with infra.redis_lock(lock_key, ttl_sec=infra.LOCK_TTL_SEC):
                # 1) —Å–æ–∑–¥–∞—ë–º run
                run_id = await infra.create_run(lab_id, strategy_id)
                await infra.mark_run_started(run_id)

                # 2) –≥—Ä—É–∑–∏–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Ç–µ—Å—Ç–∞ (–ø–æ—Ä–æ–≥–∏ min_trade_type/value, min_winrate)
                async with infra.pg_pool.acquire() as conn:
                    lab_cfg_row = await conn.fetchrow(
                        """
                        SELECT id AS lab_id, name, min_trade_type, min_trade_value, min_winrate
                        FROM laboratory_instances_v4
                        WHERE id = $1
                        """,
                        lab_id,
                    )
                if not lab_cfg_row:
                    log.error("–ù–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ laboratory_instances_v4 –¥–ª—è lab_id=%s ‚Äî —Ä–∞–Ω –ø—Ä–æ–ø—É—â–µ–Ω", lab_id)
                    await infra.mark_run_finished(run_id)
                    await infra.send_finish_signal(lab_id, strategy_id, run_id)
                    return

                lab_cfg = dict(lab_cfg_row)

                # üî∏ –æ–±–Ω–æ–≤–ª—è–µ–º last_used –¥–ª—è —ç—Ç–æ–≥–æ —Ç–µ—Å—Ç–∞
                async with infra.pg_pool.acquire() as conn:
                    await conn.execute(
                        "UPDATE laboratory_instances_v4 SET last_used = NOW() WHERE id=$1",
                        lab_id,
                    )

                # 3) –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Ç–µ—Å—Ç–∞ (–¥–ª—è —É–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏)
                params = await loader.load_lab_parameters(lab_id)
                log.debug(
                    "–°—Ç–∞—Ä—Ç —Ä–∞–Ωa lab_id=%s strategy_id=%s run_id=%s components=%d",
                    lab_id, strategy_id, run_id, len(params)
                )

                # 4) —Ñ–∏–∫—Å–∏—Ä—É–µ–º cutoff –∏ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫—ç—à–∏ –ø–æ —Å—É—â–Ω–æ—Å—Ç–∏ —Ç–µ—Å—Ç–∞
                cutoff = datetime.now()

                is_adx        = any(p["test_name"] == "adx"        for p in params)
                is_bb         = any(p["test_name"] == "bb"         for p in params)
                is_rsi        = any(p["test_name"] == "rsi"        for p in params)
                is_dmigt      = any(p["test_name"] == "dmigap_trend" for p in params)
                is_dmigap     = any(p["test_name"] == "dmigap"     for p in params)
                is_emastatus  = any(p["test_name"] == "emastatus"  for p in params)

                processed = approved = filtered = skipped = 0
                batch_uids: list[str] = []

                if is_adx and not (is_bb or is_rsi or is_dmigt or is_dmigap or is_emastatus):
                    per_tf_cache, comp_cache = await adx.load_adx_aggregates_for_strategy(strategy_id)
                    totals_by_dir = await adx.load_total_closed_by_direction(strategy_id, cutoff)

                    async def process_batch(uids: list[str]):
                        nonlocal processed, approved, filtered, skipped
                        if not uids:
                            return
                        a, f, s = await adx.process_adx_batch(
                            lab=lab_cfg,
                            strategy_id=strategy_id,
                            run_id=run_id,
                            cutoff=cutoff,
                            lab_params=params,
                            position_uids=uids,
                            per_tf_cache=per_tf_cache,
                            comp_cache=comp_cache,
                            totals_by_dir=totals_by_dir,
                        )
                        processed += len(uids); approved += a; filtered += f; skipped += s
                        await infra.update_progress_json(run_id, {
                            "cutoff_at": cutoff.isoformat(),
                            "processed": processed,
                            "approved": approved,
                            "filtered": filtered,
                            "skipped_no_data": skipped,
                        })

                elif is_bb and not (is_adx or is_rsi or is_dmigt or is_dmigap or is_emastatus):
                    per_tf_cache, comp_cache = await bb.load_bb_aggregates_for_strategy(strategy_id)
                    totals_by_dir = await bb.load_total_closed_by_direction(strategy_id, cutoff)

                    async def process_batch(uids: list[str]):
                        nonlocal processed, approved, filtered, skipped
                        if not uids:
                            return
                        a, f, s = await bb.process_bb_batch(
                            lab=lab_cfg,
                            strategy_id=strategy_id,
                            run_id=run_id,
                            cutoff=cutoff,
                            lab_params=params,
                            position_uids=uids,
                            per_tf_cache=per_tf_cache,
                            comp_cache=comp_cache,
                            totals_by_dir=totals_by_dir,
                        )
                        processed += len(uids); approved += a; filtered += f; skipped += s
                        await infra.update_progress_json(run_id, {
                            "cutoff_at": cutoff.isoformat(),
                            "processed": processed,
                            "approved": approved,
                            "filtered": filtered,
                            "skipped_no_data": skipped,
                        })

                elif is_rsi and not (is_adx or is_bb or is_dmigt or is_dmigap or is_emastatus):
                    per_tf_cache, comp_cache = await rsi.load_rsi_aggregates_for_strategy(strategy_id)
                    totals_by_dir = await rsi.load_total_closed_by_direction(strategy_id, cutoff)

                    async def process_batch(uids: list[str]):
                        nonlocal processed, approved, filtered, skipped
                        if not uids:
                            return
                        a, f, s = await rsi.process_rsi_batch(
                            lab=lab_cfg,
                            strategy_id=strategy_id,
                            run_id=run_id,
                            cutoff=cutoff,
                            lab_params=params,
                            position_uids=uids,
                            per_tf_cache=per_tf_cache,
                            comp_cache=comp_cache,
                            totals_by_dir=totals_by_dir,
                        )
                        processed += len(uids); approved += a; filtered += f; skipped += s
                        await infra.update_progress_json(run_id, {
                            "cutoff_at": cutoff.isoformat(),
                            "processed": processed,
                            "approved": approved,
                            "filtered": filtered,
                            "skipped_no_data": skipped,
                        })

                elif is_dmigt and not (is_adx or is_bb or is_rsi or is_dmigap or is_emastatus):
                    per_tf_cache, comp_cache = await dmigt.load_dmigaptrend_aggregates_for_strategy(strategy_id)
                    totals_by_dir = await dmigt.load_total_closed_by_direction(strategy_id, cutoff)

                    async def process_batch(uids: list[str]):
                        nonlocal processed, approved, filtered, skipped
                        if not uids:
                            return
                        a, f, s = await dmigt.process_dmigaptrend_batch(
                            lab=lab_cfg,
                            strategy_id=strategy_id,
                            run_id=run_id,
                            cutoff=cutoff,
                            lab_params=params,
                            position_uids=uids,
                            per_tf_cache=per_tf_cache,
                            comp_cache=comp_cache,
                            totals_by_dir=totals_by_dir,
                        )
                        processed += len(uids); approved += a; filtered += f; skipped += s
                        await infra.update_progress_json(run_id, {
                            "cutoff_at": cutoff.isoformat(),
                            "processed": processed,
                            "approved": approved,
                            "filtered": filtered,
                            "skipped_no_data": skipped,
                        })

                elif is_dmigap and not (is_adx or is_bb or is_rsi or is_dmigt or is_emastatus):
                    per_tf_cache, comp_cache = await dmigap.load_dmigap_aggregates_for_strategy(strategy_id)
                    totals_by_dir = await dmigap.load_total_closed_by_direction(strategy_id, cutoff)

                    async def process_batch(uids: list[str]):
                        nonlocal processed, approved, filtered, skipped
                        if not uids:
                            return
                        a, f, s = await dmigap.process_dmigap_batch(
                            lab=lab_cfg,
                            strategy_id=strategy_id,
                            run_id=run_id,
                            cutoff=cutoff,
                            lab_params=params,
                            position_uids=uids,
                            per_tf_cache=per_tf_cache,
                            comp_cache=comp_cache,
                            totals_by_dir=totals_by_dir,
                        )
                        processed += len(uids); approved += a; filtered += f; skipped += s
                        await infra.update_progress_json(run_id, {
                            "cutoff_at": cutoff.isoformat(),
                            "processed": processed,
                            "approved": approved,
                            "filtered": filtered,
                            "skipped_no_data": skipped,
                        })

                elif is_emastatus and not (is_adx or is_bb or is_rsi or is_dmigt or is_dmigap):
                    per_tf_cache, comp_cache = await emastatus.load_emastatus_aggregates_for_strategy(strategy_id)
                    totals_by_dir = await emastatus.load_total_closed_by_direction(strategy_id, cutoff)

                    async def process_batch(uids: list[str]):
                        nonlocal processed, approved, filtered, skipped
                        if not uids:
                            return
                        a, f, s = await emastatus.process_emastatus_batch(
                            lab=lab_cfg,
                            strategy_id=strategy_id,
                            run_id=run_id,
                            cutoff=cutoff,
                            lab_params=params,          # —Å–æ–¥–µ—Ä–∂–∏—Ç {"ema_len": ‚Ä¶} –≤ param_spec
                            position_uids=uids,
                            per_tf_cache=per_tf_cache,
                            comp_cache=comp_cache,
                            totals_by_dir=totals_by_dir,
                        )
                        processed += len(uids); approved += a; filtered += f; skipped += s
                        await infra.update_progress_json(run_id, {
                            "cutoff_at": cutoff.isoformat(),
                            "processed": processed,
                            "approved": approved,
                            "filtered": filtered,
                            "skipped_no_data": skipped,
                        })

                else:
                    async def process_batch(uids: list[str]):
                        return

                # 5) –ø—Ä–æ—Ö–æ–¥–∏–º –∑–∞–∫—Ä—ã—Ç—ã–µ –ø–æ–∑–∏—Ü–∏–∏ –ø–∞—á–∫–∞–º–∏
                async for uid in loader.iter_closed_positions_uids(strategy_id, cutoff, infra.POSITIONS_BATCH):
                    batch_uids.append(uid)
                    if len(batch_uids) >= infra.POSITIONS_BATCH:
                        await process_batch(batch_uids)
                        batch_uids.clear()

                # —Ö–≤–æ—Å—Ç
                if batch_uids:
                    await process_batch(batch_uids)
                    batch_uids.clear()

                # 6) —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å + –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ + —Å–∏–≥–Ω–∞–ª
                await infra.update_progress_json(run_id, {
                    "cutoff_at": cutoff.isoformat(),
                    "processed": processed,
                    "approved": approved,
                    "filtered": filtered,
                    "skipped_no_data": skipped,
                })
                await infra.mark_run_finished(run_id)
                await infra.send_finish_signal(lab_id, strategy_id, run_id)
                log.debug(
                    "RUN DONE lab=%s strategy=%s run_id=%s processed=%s approved=%s filtered=%s skipped=%s",
                    lab_id, strategy_id, run_id, processed, approved, filtered, skipped
                )

        except RuntimeError as e:
            if str(e).startswith("lock_busy:"):
                log.info("–ü—Ä–æ–ø—É—Å–∫: –ª–æ–∫ –∑–∞–Ω—è—Ç –¥–ª—è lab=%s strategy=%s (%s)", lab_id, strategy_id, e)
                return
            raise

    except asyncio.CancelledError:
        log.info("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–∞–Ωa lab=%s strategy=%s –ø–æ —Å–∏–≥–Ω–∞–ª—É", lab_id, strategy_id)
        raise
    except Exception as e:
        log.exception("–û—à–∏–±–∫–∞ —Ä–∞–Ωa lab=%s strategy=%s: %s", lab_id, strategy_id, e) 
               
# üî∏ –û–±—ë—Ä—Ç–∫–∞ –¥–ª—è —Å–µ–º–∞—Ñ–æ—Ä–∞ (–Ω–µ –±–æ–ª–µ–µ N –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä–∞–Ωo–≤)
async def run_guarded(lab: dict, sid: int):
    await infra.concurrency_sem.acquire()
    try:
        await process_run(lab, sid)
    finally:
        infra.concurrency_sem.release()


# üî∏ –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –∑–∞–ø—É—Å–∫–æ–≤ (–ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π —Ä–µ—Ñ—Ä–µ—à –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤/—Å—Ç—Ä–∞—Ç–µ–≥–∏–π)
async def scheduler_loop():
    
    await asyncio.sleep(120)
    
    while True:
        try:
            plan = await loader.build_run_plan()
            tasks: list[asyncio.Task] = []
            for lab_id, sid in plan:
                lab_dict = {"lab_id": lab_id}
                tasks.append(asyncio.create_task(run_guarded(lab_dict, sid)))
            if tasks:
                await asyncio.gather(*tasks)
        except asyncio.CancelledError:
            log.info("–ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            raise
        except Exception:
            log.exception("–û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞")
        await asyncio.sleep(LAB_LOOP_SLEEP_SEC)


# üî∏ main
async def main():
    infra.setup_logging()
    log.info("–ó–∞–ø—É—Å–∫ laboratory_v4 Background Worker")

    await infra.setup_pg()
    await infra.setup_redis_client()
    
    await seeder.run_adx_seeder()
    await seeder.run_bb_seeder()
    await seeder.run_rsi_seeder()
#     await seeder.run_dmigaptrend_seeder()
    await seeder.run_dmigap_seeder()
    await seeder.run_emastatus_seeder()

    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±–∞ –≤–æ—Ä–∫–µ—Ä–∞ –ø–æ–¥ –∞–≤—Ç–æ–ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–æ–º
    await asyncio.gather(
        infra.run_safe_loop(scheduler_loop, "LAB_SCHEDULER"),
        infra.run_safe_loop(results_agg.run_laboratory_results_aggregator, "LAB_RESULTS_AGG"),
    )


if __name__ == "__main__":
    asyncio.run(main())