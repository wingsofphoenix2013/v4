# laboratory_decision_maker.py â€” Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº Ñ€ÐµÑˆÐµÐ½Ð¸Ð¹ (allow/deny): ÑˆÑ‚Ð¾Ñ€ÐºÐ° Ð¿Ð¾ (gate_sid, symbol) c Ð¾Ñ‡ÐµÑ€ÐµÐ´ÑŒÑŽ, MWâ†’(PACK Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾), Ð´Ð¸Ð½Ð°Ð¼Ð¸ÐºÐ° blacklist, Ð¾Ñ‚Ð²ÐµÑ‚ Ð¸ Ð°ÑƒÐ´Ð¸Ñ‚

import asyncio
import json
import logging
import time
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

# ðŸ”¸ Ð˜Ð½Ñ„Ñ€Ð°ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð°
import laboratory_infra as infra

# ðŸ”¸ Ð›Ð¾Ð³Ð³ÐµÑ€
log = logging.getLogger("LAB_DECISION")

# ðŸ”¸ ÐŸÐ¾Ñ‚Ð¾ÐºÐ¸ Ð¸ ÑˆÐ»ÑŽÐ·
DECISION_REQ_STREAM = "laboratory:decision_request"
DECISION_RESP_STREAM = "laboratory:decision_response"
GATEWAY_REQ_STREAM = "indicator_gateway_request"

# ðŸ”¸ ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
XREAD_BLOCK_MS = 2000
XREAD_COUNT = 50
MAX_IN_FLIGHT_DECISIONS = 32
MAX_CONCURRENT_GATEWAY_CALLS = 32
COALESCE_TTL_SEC = 3
SAFETY_DEADLINE_MS = 60_000  # Ð¾Ð±Ñ‰Ð¸Ð¹ Ð¿Ð¾Ñ‚Ð¾Ð»Ð¾Ðº Ð½Ð° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÑƒ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°

# ðŸ”¸ ÐŸÐ¾Ñ€ÑÐ´Ð¾Ðº TF
TF_ORDER = ("m5", "m15", "h1")

# ðŸ”¸ ÐŸÑƒÐ±Ð»Ð¸Ñ‡Ð½Ñ‹Ðµ Ð¿Ñ€ÐµÑ„Ð¸ÐºÑÑ‹ PACK-ÐºÑÑˆÐ°
PACK_PUBLIC_PREFIX = {
    "bb": "bbpos_pack",
    "lr": "lrpos_pack",
    "atr": "atr_pack",
    "adx_dmi": "adx_dmi_pack",
    "macd": "macd_pack",
    # Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ: f"{indicator}_pack"
}

# ðŸ”¸ Ð¡ÐµÐ¼Ð°Ñ„Ð¾Ñ€Ñ‹ ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ†Ð¸Ð¸
_decisions_sem = asyncio.Semaphore(MAX_IN_FLIGHT_DECISIONS)
_gateway_sem = asyncio.Semaphore(MAX_CONCURRENT_GATEWAY_CALLS)

# ðŸ”¸ ÐšÐ¾Ð°Ð»ÐµÑÑ†ÐµÐ½Ñ (in-process) â€” key -> (expire_ms, future)
_coalesce: Dict[str, Tuple[float, asyncio.Future]] = {}


# ðŸ”¸ ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ð¸ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ
def _parse_timeframes(tf_str: str) -> List[str]:
    items = [x.strip().lower() for x in (tf_str or "").split(",") if x.strip()]
    seen, ordered = set(), []
    for tf in TF_ORDER:
        if tf in items and tf not in seen:
            seen.add(tf)
            ordered.append(tf)
    return ordered


def _parse_pack_base(base: str) -> Tuple[str, Dict[str, Any]]:
    s = base.strip().lower()
    if s.startswith("bb"):
        rest = s[2:]
        parts = rest.split("_", 2)
        L = int(parts[0])
        std = float(parts[1].replace("_", ".", 1)) if len(parts) > 1 else 2.0
        return "bb", {"length": L, "std": std}
    if s.startswith("macd"):
        return "macd", {"fast": int(s[4:])}
    if s.startswith("adx_dmi"):
        return "adx_dmi", {"length": int(s[7:])}
    if s.startswith("ema"):
        return "ema", {"length": int(s[3:])}
    if s.startswith("rsi"):
        return "rsi", {"length": int(s[3:])}
    if s.startswith("mfi"):
        return "mfi", {"length": int(s[3:])}
    if s.startswith("lr"):
        return "lr", {"length": int(s[2:])}
    if s.startswith("atr"):
        return "atr", {"length": int(s[3:])}
    return s, {}


def _public_pack_key(indicator: str, symbol: str, tf: str, base: str) -> str:
    pref = PACK_PUBLIC_PREFIX.get(indicator, f"{indicator}_pack")
    return f"{pref}:{symbol}:{tf}:{base}"


def _public_mw_key(kind: str, symbol: str, tf: str) -> str:
    return f"{kind}_pack:{symbol}:{tf}:{kind}"


def _json_or_none(s: Optional[str]) -> Optional[dict]:
    if not s:
        return None
    try:
        return json.loads(s)
    except Exception:
        return None


def _now_monotonic_ms() -> int:
    return int(time.monotonic() * 1000)


# ðŸ”¸ ÐšÐ»ÑŽÑ‡Ð¸ ÑˆÑ‚Ð¾Ñ€ÐºÐ¸/Ð¾Ñ‡ÐµÑ€ÐµÐ´Ð¸
def _gate_key(gate_sid: int, symbol: str) -> str:
    return f"lab:gate:{gate_sid}:{symbol}"


def _queue_key(gate_sid: int, symbol: str) -> str:
    return f"lab:qids:{gate_sid}:{symbol}"


def _qfields_key(req_id: str) -> str:
    return f"lab:qfields:{req_id}"


# ðŸ”¸ MGET JSON Ð¿Ð°Ñ‡ÐºÐ¾Ð¹
async def _mget_json(keys: List[str]) -> Dict[str, Optional[dict]]:
    if not keys:
        return {}
    values = await infra.redis_client.mget(*keys)
    return {k: _json_or_none(v) for k, v in zip(keys, values)}


# ðŸ”¸ Ð“Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ñ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ñ PACK Ñ‡ÐµÑ€ÐµÐ· gateway (cache-first + Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ðµ public KV)
async def _ensure_pack_available(
    symbol: str,
    tf: str,
    indicator: str,
    base: str,
    gw_params: Dict[str, Any],
    precision: int,
    deadline_ms: int,
) -> Optional[dict]:
    key = _public_pack_key(indicator, symbol, tf, base)
    cached = await infra.redis_client.get(key)
    if cached:
        obj = _json_or_none(cached)
        if obj:
            return obj

    co_key = f"COAL::pack::{key}"
    now = _now_monotonic_ms()
    rec = _coalesce.get(co_key)
    if rec and now < rec[0]:
        fut = rec[1]
        log.info("[PACK] â³ ÐšÐ¾Ð°Ð»ÐµÑÑ†ÐµÐ½Ñ Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÐµÐ³Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° key=%s", key)
        try:
            return await asyncio.wait_for(fut, timeout=max(0.1, (deadline_ms - _now_monotonic_ms()) / 1000))
        except Exception:
            return None

    loop = asyncio.get_running_loop()
    fut = loop.create_future()
    _coalesce[co_key] = (now + COALESCE_TTL_SEC * 1000, fut)

    async with _gateway_sem:
        try:
            req = {"symbol": symbol, "timeframe": tf, "indicator": indicator, "mode": "pack"}
            if indicator in ("ema", "rsi", "mfi", "lr", "atr", "adx_dmi"):
                L = int(gw_params.get("length", 0))
                if L:
                    req["length"] = str(L)
            elif indicator == "macd":
                F = int(gw_params.get("fast", 0))
                if F:
                    req["length"] = str(F)
            elif indicator == "bb":
                L = int(gw_params.get("length", 0))
                S = float(gw_params.get("std", 2.0))
                req["length"] = str(L)
                req["std"] = f"{S:.2f}"

            req_id = await infra.redis_client.xadd(GATEWAY_REQ_STREAM, req)
            log.info("[PACK] ðŸ“¤ GW Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½ ind=%s base=%s req_id=%s key=%s", indicator, base, req_id, key)

            poll_sleep = 0.1
            while _now_monotonic_ms() < deadline_ms:
                cached = await infra.redis_client.get(key)
                if cached:
                    obj = _json_or_none(cached)
                    if obj:
                        if not fut.done():
                            fut.set_result(obj)
                        return obj
                await asyncio.sleep(poll_sleep)
                if poll_sleep < 0.2:
                    poll_sleep = 0.2

            log.info("[PACK] â›” Ð˜ÑÑ‚Ñ‘Ðº Ð´ÐµÐ´Ð»Ð°Ð¹Ð½ Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ñ public KV ind=%s base=%s", indicator, base)
            if not fut.done():
                fut.set_result(None)
            return None

        except Exception:
            log.exception("[PACK] âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐµ Ð² gateway (ind=%s base=%s)", indicator, base)
            if not fut.done():
                fut.set_result(None)
            return None
        finally:
            now2 = _now_monotonic_ms()
            for ck, (exp, f) in list(_coalesce.items()):
                if now2 > exp or (f.done() and _json_or_none(f.result()) is None):
                    _coalesce.pop(ck, None)


# ðŸ”¸ ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ MW-ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ð¹ (Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½ÑƒÐ¶Ð½Ñ‹Ðµ Ð±Ð°Ð·Ñ‹)
async def _get_mw_states(
    symbol: str,
    tf: str,
    bases: List[str],
    precision: int,
    deadline_ms: int,
) -> Dict[str, Optional[str]]:
    out: Dict[str, Optional[str]] = {}
    keys = [_public_mw_key(b, symbol, tf) for b in bases]
    kv = await _mget_json(keys)

    for base in bases:
        state: Optional[str] = None
        k = _public_mw_key(base, symbol, tf)
        obj = kv.get(k)
        if obj and isinstance(obj, dict):
            st = (obj.get("pack") or {}).get("state")
            if isinstance(st, str) and st:
                state = st

        if state is None:
            obj = await _ensure_pack_available(symbol, tf, base, base, {}, precision, deadline_ms)
            if obj:
                st = (obj.get("pack") or {}).get("state")
                if isinstance(st, str) and st:
                    state = st

        out[base] = state
        log.info("[MW] ðŸ§© %s %s/%s state=%s", base, symbol, tf, state)

    return out


# ðŸ”¸ ÐœÐ°Ñ‚Ñ‡Ð¸Ð½Ð³ MW â†’ required_confirmation (winrate Ð½Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼, ÑƒÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð²ÑÐµ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ)
def _mw_match_and_required_confirmation(
    mw_rows: List[Dict[str, Any]],
    states: Dict[str, Optional[str]],
) -> Tuple[bool, Optional[int]]:
    if not mw_rows:
        return False, None
    matched_confs: List[int] = []

    for r in mw_rows:
        agg_base = (r.get("agg_base") or "").strip().lower()
        agg_state = (r.get("agg_state") or "").strip().lower()
        if not agg_base or not agg_state:
            continue

        bases = agg_base.split("_")
        if len(bases) == 1:
            base = bases[0]
            st = states.get(base)
            if not st:
                continue
            fact = st.strip().lower()
        else:
            parts, ok = [], True
            for b in bases:
                st = states.get(b)
                if not st:
                    ok = False
                    break
                parts.append(f"{b}:{st.strip().lower()}")
            if not ok:
                continue
            fact = "|".join(parts)

        if fact == agg_state:
            try:
                matched_confs.append(int(r.get("confirmation")))
            except Exception:
                continue

    if not matched_confs:
        return False, None
    if any(c == 0 for c in matched_confs):
        return True, 0
    req = min([c for c in matched_confs if c in (1, 2)], default=None)
    if req is None:
        return False, None
    return True, req


# ðŸ”¸ ÐŸÐ°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ñ‹Ð¹ ÑÐ±Ð¾Ñ€ PACK Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð² Ð¿Ð¾ Ð½ÑƒÐ¶Ð½Ñ‹Ð¼ base
async def _get_pack_objects_for_bases(
    symbol: str, tf: str, bases: List[str], precision: int, deadline_ms: int
) -> Dict[str, Optional[dict]]:
    results: Dict[str, Optional[dict]] = {}
    keys, meta = [], []

    for base in bases:
        ind, params = _parse_pack_base(base)
        meta.append((base, ind, params))
        keys.append(_public_pack_key(ind, symbol, tf, base))

    got = await _mget_json(keys)

    tasks: List[asyncio.Task] = []
    wanted: List[Tuple[str, str, Dict[str, Any]]] = []

    for (base, ind, params) in meta:
        k = _public_pack_key(ind, symbol, tf, base)
        obj = got.get(k)
        if obj is not None:
            results[base] = obj
            log.info("[PACK] ðŸ“¦ base=%s %s/%s present=%s", base, symbol, tf, bool(obj))
        else:
            wanted.append((base, ind, params))
            tasks.append(asyncio.create_task(_ensure_pack_available(
                symbol=symbol, tf=tf, indicator=ind, base=base,
                gw_params=params, precision=precision, deadline_ms=deadline_ms
            )))

    if tasks:
        fetched = await asyncio.gather(*tasks, return_exceptions=False)
        for (base, _ind, _params), obj in zip(wanted, fetched):
            results[base] = obj
            log.info("[PACK] ðŸ“¦ base=%s %s/%s present=%s", base, symbol, tf, bool(obj))

    return results


# ðŸ”¸ Ð”Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ ÑƒÑ‡Ñ‘Ñ‚ blacklist: Ð´ÐµÑ‚Ð°Ð»Ð¸ + winrate
def _pack_bl_wl_stats_with_details(
    pack_rows: List[Dict[str, Any]],
    pack_objs: Dict[str, Optional[dict]],
) -> Tuple[int, int, List[Dict[str, Any]], List[Dict[str, Any]], List[float]]:
    """
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚:
      bl_hits, wl_hits, bl_details[], wl_details[], bl_winrates[]
    Ð´ÐµÑ‚Ð°Ð»Ð¸: {id, pack_base, agg_key, agg_value, winrate?}
    """
    bl_hits = 0
    wl_hits = 0
    bl_details: List[Dict[str, Any]] = []
    wl_details: List[Dict[str, Any]] = []
    bl_winrates: List[float] = []

    for r in pack_rows:
        base = (r.get("pack_base") or "").strip().lower()
        if not base:
            continue
        pack_obj = pack_objs.get(base)
        if not pack_obj:
            continue

        pack = pack_obj.get("pack") or {}
        list_type = (r.get("list") or "").strip().lower()  # whitelist | blacklist
        agg_key = (r.get("agg_key") or "").strip().lower()
        agg_val = (r.get("agg_value") or "").strip().lower()
        if not agg_key or not agg_val:
            continue

        keys = [k.strip() for k in agg_key.split("|") if k.strip()]
        parts, ok = [], True
        for k in keys:
            v = pack.get(k)
            if v is None:
                ok = False
                break
            parts.append(f"{k}:{str(v).strip().lower()}")
        if not ok:
            continue
        fact = "|".join(parts)

        if fact == agg_val:
            det = {
                "id": int(r.get("id")) if r.get("id") is not None else None,
                "pack_base": base,
                "agg_key": agg_key,
                "agg_value": agg_val,
            }
            if list_type == "blacklist":
                bl_hits += 1
                try:
                    w = float(r.get("winrate"))
                except Exception:
                    w = None
                if w is not None:
                    bl_winrates.append(w)
                    det["winrate"] = w
                bl_details.append(det)
            elif list_type == "whitelist":
                wl_hits += 1
                try:
                    w = float(r.get("winrate"))
                except Exception:
                    w = None
                if w is not None:
                    det["winrate"] = w
                wl_details.append(det)

    return bl_hits, wl_hits, bl_details, wl_details, bl_winrates


# ðŸ”¸ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¾Ð´Ð½Ð¾Ð³Ð¾ TF (MW â†’ PACK Ñ Ð´Ð¸Ð½Ð°Ð¼Ð¸ÐºÐ¾Ð¹ blacklist)
async def _process_tf(
    sid: int,
    symbol: str,
    direction: str,
    tf: str,
    trace: bool,
    deadline_ms: int,
    telemetry: Dict[str, int],
) -> Tuple[bool, Dict[str, Any]]:
    tf_trace: Dict[str, Any] = {"tf": tf}

    mw_rows_all = (infra.mw_wl_by_strategy.get(sid) or {}).get("rows", [])
    pack_rows_all = (infra.pack_wl_by_strategy.get(sid) or {}).get("rows", [])

    mw_rows = [r for r in mw_rows_all if (r.get("timeframe") == tf and r.get("direction") == direction)]
    pack_rows = [r for r in pack_rows_all if (r.get("timeframe") == tf and r.get("direction") == direction)]

    log.info("[TF:%s] ðŸ”Ž WL ÑÑ€ÐµÐ·Ñ‹: MW=%d PACK=%d (sid=%s %s %s)", tf, len(mw_rows), len(pack_rows), sid, symbol, direction)

    if not mw_rows:
        tf_trace["mw"] = {"matched": False}
        log.info("[TF:%s] âŒ MW: Ð½ÐµÑ‚ ÑÑ‚Ñ€Ð¾Ðº Ð² WL â€” Ð¾Ñ‚ÐºÐ°Ð·", tf)
        return False, tf_trace

    needed_bases: List[str] = []
    for r in mw_rows:
        base = (r.get("agg_base") or "").strip().lower()
        if not base:
            continue
        for b in base.split("_"):
            if b in ("trend", "volatility", "extremes", "momentum") and b not in needed_bases:
                needed_bases.append(b)

    precision = int(infra.enabled_tickers.get(symbol, {}).get("precision_price", 7))
    states = await _get_mw_states(symbol, tf, needed_bases, precision, deadline_ms)

    matched, conf_req = _mw_match_and_required_confirmation(mw_rows, states)
    if trace:
        tf_trace["mw"] = {"matched": matched}
        if matched:
            tf_trace["mw"]["confirmation"] = conf_req
    if not matched:
        log.info("[TF:%s] âŒ MW: ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ð¹ Ð½ÐµÑ‚ â€” Ð¾Ñ‚ÐºÐ°Ð·", tf)
        return False, tf_trace

    if conf_req == 0:
        log.info("[TF:%s] âœ… MW: confirmation=0 â€” TF Ð¿Ñ€Ð¾Ð¹Ð´ÐµÐ½ Ð±ÐµÐ· PACK", tf)
        return True, tf_trace

    # PACK
    bases: List[str] = []
    for r in pack_rows:
        base = (r.get("pack_base") or "").strip().lower()
        if base and base not in bases:
            bases.append(base)
    if not bases:
        tf_trace["pack"] = {"bl_hits": 0, "wl_hits": 0, "required": conf_req}
        log.info("[TF:%s] âŒ PACK: WL Ð¿ÑƒÑÑ‚ â€” Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ð¹ Ð½ÐµÑ‚ (need=%s)", tf, conf_req)
        return False, tf_trace

    pack_objs = await _get_pack_objects_for_bases(symbol, tf, bases, precision, deadline_ms)
    bl_hits, wl_hits, bl_details, wl_details, bl_winrates = _pack_bl_wl_stats_with_details(pack_rows, pack_objs)

    # Ð”Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ°Ñ ÑˆÐºÐ°Ð»Ð° Ð¿Ð¾ blacklist
    extra_required = 0
    total_required = conf_req

    if bl_hits > 1:
        if trace:
            tf_trace["pack"] = {
                "bl_hits": bl_hits, "wl_hits": wl_hits,
                "required": conf_req, "extra_required": None, "total_required": None,
                "bl_details": bl_details, "wl_details": wl_details,
            }
        log.info("[TF:%s] âŒ PACK: blacklist count > 1 â€” Ð¾Ñ‚ÐºÐ°Ð·", tf)
        return False, tf_trace

    if bl_hits == 1:
        w = min(bl_winrates) if bl_winrates else None
        if w is not None:
            if w < 0.35:
                if trace:
                    tf_trace["pack"] = {
                        "bl_hits": bl_hits, "wl_hits": wl_hits,
                        "required": conf_req, "extra_required": None, "total_required": None,
                        "bl_details": bl_details, "wl_details": wl_details,
                    }
                log.info("[TF:%s] âŒ PACK: blacklist w=%.3f < 0.35 â€” Ð¾Ñ‚ÐºÐ°Ð·", tf, w)
                return False, tf_trace
            elif 0.35 <= w < 0.40:
                extra_required = 3
            elif 0.40 <= w < 0.45:
                extra_required = 2
            elif 0.45 <= w < 0.50:
                extra_required = 1
            elif w >= 0.50:
                extra_required = 1

    total_required = conf_req + extra_required

    if trace:
        tf_trace["pack"] = {
            "bl_hits": bl_hits,
            "wl_hits": wl_hits,
            "required": conf_req,
            "extra_required": extra_required,
            "total_required": total_required,
            "bl_details": bl_details,
            "wl_details": wl_details,
        }

    if wl_hits >= total_required:
        log.info("[TF:%s] âœ… PACK: Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ð¹ Ð´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ (need=%s got=%s)", tf, total_required, wl_hits)
        return True, tf_trace

    log.info("[TF:%s] âŒ PACK: Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ð¹ Ð½ÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ (need=%s got=%s)", tf, total_required, wl_hits)
    return False, tf_trace


# ðŸ”¸ Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð° (Ð¿Ð¾ÑÐ»Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ð°)
async def _persist_decision(
    req_id: str,
    log_uid: str,
    strategy_id: int,
    symbol: str,
    direction: str,
    tfr_req: str,
    tfr_proc: str,
    allow: bool,
    reason: Optional[str],
    tf_results_json: Optional[str],
    received_at_dt: datetime,
    finished_at_dt: datetime,
    duration_ms: int,
    cache_hits: int,
    gateway_requests: int,
):
    query = """
    INSERT INTO public.signal_laboratory_entries
    (req_id, log_uid, strategy_id, direction, symbol,
     timeframes_requested, timeframes_processed, protocol_version,
     allow, reason, tf_results, errors,
     received_at, finished_at, duration_ms, cache_hits, gateway_requests)
    VALUES ($1,$2,$3,$4,$5,
            $6,$7,'v1',
            $8,$9, COALESCE($10::jsonb, NULL), NULL,
            $11,$12,$13,$14,$15)
    ON CONFLICT (log_uid, strategy_id) DO UPDATE
      SET req_id=$1, direction=$4, symbol=$5,
          timeframes_requested=$6, timeframes_processed=$7,
          allow=$8, reason=$9, tf_results=COALESCE($10::jsonb, signal_laboratory_entries.tf_results),
          finished_at=$12, duration_ms=$13, cache_hits=$14, gateway_requests=$15
    """
    async with infra.pg_pool.acquire() as conn:
        await conn.execute(
            query,
            req_id, log_uid, strategy_id, direction, symbol,
            tfr_req, tfr_proc,
            allow, reason, tf_results_json,
            received_at_dt, finished_at_dt, duration_ms, cache_hits, gateway_requests
        )
    log.info("[AUDIT] ðŸ’¾ Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾ Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ log_uid=%s sid=%s allow=%s", log_uid, strategy_id, allow)


# ðŸ”¸ Ð¨Ñ‚Ð¾Ñ€ÐºÐ°/Ð¾Ñ‡ÐµÑ€ÐµÐ´ÑŒ: Ð¿Ð¾Ð¿Ñ‹Ñ‚ÐºÐ° ÑÑ‚Ð°Ñ‚ÑŒ Ð»Ð¸Ð´ÐµÑ€Ð¾Ð¼ Ð¸Ð»Ð¸ Ð¿Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° Ð² Ð¾Ñ‡ÐµÑ€ÐµÐ´ÑŒ
async def _acquire_gate_or_enqueue(
    msg_id: str,
    fields: Dict[str, str],
    gate_sid: int,
    symbol: str,
    gate_ttl_sec: int = 60,
) -> Tuple[bool, Optional[str]]:
    gk = _gate_key(gate_sid, symbol)
    qk = _queue_key(gate_sid, symbol)
    fk = _qfields_key(msg_id)

    ok = await infra.redis_client.set(gk, msg_id, ex=gate_ttl_sec, nx=True)
    if ok:
        log.info("[GATE] ðŸ” Ð›Ð¸Ð´ÐµÑ€ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½ gate_sid=%s %s req_id=%s", gate_sid, symbol, msg_id)
        return True, None

    await infra.redis_client.rpush(qk, msg_id)
    await infra.redis_client.set(fk, json.dumps(fields, ensure_ascii=False), ex=gate_ttl_sec + 60)
    log.info("[GATE] â¸ï¸ Ð’ Ð¾Ñ‡ÐµÑ€ÐµÐ´ÑŒ gate_sid=%s %s req_id=%s", gate_sid, symbol, msg_id)
    return False, "enqueued"


# ðŸ”¸ Ð ÐµÐ°ÐºÑ†Ð¸Ñ Ð½Ð° Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ðµ Ð»Ð¸Ð´ÐµÑ€Ð°
async def _on_leader_finished(gate_sid: int, symbol: str, leader_req_id: str, allow: bool):
    gk = _gate_key(gate_sid, symbol)
    qk = _queue_key(gate_sid, symbol)
    await infra.redis_client.delete(gk)

    if allow:
        pending = await infra.redis_client.lrange(qk, 0, -1)
        await infra.redis_client.delete(qk)
        if pending:
            log.info("[GATE] ðŸš« DUPLICATED gate_sid=%s %s â€” Ð¾Ñ‚ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð¾Ñ‡ÐµÑ€ÐµÐ´Ð¸ (%d ÑˆÑ‚.)", gate_sid, symbol, len(pending))
            for req_id in pending:
                await infra.redis_client.xadd(DECISION_RESP_STREAM, {
                    "req_id": req_id, "status": "ok", "allow": "false", "reason": "duplicated_entry"
                })
                await infra.redis_client.delete(_qfields_key(req_id))
        return

    next_req_id = await infra.redis_client.lpop(qk)
    if not next_req_id:
        log.info("[GATE] ðŸ” ÐžÑ‡ÐµÑ€ÐµÐ´ÑŒ Ð¿ÑƒÑÑ‚Ð° gate_sid=%s %s â€” Ð¶Ð´Ñ‘Ð¼ Ð½Ð¾Ð²Ñ‹Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹", gate_sid, symbol)
        return

    ok = await infra.redis_client.set(gk, next_req_id, ex=60, nx=True)
    if not ok:
        log.info("[GATE] âš ï¸ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð½Ð°Ð·Ð½Ð°Ñ‡Ð¸Ñ‚ÑŒ Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ð»Ð¸Ð´ÐµÑ€Ð° gate_sid=%s %s req=%s", gate_sid, symbol, next_req_id)
        return

    raw = await infra.redis_client.get(_qfields_key(next_req_id))
    if not raw:
        await infra.redis_client.xadd(DECISION_RESP_STREAM, {
            "req_id": next_req_id, "status": "error", "error": "internal_error", "message": "queued payload missing"
        })
        log.info("[GATE] âš ï¸ ÐÐµÑ‚ Ð¿Ð¾Ð»ÐµÐ¹ Ð´Ð»Ñ queued req_id=%s â€” Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½ error", next_req_id)
        return

    try:
        fields = json.loads(raw)
    except Exception:
        await infra.redis_client.xadd(DECISION_RESP_STREAM, {
            "req_id": next_req_id, "status": "error", "error": "internal_error", "message": "queued payload invalid"
        })
        log.info("[GATE] âš ï¸ ÐÐµÐ²Ð°Ð»Ð¸Ð´Ð½Ñ‹Ðµ Ð¿Ð¾Ð»Ñ Ð´Ð»Ñ queued req_id=%s â€” Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½ error", next_req_id)
        return

    asyncio.create_task(_process_request_core(next_req_id, fields))


# ðŸ”¸ Ð¯Ð´Ñ€Ð¾ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° (Ð´Ð»Ñ Ð»Ð¸Ð´ÐµÑ€Ð°)
async def _process_request_core(msg_id: str, fields: Dict[str, str]):
    async with _decisions_sem:
        t0 = _now_monotonic_ms()
        received_at_dt = datetime.utcnow()

        log_uid = fields.get("log_uid") or ""
        strategy_id_s = fields.get("strategy_id") or ""
        client_sid_s = fields.get("client_strategy_id") or ""  # Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾
        direction = (fields.get("direction") or "").strip().lower()
        symbol = (fields.get("symbol") or "").strip().upper()
        tfs_raw = fields.get("timeframes") or ""
        trace_flag = (fields.get("trace") or "false").lower() == "true"
        deadline_ms_req = None
        try:
            if "deadline_ms" in fields:
                deadline_ms_req = int(fields["deadline_ms"])
        except Exception:
            deadline_ms_req = None

        if not log_uid or not strategy_id_s.isdigit() or direction not in ("long", "short") or not symbol or not tfs_raw:
            await infra.redis_client.xadd(DECISION_RESP_STREAM, {
                "req_id": msg_id, "status": "error", "error": "bad_request", "message": "missing or invalid fields"
            })
            log.info("[REQ] âŒ bad_request fields=%s", fields)
            return

        # master SID (Ð´Ð»Ñ WL/BL)
        sid = int(strategy_id_s)
        # gate SID (Ð´Ð»Ñ ÑˆÑ‚Ð¾Ñ€ÐºÐ¸/Ð¾Ñ‡ÐµÑ€ÐµÐ´Ð¸): ÐºÐ»Ð¸ÐµÐ½Ñ‚ÑÐºÐ¸Ð¹, ÐµÑÐ»Ð¸ Ð¿ÐµÑ€ÐµÐ´Ð°Ð½ Ð¸ Ð²Ð°Ð»Ð¸Ð´ÐµÐ½, Ð¸Ð½Ð°Ñ‡Ðµ master
        gate_sid = int(client_sid_s) if client_sid_s.isdigit() else sid

        tfs = _parse_timeframes(tfs_raw)
        if not tfs:
            await infra.redis_client.xadd(DECISION_RESP_STREAM, {
                "req_id": msg_id, "status": "error", "error": "bad_request", "message": "timeframes invalid"
            })
            log.info("[REQ] âŒ bad_request timeframes=%s", tfs_raw)
            return

        if symbol not in infra.enabled_tickers:
            await infra.redis_client.xadd(DECISION_RESP_STREAM, {
                "req_id": msg_id, "status": "error", "error": "symbol_not_active", "message": f"{symbol}"
            })
            log.info("[REQ] âŒ symbol_not_active %s", symbol)
            return

        if sid not in infra.enabled_strategies:
            await infra.redis_client.xadd(DECISION_RESP_STREAM, {
                "req_id": msg_id, "status": "error", "error": "strategy_not_enabled", "message": f"{sid}"
            })
            log.info("[REQ] âŒ strategy_not_enabled %s", sid)
            return

        log.info("[REQ] ðŸ“¥ log_uid=%s sid=%s gate_sid=%s %s %s tfs=%s",
                 log_uid, sid, gate_sid, symbol, direction, ",".join(tfs))

        # Ð¶Ð´Ñ‘Ð¼ Â«ÑˆÑ‚Ð¾Ñ€ÐºÐ¸Â» WL (ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¾)
        await infra.wait_mw_ready(sid, timeout_sec=5.0)
        await infra.wait_pack_ready(sid, timeout_sec=5.0)

        deadline_ms = t0 + (deadline_ms_req or SAFETY_DEADLINE_MS)

        telemetry = {"cache_hits": 0, "gateway_requests": 0}
        tf_results: List[Dict[str, Any]] = []
        allow = True
        reason: Optional[str] = None

        # Ð¿Ð¾ÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° TF
        for tf in tfs:
            tf_ok, tf_trace = await _process_tf(
                sid=sid, symbol=symbol, direction=direction, tf=tf,
                trace=trace_flag, deadline_ms=deadline_ms, telemetry=telemetry,
            )
            if trace_flag:
                tf_results.append(tf_trace)

            if not tf_ok:
                allow = False
                if "mw" in tf_trace and not tf_trace["mw"].get("matched", True):
                    reason = f"mw_no_match@{tf}"
                elif "pack" in tf_trace and tf_trace["pack"].get("bl_hits", 0) > 0 and tf_trace["pack"].get("wl_hits", 0) < (tf_trace["pack"].get("total_required") or tf_trace["pack"].get("required")):
                    # BL ÑÑ€Ð°Ð±Ð¾Ñ‚Ð°Ð» ÐºÐ°Ðº Ð±Ð»Ð¾ÐºÐ¸Ñ€ÑƒÑŽÑ‰Ð¸Ð¹
                    reason = f"pack_blacklist_hit@{tf}"
                elif "pack" in tf_trace:
                    need = tf_trace["pack"].get("total_required") or tf_trace["pack"].get("required")
                    got = tf_trace["pack"].get("wl_hits")
                    reason = f"pack_not_enough_confirm@{tf}: need={need} got={got}"
                else:
                    reason = f"deny@{tf}"
                log.info("[TF:%s] â›” ÐžÑÑ‚Ð°Ð½Ð¾Ð² Ð¿Ð¾ Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ðµ: %s", tf, reason)
                break
            else:
                log.info("[TF:%s] âœ… TF Ð¿Ñ€Ð¾Ð¹Ð´ÐµÐ½", tf)

        finished_at_dt = datetime.utcnow()
        duration_ms = _now_monotonic_ms() - t0

        # Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚
        resp = {
            "req_id": msg_id,
            "status": "ok",
            "allow": "true" if allow else "false",
            "log_uid": log_uid,
            "strategy_id": str(sid),           # master SID
            "direction": direction,
            "symbol": symbol,
            "timeframes": ",".join(tfs),
        }
        if client_sid_s:
            resp["client_strategy_id"] = client_sid_s
        if not allow and reason:
            resp["reason"] = reason
        if trace_flag:
            try:
                resp["tf_results"] = json.dumps(tf_results, ensure_ascii=False)
            except Exception:
                pass

        await infra.redis_client.xadd(DECISION_RESP_STREAM, resp)
        log.info("[RESP] ðŸ“¤ log_uid=%s sid=%s gate_sid=%s allow=%s dur=%dms",
                 log_uid, sid, gate_sid, allow, duration_ms)

        # Ð·Ð°Ð¿Ð¸ÑÑŒ Ð² Ð‘Ð”
        try:
            tf_results_json = json.dumps(tf_results, ensure_ascii=False) if trace_flag else None
            await _persist_decision(
                req_id=msg_id,
                log_uid=log_uid,
                strategy_id=sid,
                symbol=symbol,
                direction=direction,
                tfr_req=tfs_raw,
                tfr_proc=",".join(tfs),
                allow=allow,
                reason=reason,
                tf_results_json=tf_results_json,
                received_at_dt=received_at_dt,
                finished_at_dt=finished_at_dt,
                duration_ms=duration_ms,
                cache_hits=telemetry.get("cache_hits", 0),
                gateway_requests=telemetry.get("gateway_requests", 0),
            )
        except Exception:
            log.exception("[AUDIT] âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð¿Ð¸ÑÐ¸ Ð°ÑƒÐ´Ð¸Ñ‚Ð° log_uid=%s sid=%s", log_uid, sid)

        # Ñ€ÐµÐ°ÐºÑ†Ð¸Ñ Ð²Ð¾Ñ€Ð¾Ñ‚ (Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ gate_sid)
        await _on_leader_finished(gate_sid=gate_sid, symbol=symbol, leader_req_id=msg_id, allow=allow)


# ðŸ”¸ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð²Ñ…Ð¾Ð´ÑÑ‰ÐµÐ³Ð¾: ÑˆÑ‚Ð¾Ñ€ÐºÐ°/Ð¾Ñ‡ÐµÑ€ÐµÐ´ÑŒ â†’ Ð»Ð¸Ð´ÐµÑ€ Ð¸Ð»Ð¸ Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ðµ
async def _handle_incoming(msg_id: str, fields: Dict[str, str]):
    strategy_id_s = fields.get("strategy_id") or ""
    client_sid_s = fields.get("client_strategy_id") or ""
    symbol = (fields.get("symbol") or "").strip().upper()
    if not strategy_id_s.isdigit() or not symbol:
        await infra.redis_client.xadd(DECISION_RESP_STREAM, {
            "req_id": msg_id, "status": "error", "error": "bad_request", "message": "missing sid/symbol"
        })
        log.info("[REQ] âŒ bad_request (no sid/symbol) fields=%s", fields)
        return

    sid = int(strategy_id_s)
    gate_sid = int(client_sid_s) if client_sid_s.isdigit() else sid

    is_leader, _ = await _acquire_gate_or_enqueue(msg_id, fields, gate_sid, symbol, gate_ttl_sec=60)
    if is_leader:
        await _process_request_core(msg_id, fields)
    else:
        log.info("[REQ] â³ Ð—Ð°Ð¿Ñ€Ð¾Ñ Ð¿Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½ Ð² Ð¾Ñ‡ÐµÑ€ÐµÐ´ÑŒ gate_sid=%s %s req_id=%s", gate_sid, symbol, msg_id)


# ðŸ”¸ Ð“Ð»Ð°Ð²Ð½Ñ‹Ð¹ ÑÐ»ÑƒÑˆÐ°Ñ‚ÐµÐ»ÑŒ decision_request
async def run_laboratory_decision_maker():
    """
    Ð¡Ð»ÑƒÑˆÐ°ÐµÑ‚ laboratory:decision_request Ð¸ Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÑ‚ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹ Ð² laboratory:decision_response.
    ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐÐžÐ’Ð«Ð• ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ (ÑÑ‚Ð°Ñ€Ñ‚ Ñ '$'). Ð’ÑÑ‚Ñ€Ð¾ÐµÐ½Ñ‹ ÑˆÑ‚Ð¾Ñ€ÐºÐ°/Ð¾Ñ‡ÐµÑ€ÐµÐ´ÑŒ per (gate_sid, symbol),
    Ð³Ð´Ðµ gate_sid = client_strategy_id (ÐµÑÐ»Ð¸ Ð¿ÐµÑ€ÐµÐ´Ð°Ð½) Ð¸Ð½Ð°Ñ‡Ðµ strategy_id (master).
    """
    log.info("ðŸ›°ï¸ LAB_DECISION ÑÐ»ÑƒÑˆÐ°Ñ‚ÐµÐ»ÑŒ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½ (BLOCK=%d COUNT=%d MAX=%d)",
             XREAD_BLOCK_MS, XREAD_COUNT, MAX_IN_FLIGHT_DECISIONS)

    last_id = "$"  # Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð¾Ð²Ñ‹Ðµ, Ð±ÐµÐ· Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸
    redis = infra.redis_client

    while True:
        try:
            resp = await redis.xread(
                streams={DECISION_REQ_STREAM: last_id},
                count=XREAD_COUNT,
                block=XREAD_BLOCK_MS
            )
            if not resp:
                continue

            for _, messages in resp:
                for msg_id, fields in messages:
                    last_id = msg_id
                    asyncio.create_task(_handle_incoming(msg_id, fields))

        except asyncio.CancelledError:
            log.info("â¹ï¸ LAB_DECISION Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½ Ð¿Ð¾ ÑÐ¸Ð³Ð½Ð°Ð»Ñƒ")
            raise
        except Exception:
            log.exception("âŒ LAB_DECISION Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð² Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¼ Ñ†Ð¸ÐºÐ»Ðµ")
            await asyncio.sleep(1.0)