# laboratory_decision_maker.py ‚Äî –≠—Ç–∞–ø 2: —Å–±–æ—Ä –ø–æ–ª–Ω–æ–≥–æ —Å–Ω–∏–º–∫–∞ MW/PACK –ø–æ –∑–∞–ø—Ä–æ—Å—É (–≤—Å–µ–≥–¥–∞ deny) + –ø–æ–¥—Å—á—ë—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π (MW-WL / PACK-WL / PACK-BL) –∏ –∑–∞–ø–∏—Å—å –ø–æ –ö–ê–ñ–î–û–ú–£ TF

# üî∏ –ò–º–ø–æ—Ä—Ç—ã
import asyncio
import json
import logging
import time
from datetime import datetime
from decimal import Decimal
from typing import Any, Dict, List, Optional, Tuple

# üî∏ –ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞
import laboratory_infra as infra

# üî∏ –õ–æ–≥–≥–µ—Ä
log = logging.getLogger("LAB_DECISION")

# üî∏ –ü–æ—Ç–æ–∫–∏ –∏ —à–ª—é–∑—ã
DECISION_REQ_STREAM = "laboratory:decision_request"
DECISION_RESP_STREAM = "laboratory:decision_response"
GATEWAY_REQ_STREAM = "indicator_gateway_request"

# üî∏ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏/–¥–µ–¥–ª–∞–π–Ω–æ–≤/–∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏–∏
LAB_DEADLINE_MS = 90_000                 # –æ–±—â–∏–π –¥–µ–¥–ª–∞–π–Ω –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É –æ–¥–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ (90—Å)
XREAD_BLOCK_MS = 1_000                   # –±–ª–æ–∫–∏—Ä—É—é—â–µ–µ —á—Ç–µ–Ω–∏–µ –≤—Ö–æ–¥–Ω–æ–≥–æ —Å—Ç—Ä–∏–º–∞
XREAD_COUNT = 50
MAX_IN_FLIGHT_DECISIONS = 32
MAX_CONCURRENT_GATEWAY_CALLS = 32
COALESCE_TTL_SEC = 3                     # –∫–æ–∞–ª–µ—Å—Ü–µ–Ω—Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö gateway-–∑–∞–ø—Ä–æ—Å–æ–≤ –≤–Ω—É—Ç—Ä–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞
GATE_TTL_SEC = 100                       # TTL ¬´–≤–æ—Ä–æ—Ç¬ª (gate_sid,symbol), —á—É—Ç—å –±–æ–ª—å—à–µ –¥–µ–¥–ª–∞–π–Ω–∞

# üî∏ –¢–∞–π–º—Ñ—Ä–µ–π–º—ã (–ø–æ—Ä—è–¥–æ–∫ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏)
TF_ORDER = ("m5", "m15", "h1")

# üî∏ –ü—É–±–ª–∏—á–Ω—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã PACK-–∫—ç—à–∞ (KV)
PACK_PUBLIC_PREFIX = {
    "bb": "bbpos_pack",
    "lr": "lrpos_pack",
    "atr": "atr_pack",
    "adx_dmi": "adx_dmi_pack",
    "macd": "macd_pack",
    # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: f"{indicator}_pack"
}

# üî∏ –°–µ–º–∞—Ñ–æ—Ä—ã –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏–∏
_decisions_sem = asyncio.Semaphore(MAX_IN_FLIGHT_DECISIONS)
_gateway_sem = asyncio.Semaphore(MAX_CONCURRENT_GATEWAY_CALLS)

# üî∏ –ö–æ–∞–ª–µ—Å—Ü–µ–Ω—Å (in-process): key -> (expire_ms, future)
_coalesce: Dict[str, Tuple[float, asyncio.Future]] = {}

# üî∏ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –∫ JSON-safe –≤–∏–¥—É
def _to_json_safe(obj: Any) -> Any:
    # –ø—Ä–æ—Å—Ç—ã–µ —Ç–∏–ø—ã
    if obj is None or isinstance(obj, (str, int, float, bool)):
        return obj
    # Decimal -> float
    if isinstance(obj, Decimal):
        try:
            return float(obj)
        except Exception:
            return str(obj)
    # datetime -> ISO
    if isinstance(obj, datetime):
        try:
            return obj.replace(tzinfo=None).isoformat()
        except Exception:
            return str(obj)
    # dict -> —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ
    if isinstance(obj, dict):
        return {k: _to_json_safe(v) for k, v in obj.items()}
    # list/tuple -> —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ
    if isinstance(obj, (list, tuple)):
        return [_to_json_safe(v) for v in obj]
    # fallback: —Å—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
    return str(obj)

# üî∏ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä—Å–µ—Ä—ã/—É—Ç–∏–ª–∏—Ç—ã
def _parse_timeframes(tf_str: str) -> List[str]:
    items = [x.strip().lower() for x in (tf_str or "").split(",") if x.strip()]
    seen, ordered = set(), []
    for tf in TF_ORDER:
        if tf in items and tf not in seen:
            seen.add(tf)
            ordered.append(tf)
    return ordered

# üî∏ –ü–∞—Ä—Å–∏–Ω–≥ pack_base ‚Üí (indicator, params)
def _parse_pack_base(base: str) -> Tuple[str, Dict[str, Any]]:
    s = (base or "").strip().lower()
    if not s:
        return "", {}
    if s.startswith("bb"):
        rest = s[2:]
        parts = rest.split("_", 2)
        L = int(parts[0])
        std = float(parts[1].replace("_", ".", 1)) if len(parts) > 1 else 2.0
        return "bb", {"length": L, "std": std}
    if s.startswith("macd"):
        return "macd", {"fast": int(s[4:] or 0)}
    if s.startswith("adx_dmi"):
        return "adx_dmi", {"length": int(s[7:] or 0)}
    if s.startswith("ema"):
        return "ema", {"length": int(s[3:] or 0)}
    if s.startswith("rsi"):
        return "rsi", {"length": int(s[3:] or 0)}
    if s.startswith("mfi"):
        return "mfi", {"length": int(s[3:] or 0)}
    if s.startswith("lr"):
        return "lr", {"length": int(s[2:] or 0)}
    if s.startswith("atr"):
        return "atr", {"length": int(s[3:] or 0)}
    # MW packs (trend/volatility/momentum/extremes)
    if s in ("trend", "volatility", "momentum", "extremes"):
        return s, {}
    return s, {}

# üî∏ –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—É–±–ª–∏—á–Ω–æ–≥–æ KV-–∫–ª—é—á–∞ –¥–ª—è PACK-–æ–±—ä–µ–∫—Ç–∞
def _public_pack_key(indicator: str, symbol: str, tf: str, base: str) -> str:
    pref = PACK_PUBLIC_PREFIX.get(indicator, f"{indicator}_pack")
    return f"{pref}:{symbol}:{tf}:{base}"

# üî∏ –ü—É–±–ª–∏—á–Ω—ã–π KV-–∫–ª—é—á MW-–ø–∞–∫–µ—Ç–∞
def _public_mw_key(kind: str, symbol: str, tf: str) -> str:
    return f"{kind}_pack:{symbol}:{tf}:{kind}"

# üî∏ –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π json.loads
def _json_or_none(s: Optional[str]) -> Optional[dict]:
    if not s:
        return None
    try:
        return json.loads(s)
    except Exception:
        return None

# üî∏ –¢–µ–∫—É—â–µ–µ –º–æ–Ω–æ—Ç–æ–Ω–Ω–æ–µ –≤—Ä–µ–º—è –≤ –º—Å
def _now_monotonic_ms() -> int:
    return int(time.monotonic() * 1000)

# üî∏ MGET JSON –ø–∞—á–∫–æ–π
async def _mget_json(keys: List[str]) -> Dict[str, Optional[dict]]:
    if not keys:
        return {}
    values = await infra.redis_client.mget(*keys)
    return {k: _json_or_none(v) for k, v in zip(keys, values)}

# üî∏ –ó–∞–ø—Ä–æ—Å –∏ –æ–∂–∏–¥–∞–Ω–∏–µ –ø–æ—è–≤–ª–µ–Ω–∏—è PACK –≤ –ø—É–±–ª–∏—á–Ω–æ–º KV (cache-first, —Å –∫–æ–∞–ª–µ—Å—Ü–µ–Ω—Å–æ–º)
async def _ensure_pack_available(
    symbol: str,
    tf: str,
    indicator: str,
    base: str,
    gw_params: Dict[str, Any],
    deadline_ms: int,
    telemetry: Dict[str, int],
) -> Tuple[Optional[dict], str]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (obj, source), –≥–¥–µ source ‚àà {"kv","gateway","timeout"}.
    """
    key = _public_pack_key(indicator, symbol, tf, base)
    # cache-first
    cached = await infra.redis_client.get(key)
    if cached:
        obj = _json_or_none(cached)
        if obj:
            telemetry["kv_hits"] = telemetry.get("kv_hits", 0) + 1
            return obj, "kv"

    # –∫–æ–∞–ª–µ—Å—Ü–µ–Ω—Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ
    co_key = f"COAL::pack::{key}"
    now = _now_monotonic_ms()
    rec = _coalesce.get(co_key)
    if rec and now < rec[0]:
        fut = rec[1]
        try:
            obj = await asyncio.wait_for(
                fut, timeout=max(0.05, (deadline_ms - _now_monotonic_ms()) / 1000)
            )
            if obj:
                return obj, "gateway"
            return None, "timeout"
        except Exception:
            return None, "timeout"

    loop = asyncio.get_running_loop()
    fut = loop.create_future()
    _coalesce[co_key] = (now + COALESCE_TTL_SEC * 1000, fut)

    async with _gateway_sem:
        try:
            # —Ñ–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∫ gateway
            req: Dict[str, Any] = {"symbol": symbol, "timeframe": tf, "indicator": indicator, "mode": "pack"}
            if indicator in ("ema", "rsi", "mfi", "lr", "atr", "adx_dmi"):
                L = int(gw_params.get("length") or 0)
                if L:
                    req["length"] = str(L)
            elif indicator == "macd":
                F = int(gw_params.get("fast") or 0)
                if F:
                    req["length"] = str(F)
            elif indicator == "bb":
                L = int(gw_params.get("length") or 0)
                S = float(gw_params.get("std") or 2.0)
                if L:
                    req["length"] = str(L)
                req["std"] = f"{S:.2f}"

            # –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∏ –∂–¥—ë–º –ø–æ—è–≤–ª–µ–Ω–∏—è –ø—É–±–ª–∏—á–Ω–æ–≥–æ KV –¥–æ –¥–µ–¥–ª–∞–π–Ω–∞
            telemetry["gateway_requests"] = telemetry.get("gateway_requests", 0) + 1
            await infra.redis_client.xadd(GATEWAY_REQ_STREAM, req)

            poll_sleep = 0.1
            while _now_monotonic_ms() < deadline_ms:
                cached = await infra.redis_client.get(key)
                if cached:
                    obj = _json_or_none(cached)
                    if obj:
                        if not fut.done():
                            fut.set_result(obj)
                        return obj, "gateway"
                await asyncio.sleep(poll_sleep)
                if poll_sleep < 0.2:
                    poll_sleep = 0.2

            # –∏—Å—Ç—ë–∫ –¥–µ–¥–ª–∞–π–Ω
            if not fut.done():
                fut.set_result(None)
            return None, "timeout"

        except Exception:
            log.exception("[PACK] ‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ gateway ind=%s base=%s", indicator, base)
            if not fut.done():
                fut.set_result(None)
            return None, "timeout"
        finally:
            # –æ—á–∏—Å—Ç–∫–∞ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∑–∞–ø–∏—Å–µ–π –∫–æ–∞–ª–µ—Å—Ü–µ–Ω—Å–∞
            now2 = _now_monotonic_ms()
            for ck, (exp, f) in list(_coalesce.items()):
                if now2 > exp or (f.done() and _json_or_none(f.result()) is None):
                    _coalesce.pop(ck, None)

# üî∏ –°–Ω—è—Ç–∏–µ MW-–ø–∞–∫–µ—Ç–∞ (cache-first ‚Üí gateway)
async def _get_mw_pack(symbol: str, tf: str, kind: str, deadline_ms: int, telemetry: Dict[str, int]) -> Tuple[Optional[dict], str]:
    key = _public_mw_key(kind, symbol, tf)
    cached = await infra.redis_client.get(key)
    if cached:
        obj = _json_or_none(cached)
        if obj:
            telemetry["kv_hits"] = telemetry.get("kv_hits", 0) + 1
            return obj, "kv"

    # –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî –æ–±—Ä–∞—Ç–∏–º—Å—è –∫ gateway (ind=kind, base=kind)
    obj, src = await _ensure_pack_available(
        symbol=symbol, tf=tf, indicator=kind, base=kind, gw_params={}, deadline_ms=deadline_ms, telemetry=telemetry
    )
    return obj, src

# üî∏ –°–Ω–∏–º–æ–∫ MW –¥–ª—è (sid, symbol, direction, tf)
async def _collect_mw_snapshot(
    sid: int, symbol: str, direction: str, tf: str, deadline_ms: int, telemetry: Dict[str, int]
) -> Dict[str, Any]:
    out: Dict[str, Any] = {"states": {}, "rules": []}

    # always 4 MW bases
    for kind in ("trend", "volatility", "momentum", "extremes"):
        obj, src = await _get_mw_pack(symbol, tf, kind, deadline_ms, telemetry)
        if obj:
            obj2 = dict(obj)
            obj2["source"] = src
            out["states"][kind] = obj2
        else:
            out["states"][kind] = {"source": "timeout", "pack": None}

    # MW –ø—Ä–∞–≤–∏–ª–∞ –∏–∑ –∫—ç—à–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
    mw_rows_all = (infra.mw_wl_by_strategy.get(sid) or {}).get("rows", [])
    out["rules"] = [
        dict(r) for r in mw_rows_all
        if (str(r.get("timeframe")) == tf and str(r.get("direction")).lower() == direction)
    ]
    return out

# üî∏ –°–Ω–∏–º–æ–∫ PACK –¥–ª—è (sid, symbol, direction, tf)
async def _collect_pack_snapshot(
    sid: int, symbol: str, direction: str, tf: str, deadline_ms: int, telemetry: Dict[str, int]
) -> Dict[str, Any]:
    out: Dict[str, Any] = {"objects": {}, "rules": []}

    # –≤—Å–µ –ø—Ä–∞–≤–∏–ª–∞ PACK (WL –∏ BL) –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ TF/–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
    pack_rows_all = (infra.pack_wl_by_strategy.get(sid) or {}).get("rows", [])
    rows_tf = [
        dict(r) for r in pack_rows_all
        if (str(r.get("timeframe")) == tf and str(r.get("direction")).lower() == direction)
    ]
    out["rules"] = rows_tf

    # —Å–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö base –∏–∑ –ø—Ä–∞–≤–∏–ª
    bases: List[str] = []
    for r in rows_tf:
        base = (r.get("pack_base") or "").strip().lower()
        if base and base not in bases:
            bases.append(base)

    # –∑–∞–≥—Ä—É–∑–∫–∞ PACK-–æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ base
    tasks: List[asyncio.Task] = []
    meta: List[Tuple[str, str, Dict[str, Any]]] = []
    for base in bases:
        ind, params = _parse_pack_base(base)
        meta.append((base, ind, params))
        tasks.append(asyncio.create_task(_ensure_pack_available(
            symbol=symbol, tf=tf, indicator=ind, base=base, gw_params=params, deadline_ms=deadline_ms, telemetry=telemetry
        )))

    if tasks:
        fetched = await asyncio.gather(*tasks, return_exceptions=False)
        for (base, _ind, _params), (obj, src) in zip(meta, fetched):
            if obj:
                obj2 = dict(obj)
                obj2["source"] = src
                out["objects"][base] = obj2
            else:
                out["objects"][base] = {"source": "timeout", "pack": None}

    return out

# üî∏ –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ñ–∞–∫—Ç–∞ –¥–ª—è MW –ø–æ agg_base
def _build_mw_fact(states: Dict[str, Any], agg_base: str) -> Optional[str]:
    if not agg_base:
        return None
    parts: List[str] = []
    for base in (agg_base.strip().lower().split("_")):
        node = states.get(base) or {}
        pack = node.get("pack") or {}
        st = pack.get("state")
        if not isinstance(st, str) or not st:
            return None
        parts.append(f"{base}:{st.strip().lower()}")
    return "|".join(parts)

# üî∏ –ü–æ–¥—Å—á—ë—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –¥–ª—è MW-WL
def _mw_count_hits(mw_rules: List[Dict[str, Any]], states: Dict[str, Any]) -> Tuple[int, int]:
    total = 0
    hits = 0
    for r in mw_rules:
        agg_base = str(r.get("agg_base") or "").strip().lower()
        agg_state = str(r.get("agg_state") or "").strip().lower()
        if not agg_base or not agg_state:
            continue
        total += 1
        fact = _build_mw_fact(states, agg_base)
        if fact is not None and fact == agg_state:
            hits += 1
    return hits, total

# üî∏ –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ñ–∞–∫—Ç–∞ –¥–ª—è PACK –ø–æ agg_key –∏–∑ pack payload
def _build_pack_fact(pack_obj: Dict[str, Any], agg_key: str) -> Optional[str]:
    if not agg_key:
        return None
    pack_payload = (pack_obj or {}).get("pack") or {}
    keys = [k.strip() for k in agg_key.strip().lower().split("|") if k.strip()]
    parts: List[str] = []
    for k in keys:
        v = pack_payload.get(k)
        if v is None:
            return None
        parts.append(f"{k}:{str(v).strip().lower()}")
    return "|".join(parts)

# üî∏ –ü–æ–¥—Å—á—ë—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –¥–ª—è PACK (WL/BL)
def _pack_count_hits(
    pack_rules: List[Dict[str, Any]],
    pack_objs: Dict[str, Optional[dict]],
) -> Tuple[int, int, int, int]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (wl_hits, wl_total, bl_hits, bl_total)
    """
    wl_total = 0
    wl_hits = 0
    bl_total = 0
    bl_hits = 0

    for r in pack_rules:
        list_type = str(r.get("list") or "").strip().lower()
        base = str(r.get("pack_base") or "").strip().lower()
        agg_key = str(r.get("agg_key") or "").strip().lower()
        agg_val = str(r.get("agg_value") or "").strip().lower()
        if not base or not agg_key or not agg_val:
            continue

        # —Å—á–∏—Ç–∞–µ–º totals –ø–æ —Ç–∏–ø—É
        if list_type == "whitelist":
            wl_total += 1
        elif list_type == "blacklist":
            bl_total += 1
        else:
            continue

        pack_obj = pack_objs.get(base)
        if not pack_obj:
            # –æ–±—ä–µ–∫—Ç –Ω–µ —Å–æ–±—Ä–∞–Ω/timeout ‚Äî –Ω–µ —Å—á–∏—Ç–∞–µ–º hit
            continue

        fact = _build_pack_fact(pack_obj, agg_key)
        if fact is None:
            continue

        if fact == agg_val:
            if list_type == "whitelist":
                wl_hits += 1
            else:
                bl_hits += 1

    return wl_hits, wl_total, bl_hits, bl_total

# üî∏ –ü–µ—Ä—Å–∏—Å—Ç –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –ø–æ –ö–û–ù–ö–†–ï–¢–ù–û–ú–£ TF (–≠—Ç–∞–ø 2: –≤—Å–µ–≥–¥–∞ allow=false + reason=stage2_count_only + —Å—á—ë—Ç—á–∏–∫–∏)
async def _persist_decision_tf(
    req_id: str,
    log_uid: str,
    strategy_id: int,
    client_strategy_id: Optional[int],
    symbol: str,
    direction: str,
    tf: str,
    tfr_req: str,
    tf_result_json: Optional[str],
    received_at_dt: datetime,
    finished_at_dt: datetime,
    duration_ms: int,
    kv_hits: int,
    gateway_requests: int,
    mw_wl_hits: int,
    mw_wl_total: int,
    pack_wl_hits: int,
    pack_wl_total: int,
    pack_bl_hits: int,
    pack_bl_total: int,
):
    async with infra.pg_pool.acquire() as conn:
        if client_strategy_id is None:
            # update (master-only)
            upd_status = await conn.execute(
                """
                UPDATE public.signal_laboratory_entries
                   SET req_id=$1,
                       direction=$2,
                       symbol=$3,
                       tf=$4,
                       timeframes_requested=$5,
                       timeframes_processed=$6,
                       allow=false,
                       reason='stage2_count_only',
                       tf_results=COALESCE($7::jsonb, signal_laboratory_entries.tf_results),
                       finished_at=$8,
                       duration_ms=$9,
                       cache_hits=$10,
                       gateway_requests=$11,
                       mw_wl_rules_total=$12,
                       mw_wl_hits=$13,
                       pack_wl_rules_total=$14,
                       pack_wl_hits=$15,
                       pack_bl_rules_total=$16,
                       pack_bl_hits=$17
                 WHERE log_uid=$18 AND strategy_id=$19 AND client_strategy_id IS NULL AND tf=$4
                """,
                req_id, direction, symbol, tf, tfr_req, tf, tf_result_json,
                finished_at_dt, duration_ms, kv_hits, gateway_requests,
                mw_wl_total, mw_wl_hits, pack_wl_total, pack_wl_hits, pack_bl_total, pack_bl_hits,
                log_uid, strategy_id
            )
            if upd_status.startswith("UPDATE 1"):
                return
            # insert (master-only)
            ins_status = await conn.execute(
                """
                INSERT INTO public.signal_laboratory_entries
                    (req_id, log_uid, strategy_id, client_strategy_id, direction, symbol, tf,
                     timeframes_requested, timeframes_processed, protocol_version,
                     allow, reason, tf_results, errors,
                     received_at, finished_at, duration_ms, cache_hits, gateway_requests,
                     mw_wl_rules_total, mw_wl_hits, pack_wl_rules_total, pack_wl_hits, pack_bl_rules_total, pack_bl_hits)
                VALUES ($1,$2,$3,NULL,$4,$5,$6,
                        $7,$8,'v1',
                        false,'stage2_count_only',COALESCE($9::jsonb,NULL),NULL,
                        $10,$11,$12,$13,$14,
                        $15,$16,$17,$18,$19,$20)
                ON CONFLICT DO NOTHING
                """,
                req_id, log_uid, strategy_id, direction, symbol, tf,
                tfr_req, tf, tf_result_json,
                received_at_dt, finished_at_dt, duration_ms, kv_hits, gateway_requests,
                mw_wl_total, mw_wl_hits, pack_wl_total, pack_wl_hits, pack_bl_total, pack_bl_hits
            )
            if ins_status.endswith(" 1"):
                return
            # race: update again
            await conn.execute(
                """
                UPDATE public.signal_laboratory_entries
                   SET req_id=$1,
                       direction=$2,
                       symbol=$3,
                       tf=$4,
                       timeframes_requested=$5,
                       timeframes_processed=$6,
                       allow=false,
                       reason='stage2_count_only',
                       tf_results=COALESCE($7::jsonb, signal_laboratory_entries.tf_results),
                       finished_at=$8,
                       duration_ms=$9,
                       cache_hits=$10,
                       gateway_requests=$11,
                       mw_wl_rules_total=$12,
                       mw_wl_hits=$13,
                       pack_wl_rules_total=$14,
                       pack_wl_hits=$15,
                       pack_bl_rules_total=$16,
                       pack_bl_hits=$17
                 WHERE log_uid=$18 AND strategy_id=$19 AND client_strategy_id IS NULL AND tf=$4
                """,
                req_id, direction, symbol, tf, tfr_req, tf, tf_result_json,
                finished_at_dt, duration_ms, kv_hits, gateway_requests,
                mw_wl_total, mw_wl_hits, pack_wl_total, pack_wl_hits, pack_bl_total, pack_bl_hits,
                log_uid, strategy_id
            )
            return

        # client_strategy_id IS NOT NULL
        upd_status = await conn.execute(
            """
            UPDATE public.signal_laboratory_entries
               SET req_id=$1,
                   direction=$2,
                   symbol=$3,
                   tf=$4,
                   timeframes_requested=$5,
                   timeframes_processed=$6,
                   allow=false,
                   reason='stage2_count_only',
                   tf_results=COALESCE($7::jsonb, signal_laboratory_entries.tf_results),
                   finished_at=$8,
                   duration_ms=$9,
                   cache_hits=$10,
                   gateway_requests=$11,
                   mw_wl_rules_total=$12,
                   mw_wl_hits=$13,
                   pack_wl_rules_total=$14,
                   pack_wl_hits=$15,
                   pack_bl_rules_total=$16,
                   pack_bl_hits=$17
             WHERE log_uid=$18 AND strategy_id=$19 AND client_strategy_id=$20 AND tf=$4
            """,
            req_id, direction, symbol, tf, tfr_req, tf, tf_result_json,
            finished_at_dt, duration_ms, kv_hits, gateway_requests,
            mw_wl_total, mw_wl_hits, pack_wl_total, pack_wl_hits, pack_bl_total, pack_bl_hits,
            log_uid, strategy_id, int(client_strategy_id)
        )
        if upd_status.startswith("UPDATE 1"):
            return
        ins_status = await conn.execute(
            """
            INSERT INTO public.signal_laboratory_entries
                (req_id, log_uid, strategy_id, client_strategy_id, direction, symbol, tf,
                 timeframes_requested, timeframes_processed, protocol_version,
                 allow, reason, tf_results, errors,
                 received_at, finished_at, duration_ms, cache_hits, gateway_requests,
                 mw_wl_rules_total, mw_wl_hits, pack_wl_rules_total, pack_wl_hits, pack_bl_rules_total, pack_bl_hits)
            VALUES ($1,$2,$3,$4,$5,$6,$7,
                    $8,$9,'v1',
                    false,'stage2_count_only',COALESCE($10::jsonb,NULL),NULL,
                    $11,$12,$13,$14,$15,
                    $16,$17,$18,$19,$20,$21)
            ON CONFLICT DO NOTHING
            """,
            req_id, log_uid, strategy_id, int(client_strategy_id), direction, symbol, tf,
            tfr_req, tf, tf_result_json,
            received_at_dt, finished_at_dt, duration_ms, kv_hits, gateway_requests,
            mw_wl_total, mw_wl_hits, pack_wl_total, pack_wl_hits, pack_bl_total, pack_bl_hits
        )
        if ins_status.endswith(" 1"):
            return
        await conn.execute(
            """
            UPDATE public.signal_laboratory_entries
               SET req_id=$1,
                   direction=$2,
                   symbol=$3,
                   tf=$4,
                   timeframes_requested=$5,
                   timeframes_processed=$6,
                   allow=false,
                   reason='stage2_count_only',
                   tf_results=COALESCE($7::jsonb, signal_laboratory_entries.tf_results),
                   finished_at=$8,
                   duration_ms=$9,
                   cache_hits=$10,
                   gateway_requests=$11,
                   mw_wl_rules_total=$12,
                   mw_wl_hits=$13,
                   pack_wl_rules_total=$14,
                   pack_wl_hits=$15,
                   pack_bl_rules_total=$16,
                   pack_bl_hits=$17
             WHERE log_uid=$18 AND strategy_id=$19 AND client_strategy_id=$20 AND tf=$4
            """,
            req_id, direction, symbol, tf, tfr_req, tf, tf_result_json,
            finished_at_dt, duration_ms, kv_hits, gateway_requests,
            mw_wl_total, mw_wl_hits, pack_wl_total, pack_wl_hits, pack_bl_total, pack_bl_hits,
            log_uid, strategy_id, int(client_strategy_id)
        )

# üî∏ –ö–ª—é—á–∏ —à—Ç–æ—Ä–∫–∏/–æ—á–µ—Ä–µ–¥–∏
def _gate_key(gate_sid: int, symbol: str) -> str:
    return f"lab:gate:{gate_sid}:{symbol}"

def _queue_key(gate_sid: int, symbol: str) -> str:
    return f"lab:qids:{gate_sid}:{symbol}"

def _qfields_key(req_id: str) -> str:
    return f"lab:qfields:{req_id}"

# üî∏ –ü–æ–ª—É—á–∏—Ç—å –ª–∏–¥–µ—Ä—Å—Ç–≤–æ –∏–ª–∏ –≤—Å—Ç–∞—Ç—å –≤ –æ—á–µ—Ä–µ–¥—å (anti-dup per (gate_sid,symbol))
async def _acquire_gate_or_enqueue(
    msg_id: str,
    fields: Dict[str, str],
    gate_sid: int,
    symbol: str,
    gate_ttl_sec: int = GATE_TTL_SEC,
) -> Tuple[bool, Optional[str]]:
    gk = _gate_key(gate_sid, symbol)
    qk = _queue_key(gate_sid, symbol)
    fk = _qfields_key(msg_id)

    ok = await infra.redis_client.set(gk, msg_id, ex=gate_ttl_sec, nx=True)
    if ok:
        log.debug("[GATE] üîê –ª–∏–¥–µ—Ä –ø–æ–ª—É—á–µ–Ω gate_sid=%s %s req_id=%s", gate_sid, symbol, msg_id)
        return True, None

    await infra.redis_client.rpush(qk, msg_id)
    await infra.redis_client.set(fk, json.dumps(fields, ensure_ascii=False), ex=gate_ttl_sec + 60)
    log.debug("[GATE] ‚è∏Ô∏è –≤ –æ—á–µ—Ä–µ–¥—å gate_sid=%s %s req_id=%s", gate_sid, symbol, msg_id)
    return False, "enqueued"

# üî∏ –†–µ–∞–∫—Ü–∏—è –ø–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –ª–∏–¥–µ—Ä–∞ (allow=false ‚Üí –Ω–∞–∑–Ω–∞—á–∏—Ç—å —Å–ª–µ–¥—É—é—â–µ–≥–æ)
async def _on_leader_finished(gate_sid: int, symbol: str, leader_req_id: str, allow: bool):
    gk = _gate_key(gate_sid, symbol)
    qk = _queue_key(gate_sid, symbol)
    await infra.redis_client.delete(gk)

    if allow:
        pending = await infra.redis_client.lrange(qk, 0, -1)
        await infra.redis_client.delete(qk)
        if pending:
            log.debug("[GATE] üö´ duplicated gate_sid=%s %s ‚Äî –æ—Ç–∫–∞–∑—ã–≤–∞–µ–º –æ—á–µ—Ä–µ–¥–∏ (%d)", gate_sid, symbol, len(pending))
            for req_id in pending:
                await infra.redis_client.xadd(DECISION_RESP_STREAM, {
                    "req_id": req_id, "status": "ok", "allow": "false", "reason": "duplicated_entry"
                })
                await infra.redis_client.delete(_qfields_key(req_id))
        return

    next_req_id = await infra.redis_client.lpop(qk)
    if not next_req_id:
        log.debug("[GATE] üîÅ –æ—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞ gate_sid=%s %s", gate_sid, symbol)
        return

    ok = await infra.redis_client.set(gk, next_req_id, ex=GATE_TTL_SEC, nx=True)
    if not ok:
        log.debug("[GATE] ‚ö†Ô∏è –Ω–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–∑–Ω–∞—á–∏—Ç—å –ª–∏–¥–µ—Ä–∞ gate_sid=%s %s req=%s", gate_sid, symbol, next_req_id)
        return

    raw = await infra.redis_client.get(_qfields_key(next_req_id))
    if not raw:
        await infra.redis_client.xadd(DECISION_RESP_STREAM, {
            "req_id": next_req_id, "status": "error", "error": "internal_error", "message": "queued payload missing"
        })
        return

    try:
        fields = json.loads(raw)
    except Exception:
        await infra.redis_client.xadd(DECISION_RESP_STREAM, {
            "req_id": next_req_id, "status": "error", "error": "internal_error", "message": "queued payload invalid"
        })
        return

    asyncio.create_task(_process_request_core(next_req_id, fields))

# üî∏ –Ø–¥—Ä–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ (–≠—Ç–∞–ø 2: —Å–±–æ—Ä —Å–Ω–∏–º–∫–∞ + –ø–æ–¥—Å—á—ë—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π; –í–°–ï–ì–î–ê deny –≤ –æ—Ç–≤–µ—Ç)
async def _process_request_core(msg_id: str, fields: Dict[str, str]):
    async with _decisions_sem:
        t0 = _now_monotonic_ms()
        received_at_dt = datetime.utcnow()

        # –ø–∞—Ä—Å–∏–Ω–≥ –±–∞–∑–æ–≤—ã—Ö –ø–æ–ª–µ–π
        log_uid = fields.get("log_uid") or ""
        strategy_id_s = fields.get("strategy_id") or ""
        client_sid_s = fields.get("client_strategy_id") or ""
        direction = (fields.get("direction") or "").strip().lower()
        symbol = (fields.get("symbol") or "").strip().upper()
        tfs_raw = fields.get("timeframes") or ""

        # –±–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
        if not log_uid or not strategy_id_s.isdigit() or direction not in ("long", "short") or not symbol or not tfs_raw:
            await infra.redis_client.xadd(DECISION_RESP_STREAM, {
                "req_id": msg_id, "status": "error", "error": "bad_request", "message": "missing or invalid fields"
            })
            log.info("[REQ] ‚ùå bad_request log_uid=%s sid=%s symbol=%s dir=%s tfs=%s", log_uid, strategy_id_s, symbol, direction, tfs_raw)
            return

        sid = int(strategy_id_s)
        gate_sid = int(client_sid_s) if client_sid_s.isdigit() else sid

        # –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Ç–∏–∫–µ—Ä–∞/—Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        if symbol not in infra.enabled_tickers:
            await infra.redis_client.xadd(DECISION_RESP_STREAM, {
                "req_id": msg_id, "status": "error", "error": "symbol_not_active", "message": f"{symbol}"
            })
            log.info("[REQ] ‚ùå symbol_not_active log_uid=%s sid=%s %s", log_uid, sid, symbol)
            return
        if sid not in infra.enabled_strategies:
            await infra.redis_client.xadd(DECISION_RESP_STREAM, {
                "req_id": msg_id, "status": "error", "error": "strategy_not_enabled", "message": f"{sid}"
            })
            log.info("[REQ] ‚ùå strategy_not_enabled log_uid=%s sid=%s", log_uid, sid)
            return

        # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è TF –∏ –¥–µ–¥–ª–∞–π–Ω
        tfs = _parse_timeframes(tfs_raw)
        deadline_ms = t0 + LAB_DEADLINE_MS

        # –æ–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ MW-–∫—ç—à–∞ –¥–ª—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ (—à—Ç–æ—Ä–∫–∞)
        await infra.wait_mw_ready(sid, timeout_sec=5.0)

        # –ª–æ–≥ —Å—Ç–∞—Ä—Ç–∞
        log.info(
            "[REQ] ‚ñ∂Ô∏è start log_uid=%s master_sid=%s client_sid=%s %s %s tfs=%s deadline=90s",
            log_uid, sid, (client_sid_s or "-"), symbol, direction, ",".join(tfs)
        )

        telemetry: Dict[str, int] = {"kv_hits": 0, "gateway_requests": 0}
        tf_results_for_response: List[Dict[str, Any]] = []

        # —Ü–∏–∫–ª –ø–æ –∫–∞–∂–¥–æ–π –∑–∞–ø—Ä–æ—à–µ–Ω–Ω–æ–π TF ‚Äî —Å–±–æ—Ä —Å–Ω–∏–º–∫–∞, –ø–æ–¥—Å—á—ë—Ç –º–∞—Ç—á–µ–π –∏ –∑–∞–ø–∏—Å—å –û–î–ù–û–ô —Å—Ç—Ä–æ–∫–∏ –Ω–∞ TF
        for tf in tfs:
            # MW snapshot
            mw_snap = await _collect_mw_snapshot(
                sid=sid, symbol=symbol, direction=direction, tf=tf, deadline_ms=deadline_ms, telemetry=telemetry
            )

            # PACK snapshot
            pack_snap = await _collect_pack_snapshot(
                sid=sid, symbol=symbol, direction=direction, tf=tf, deadline_ms=deadline_ms, telemetry=telemetry
            )

            # —Ñ–ª–∞–≥ –Ω–µ–ø–æ–ª–Ω–æ–≥–æ —Å–±–æ—Ä–∞ –ø–æ TF
            incomplete = False
            for kind in ("trend", "volatility", "momentum", "extremes"):
                node = mw_snap["states"].get(kind)
                if not node or (isinstance(node, dict) and node.get("source") == "timeout"):
                    incomplete = True
                    break
            if not incomplete:
                for base, node in (pack_snap.get("objects") or {}).items():
                    if not node or (isinstance(node, dict) and node.get("source") == "timeout"):
                        incomplete = True
                        break

            # –ü–æ–¥—Å—á—ë—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π MW
            mw_hits, mw_total = _mw_count_hits(mw_snap.get("rules", []), mw_snap.get("states", {}))

            # –ü–æ–¥—Å—á—ë—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π PACK (WL/BL)
            pack_wl_hits, pack_wl_total, pack_bl_hits, pack_bl_total = _pack_count_hits(
                pack_snap.get("rules", []), pack_snap.get("objects", {})
            )

            # —Å–æ–±–µ—Ä—ë–º –æ–¥–∏–Ω–æ—á–Ω—ã–π TF-—Ä–µ–∑—É–ª—å—Ç–∞—Ç (–¥–ª—è –ë–î –∏ –æ—Ç–≤–µ—Ç–∞)
            tf_result_obj = {
                "tf": tf,
                "collect_incomplete": incomplete,
                "mw": mw_snap,
                "pack": pack_snap,
                "counters": {
                    "mw_wl_hits": mw_hits, "mw_wl_total": mw_total,
                    "pack_wl_hits": pack_wl_hits, "pack_wl_total": pack_wl_total,
                    "pack_bl_hits": pack_bl_hits, "pack_bl_total": pack_bl_total,
                },
            }
            tf_results_for_response.append(tf_result_obj)

            # –ª–æ–≥ –ø–æ TF (log.info)
            log.info(
                "[TF:%s] match mw_wl: %d/%d  pack_wl: %d/%d  pack_bl: %d/%d  incomplete=%s  kv_hits=%d gw_reqs=%d",
                tf, mw_hits, mw_total, pack_wl_hits, pack_wl_total, pack_bl_hits, pack_bl_total,
                str(incomplete).lower(), telemetry.get("kv_hits", 0), telemetry.get("gateway_requests", 0)
            )

            # –∑–∞–ø–∏—Å—å –û–î–ù–û–ô —Å—Ç—Ä–æ–∫–∏ –Ω–∞ TF
            finished_at_dt = datetime.utcnow()
            duration_ms = _now_monotonic_ms() - t0
            try:
                tf_json_safe = _to_json_safe(tf_result_obj)
                tf_json_text = json.dumps(tf_json_safe, ensure_ascii=False)
                await _persist_decision_tf(
                    req_id=msg_id,
                    log_uid=log_uid,
                    strategy_id=sid,
                    client_strategy_id=int(client_sid_s) if client_sid_s.isdigit() else None,
                    symbol=symbol,
                    direction=direction,
                    tf=tf,
                    tfr_req=tfs_raw,
                    tf_result_json=tf_json_text,
                    received_at_dt=received_at_dt,
                    finished_at_dt=finished_at_dt,
                    duration_ms=duration_ms,
                    kv_hits=telemetry.get("kv_hits", 0),
                    gateway_requests=telemetry.get("gateway_requests", 0),
                    mw_wl_hits=mw_hits,
                    mw_wl_total=mw_total,
                    pack_wl_hits=pack_wl_hits,
                    pack_wl_total=pack_wl_total,
                    pack_bl_hits=pack_bl_hits,
                    pack_bl_total=pack_bl_total,
                )
            except Exception:
                log.exception("[AUDIT] ‚ùå –æ—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ —Å—Ç—Ä–æ–∫–∏ TF=%s log_uid=%s sid=%s csid=%s", tf, log_uid, sid, client_sid_s or "-")

        # —Ñ–æ—Ä–º–∏—Ä—É–µ–º –û–¢–í–ï–¢ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ ‚Äî –≤—Å–µ–≥–¥–∞ deny –Ω–∞ –≠—Ç–∞–ø–µ 2 (–µ–¥–∏–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–µ—Å—å –∑–∞–ø—Ä–æ—Å)
        finished_at_dt = datetime.utcnow()
        duration_ms_total = _now_monotonic_ms() - t0

        resp = {
            "req_id": msg_id,
            "status": "ok",
            "allow": "false",
            "reason": "stage2_count_only",
            "log_uid": log_uid,
            "strategy_id": str(sid),
            "direction": direction,
            "symbol": symbol,
            "timeframes": ",".join(tfs),
        }
        if client_sid_s:
            resp["client_strategy_id"] = client_sid_s

        # –ø–æ–ª–æ–∂–∏–º —Å–≤–æ–¥–Ω—ã–π –º–∞—Å—Å–∏–≤ TF –≤ –æ—Ç–≤–µ—Ç (–¥–ª—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏)
        try:
            resp["tf_results"] = json.dumps(_to_json_safe(tf_results_for_response), ensure_ascii=False)
        except Exception:
            pass

        await infra.redis_client.xadd(DECISION_RESP_STREAM, resp)

        # —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ª–æ–≥ (log.info)
        log.info(
            "[RESP] ‚õî deny log_uid=%s sid=%s csid=%s reason=stage2_count_only dur=%dms kv_hits=%d gw_reqs=%d",
            log_uid, sid, (client_sid_s or "-"), duration_ms_total, telemetry.get("kv_hits", 0), telemetry.get("gateway_requests", 0)
        )

        # –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –≤–æ—Ä–æ—Ç: allow=false ‚Üí –ø–æ–¥–æ–±—Ä–∞—Ç—å —Å–ª–µ–¥—É—é—â–µ–≥–æ –∏–∑ –æ—á–µ—Ä–µ–¥–∏
        await _on_leader_finished(gate_sid=gate_sid, symbol=symbol, leader_req_id=msg_id, allow=False)

# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥—è—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: –ø–æ–ª—É—á–∏—Ç—å –ª–∏–¥–µ—Ä—Å—Ç–≤–æ –∏–ª–∏ –≤—Å—Ç–∞—Ç—å –≤ –æ—á–µ—Ä–µ–¥—å
async def _handle_incoming(msg_id: str, fields: Dict[str, str]):
    strategy_id_s = fields.get("strategy_id") or ""
    client_sid_s = fields.get("client_strategy_id") or ""
    symbol = (fields.get("symbol") or "").strip().upper()
    if not strategy_id_s.isdigit() or not symbol:
        await infra.redis_client.xadd(DECISION_RESP_STREAM, {
            "req_id": msg_id, "status": "error", "error": "bad_request", "message": "missing sid/symbol"
        })
        log.info("[REQ] ‚ùå bad_request (no sid/symbol) fields=%s", fields)
        return

    sid = int(strategy_id_s)
    gate_sid = int(client_sid_s) if client_sid_s.isdigit() else sid

    is_leader, _ = await _acquire_gate_or_enqueue(msg_id, fields, gate_sid, symbol, gate_ttl_sec=GATE_TTL_SEC)
    if is_leader:
        await _process_request_core(msg_id, fields)
    else:
        log.debug("[REQ] ‚è≥ queued gate_sid=%s %s req_id=%s", gate_sid, symbol, msg_id)

# üî∏ –ì–ª–∞–≤–Ω—ã–π —Å–ª—É—à–∞—Ç–µ–ª—å decision_request (–≠—Ç–∞–ø 2)
async def run_laboratory_decision_maker():
    """
    –°–ª—É—à–∞–µ—Ç laboratory:decision_request, —Å–æ–±–∏—Ä–∞–µ—Ç —Å–Ω–∏–º–æ–∫ MW/PACK, —Å—á–∏—Ç–∞–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è (MW-WL / PACK-WL / PACK-BL)
    –∏ –ø–∏—à–µ—Ç –ü–û –û–î–ù–û–ô —Å—Ç—Ä–æ–∫–µ –Ω–∞ –∫–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–π TF –≤ signal_laboratory_entries. –í –æ—Ç–≤–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç
    status=ok, allow=false, reason=stage2_count_only.
    –†–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å –ù–û–í–´–ú–ò —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ (—Å—Ç–∞—Ä—Ç —Å '$'). –í—Å—Ç—Ä–æ–µ–Ω—ã –≤–æ—Ä–æ—Ç–∞/–æ—á–µ—Ä–µ–¥—å per (gate_sid, symbol).
    """
    log.info("üõ∞Ô∏è LAB_DECISION —Å–ª—É—à–∞—Ç–µ–ª—å –∑–∞–ø—É—â–µ–Ω (BLOCK=%d COUNT=%d DEADLINE=%ds)",
             XREAD_BLOCK_MS, XREAD_COUNT, LAB_DEADLINE_MS // 1000)

    last_id = "$"  # —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ
    redis = infra.redis_client

    while True:
        try:
            resp = await redis.xread(
                streams={DECISION_REQ_STREAM: last_id},
                count=XREAD_COUNT,
                block=XREAD_BLOCK_MS
            )
            if not resp:
                continue

            for _, messages in resp:
                for msg_id, fields in messages:
                    last_id = msg_id
                    asyncio.create_task(_handle_incoming(msg_id, fields))

        except asyncio.CancelledError:
            log.info("‚èπÔ∏è LAB_DECISION –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ —Å–∏–≥–Ω–∞–ª—É")
            raise
        except Exception:
            log.exception("‚ùå LAB_DECISION –æ—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ")
            await asyncio.sleep(1.0)