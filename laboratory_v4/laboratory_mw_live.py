# laboratory_mw_live.py â€” Ð²Ð¾Ñ€ÐºÐµÑ€ laboratory_v4: MW-ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ (trend/volatility/momentum/extremes),
# Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ live-Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ð¸Ð· in-memory ÐºÐµÑˆÐ° (ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ), Ð¿ÑƒÐ±Ð»Ð¸ÐºÑƒÐµÑ‚ Ð² lab_live:mw:...

# ðŸ”¸ Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ñ‹
import asyncio
import logging
import time
import json
from datetime import datetime
from typing import Tuple, Dict

from lab_utils import floor_to_bar
from compute_only import compute_snapshot_values_async  # fallback-Ñ€Ð°ÑÑ‡Ñ‘Ñ‚, ÐµÑÐ»Ð¸ Ð² ÐºÐµÑˆÐµ Ð½ÐµÑ‚ live
from laboratory_config import get_live_values           # Ñ‡Ñ‚ÐµÐ½Ð¸Ðµ live Ð¸Ð· ÐºÐµÑˆÐ° IND

# ðŸ”¸ ÐŸÐ°ÐºÐµÑ‚Ð½Ñ‹Ðµ Ð±Ð¸Ð»Ð´ÐµÑ€Ñ‹ MW (Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÑŽÑ‚ Ð½Ð° Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¼ Ð±Ð°Ñ€Ðµ, hysteresis+dwell Ñ‡ÐµÑ€ÐµÐ· laboratory_mw_shared Ð² ÑÐ°Ð¼Ð¸Ñ… Ð¿Ð°ÐºÐ°Ñ…)
from packs.trend_pack import build_trend_pack
from packs.volatility_pack import build_volatility_pack
from packs.momentum_pack import build_momentum_pack
from packs.extremes_pack import build_extremes_pack

# ðŸ”¸ Ð›Ð¾Ð³Ð³ÐµÑ€
log = logging.getLogger("LAB_MW_LIVE")

# ðŸ”¸ ÐšÐ¾Ð½ÑÑ‚Ð°Ð½Ñ‚Ñ‹ Ð²Ð¾Ñ€ÐºÐµÑ€Ð°
TF_SET = ("m5", "m15", "h1")   # Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÐ¼Ñ‹Ðµ TF
LAB_PREFIX = "lab_live"        # Ð¿Ñ€ÐµÑ„Ð¸ÐºÑ Ð¿Ñ€Ð¾ÑÑ‚Ñ€Ð°Ð½ÑÑ‚Ð²Ð° Ð»Ð°Ð±Ð¾Ñ€Ð°Ñ‚Ð¾Ñ€Ð¸Ð¸
LAB_TTL_SEC = 60               # TTL KV-Ð·Ð°Ð¿Ð¸ÑÐµÐ¹
TICK_INTERVAL_SEC = 15         # Ð¿ÐµÑ€Ð¸Ð¾Ð´ Ñ‚Ð¸ÐºÐ° Ð¿ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ†Ð¸Ð¸
MAX_CONCURRENCY = 64           # Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾ Ð¾Ð±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼Ñ‹Ðµ Ð¿Ð°Ñ€Ñ‹ (symbol, tf)
KIND_CONCURRENCY = 4           # Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»Ð¸Ð·Ð¼ Ð¿Ð¾ Ð²Ð¸Ð´Ð°Ð¼ MW Ð²Ð½ÑƒÑ‚Ñ€Ð¸ Ð¾Ð´Ð½Ð¾Ð¹ Ð¿Ð°Ñ€Ñ‹ (Ð¸Ñ… 4)

# ðŸ”¸ Ð¡Ð¾Ð¿Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ kind â†’ builder
BUILDERS = {
    "trend": build_trend_pack,
    "volatility": build_volatility_pack,
    "momentum": build_momentum_pack,
    "extremes": build_extremes_pack,
}

# ðŸ”¸ Ð¡Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ KV-ÐºÐ»ÑŽÑ‡ MW
def _mw_key(symbol: str, tf: str, kind: str) -> str:
    return f"{LAB_PREFIX}:mw:{symbol}:{tf}:{kind}"

# ðŸ”¸ ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð¾Ð²Ð°Ñ‚ÑŒ Ð´ÐµÑ‚Ð°Ð»Ð¸ Ð´Ð»Ñ Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ (Ð¿ÐµÑ€ÐµÐ½Ð¾Ñ streak_preview â†’ streak)
def _normalize_details(details: Dict) -> Dict:
    if not isinstance(details, dict):
        return {}
    sp = details.get("streak_preview")
    if sp is not None and "streak" not in details:
        try:
            details["streak"] = int(sp)
        except Exception:
            pass
    return details

# ðŸ”¸ ÐŸÑƒÐ±Ð»Ð¸ÐºÐ°Ñ†Ð¸Ñ Ð¾Ð´Ð½Ð¾Ð³Ð¾ MW-Ð¿Ð°ÐºÐµÑ‚Ð° Ð² KV lab_live:mw:... Ñ TTL
async def _persist_mw(redis, symbol: str, tf: str, kind: str, pack_obj: Dict) -> bool:
    try:
        pack = pack_obj.get("pack", {})
        state = pack.get("state")
        if state is None:
            return False

        open_time = pack.get("open_time") or datetime.utcnow().isoformat()
        details = _normalize_details(dict(pack))

        payload = {
            "state": state,
            "version": 1,
            "open_time": open_time,
            "computed_at": datetime.utcnow().isoformat(),
            "details": details,
        }
        key = _mw_key(symbol, tf, kind)
        await redis.set(key, json.dumps(payload), ex=LAB_TTL_SEC)
        return True
    except Exception as e:
        log.warning("persist error %s/%s kind=%s: %s", symbol, tf, kind, e)
        return False


# ðŸ”¸ ÐžÐ±Ñ‘Ñ€Ñ‚ÐºÐ° compute_fn: Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ live-Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ð¸Ð· ÐºÐµÑˆÐ° IND Ð´Ð»Ñ Ñ‚ÐµÐºÑƒÑ‰ÐµÐ³Ð¾ Ð±Ð°Ñ€Ð°, Ð¿Ñ€Ð¸ Ð¿Ñ€Ð¾Ð¼Ð°Ñ…Ðµ â€” ÑÑ‡Ð¸Ñ‚Ð°ÐµÑ‚ ÐºÐ°Ðº Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾
async def compute_fn_cached(inst: dict, symbol: str, df, precision: int) -> Dict[str, str]:
    """
    inst: {"indicator": "...", "params": {...}, "timeframe": tf}
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ {param_name -> "ÑÑ‚Ñ€Ð¾ÐºÐ°-Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ"}, ÐºÐ°Ðº compute_snapshot_values_async.
    Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¿Ñ‹Ñ‚Ð°ÐµÑ‚ÑÑ Ð²Ð·ÑÑ‚ÑŒ Ð¸Ð· live-ÐºÐµÑˆÐ° Ð¿Ð¾ (symbol, tf, open_ms), Ð³Ð´Ðµ open_ms â€” Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ð¹ Ð¸Ð½Ð´ÐµÐºÑ df.
    ÐŸÑ€Ð¾Ð¼Ð°Ñ… â†’ fallback Ðº compute_snapshot_values_async.
    """
    try:
        tf = inst.get("timeframe")
        if tf is None:
            return await compute_snapshot_values_async(inst, symbol, df, precision)

        # Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ð¼ open_ms Ð¿Ð¾ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐ¹ ÑÑ‚Ñ€Ð¾ÐºÐµ df
        try:
            last_ts = df.index[-1]
            open_ms = int(last_ts.value // 1_000_000)  # ns â†’ ms
        except Exception:
            return await compute_snapshot_values_async(inst, symbol, df, precision)

        cached = get_live_values(symbol, tf, open_ms)
        if not cached:
            return await compute_snapshot_values_async(inst, symbol, df, precision)

        # Ð²Ð¾ÑÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ð¼ base ÐºÐ°Ðº Ð² compute_only: macd{fast} | {indicator}{length} | indicator
        indicator = inst.get("indicator")
        params = inst.get("params") or {}
        if indicator == "macd":
            base = f"macd{params['fast']}"
        elif "length" in params:
            base = f"{indicator}{params['length']}"
        else:
            base = str(indicator)

        # Ð¾Ñ‚Ð±ÐµÑ€Ñ‘Ð¼ Ð¸Ð· ÐºÐµÑˆÐ° ÐºÐ»ÑŽÑ‡Ð¸, Ð¾Ñ‚Ð½Ð¾ÑÑÑ‰Ð¸ÐµÑÑ Ðº ÑÑ‚Ð¾Ð¼Ñƒ base
        out: Dict[str, str] = {}
        for k, v in cached.items():
            s = str(k)
            if s == base or s.startswith(f"{base}_"):
                out[s] = str(v)

        # ÐµÑÐ»Ð¸ Ð½Ð¸Ñ‡ÐµÐ³Ð¾ Ð½Ðµ Ð½Ð°ÑˆÐ»Ð¸ â€” fallback
        if not out:
            return await compute_snapshot_values_async(inst, symbol, df, precision)
        return out
    except Exception:
        # Ð»ÑŽÐ±Ð¾Ð¹ ÑÐ±Ð¾Ð¹ â€” Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ñ‹Ð¹ fallback
        return await compute_snapshot_values_async(inst, symbol, df, precision)


# ðŸ”¸ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¾Ð´Ð½Ð¾Ð¹ Ð¿Ð°Ñ€Ñ‹ (symbol, tf): Ñ€Ð°ÑÑ‡Ñ‘Ñ‚ 4 MW-Ð¿Ð°ÐºÐµÑ‚Ð¾Ð² Ð¸ Ð¿ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ†Ð¸Ñ
async def _process_pair(
    redis,
    symbol: str,
    tf: str,
    open_ms: int,
    precision: int,
) -> Tuple[int, int]:
    """
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ (published_states, skipped_states)
    """
    published = 0
    skipped = 0

    # Ð²Ð½ÑƒÑ‚Ñ€Ð¸ Ð¿Ð°Ñ€Ñ‹ Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð¼ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»Ð¸Ð·Ð¼ Ð¿Ð¾ Ð²Ð¸Ð´Ð°Ð¼ MW
    kind_sem = asyncio.Semaphore(KIND_CONCURRENCY)

    async def _build_and_publish(kind: str) -> Tuple[int, int]:
        async with kind_sem:
            try:
                builder = BUILDERS.get(kind)
                if builder is None:
                    return (0, 1)

                # Ð±Ð¸Ð»Ð´ÐµÑ€Ñ‹ Ð¾Ð¶Ð¸Ð´Ð°ÑŽÑ‚ now_ms; ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð¸Ð·ÑƒÐµÐ¼ÑÑ Ð½Ð° open_ms
                pack_obj = await builder(
                    symbol, tf, open_ms, precision, redis, compute_fn_cached
                )
                if not pack_obj:
                    return (0, 1)

                ok = await _persist_mw(redis, symbol, tf, kind, pack_obj)
                return (1 if ok else 0, 0 if ok else 1)
            except Exception as e:
                log.warning("mw build error %s/%s kind=%s: %s", symbol, tf, kind, e)
                return (0, 1)

    results = await asyncio.gather(
        *[asyncio.create_task(_build_and_publish(k)) for k in BUILDERS.keys()],
        return_exceptions=False,
    )

    for pub, sk in results:
        published += pub
        skipped += sk

    return (published, skipped)


# ðŸ”¸ ÐžÐ´Ð¸Ð½Ð¾Ñ‡Ð½Ñ‹Ð¹ Ñ‚Ð¸Ðº: Ð²Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ð¾Ð´Ð¸Ð½ Ð¿Ñ€Ð¾Ñ…Ð¾Ð´ Ð¿Ð¾ ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ð¼ TF (Ð±ÐµÐ· Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ¸/Ñ†Ð¸ÐºÐ»Ð°)
async def tick_mw(
    pg,
    redis,
    get_active_symbols,      # callable() -> list[str]
    get_precision,           # callable(symbol) -> int|None
    get_last_bar,            # callable(symbol, tf) -> int|None
    tf_set: Tuple[str, ...] = TF_SET,
) -> Tuple[int, int, int, int]:
    """
    Ð’Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ð¾Ð´Ð¸Ð½ MW-Ð¿Ñ€Ð¾Ñ…Ð¾Ð´ Ð¿Ð¾ Ð²ÑÐµÐ¼ ÑÐ¸Ð¼Ð²Ð¾Ð»Ð°Ð¼ Ð¸ tf_set.
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð°Ð³Ñ€ÐµÐ³Ð°Ñ‚Ñ‹: (pairs, published_states, skipped, elapsed_ms).
    """
    t0 = time.monotonic()
    now_ms = int(time.time() * 1000)

    symbols = get_active_symbols()
    if not symbols:
        return (0, 0, 0, int((time.monotonic() - t0) * 1000))

    sem = asyncio.Semaphore(MAX_CONCURRENCY)

    total_pairs = 0
    total_published = 0
    total_skipped = 0

    async def run_one(sym: str, tf: str):
        nonlocal total_pairs, total_published, total_skipped
        async with sem:
            last = get_last_bar(sym, tf)
            open_ms = last if last is not None else floor_to_bar(now_ms, tf)
            prec = get_precision(sym) or 8
            try:
                pub, sk = await _process_pair(redis, sym, tf, open_ms, prec)
            except Exception as e:
                log.warning("pair error %s/%s: %s", sym, tf, e)
                pub, sk = 0, 4
            total_pairs += 1
            total_published += pub
            total_skipped += sk

    tasks = [
        asyncio.create_task(run_one(sym, tf))
        for sym in symbols
        for tf in tf_set
    ]
    if tasks:
        await asyncio.gather(*tasks, return_exceptions=False)

    elapsed_ms = int((time.monotonic() - t0) * 1000)
    return (total_pairs, total_published, total_skipped, elapsed_ms)


# ðŸ”¸ ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð²Ð¾Ñ€ÐºÐµÑ€: ÐºÐ°Ð¶Ð´Ñ‹Ðµ N ÑÐµÐºÑƒÐ½Ð´ Ð¿ÑƒÐ±Ð»Ð¸ÐºÑƒÐµÑ‚ MW-ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ Ð¿Ð¾ Ð²ÑÐµÐ¼ Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¼ Ñ‚Ð¸ÐºÐµÑ€Ð°Ð¼ Ð¸ TF
async def run_lab_mw_live(
    pg,
    redis,
    get_active_symbols,      # callable() -> list[str]
    get_precision,           # callable(symbol) -> int|None
    get_last_bar,            # callable(symbol, tf) -> int|None
    tf_set: Tuple[str, ...] = TF_SET,
    tick_interval_sec: int = TICK_INTERVAL_SEC,
):
    while True:
        pairs, published, skipped, elapsed_ms = await tick_mw(
            pg=pg,
            redis=redis,
            get_active_symbols=get_active_symbols,
            get_precision=get_precision,
            get_last_bar=get_last_bar,
            tf_set=tf_set,
        )

        log.info(
            "LAB MW: tick done tf=%s pairs=%d states=%d skipped=%d elapsed_ms=%d",
            ",".join(tf_set), pairs, published, skipped, elapsed_ms
        )

        await asyncio.sleep(tick_interval_sec)