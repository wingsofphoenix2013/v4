# laboratory_decision_filler.py ‚Äî –ø–æ—Å—Ç-allow –Ω–∞–ø–æ–ª–Ω–∏—Ç–µ–ª—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (LPS): —Å–∏–¥–∏–Ω–≥ –∏–∑ SLE –∏ –¥–æ–ø–∏—Å—å –ø–æ –∑–∞–∫—Ä—ã—Ç–∏—é –ø–æ–∑–∏—Ü–∏–π

import asyncio
import json
import logging
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

# üî∏ –ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞
import laboratory_infra as infra

# üî∏ –õ–æ–≥–≥–µ—Ä
log = logging.getLogger("LAB_FILLER")

# üî∏ –°—Ç—Ä–∏–º—ã
DECISION_FILLER_STREAM = "laboratory_decision_filler"   # —Å–∏–¥–∏–Ω–≥ –ø–æ—Å–ª–µ allow=true
SIGNAL_LOG_QUEUE_STREAM = "signal_log_queue"            # –≤–Ω–µ—à–Ω—è—è —à–∏–Ω–∞: —Å–æ–±—ã—Ç–∏–µ –∑–∞–∫—Ä—ã—Ç–∏—è –ø–æ–∑–∏—Ü–∏–∏

# üî∏ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —á—Ç–µ–Ω–∏—è —Å—Ç—Ä–∏–º–æ–≤
XREAD_BLOCK_MS = 2000
XREAD_COUNT = 50


# üî∏ –£—Ç–∏–ª–∏—Ç—ã

def _now_ms() -> int:
    return int(asyncio.get_running_loop().time() * 1000)


def _as_int(x: Any, default: Optional[int] = None) -> Optional[int]:
    try:
        return int(x)
    except Exception:
        return default


def _lower_str(x: Any) -> str:
    return str(x).strip().lower()


def _extract_stream_payload(fields: Dict[str, str]) -> Dict[str, Any]:
    """
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–≤–∞ —Ñ–æ—Ä–º–∞—Ç–∞:
      - –ø–ª–æ—Å–∫–∏–µ –ø–æ–ª—è
      - {'data': '<json>'} –∏–ª–∏ {'data':'{...}'}
    """
    payload: Dict[str, Any] = {}
    # –±–∞–∑–æ–≤–∞—è —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∞
    for k, v in fields.items():
        if isinstance(v, str) and v.startswith("{"):
            try:
                payload[k] = json.loads(v)
            except Exception:
                payload[k] = v
        else:
            payload[k] = v

    # –µ—Å–ª–∏ –≤—Å—ë –ª–µ–∂–∏—Ç –ø–æ–¥ 'data' ‚Äî —Ä–∞–∑–≤–æ—Ä–∞—á–∏–≤–∞–µ–º
    if "data" in payload and isinstance(payload["data"], dict):
        payload = payload["data"]

    return payload


def _pack_family_from_base(pack_base: str) -> str:
    s = _lower_str(pack_base)
    if s.startswith("ema"):
        return "ema"
    if s.startswith("macd"):
        return "macd"
    if s.startswith("lr"):
        return "lr"
    if s.startswith("adx_dmi"):
        return "adx_dmi"
    if s.startswith("bb"):
        return "bb"
    if s.startswith("atr"):
        return "atr"
    if s.startswith("rsi"):
        return "rsi"
    if s.startswith("mfi"):
        return "mfi"
    return s.split("_", 1)[0] if "_" in s else s


def _match_pack_rule(rule: Dict[str, Any], pack_objs: Dict[str, Any]) -> bool:
    """
    –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ PACK-–ø—Ä–∞–≤–∏–ª–∞ —Å –æ–±—ä–µ–∫—Ç–æ–º:
      - rule['agg_key'] = "key1|key2"
      - rule['agg_value'] = "key1:val1|key2:val2" –∏–ª–∏ "some_scalar" (solo —Å –∫–ª—é—á–æ–º)
      - —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—ã–ø–æ–ª–Ω—è–µ–º –∫–∞–∫ –ø–æ–ª–Ω–æ–µ —Ä–∞–≤–µ–Ω—Å—Ç–≤–æ —Ñ–∞–∫—Ç-—Å—Ç—Ä–æ–∫–∏ –∏ agg_value (–æ–±–∞ –≤ lower)
    """
    base = _lower_str(rule.get("pack_base", ""))
    if not base:
        return False
    po = pack_objs.get(base) or {}
    pack = po.get("pack") or {}
    agg_key = _lower_str(rule.get("agg_key", ""))
    agg_val = _lower_str(rule.get("agg_value", ""))
    if not agg_key or not agg_val:
        return False

    keys = [k.strip() for k in agg_key.split("|") if k.strip()]
    parts: List[str] = []
    for k in keys:
        v = pack.get(k)
        if v is None:
            return False
        parts.append(f"{k}:{_lower_str(v)}")
    fact = "|".join(parts)
    return fact == agg_val


def _compute_pack_family_counts_for_matches(tf_pack: Dict[str, Any]) -> Dict[str, Dict[str, int]]:
    """
    –°—á–∏—Ç–∞–µ—Ç pack_family_counts –ø–æ –°–û–í–ü–ê–í–®–ò–ú –ø—Ä–∞–≤–∏–ª–∞–º (–æ—Ç–¥–µ–ª—å–Ω–æ WL/BL):
      {"ema":{"wl":5,"bl":1}, "lr":{"wl":3,"bl":0}, ...}
    """
    rules: List[Dict[str, Any]] = (tf_pack or {}).get("rules") or []
    objs: Dict[str, Any] = (tf_pack or {}).get("objects") or {}
    out: Dict[str, Dict[str, int]] = {}
    if not rules or not objs:
        return out

    for r in rules:
        list_tag = _lower_str(r.get("list", ""))
        if list_tag not in ("whitelist", "blacklist"):
            continue
        matched = _match_pack_rule(r, objs)
        if not matched:
            continue
        fam = _pack_family_from_base(str(r.get("pack_base", "")))
        out.setdefault(fam, {"wl": 0, "bl": 0})
        if list_tag == "whitelist":
            out[fam]["wl"] += 1
        else:
            out[fam]["bl"] += 1

    return out


def _parse_tf_origin_map(s: Optional[str]) -> Dict[str, str]:
    """
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –≤–∏–¥–∞ "m5:mw,m15:pack" ‚Üí {"m5":"mw","m15":"pack"}
    """
    out: Dict[str, str] = {}
    if not s:
        return out
    for part in str(s).split(","):
        part = part.strip()
        if not part or ":" not in part:
            continue
        tf, origin = part.split(":", 1)
        tf = _lower_str(tf)
        origin = _lower_str(origin)
        if tf in ("m5", "m15", "h1") and origin in ("mw", "pack"):
            out[tf] = origin
    return out


# üî∏ –°–∏–¥–∏–Ω–≥ LPS –∏–∑ SLE –ø–æ –æ–¥–Ω–æ–º—É allow-—Å–æ–±—ã—Ç–∏—é
async def _seed_lps_from_sle(
    req_id: str,
    log_uid: str,
    master_sid: int,
    client_sid_opt: Optional[int],
    decision_mode_opt: Optional[str],
    decision_tf_origins_opt: Optional[str],
) -> int:
    """
    –ë–µ—Ä—ë—Ç —Å—Ç—Ä–æ–∫–∏ –∏–∑ signal_laboratory_entries –ø–æ (log_uid, strategy_id, [client_strategy_id]) –∏ –∑–∞–≤–æ–¥–∏—Ç/–æ–±–Ω–æ–≤–ª—è–µ—Ç
    –ø–æ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ –Ω–∞ –∫–∞–∂–¥—ã–π TF –≤ laboratoty_position_stat.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö TF-—Å—Ç—Ä–æ–∫.
    """
    tf_origin_map = _parse_tf_origin_map(decision_tf_origins_opt)

    async with infra.pg_pool.acquire() as conn:
        # —á–∏—Ç–∞–µ–º –≤—Å–µ TF-—Å—Ç—Ä–æ–∫–∏ –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –∑–∞–ø—Ä–æ—Å—É
        if client_sid_opt is not None:
            rows = await conn.fetch(
                """
                SELECT
                    strategy_id, client_strategy_id, symbol, direction,
                    timeframes_processed, tf_results,
                    mw_wl_match_count, pack_wl_match_count, pack_bl_match_count
                FROM signal_laboratory_entries
                WHERE log_uid = $1
                  AND strategy_id = $2
                  AND client_strategy_id = $3
                """,
                log_uid, master_sid, client_sid_opt
            )
        else:
            rows = await conn.fetch(
                """
                SELECT
                    strategy_id, client_strategy_id, symbol, direction,
                    timeframes_processed, tf_results,
                    mw_wl_match_count, pack_wl_match_count, pack_bl_match_count
                FROM signal_laboratory_entries
                WHERE log_uid = $1
                  AND strategy_id = $2
                  AND client_strategy_id IS NULL
                """,
                log_uid, master_sid
            )

        if not rows:
            log.info("[SEED] ‚ö†Ô∏è SLE –Ω–µ –Ω–∞–π–¥–µ–Ω (log_uid=%s sid=%s csid=%s)", log_uid, master_sid, client_sid_opt or "-")
            return 0

        processed = 0
        for r in rows:
            tf = _lower_str(r["timeframes_processed"] or "")
            if tf not in ("m5", "m15", "h1"):
                continue

            symbol = str(r["symbol"]).upper()
            direction = _lower_str(r["direction"])
            mw_cnt = int(r["mw_wl_match_count"] or 0)
            pack_wl_cnt = int(r["pack_wl_match_count"] or 0)
            pack_bl_cnt = int(r["pack_bl_match_count"] or 0)

            # tf_results ‚Äî –æ–¥–Ω–∞ TF-—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ (–º—ã –ø–∏—Å–∞–ª–∏ –ø–æ —Å—Ç—Ä–æ–∫–µ –Ω–∞ TF)
            try:
                tf_obj = json.loads(r["tf_results"]) if r["tf_results"] else {}
            except Exception:
                tf_obj = {}

            mw_states = (tf_obj.get("mw") or {}).get("states")
            pack_family_counts = _compute_pack_family_counts_for_matches(tf_obj.get("pack") or {})

            # decision_origin –ø–æ TF
            tf_origin = tf_origin_map.get(tf)
            if not tf_origin:
                # —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –µ—Å–ª–∏ MW –¥–∞–ª —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ ‚Äî "mw", –∏–Ω–∞—á–µ (allow=true –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–ª —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ) ‚Üí "pack"
                tf_origin = "mw" if mw_cnt >= 1 else ("pack" if pack_wl_cnt >= 1 else None)

            # upsert –≤ LPS –ø–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–º—É –∫–ª—é—á—É uq_lps_unique
            try:
                await conn.execute(
                    """
                    INSERT INTO laboratoty_position_stat (
                        log_uid, strategy_id, client_strategy_id,
                        symbol, direction, tf,
                        mw_states,
                        mw_match_count, pack_wl_match_count, pack_bl_match_count,
                        pack_family_counts,
                        decision_mode, decision_origin,
                        created_at, updated_at
                    ) VALUES (
                        $1, $2, $3,
                        $4, $5, $6,
                        COALESCE($7::jsonb, NULL),
                        $8, $9, $10,
                        COALESCE($11::jsonb, NULL),
                        $12, $13,
                        NOW(), NOW()
                    )
                    ON CONFLICT ON CONSTRAINT uq_lps_unique DO UPDATE SET
                        mw_states = COALESCE(EXCLUDED.mw_states, laboratoty_position_stat.mw_states),
                        mw_match_count = EXCLUDED.mw_match_count,
                        pack_wl_match_count = EXCLUDED.pack_wl_match_count,
                        pack_bl_match_count = EXCLUDED.pack_bl_match_count,
                        pack_family_counts = COALESCE(EXCLUDED.pack_family_counts, laboratoty_position_stat.pack_family_counts),
                        decision_mode = COALESCE(EXCLUDED.decision_mode, laboratoty_position_stat.decision_mode),
                        decision_origin = COALESCE(EXCLUDED.decision_origin, laboratoty_position_stat.decision_origin),
                        updated_at = NOW()
                    """,
                    log_uid, int(r["strategy_id"]), _as_int(r["client_strategy_id"]),
                    symbol, direction, tf,
                    json.dumps(mw_states, ensure_ascii=False) if isinstance(mw_states, dict) else None,
                    mw_cnt, pack_wl_cnt, pack_bl_cnt,
                    json.dumps(pack_family_counts, ensure_ascii=False) if pack_family_counts else None,
                    (decision_mode_opt or None),
                    (tf_origin or None),
                )
                processed += 1
            except Exception:
                log.exception("[SEED] ‚ùå –æ—à–∏–±–∫–∞ upsert LPS (log_uid=%s tf=%s)", log_uid, tf)

        log.info(
            "[SEED] ‚úÖ LPS upsert –∑–∞–≤–µ—Ä—à—ë–Ω: log_uid=%s sid=%s csid=%s rows=%d",
            log_uid, master_sid, client_sid_opt or "-", processed
        )
        return processed


# üî∏ –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–±—ã—Ç–∏—è allow=true –∏–∑ decision_maker
async def _handle_seed_message(msg_id: str, fields: Dict[str, str]):
    payload = _extract_stream_payload(fields)

    log_uid = payload.get("log_uid")
    req_id = payload.get("req_id")
    master_sid = _as_int(payload.get("strategy_id"))
    client_sid = _as_int(payload.get("client_strategy_id"))
    decision_mode = _lower_str(payload.get("decision_mode", "")) or None
    tf_origins = payload.get("decision_tf_origins")  # "m5:mw,m15:pack" (–µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω–æ)

    if not log_uid or not master_sid or not req_id:
        log.info("[SEED] ‚ö†Ô∏è –ø—Ä–æ–ø—É—Å–∫ msg=%s: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–æ–ª–µ–π payload=%s", msg_id, payload)
        return

    try:
        await _seed_lps_from_sle(
            req_id=req_id,
            log_uid=str(log_uid),
            master_sid=int(master_sid),
            client_sid_opt=client_sid,
            decision_mode_opt=decision_mode,
            decision_tf_origins_opt=tf_origins,
        )
    except Exception:
        log.exception("[SEED] ‚ùå –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ seed-—Å–æ–æ–±—â–µ–Ω–∏—è (log_uid=%s)", log_uid)


# üî∏ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ LPS –ø–æ —Å–æ–±—ã—Ç–∏—é –∑–∞–∫—Ä—ã—Ç–∏—è –ø–æ–∑–∏—Ü–∏–∏
async def _handle_close_message(msg_id: str, fields: Dict[str, str]):
    payload = _extract_stream_payload(fields)

    if _lower_str(payload.get("status", "")) != "closed":
        return

    log_uid = payload.get("log_uid")
    position_uid = payload.get("position_uid")
    client_sid = _as_int(payload.get("strategy_id"))  # –≤ —ç—Ç–æ–º —Å—Ç—Ä–∏–º–µ ‚Äî SID –∑–µ—Ä–∫–∞–ª–∞!

    if not log_uid or not position_uid or client_sid is None:
        log.info("[CLOSE] ‚ö†Ô∏è –ø—Ä–æ–ø—É—Å–∫ msg=%s: –Ω–µ—Ç log_uid/position_uid/strategy_id payload=%s", msg_id, payload)
        return

    # —á–∏—Ç–∞–µ–º –ø–æ–∑–∏—Ü–∏—é (—É–∂–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –≤–Ω–µ—à–Ω–∏–º –º–æ–¥—É–ª–µ–º)
    async with infra.pg_pool.acquire() as conn:
        pos = await conn.fetchrow(
            """
            SELECT position_uid, pnl, closed_at
            FROM positions_v4
            WHERE position_uid = $1
            """,
            position_uid
        )
        if not pos:
            log.info("[CLOSE] ‚ö†Ô∏è –ø–æ–∑–∏—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ position_uid=%s", position_uid)
            return

        pnl = pos["pnl"]
        closed_at = pos["closed_at"]
        # result: —Å—Ç—Ä–æ–≥–æ > 0
        result_flag = bool(pnl is not None and float(pnl) > 0.0)

        # –∞–ø–¥–µ–π—Ç –≤—Å–µ—Ö TF-—Å—Ç—Ä–æ–∫ LPS –ø–æ (log_uid, client_sid)
        try:
            status = await conn.execute(
                """
                UPDATE laboratoty_position_stat
                   SET position_uid = $1,
                       pnl = $2,
                       result = $3,
                       closed_at = $4,
                       updated_at = NOW()
                 WHERE log_uid = $5
                   AND client_strategy_id = $6
                """,
                position_uid, pnl, result_flag, closed_at, log_uid, client_sid
            )
            # status –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ "UPDATE <n>"
            updated = int(status.split()[-1]) if status.startswith("UPDATE") else 0
            log.info(
                "[CLOSE] ‚úÖ LPS –æ–±–Ω–æ–≤–ª—ë–Ω: log_uid=%s csid=%s pos=%s pnl=%s result=%s rows=%d",
                log_uid, client_sid, position_uid, str(pnl), str(result_flag).lower(), updated
            )
        except Exception:
            log.exception("[CLOSE] ‚ùå –æ—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è LPS (log_uid=%s csid=%s)", log_uid, client_sid)


# üî∏ –ì–ª–∞–≤–Ω—ã–π —Å–ª—É—à–∞—Ç–µ–ª—å: —Å–∏–¥–∏–Ω–≥ –ø–æ—Å–ª–µ allow=true
async def run_laboratory_decision_filler():
    """
    –°–ª—É—à–∞–µ—Ç laboratory_decision_filler –∏ –Ω–∞ –∫–∞–∂–¥–æ–µ allow=true —Å–æ–±—ã—Ç–∏–µ —Å–æ–∑–¥–∞—ë—Ç/–æ–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç—Ä–æ–∫–∏ –≤ laboratoty_position_stat
    –ø–æ –≤—Å–µ–º TF –¥–∞–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ (–ø–æ –¥–∞–Ω–Ω—ã–º –∏–∑ signal_laboratory_entries).
    """
    log.debug("üõ∞Ô∏è LAB_DECISION_FILLER —Å–ª—É—à–∞—Ç–µ–ª—å –∑–∞–ø—É—â–µ–Ω (BLOCK=%d COUNT=%d)", XREAD_BLOCK_MS, XREAD_COUNT)

    last_id = "$"
    redis = infra.redis_client

    while True:
        try:
            resp = await redis.xread(
                streams={DECISION_FILLER_STREAM: last_id},
                count=XREAD_COUNT,
                block=XREAD_BLOCK_MS
            )
            if not resp:
                continue

            for _, messages in resp:
                for msg_id, fields in messages:
                    last_id = msg_id
                    try:
                        await _handle_seed_message(msg_id, fields)
                    except Exception:
                        log.exception("‚ùå –û—à–∏–±–∫–∞ seed-—Å–æ–æ–±—â–µ–Ω–∏—è msg_id=%s", msg_id)

        except asyncio.CancelledError:
            log.debug("‚èπÔ∏è LAB_DECISION_FILLER –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ —Å–∏–≥–Ω–∞–ª—É")
            raise
        except Exception:
            log.exception("‚ùå LAB_DECISION_FILLER –æ—à–∏–±–∫–∞ —Ü–∏–∫–ª–∞")
            await asyncio.sleep(1.0)


# üî∏ –°–ª—É—à–∞—Ç–µ–ª—å –∑–∞–∫—Ä—ã—Ç–∏—è –ø–æ–∑–∏—Ü–∏–π: –¥–æ–ø–æ–ª–Ω—è–µ—Ç LPS pnl/result/closed_at/position_uid
async def run_position_close_updater():
    """
    –°–ª—É—à–∞–µ—Ç signal_log_queue. –ù–∞ —Å–æ–±—ã—Ç–∏—è—Ö —Å–æ status='closed' –ø–æ–¥—Ç—è–≥–∏–≤–∞–µ—Ç –∏–∑ positions_v4 PnL/closed_at
    –∏ –¥–æ–ø–∏—Å—ã–≤–∞–µ—Ç –∏—Ö –≤ laboratoty_position_stat (–ø–æ log_uid + client_strategy_id).
    """
    log.debug("üõ∞Ô∏è LAB_POS_CLOSE_FILLER —Å–ª—É—à–∞—Ç–µ–ª—å –∑–∞–ø—É—â–µ–Ω (BLOCK=%d COUNT=%d)", XREAD_BLOCK_MS, XREAD_COUNT)

    last_id = "$"
    redis = infra.redis_client

    while True:
        try:
            resp = await redis.xread(
                streams={SIGNAL_LOG_QUEUE_STREAM: last_id},
                count=XREAD_COUNT,
                block=XREAD_BLOCK_MS
            )
            if not resp:
                continue

            for _, messages in resp:
                for msg_id, fields in messages:
                    last_id = msg_id
                    try:
                        await _handle_close_message(msg_id, fields)
                    except Exception:
                        log.exception("‚ùå –û—à–∏–±–∫–∞ close-—Å–æ–æ–±—â–µ–Ω–∏—è msg_id=%s", msg_id)

        except asyncio.CancelledError:
            log.debug("‚èπÔ∏è LAB_POS_CLOSE_FILLER –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ —Å–∏–≥–Ω–∞–ª—É")
            raise
        except Exception:
            log.exception("‚ùå LAB_POS_CLOSE_FILLER –æ—à–∏–±–∫–∞ —Ü–∏–∫–ª–∞")
            await asyncio.sleep(1.0)