# laboratory_decision_filler.py ‚Äî post-allow ¬´–ø–∏—Å–∞—Ç–µ–ª—å¬ª —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏:

import asyncio
import json
import logging
import time
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

# üî∏ –ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞
import laboratory_infra as infra

# üî∏ –õ–æ–≥–≥–µ—Ä
log = logging.getLogger("LAB_DECISION_FILLER")

# üî∏ –ü–æ—Ç–æ–∫–∏ –∏ —à–ª—é–∑
DECISION_FILLER_STREAM   = "laboratory_decision_filler"  # –∏—Å—Ç–æ—á–Ω–∏–∫ seed-—Å–æ–±—ã—Ç–∏–π –æ—Ç decision_maker
POSITION_CLOSE_STREAM    = "signal_log_queue"            # –ø–æ—Ç–æ–∫ —Å–æ–±—ã—Ç–∏–π –ø–æ –ø–æ–∑–∏—Ü–∏—è–º (–æ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏–π)
GATEWAY_REQ_STREAM       = "indicator_gateway_request"   # indicator_gateway –≤—Ö–æ–¥—è—â–∏–π —Å—Ç—Ä–∏–º

# üî∏ Consumer Group –¥–ª—è –∑–∞–∫—Ä—ã—Ç–∏–π (—á—Ç–æ–±—ã –Ω–µ –º–µ—à–∞—Ç—å –¥—Ä—É–≥–∏–º)
POS_CLOSE_GROUP          = "lab_pos_closed"
POS_CLOSE_CONSUMER       = "filler-consumer-1"

# üî∏ –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
XREAD_BLOCK_MS = 2000
XREAD_COUNT    = 50
MAX_IN_FLIGHT  = 16
MAX_CONCURRENT_GATEWAY_CALLS = 32
COALESCE_TTL_SEC = 3

# üî∏ –ü–æ—Ä—è–¥–æ–∫ TF
TF_ORDER = ("m5", "m15", "h1")

# üî∏ –ü—É–±–ª–∏—á–Ω—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã PACK-–∫—ç—à–∞
PACK_PUBLIC_PREFIX = {
    "bb": "bbpos_pack",
    "lr": "lrpos_pack",
    "atr": "atr_pack",
    "adx_dmi": "adx_dmi_pack",
    "macd": "macd_pack",
    # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: f"{indicator}_pack"
}

# üî∏ –°–µ–º–∞—Ñ–æ—Ä—ã –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏–∏
_filler_sem  = asyncio.Semaphore(MAX_IN_FLIGHT)
_gateway_sem = asyncio.Semaphore(MAX_CONCURRENT_GATEWAY_CALLS)

# üî∏ –ö–æ–∞–ª–µ—Å—Ü–µ–Ω—Å (in-process): key -> (expire_ms, future)
_coalesce: Dict[str, Tuple[float, asyncio.Future]] = {}


# üî∏ –£—Ç–∏–ª–∏—Ç—ã –≤—Ä–µ–º–µ–Ω–∏/–ø–∞—Ä—Å–∏–Ω–≥–∞
def _now_monotonic_ms() -> int:
    return int(time.monotonic() * 1000)


def _parse_timeframes(tf_str: str) -> List[str]:
    items = [x.strip().lower() for x in (tf_str or "").split(",") if x.strip()]
    seen, ordered = set(), []
    for tf in TF_ORDER:
        if tf in items and tf not in seen:
            seen.add(tf)
            ordered.append(tf)
    return ordered


def _parse_pack_base(base: str) -> Tuple[str, Dict[str, Any]]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (indicator, params) –ø–æ pack_base (rsi14, ema21, bb20_2_0, macd12, adx_dmi14, lr50, atr14)."""
    s = base.strip().lower()
    if s.startswith("bb"):
        rest = s[2:]
        parts = rest.split("_", 2)
        L = int(parts[0])
        std = float(parts[1].replace("_", ".", 1)) if len(parts) > 1 else 2.0
        return "bb", {"length": L, "std": std}
    if s.startswith("macd"):
        return "macd", {"fast": int(s[4:])}
    if s.startswith("adx_dmi"):
        return "adx_dmi", {"length": int(s[7:])}
    if s.startswith("ema"):
        return "ema", {"length": int(s[3:])}
    if s.startswith("rsi"):
        return "rsi", {"length": int(s[3:])}
    if s.startswith("mfi"):
        return "mfi", {"length": int(s[3:])}
    if s.startswith("lr"):
        return "lr", {"length": int(s[2:])}
    if s.startswith("atr"):
        return "atr", {"length": int(s[3:])}
    return s, {}


def _public_pack_key(indicator: str, symbol: str, tf: str, base: str) -> str:
    pref = PACK_PUBLIC_PREFIX.get(indicator, f"{indicator}_pack")
    return f"{pref}:{symbol}:{tf}:{base}"


def _public_mw_key(kind: str, symbol: str, tf: str) -> str:
    return f"{kind}_pack:{symbol}:{tf}:{kind}"


def _json_or_none(s: Optional[str]) -> Optional[dict]:
    if not s:
        return None
    try:
        return json.loads(s)
    except Exception:
        return None


async def _mget_json(keys: List[str]) -> Dict[str, Optional[dict]]:
    if not keys:
        return {}
    values = await infra.redis_client.mget(*keys)
    return {k: _json_or_none(v) for k, v in zip(keys, values)}


# üî∏ –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ –ø–æ–ª—É—á–∏—Ç—å pack-–æ–±—ä–µ–∫—Ç (cache-first + gateway)
async def _ensure_pack_available(
    symbol: str,
    tf: str,
    indicator: str,
    base: str,
    gw_params: Dict[str, Any],
    precision: int,
    deadline_ms: int,
) -> Optional[dict]:
    key = _public_pack_key(indicator, symbol, tf, base)
    cached = await infra.redis_client.get(key)
    if cached:
        obj = _json_or_none(cached)
        if obj:
            return obj

    co_key = f"COAL::pack::{key}"
    now = _now_monotonic_ms()
    rec = _coalesce.get(co_key)
    if rec and now < rec[0]:
        fut = rec[1]
        try:
            return await asyncio.wait_for(fut, timeout=max(0.2, (deadline_ms - _now_monotonic_ms()) / 1000))
        except Exception:
            return None

    loop = asyncio.get_running_loop()
    fut = loop.create_future()
    _coalesce[co_key] = (now + COALESCE_TTL_SEC * 1000, fut)

    async with _gateway_sem:
        try:
            req = {"symbol": symbol, "timeframe": tf, "indicator": indicator, "mode": "pack"}
            if indicator in ("ema", "rsi", "mfi", "lr", "atr", "adx_dmi"):
                L = int(gw_params.get("length", 0))
                if L:
                    req["length"] = str(L)
            elif indicator == "macd":
                F = int(gw_params.get("fast", 0))
                if F:
                    req["length"] = str(F)
            elif indicator == "bb":
                L = int(gw_params.get("length", 0))
                S = float(gw_params.get("std", 2.0))
                req["length"] = str(L)
                req["std"] = f"{S:.2f}"

            await infra.redis_client.xadd(GATEWAY_REQ_STREAM, req)
            poll_sleep = 0.1
            while _now_monotonic_ms() < deadline_ms:
                cached = await infra.redis_client.get(key)
                if cached:
                    obj = _json_or_none(cached)
                    if obj:
                        if not fut.done():
                            fut.set_result(obj)
                        return obj
                await asyncio.sleep(poll_sleep)
                if poll_sleep < 0.25:
                    poll_sleep = 0.25

            if not fut.done():
                fut.set_result(None)
            return None

        except Exception:
            log.exception("[FILLER] ‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ gateway ind=%s base=%s", indicator, base)
            if not fut.done():
                fut.set_result(None)
            return None
        finally:
            now2 = _now_monotonic_ms()
            for ck, (exp, f) in list(_coalesce.items()):
                if now2 > exp or (f.done() and _json_or_none(f.result()) is None):
                    _coalesce.pop(ck, None)


# üî∏ MW: —Å–Ω—è—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏—è + –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –í–°–ï —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
async def _collect_mw(
    sid: int,
    symbol: str,
    tf: str,
    direction: str,
    precision: int,
    deadline_ms: int,
) -> Tuple[Dict[str, Optional[str]], List[Dict[str, Any]]]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (mw_states, mw_matches[])."""
    mw_rows_all = (infra.mw_wl_by_strategy.get(sid) or {}).get("rows", [])
    mw_rows = [r for r in mw_rows_all if (r.get("timeframe") == tf and r.get("direction") == direction)]

    # –∫–∞–∫–∏–µ –±–∞–∑—ã –Ω—É–∂–Ω—ã
    needed_bases: List[str] = []
    for r in mw_rows:
        base = (r.get("agg_base") or "").strip().lower()
        if not base:
            continue
        for b in base.split("_"):
            if b in ("trend", "volatility", "extremes", "momentum") and b not in needed_bases:
                needed_bases.append(b)

    # states: cache-first ‚Üí gateway
    states: Dict[str, Optional[str]] = {}
    keys = [_public_mw_key(b, symbol, tf) for b in needed_bases]
    kv = await _mget_json(keys)
    for base in needed_bases:
        st = None
        obj = kv.get(_public_mw_key(base, symbol, tf))
        if obj and isinstance(obj, dict):
            st = (obj.get("pack") or {}).get("state")
        if not st:
            obj = await _ensure_pack_available(symbol, tf, base, base, {}, precision, deadline_ms)
            if obj:
                st = (obj.get("pack") or {}).get("state")
        states[base] = st

    # –ø–æ—Å—Ç—Ä–æ–∏–º –í–°–ï —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
    matches: List[Dict[str, Any]] = []
    for r in mw_rows:
        agg_base = (r.get("agg_base") or "").strip().lower()
        agg_state = (r.get("agg_state") or "").strip().lower()
        if not agg_base or not agg_state:
            continue
        bases = agg_base.split("_")

        # –ø–æ—Å—Ç—Ä–æ–∏—Ç—å —Ñ–∞–∫—Ç
        if len(bases) == 1:
            base = bases[0]
            cur = states.get(base)
            if not cur:
                continue
            fact = cur.strip().lower()
        else:
            parts, ok = [], True
            for b in bases:
                cur = states.get(b)
                if not cur:
                    ok = False
                    break
                parts.append(f"{b}:{cur.strip().lower()}")
            if not ok:
                continue
            fact = "|".join(parts)

        if fact == agg_state:
            matches.append({
                "id": int(r.get("id")) if r.get("id") is not None else None,
                "agg_base": agg_base,
                "agg_state": agg_state,
                "confirmation": int(r.get("confirmation")) if r.get("confirmation") is not None else None,
                "winrate": float(r.get("winrate")) if r.get("winrate") is not None else None,
                "confidence": float(r.get("confidence")) if r.get("confidence") is not None else None,
            })

    return states, matches


# üî∏ PACK: —Å–æ–±—Ä–∞—Ç—å –í–°–ï WL/BL —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –∏ —Å—á—ë—Ç—á–∏–∫–∏ –ø–æ —Å–µ–º–µ–π—Å—Ç–≤–∞–º
async def _collect_pack(
    sid: int,
    symbol: str,
    tf: str,
    direction: str,
    precision: int,
    deadline_ms: int,
) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]], Dict[str, int]]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (wl_matches[], bl_matches[], wl_family_counts)."""
    pack_rows_all = (infra.pack_wl_by_strategy.get(sid) or {}).get("rows", [])
    rows_tf = [r for r in pack_rows_all if (r.get("timeframe") == tf and r.get("direction") == direction)]

    # –°–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö pack_base
    bases: List[str] = []
    for r in rows_tf:
        base = (r.get("pack_base") or "").strip().lower()
        if base and base not in bases:
            bases.append(base)

    # –ü–æ–ª—É—á–∞–µ–º –æ–±—ä–µ–∫—Ç—ã PACK (cache-first ‚Üí gateway) –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    pack_objs: Dict[str, Optional[dict]] = {}
    keys, meta = [], []
    for base in bases:
        ind, params = _parse_pack_base(base)
        meta.append((base, ind, params))
        keys.append(_public_pack_key(ind, symbol, tf, base))

    got = await _mget_json(keys)
    tasks: List[asyncio.Task] = []
    wanted: List[Tuple[str, str, Dict[str, Any]]] = []
    for (base, ind, params) in meta:
        k = _public_pack_key(ind, symbol, tf, base)
        obj = got.get(k)
        if obj is not None:
            pack_objs[base] = obj
        else:
            wanted.append((base, ind, params))
            tasks.append(asyncio.create_task(_ensure_pack_available(
                symbol=symbol, tf=tf, indicator=ind, base=base,
                gw_params=params, precision=precision, deadline_ms=deadline_ms
            )))
    if tasks:
        fetched = await asyncio.gather(*tasks, return_exceptions=False)
        for (base, _ind, _params), obj in zip(wanted, fetched):
            pack_objs[base] = obj

    # –°—Ç—Ä–æ–∏–º –í–°–ï —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è WL/BL
    wl_matches: List[Dict[str, Any]] = []
    bl_matches: List[Dict[str, Any]] = []
    wl_family_counts: Dict[str, int] = {"ema":0,"lr":0,"rsi":0,"mfi":0,"bb":0,"atr":0,"adx_dmi":0,"macd":0}

    for r in rows_tf:
        base = (r.get("pack_base") or "").strip().lower()
        if not base:
            continue
        po = pack_objs.get(base)
        if not po:
            continue
        pack = (po.get("pack") or {})
        list_type = (r.get("list") or "").strip().lower()
        agg_key = (r.get("agg_key") or "").strip().lower()
        agg_val = (r.get("agg_value") or "").strip().lower()
        if not agg_key or not agg_val:
            continue

        # —Å—Ç—Ä–æ–∏–º —Ñ–∞–∫—Ç –≤ –ø–æ—Ä—è–¥–∫–µ –∫–ª—é—á–µ–π
        keys_k = [k.strip() for k in agg_key.split("|") if k.strip()]
        parts, ok = [], True
        for k in keys_k:
            v = pack.get(k)
            if v is None:
                ok = False
                break
            parts.append(f"{k}:{str(v).strip().lower()}")
        if not ok:
            continue
        fact = "|".join(parts)

        if fact == agg_val:
            ind, _ = _parse_pack_base(base)
            det = {
                "id": int(r.get("id")) if r.get("id") is not None else None,
                "pack_base": base,
                "agg_key": agg_key,
                "agg_value": agg_val,
                "winrate": float(r.get("winrate")) if r.get("winrate") is not None else None,
            }
            if list_type == "whitelist":
                wl_matches.append(det)
                if ind in wl_family_counts:
                    wl_family_counts[ind] += 1
            elif list_type == "blacklist":
                bl_matches.append(det)

    return wl_matches, bl_matches, wl_family_counts


# üî∏ –ó–∞–ø–∏—Å—å/–∞–ø—Å–µ—Ä—Ç–∞ –≤ laboratoty_position_stat (–¥–≤—É—Ö—Ñ–∞–∑–Ω—ã–π upsert)
async def _upsert_lps(
    log_uid: str,
    sid: int,
    client_sid: Optional[int],
    symbol: str,
    direction: str,
    tf: str,
    mw_states: Dict[str, Optional[str]],
    mw_matches: List[Dict[str, Any]],
    pack_wl_matches: List[Dict[str, Any]],
    pack_bl_matches: List[Dict[str, Any]],
    wl_family_counts: Dict[str, int],
    decision_mode: Optional[str] = None,
    decision_origin: Optional[str] = None,
):
    mw_match_count      = len(mw_matches)
    pack_wl_match_count = len(pack_wl_matches)
    pack_bl_match_count = len(pack_bl_matches)

    # json dumps
    states_json = json.dumps(mw_states, ensure_ascii=False) if mw_states else None
    mw_json     = json.dumps(mw_matches, ensure_ascii=False) if mw_matches else None
    wl_json     = json.dumps(pack_wl_matches, ensure_ascii=False) if pack_wl_matches else None
    bl_json     = json.dumps(pack_bl_matches, ensure_ascii=False) if pack_bl_matches else None
    fam_json    = json.dumps(wl_family_counts, ensure_ascii=False) if wl_family_counts else None

    async with infra.pg_pool.acquire() as conn:
        if client_sid is None:
            # UPDATE
            upd = await conn.execute(
                """
                UPDATE public.laboratoty_position_stat
                   SET mw_states = COALESCE($1::jsonb, mw_states),
                       mw_matches = COALESCE($2::jsonb, mw_matches),
                       pack_wl_matches = COALESCE($3::jsonb, pack_wl_matches),
                       pack_bl_matches = COALESCE($4::jsonb, pack_bl_matches),
                       mw_match_count = $5,
                       pack_wl_match_count = $6,
                       pack_bl_match_count = $7,
                       pack_family_counts = COALESCE($8::jsonb, pack_family_counts),
                       decision_mode = COALESCE($9, decision_mode),
                       decision_origin = COALESCE($10, decision_origin),
                       updated_at = NOW()
                 WHERE log_uid=$11 AND strategy_id=$12 AND client_strategy_id IS NULL AND tf=$13
                """,
                states_json, mw_json, wl_json, bl_json,
                mw_match_count, pack_wl_match_count, pack_bl_match_count,
                fam_json, decision_mode, decision_origin, log_uid, sid, tf
            )
            if upd.startswith("UPDATE 1"):
                log.debug("[FILLER] ‚úèÔ∏è LPS UPDATE log_uid=%s sid=%s tf=%s (master)", log_uid, sid, tf)
                return

            # INSERT DO NOTHING
            ins = await conn.execute(
                """
                INSERT INTO public.laboratoty_position_stat
                    (log_uid, strategy_id, client_strategy_id, symbol, direction, tf,
                     mw_states, mw_matches, pack_wl_matches, pack_bl_matches,
                     mw_match_count, pack_wl_match_count, pack_bl_match_count, pack_family_counts,
                     decision_mode, decision_origin,
                     created_at, updated_at)
                VALUES ($1,$2,NULL,$3,$4,$5,
                        COALESCE($6::jsonb, NULL), COALESCE($7::jsonb, NULL),
                        COALESCE($8::jsonb, NULL), COALESCE($9::jsonb, NULL),
                        $10,$11,$12,COALESCE($13::jsonb, NULL),
                        $14,$15,
                        NOW(), NOW())
                ON CONFLICT DO NOTHING
                """,
                log_uid, sid, symbol, direction, tf,
                states_json, mw_json, wl_json, bl_json,
                mw_match_count, pack_wl_match_count, pack_bl_match_count, fam_json,
                decision_mode, decision_origin
            )
            if ins.endswith(" 1"):
                log.debug("[FILLER] ‚úçÔ∏è  LPS INSERT log_uid=%s sid=%s tf=%s (master)", log_uid, sid, tf)
                return

            # race ‚Üí UPDATE
            await conn.execute(
                """
                UPDATE public.laboratoty_position_stat
                   SET mw_states = COALESCE($1::jsonb, mw_states),
                       mw_matches = COALESCE($2::jsonb, mw_matches),
                       pack_wl_matches = COALESCE($3::jsonb, pack_wl_matches),
                       pack_bl_matches = COALESCE($4::jsonb, pack_bl_matches),
                       mw_match_count = $5,
                       pack_wl_match_count = $6,
                       pack_bl_match_count = $7,
                       pack_family_counts = COALESCE($8::jsonb, pack_family_counts),
                       decision_mode = COALESCE($9, decision_mode),
                       decision_origin = COALESCE($10, decision_origin),
                       updated_at = NOW()
                 WHERE log_uid=$11 AND strategy_id=$12 AND client_strategy_id IS NULL AND tf=$13
                """,
                states_json, mw_json, wl_json, bl_json,
                mw_match_count, pack_wl_match_count, pack_bl_match_count,
                fam_json, decision_mode, decision_origin, log_uid, sid, tf
            )
            log.debug("[FILLER] ‚úèÔ∏è LPS UPDATE (race) log_uid=%s sid=%s tf=%s (master)", log_uid, sid, tf)

        else:
            # UPDATE
            upd = await conn.execute(
                """
                UPDATE public.laboratoty_position_stat
                   SET mw_states = COALESCE($1::jsonb, mw_states),
                       mw_matches = COALESCE($2::jsonb, mw_matches),
                       pack_wl_matches = COALESCE($3::jsonb, pack_wl_matches),
                       pack_bl_matches = COALESCE($4::jsonb, pack_bl_matches),
                       mw_match_count = $5,
                       pack_wl_match_count = $6,
                       pack_bl_match_count = $7,
                       pack_family_counts = COALESCE($8::jsonb, pack_family_counts),
                       decision_mode = COALESCE($9, decision_mode),
                       decision_origin = COALESCE($10, decision_origin),
                       updated_at = NOW()
                 WHERE log_uid=$11 AND strategy_id=$12 AND client_strategy_id=$13 AND tf=$14
                """,
                states_json, mw_json, wl_json, bl_json,
                mw_match_count, pack_wl_match_count, pack_bl_match_count,
                fam_json, decision_mode, decision_origin, log_uid, sid, int(client_sid), tf
            )
            if upd.startswith("UPDATE 1"):
                log.debug("[FILLER] ‚úèÔ∏è LPS UPDATE log_uid=%s sid=%s csid=%s tf=%s", log_uid, sid, client_sid, tf)
                return

            # INSERT DO NOTHING
            ins = await conn.execute(
                """
                INSERT INTO public.laboratoty_position_stat
                    (log_uid, strategy_id, client_strategy_id, symbol, direction, tf,
                     mw_states, mw_matches, pack_wl_matches, pack_bl_matches,
                     mw_match_count, pack_wl_match_count, pack_bl_match_count, pack_family_counts,
                     decision_mode, decision_origin,
                     created_at, updated_at)
                VALUES ($1,$2,$3,$4,$5,$6,
                        COALESCE($7::jsonb, NULL), COALESCE($8::jsonb, NULL),
                        COALESCE($9::jsonb, NULL), COALESCE($10::jsonb, NULL),
                        $11,$12,$13,COALESCE($14::jsonb, NULL),
                        $15,$16,
                        NOW(), NOW())
                ON CONFLICT DO NOTHING
                """,
                log_uid, sid, int(client_sid), symbol, direction, tf,
                states_json, mw_json, wl_json, bl_json,
                mw_match_count, pack_wl_match_count, pack_bl_match_count, fam_json,
                decision_mode, decision_origin
            )
            if ins.endswith(" 1"):
                log.debug("[FILLER] ‚úçÔ∏è  LPS INSERT log_uid=%s sid=%s csid=%s tf=%s", log_uid, sid, client_sid, tf)
                return

            # race ‚Üí UPDATE
            await conn.execute(
                """
                UPDATE public.laboratoty_position_stat
                   SET mw_states = COALESCE($1::jsonb, mw_states),
                       mw_matches = COALESCE($2::jsonb, mw_matches),
                       pack_wl_matches = COALESCE($3::jsonb, pack_wl_matches),
                       pack_bl_matches = COALESCE($4::jsonb, pack_bl_matches),
                       mw_match_count = $5,
                       pack_wl_match_count = $6,
                       pack_bl_match_count = $7,
                       pack_family_counts = COALESCE($8::jsonb, pack_family_counts),
                       decision_mode = COALESCE($9, decision_mode),
                       decision_origin = COALESCE($10, decision_origin),
                       updated_at = NOW()
                 WHERE log_uid=$11 AND strategy_id=$12 AND client_strategy_id=$13 AND tf=$14
                """,
                states_json, mw_json, wl_json, bl_json,
                mw_match_count, pack_wl_match_count, pack_bl_match_count,
                fam_json, decision_mode, decision_origin, log_uid, sid, int(client_sid), tf
            )
            log.debug("[FILLER] ‚úèÔ∏è LPS UPDATE (race) log_uid=%s sid=%s csid=%s tf=%s", log_uid, sid, client_sid, tf)
            
# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ seed-—Å–æ–æ–±—â–µ–Ω–∏—è (–ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –ø–æ TF)
async def _process_seed(msg_id: str, fields: Dict[str, str]):
    async with _filler_sem:
        t0 = _now_monotonic_ms()

        log_uid   = fields.get("log_uid") or ""
        sid_s     = fields.get("strategy_id") or ""
        client_s  = fields.get("client_strategy_id") or ""
        symbol    = (fields.get("symbol") or "").strip().upper()
        direction = (fields.get("direction") or "").strip().lower()
        tfs_raw   = fields.get("timeframes") or ""

        # üî∏ –ù–æ–≤—ã–µ –ø–æ–ª—è –¥–ª—è —Ñ–∏–∫—Å–∞—Ü–∏–∏ —Ä–µ–∂–∏–º–∞ –∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        decision_mode = (fields.get("decision_mode") or "").strip().lower() or None
        origins_raw   = (fields.get("decision_tf_origins") or "").strip()
        tf_origins: Dict[str, str] = {}
        if origins_raw:
            try:
                for part in origins_raw.split(","):
                    if ":" in part:
                        tf, origin = part.split(":", 1)
                        tf_origins[tf.strip()] = origin.strip()
            except Exception:
                log.debug("[FILLER] ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ decision_tf_origins: %s", origins_raw)

        if not log_uid or not sid_s.isdigit() or not symbol or direction not in ("long", "short") or not tfs_raw:
            log.debug("[FILLER] ‚ùå bad seed msg=%s fields=%s", msg_id, fields)
            return

        sid = int(sid_s)
        client_sid = int(client_s) if client_s.isdigit() else None
        tfs = _parse_timeframes(tfs_raw)
        if not tfs:
            log.debug("[FILLER] ‚ùå empty TF seed log_uid=%s", log_uid)
            return

        precision = int(infra.enabled_tickers.get(symbol, {}).get("precision_price", 7))
        deadline_ms = _now_monotonic_ms() + 60_000  # –≤–µ—Ä—Ö–Ω–∏–π –ø–æ—Ç–æ–ª–æ–∫ –Ω–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏–µ –æ–¥–Ω–æ–π –∑–∞—è–≤–∫–∏

        for tf in tfs:
            try:
                # MW
                mw_states, mw_matches = await _collect_mw(sid, symbol, tf, direction, precision, deadline_ms)

                # PACK
                pack_wl_matches, pack_bl_matches, wl_family_counts = await _collect_pack(
                    sid, symbol, tf, direction, precision, deadline_ms
                )

                # –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ –ø—Ä–æ—Ö–æ–¥–∞ TF (mw –∏–ª–∏ pack)
                decision_origin = tf_origins.get(tf)

                # –ó–∞–ø–∏—Å—å –≤ —Ç–∞–±–ª–∏—Ü—É —Å –Ω–æ–≤—ã–º–∏ –ø–æ–ª—è–º–∏
                await _upsert_lps(
                    log_uid=log_uid,
                    sid=sid,
                    client_sid=client_sid,
                    symbol=symbol,
                    direction=direction,
                    tf=tf,
                    mw_states=mw_states,
                    mw_matches=mw_matches,
                    pack_wl_matches=pack_wl_matches,
                    pack_bl_matches=pack_bl_matches,
                    wl_family_counts=wl_family_counts,
                    decision_mode=decision_mode,
                    decision_origin=decision_origin,
                )
                log.debug(
                    "[FILLER] ‚úÖ TF –∑–∞–ø–∏—Å–∞–Ω log_uid=%s sid=%s csid=%s %s %s (mode=%s origin=%s)",
                    log_uid, sid, client_sid, symbol, tf, decision_mode, decision_origin
                )

            except Exception:
                log.exception("[FILLER] ‚ùå –û—à–∏–±–∫–∞ TF log_uid=%s sid=%s tf=%s", log_uid, sid, tf)

        dur = _now_monotonic_ms() - t0
        log.debug(
            "[FILLER] üì¶ seed done log_uid=%s sid=%s csid=%s tfs=%s dur=%dms mode=%s",
            log_uid, sid, client_sid, ",".join(tfs), dur, decision_mode
        )

# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–±—ã—Ç–∏—è –∑–∞–∫—Ä—ã—Ç–∏—è –ø–æ–∑–∏—Ü–∏–∏ –∏–∑ signal_log_queue
async def _process_position_closed(msg_id: str, fields: Dict[str, str]):
    """
    –°–æ–æ–±—â–µ–Ω–∏–µ –ø—É–±–ª–∏–∫—É–µ—Ç—Å—è –ü–û–°–õ–ï –∑–∞–ø–∏—Å–∏ –≤ positions_v4 ‚Äî –ø–æ–∑–∏—Ü–∏—è —É–∂–µ –µ—Å—Ç—å.
    –ë–µ—Ä—ë–º log_uid, client_strategy_id (–∏–∑ strategy_id –ø–æ–ª—è —Å–æ–±—ã—Ç–∏—è), position_uid –∏ –¥–æ–ø–∏—Å—ã–≤–∞–µ–º –≤ laboratoty_position_stat:
    position_uid, pnl, result, closed_at ‚Äî –¥–ª—è –≤—Å–µ—Ö TF –ø–æ (log_uid, client_strategy_id).
    """
    log_uid = fields.get("log_uid") or ""
    client_sid_s = fields.get("strategy_id") or ""  # –≤ —ç—Ç–æ–º —Å—Ç—Ä–∏–º–µ —ç—Ç–æ –ò–ú–ï–ù–ù–û –∫–ª–∏–µ–Ω—Ç—Å–∫–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è
    status = (fields.get("status") or "").strip().lower()
    position_uid = fields.get("position_uid") or ""

    if status != "closed":
        # –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –¥—Ä—É–≥–∏–µ —Å—Ç–∞—Ç—É—Å—ã; ack –ø—Ä–æ–∏–∑–æ–π–¥—ë—Ç –≤ –≤—ã–∑—ã–≤–∞—é—â–µ–º –º–µ—Å—Ç–µ
        log.debug("[CLOSE] skip non-closed msg=%s status=%s", msg_id, status)
        return

    if not log_uid or not client_sid_s.isdigit() or not position_uid:
        log.debug("[CLOSE] ‚ùå bad closed event msg=%s fields=%s", msg_id, fields)
        return

    client_sid = int(client_sid_s)

    # —á–∏—Ç–∞–µ–º —Ñ–∞–∫—Ç –ø–æ–∑–∏—Ü–∏–∏
    async with infra.pg_pool.acquire() as conn:
        pos = await conn.fetchrow(
            """
            SELECT id, position_uid, pnl, closed_at
            FROM public.positions_v4
            WHERE position_uid = $1
            """,
            position_uid
        )
        if not pos:
            # –ø–æ —É—Å–ª–æ–≤–∏—è–º —ç—Ç–æ –º–∞–ª–æ–≤–µ—Ä–æ—è—Ç–Ω–æ (—Å–æ–±—ã—Ç–∏–µ –ø—É–±–ª–∏–∫—É–µ—Ç—Å—è –ø–æ—Å–ª–µ –∑–∞–ø–∏—Å–∏), –Ω–æ –µ—Å–ª–∏ —Ç–∞–∫ ‚Äî –ø—Ä–æ—Å—Ç–æ –ª–æ–≥ –∏ –≤—ã—Ö–æ–¥–∏–º
            log.debug("[CLOSE] ‚ÑπÔ∏è position not found (uid=%s), skip", position_uid)
            return

        pnl = pos["pnl"]
        closed_at = pos["closed_at"] or datetime.utcnow()
        result = (pnl is not None and pnl > 0)

        # –∞–ø–¥–µ–π—Ç –í–°–ï–• TF-—Å—Ç—Ä–æ–∫ –ø–æ (log_uid, client_sid)
        upd_status = await conn.execute(
            """
            UPDATE public.laboratoty_position_stat
               SET position_uid = $1,
                   pnl = $2,
                   result = $3,
                   closed_at = $4,
                   updated_at = NOW()
             WHERE log_uid = $5
               AND client_strategy_id = $6
            """,
            position_uid, pnl, result, closed_at, log_uid, client_sid
        )

        # –ï—Å–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–æ 0 —Å—Ç—Ä–æ–∫ ‚Äî —ç—Ç–æ –Ω–µ –æ—à–∏–±–∫–∞ (—Å—Ç–∞—Ä—ã–µ –ø–æ–∑–∏—Ü–∏–∏, –º—ã –∏—Ö –Ω–µ –æ–±–æ–≥–∞—â–∞–ª–∏ seed'–æ–º)
        if upd_status.startswith("UPDATE 0"):
            log.debug("[CLOSE] ‚ÑπÔ∏è no LPS rows for log_uid=%s csid=%s (probably legacy), skip", log_uid, client_sid)
        else:
            log.debug("[CLOSE] ‚úÖ LPS updated for log_uid=%s csid=%s (%s)", log_uid, client_sid, upd_status)


# üî∏ –ì–ª–∞–≤–Ω—ã–π —Å–ª—É—à–∞—Ç–µ–ª—å seed-—Å—Ç—Ä–∏–º–∞
async def run_laboratory_decision_filler():
    """
    –°–ª—É—à–∞–µ—Ç laboratory_decision_filler –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫–∏ –≤ laboratoty_position_stat:
      ‚Äî –ø–æ –∫–∞–∂–¥–æ–º—É TF —Å–æ–±–∏—Ä–∞–µ—Ç –í–°–ï —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è MW/PACK,
      ‚Äî —Å—á–∏—Ç–∞–µ—Ç –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—á—ë—Ç—á–∏–∫–∏,
      ‚Äî –¥–µ–ª–∞–µ—Ç upsert (–±–µ–∑ –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã—Ö –ø–æ–ª–µ–π).
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ –ù–û–í–´–ï —Å–æ–æ–±—â–µ–Ω–∏—è (—Å—Ç–∞—Ä—Ç —Å '$').
    """
    log.debug("üõ∞Ô∏è LAB_DECISION_FILLER(seeds) –∑–∞–ø—É—â–µ–Ω (BLOCK=%d COUNT=%d MAX=%d)",
             XREAD_BLOCK_MS, XREAD_COUNT, MAX_IN_FLIGHT)

    last_id = "$"
    redis = infra.redis_client

    while True:
        try:
            resp = await redis.xread(streams={DECISION_FILLER_STREAM: last_id},
                                     count=XREAD_COUNT, block=XREAD_BLOCK_MS)
            if not resp:
                continue

            for _, messages in resp:
                for msg_id, fields in messages:
                    last_id = msg_id
                    asyncio.create_task(_process_seed(msg_id, fields))

        except asyncio.CancelledError:
            log.debug("‚èπÔ∏è LAB_DECISION_FILLER(seeds) –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ —Å–∏–≥–Ω–∞–ª—É")
            raise
        except Exception:
            log.exception("‚ùå LAB_DECISION_FILLER(seeds) –æ—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ")
            await asyncio.sleep(1.0)


# üî∏ –°–ª—É—à–∞—Ç–µ–ª—å –∑–∞–∫—Ä—ã—Ç–∏–π –ø–æ–∑–∏—Ü–∏–π (consumer group, —á—Ç–æ–±—ã –Ω–µ –º–µ—à–∞—Ç—å –¥—Ä—É–≥–∏–º)
async def run_position_close_updater():
    """
    –°–ª—É—à–∞–µ—Ç signal_log_queue –≤ —Å–≤–æ–µ–π consumer group –∏ –¥–æ–ø–∏—Å—ã–≤–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –ø–æ–ª—è –≤ laboratoty_position_stat
    –ø–æ –∫–∞–∂–¥–æ–º—É –∑–∞–∫—Ä—ã—Ç–∏—é –ø–æ–∑–∏—Ü–∏–∏ (status=closed).
    """
    log.debug("üõ∞Ô∏è LAB_DECISION_FILLER(close) –∑–∞–ø—É—â–µ–Ω (GROUP=%s)", POS_CLOSE_GROUP)
    redis = infra.redis_client

    # —Å–æ–∑–¥–∞—ë–º consumer group –∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ
    try:
        await redis.xgroup_create(POS_CLOSE_STREAM=POSITION_CLOSE_STREAM)  # intentionally wrong to force NameError to remind fix
    except TypeError:
        # –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –≤—ã–∑–æ–≤:
        try:
            await redis.xgroup_create(POSITION_CLOSE_STREAM, POS_CLOSE_GROUP, id="$", mkstream=True)
        except Exception as e:
            if "BUSYGROUP" not in str(e):
                log.warning("xgroup_create error: %s", e)

    while True:
        try:
            resp = await redis.xreadgroup(
                POS_CLOSE_GROUP, POS_CLOSE_CONSUMER,
                streams={POSITION_CLOSE_STREAM: ">"},
                count=XREAD_COUNT,
                block=XREAD_BLOCK_MS
            )
            if not resp:
                continue

            for _, messages in resp:
                for msg_id, fields in messages:
                    try:
                        await _process_position_closed(msg_id, fields)
                        # –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Ç–æ–≥–æ, –±—ã–ª–∏ LPS-—Å—Ç—Ä–æ–∫–∏ –∏–ª–∏ –Ω–µ—Ç
                        await redis.xack(POSITION_CLOSE_STREAM, POS_CLOSE_GROUP, msg_id)
                    except Exception:
                        log.exception("[CLOSE] ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ msg=%s", msg_id)
                        # ack –≤—Å—ë —Ä–∞–≤–Ω–æ, —á—Ç–æ–±—ã –Ω–µ –∑–∞—Ü–∏–∫–ª–∏—Ç—å—Å—è (–Ω–∞–≥—Ä—É–∑–∫–∞ –Ω–∏–∑–∫–∞—è, —Å–æ–æ–±—â–µ–Ω–∏–π –º–Ω–æ–≥–æ –Ω–µ –±—É–¥–µ—Ç)
                        await redis.xack(POSITION_CLOSE_STREAM, POS_CLOSE_GROUP, msg_id)

        except asyncio.CancelledError:
            log.debug("‚èπÔ∏è LAB_DECISION_FILLER(close) –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ —Å–∏–≥–Ω–∞–ª—É")
            raise
        except Exception:
            log.exception("‚ùå LAB_DECISION_FILLER(close) –æ—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ")
            await asyncio.sleep(1.0)