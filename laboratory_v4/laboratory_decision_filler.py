# laboratory_decision_filler.py ‚Äî –ø–æ—Å—Ç-allow –Ω–∞–ø–æ–ª–Ω–∏—Ç–µ–ª—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (LPS): —Å–∏–¥–∏–Ω–≥ –∏–∑ SLE –∏ –¥–æ–ø–∏—Å—å –ø–æ –∑–∞–∫—Ä—ã—Ç–∏—é –ø–æ–∑–∏—Ü–∏–π

import asyncio
import json
import logging
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

# üî∏ –ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞
import laboratory_infra as infra

# üî∏ –õ–æ–≥–≥–µ—Ä
log = logging.getLogger("LAB_FILLER")

# üî∏ –°—Ç—Ä–∏–º—ã
DECISION_FILLER_STREAM = "laboratory_decision_filler"   # —Å–∏–¥–∏–Ω–≥ –ø–æ—Å–ª–µ allow=true
SIGNAL_LOG_QUEUE_STREAM = "signal_log_queue"            # –≤–Ω–µ—à–Ω—è—è —à–∏–Ω–∞: —Å–æ–±—ã—Ç–∏–µ –∑–∞–∫—Ä—ã—Ç–∏—è –ø–æ–∑–∏—Ü–∏–∏

# üî∏ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —á—Ç–µ–Ω–∏—è —Å—Ç—Ä–∏–º–æ–≤
XREAD_BLOCK_MS = 2000
XREAD_COUNT = 50


# üî∏ –£—Ç–∏–ª–∏—Ç—ã

def _now_ms() -> int:
    return int(asyncio.get_running_loop().time() * 1000)


def _as_int(x: Any, default: Optional[int] = None) -> Optional[int]:
    try:
        return int(x)
    except Exception:
        return default


def _lower_str(x: Any) -> str:
    return str(x).strip().lower()


def _extract_stream_payload(fields: Dict[str, str]) -> Dict[str, Any]:
    """
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–≤–∞ —Ñ–æ—Ä–º–∞—Ç–∞:
      - –ø–ª–æ—Å–∫–∏–µ –ø–æ–ª—è
      - {'data': '<json>'} –∏–ª–∏ {'data':'{...}'}
    """
    payload: Dict[str, Any] = {}
    # –±–∞–∑–æ–≤–∞—è —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∞
    for k, v in fields.items():
        if isinstance(v, str) and v.startswith("{"):
            try:
                payload[k] = json.loads(v)
            except Exception:
                payload[k] = v
        else:
            payload[k] = v

    # –µ—Å–ª–∏ –≤—Å—ë –ª–µ–∂–∏—Ç –ø–æ–¥ 'data' ‚Äî —Ä–∞–∑–≤–æ—Ä–∞—á–∏–≤–∞–µ–º
    if "data" in payload and isinstance(payload["data"], dict):
        payload = payload["data"]

    return payload


def _pack_family_from_base(pack_base: str) -> str:
    s = _lower_str(pack_base)
    if s.startswith("ema"):
        return "ema"
    if s.startswith("macd"):
        return "macd"
    if s.startswith("lr"):
        return "lr"
    if s.startswith("adx_dmi"):
        return "adx_dmi"
    if s.startswith("bb"):
        return "bb"
    if s.startswith("atr"):
        return "atr"
    if s.startswith("rsi"):
        return "rsi"
    if s.startswith("mfi"):
        return "mfi"
    return s.split("_", 1)[0] if "_" in s else s


def _match_pack_rule(rule: Dict[str, Any], pack_objs: Dict[str, Any]) -> bool:
    """
    –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ PACK-–ø—Ä–∞–≤–∏–ª–∞ —Å –æ–±—ä–µ–∫—Ç–æ–º:
      - rule['agg_key'] = "key1|key2"
      - rule['agg_value'] = "key1:val1|key2:val2" –∏–ª–∏ "some_scalar" (solo —Å –∫–ª—é—á–æ–º)
      - —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—ã–ø–æ–ª–Ω—è–µ–º –∫–∞–∫ –ø–æ–ª–Ω–æ–µ —Ä–∞–≤–µ–Ω—Å—Ç–≤–æ —Ñ–∞–∫—Ç-—Å—Ç—Ä–æ–∫–∏ –∏ agg_value (–æ–±–∞ –≤ lower)
    """
    base = _lower_str(rule.get("pack_base", ""))
    if not base:
        return False
    po = pack_objs.get(base) or {}
    pack = po.get("pack") or {}
    agg_key = _lower_str(rule.get("agg_key", ""))
    agg_val = _lower_str(rule.get("agg_value", ""))
    if not agg_key or not agg_val:
        return False

    keys = [k.strip() for k in agg_key.split("|") if k.strip()]
    parts: List[str] = []
    for k in keys:
        v = pack.get(k)
        if v is None:
            return False
        parts.append(f"{k}:{_lower_str(v)}")
    fact = "|".join(parts)
    return fact == agg_val


def _compute_pack_family_counts_for_matches(tf_pack: Dict[str, Any]) -> Dict[str, Dict[str, int]]:
    """
    –°—á–∏—Ç–∞–µ—Ç pack_family_counts –ø–æ –°–û–í–ü–ê–í–®–ò–ú –ø—Ä–∞–≤–∏–ª–∞–º (–æ—Ç–¥–µ–ª—å–Ω–æ WL/BL):
      {"ema":{"wl":5,"bl":1}, "lr":{"wl":3,"bl":0}, ...}
    """
    rules: List[Dict[str, Any]] = (tf_pack or {}).get("rules") or []
    objs: Dict[str, Any] = (tf_pack or {}).get("objects") or {}
    out: Dict[str, Dict[str, int]] = {}
    if not rules or not objs:
        return out

    for r in rules:
        list_tag = _lower_str(r.get("list", ""))
        if list_tag not in ("whitelist", "blacklist"):
            continue
        matched = _match_pack_rule(r, objs)
        if not matched:
            continue
        fam = _pack_family_from_base(str(r.get("pack_base", "")))
        out.setdefault(fam, {"wl": 0, "bl": 0})
        if list_tag == "whitelist":
            out[fam]["wl"] += 1
        else:
            out[fam]["bl"] += 1

    return out


def _parse_tf_origin_map(s: Optional[str]) -> Dict[str, str]:
    """
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –≤–∏–¥–∞ "m5:mw,m15:pack" ‚Üí {"m5":"mw","m15":"pack"}
    """
    out: Dict[str, str] = {}
    if not s:
        return out
    for part in str(s).split(","):
        part = part.strip()
        if not part or ":" not in part:
            continue
        tf, origin = part.split(":", 1)
        tf = _lower_str(tf)
        origin = _lower_str(origin)
        if tf in ("m5", "m15", "h1") and origin in ("mw", "pack"):
            out[tf] = origin
    return out

# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ seed-—Å–æ–æ–±—â–µ–Ω–∏—è (allow=true): —Ç—è–Ω–µ–º —Å—Ç—Ä–æ–∫–∏ –∏–∑ SLE –∏ –∞–ø—Å–µ—Ä—Ç–∏–º LPS
async def _handle_seed_message(msg_id: str, fields: dict):
    # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è payload
    payload = {}
    for k, v in (fields or {}).items():
        if isinstance(v, str) and v.startswith("{"):
            try:
                payload[k] = json.loads(v)
            except Exception:
                payload[k] = v
        else:
            payload[k] = v
    if "data" in payload and isinstance(payload["data"], dict):
        payload = payload["data"]

    req_id = payload.get("req_id")
    log_uid = payload.get("log_uid")

    if not req_id or not log_uid:
        log.info("[SEED] ‚ö†Ô∏è –ø—Ä–æ–ø—É—Å–∫ msg=%s: –Ω–µ—Ç req_id/log_uid payload=%r", msg_id, payload)
        return

    # —Ç—è–Ω–µ–º –≤—Å–µ TF-—Å—Ç—Ä–æ–∫–∏ –∏–∑ SLE –ø–æ —ç—Ç–æ–º—É req_id+log_uid
    async with infra.pg_pool.acquire() as conn:
        rows = await conn.fetch(
            """
            SELECT
                req_id, log_uid, strategy_id, client_strategy_id, symbol, direction,
                tf,
                allow AS allow_tf,
                reason AS reason_tf,
                -- —Å—á—ë—Ç—á–∏–∫–∏ –∏–∑ –∫–æ–ª–æ–Ω–æ–∫ SLE
                mw_wl_hits,
                mw_wl_rules_total,
                pack_wl_hits,
                pack_wl_rules_total,
                pack_bl_hits,
                pack_bl_rules_total,
                tf_results
            FROM public.signal_laboratory_entries
            WHERE req_id = $1 AND log_uid = $2
            """,
            req_id, log_uid
        )

        if not rows:
            log.info("[SEED] ‚ö†Ô∏è –Ω–µ—Ç —Å—Ç—Ä–æ–∫ SLE –ø–æ req_id=%s log_uid=%s ‚Äî –æ—Ç–ª–æ–∂–∏–º", req_id, log_uid)
            return

        upserts = 0
        for r in rows:
            sid = int(r["strategy_id"])
            csid_raw = r["client_strategy_id"]
            try:
                csid = int(csid_raw) if csid_raw is not None else None
            except Exception:
                csid = None

            symbol = str(r["symbol"])
            direction = str(r["direction"])
            tf = str(r["tf"])

            # origin –∏–∑ reason –ø—Ä–∏ allow=true
            reason_tf = (r["reason_tf"] or "").lower() if r["reason_tf"] is not None else ""
            allow_tf = bool(r["allow_tf"])
            decision_origin = None
            if allow_tf:
                if reason_tf.startswith("ok_by_mw"):
                    decision_origin = "mw"
                elif reason_tf.startswith("ok_by_pack"):
                    decision_origin = "pack"
                elif reason_tf.startswith("ok_by_mw_and_pack"):
                    decision_origin = "mw"  # –¥–ª—è mw_and_pack ‚Äî –æ–±–µ –ø–ª–æ—Å–∫–æ—Å—Ç–∏; —Ñ–∏–∫—Å–∏—Ä—É–µ–º –∫–∞–∫ mw

            # decision_mode –∏–∑ tf_results.meta (–≤ SLE –æ—Ç–¥–µ–ª—å–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏ –Ω–µ—Ç)
            decision_mode = None
            tr = r["tf_results"]
            if isinstance(tr, str):
                try:
                    tr = json.loads(tr)
                except Exception:
                    tr = None
            if isinstance(tr, dict):
                decision_mode = tr.get("decision_mode") or (tr.get("meta") or {}).get("decision_mode")

            # —Å—á—ë—Ç—á–∏–∫–∏: –±–µ—Ä—ë–º hits –∏–∑ SLE-–∫–æ–ª–æ–Ω–æ–∫ (totals –Ω–∞–º –≤ LPS –Ω–µ —Ç—Ä–µ–±—É—é—Ç—Å—è)
            def _i(x): 
                try: return int(x)
                except Exception: return 0

            mw_hits       = _i(r["mw_wl_hits"])
            pack_wl_hits  = _i(r["pack_wl_hits"])
            pack_bl_hits  = _i(r["pack_bl_hits"])

            # –∞–ø—Å–µ—Ä—Ç –≤ LPS (–∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ –ø–æ uq_lps_unique)
            await conn.execute(
                """
                INSERT INTO public.laboratoty_position_stat (
                    log_uid, strategy_id, client_strategy_id, symbol, direction, tf,
                    mw_match_count, pack_wl_match_count, pack_bl_match_count,
                    decision_mode, decision_origin, created_at, updated_at
                ) VALUES (
                    $1,$2,$3,$4,$5,$6,
                    $7,$8,$9,
                    $10,$11, NOW(), NOW()
                )
                ON CONFLICT (log_uid, strategy_id, COALESCE(client_strategy_id, '-1'::integer), tf)
                DO UPDATE SET
                    mw_match_count = EXCLUDED.mw_match_count,
                    pack_wl_match_count = EXCLUDED.pack_wl_match_count,
                    pack_bl_match_count = EXCLUDED.pack_bl_match_count,
                    decision_mode = COALESCE(EXCLUDED.decision_mode, laboratoty_position_stat.decision_mode),
                    decision_origin = COALESCE(EXCLUDED.decision_origin, laboratoty_position_stat.decision_origin),
                    updated_at = NOW()
                """,
                log_uid, sid, csid, symbol, direction, tf,
                mw_hits, pack_wl_hits, pack_bl_hits,
                decision_mode, decision_origin
            )
            upserts += 1

        log.info("[SEED] ‚úÖ upsert LPS: req_id=%s log_uid=%s rows=%d", req_id, log_uid, upserts)

# üî∏ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ LPS –ø–æ —Å–æ–±—ã—Ç–∏—é –∑–∞–∫—Ä—ã—Ç–∏—è –ø–æ–∑–∏—Ü–∏–∏
async def _handle_close_message(msg_id: str, fields: Dict[str, str]):
    payload = _extract_stream_payload(fields)

    if _lower_str(payload.get("status", "")) != "closed":
        return

    log_uid = payload.get("log_uid")
    position_uid = payload.get("position_uid")
    client_sid = _as_int(payload.get("strategy_id"))  # –≤ —ç—Ç–æ–º —Å—Ç—Ä–∏–º–µ ‚Äî SID –∑–µ—Ä–∫–∞–ª–∞!

    if not log_uid or not position_uid or client_sid is None:
        log.info("[CLOSE] ‚ö†Ô∏è –ø—Ä–æ–ø—É—Å–∫ msg=%s: –Ω–µ—Ç log_uid/position_uid/strategy_id payload=%s", msg_id, payload)
        return

    # —á–∏—Ç–∞–µ–º –ø–æ–∑–∏—Ü–∏—é (—É–∂–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –≤–Ω–µ—à–Ω–∏–º –º–æ–¥—É–ª–µ–º)
    async with infra.pg_pool.acquire() as conn:
        pos = await conn.fetchrow(
            """
            SELECT position_uid, pnl, closed_at
            FROM positions_v4
            WHERE position_uid = $1
            """,
            position_uid
        )
        if not pos:
            log.info("[CLOSE] ‚ö†Ô∏è –ø–æ–∑–∏—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ position_uid=%s", position_uid)
            return

        pnl = pos["pnl"]
        closed_at = pos["closed_at"]
        # result: —Å—Ç—Ä–æ–≥–æ > 0
        result_flag = bool(pnl is not None and float(pnl) > 0.0)

        # –∞–ø–¥–µ–π—Ç –≤—Å–µ—Ö TF-—Å—Ç—Ä–æ–∫ LPS –ø–æ (log_uid, client_sid)
        try:
            status = await conn.execute(
                """
                UPDATE laboratoty_position_stat
                   SET position_uid = $1,
                       pnl = $2,
                       result = $3,
                       closed_at = $4,
                       updated_at = NOW()
                 WHERE log_uid = $5
                   AND client_strategy_id = $6
                """,
                position_uid, pnl, result_flag, closed_at, log_uid, client_sid
            )
            # status –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ "UPDATE <n>"
            updated = int(status.split()[-1]) if status.startswith("UPDATE") else 0
            log.info(
                "[CLOSE] ‚úÖ LPS –æ–±–Ω–æ–≤–ª—ë–Ω: log_uid=%s csid=%s pos=%s pnl=%s result=%s rows=%d",
                log_uid, client_sid, position_uid, str(pnl), str(result_flag).lower(), updated
            )
        except Exception:
            log.exception("[CLOSE] ‚ùå –æ—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è LPS (log_uid=%s csid=%s)", log_uid, client_sid)


# üî∏ –ì–ª–∞–≤–Ω—ã–π —Å–ª—É—à–∞—Ç–µ–ª—å: —Å–∏–¥–∏–Ω–≥ –ø–æ—Å–ª–µ allow=true
async def run_laboratory_decision_filler():
    """
    –°–ª—É—à–∞–µ—Ç laboratory_decision_filler –∏ –Ω–∞ –∫–∞–∂–¥–æ–µ allow=true —Å–æ–±—ã—Ç–∏–µ —Å–æ–∑–¥–∞—ë—Ç/–æ–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç—Ä–æ–∫–∏ –≤ laboratoty_position_stat
    –ø–æ –≤—Å–µ–º TF –¥–∞–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ (–ø–æ –¥–∞–Ω–Ω—ã–º –∏–∑ signal_laboratory_entries).
    """
    log.debug("üõ∞Ô∏è LAB_DECISION_FILLER —Å–ª—É—à–∞—Ç–µ–ª—å –∑–∞–ø—É—â–µ–Ω (BLOCK=%d COUNT=%d)", XREAD_BLOCK_MS, XREAD_COUNT)

    last_id = "$"
    redis = infra.redis_client

    while True:
        try:
            resp = await redis.xread(
                streams={DECISION_FILLER_STREAM: last_id},
                count=XREAD_COUNT,
                block=XREAD_BLOCK_MS
            )
            if not resp:
                continue

            for _, messages in resp:
                for msg_id, fields in messages:
                    last_id = msg_id
                    try:
                        await _handle_seed_message(msg_id, fields)
                    except Exception:
                        log.exception("‚ùå –û—à–∏–±–∫–∞ seed-—Å–æ–æ–±—â–µ–Ω–∏—è msg_id=%s", msg_id)

        except asyncio.CancelledError:
            log.debug("‚èπÔ∏è LAB_DECISION_FILLER –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ —Å–∏–≥–Ω–∞–ª—É")
            raise
        except Exception:
            log.exception("‚ùå LAB_DECISION_FILLER –æ—à–∏–±–∫–∞ —Ü–∏–∫–ª–∞")
            await asyncio.sleep(1.0)


# üî∏ –°–ª—É—à–∞—Ç–µ–ª—å –∑–∞–∫—Ä—ã—Ç–∏—è –ø–æ–∑–∏—Ü–∏–π: –¥–æ–ø–æ–ª–Ω—è–µ—Ç LPS pnl/result/closed_at/position_uid
async def run_position_close_updater():
    """
    –°–ª—É—à–∞–µ—Ç signal_log_queue. –ù–∞ —Å–æ–±—ã—Ç–∏—è—Ö —Å–æ status='closed' –ø–æ–¥—Ç—è–≥–∏–≤–∞–µ—Ç –∏–∑ positions_v4 PnL/closed_at
    –∏ –¥–æ–ø–∏—Å—ã–≤–∞–µ—Ç –∏—Ö –≤ laboratoty_position_stat (–ø–æ log_uid + client_strategy_id).
    """
    log.debug("üõ∞Ô∏è LAB_POS_CLOSE_FILLER —Å–ª—É—à–∞—Ç–µ–ª—å –∑–∞–ø—É—â–µ–Ω (BLOCK=%d COUNT=%d)", XREAD_BLOCK_MS, XREAD_COUNT)

    last_id = "$"
    redis = infra.redis_client

    while True:
        try:
            resp = await redis.xread(
                streams={SIGNAL_LOG_QUEUE_STREAM: last_id},
                count=XREAD_COUNT,
                block=XREAD_BLOCK_MS
            )
            if not resp:
                continue

            for _, messages in resp:
                for msg_id, fields in messages:
                    last_id = msg_id
                    try:
                        await _handle_close_message(msg_id, fields)
                    except Exception:
                        log.exception("‚ùå –û—à–∏–±–∫–∞ close-—Å–æ–æ–±—â–µ–Ω–∏—è msg_id=%s", msg_id)

        except asyncio.CancelledError:
            log.debug("‚èπÔ∏è LAB_POS_CLOSE_FILLER –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ —Å–∏–≥–Ω–∞–ª—É")
            raise
        except Exception:
            log.exception("‚ùå LAB_POS_CLOSE_FILLER –æ—à–∏–±–∫–∞ —Ü–∏–∫–ª–∞")
            await asyncio.sleep(1.0)