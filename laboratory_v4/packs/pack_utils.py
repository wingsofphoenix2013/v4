# packs/pack_utils.py â€” ÑƒÑ‚Ð¸Ð»Ð¸Ñ‚Ñ‹ Ð´Ð»Ñ on-demand Ð¿Ð°ÐºÐµÑ‚Ð¾Ð² (Ð²Ñ€ÐµÐ¼Ñ Ð±Ð°Ñ€Ð°, Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° OHLCV Ð¸Ð· TS, ÐºÐ¾Ñ€Ð·Ð¸Ð½Ñ‹/Ñ‚Ñ€ÐµÐ½Ð´Ñ‹) + in-process DF memo

# ðŸ”¸ Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ñ‹
import asyncio
import logging
import time
from datetime import datetime
from typing import Optional
import pandas as pd

# ðŸ”¸ Ð›Ð¾Ð³Ð³ÐµÑ€ Ð¼Ð¾Ð´ÑƒÐ»Ñ
log = logging.getLogger("PACK_UTILS")

# ðŸ”¸ Ð¢Ð°Ð¹Ð¼ÑˆÐ°Ð³Ð¸ TF (Ð¼Ñ Ð¸ Ð¼Ð¸Ð½ÑƒÑ‚Ñ‹)
STEP_MIN = {"m5": 5, "m15": 15, "h1": 60}
STEP_MS  = {"m5": 300_000, "m15": 900_000, "h1": 3_600_000}

# ðŸ”¸ ÐŸÑ€ÐµÑ„Ð¸ÐºÑÑ‹ Redis
BB_TS_PREFIX = "bb:ts"  # bb:ts:{symbol}:{tf}:{field}
IND_KV_PREFIX = "ind"   # ind:{symbol}:{tf}:{param_name}

# ðŸ”¸ In-process memo Ð´Ð»Ñ OHLCV DataFrame (ÑÐ½Ð¸Ð¶Ð°ÐµÑ‚ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ñ‹ TS.RANGE Ð²Ð½ÑƒÑ‚Ñ€Ð¸ Ñ‚Ð¸ÐºÐ°)
_DF_MEMO: dict[tuple[str, str, int, int], tuple[float, pd.DataFrame]] = {}  # (symbol, tf, end_ts_ms, bars) -> (exp_ts, df)
DF_MEMO_TTL_SEC = 10

# ðŸ”¸ ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ Ðº Ð½Ð°Ñ‡Ð°Ð»Ñƒ Ð±Ð°Ñ€Ð°
def floor_to_bar(ts_ms: int, tf: str) -> int:
    step = STEP_MS[tf]
    return (ts_ms // step) * step

# ðŸ”¸ Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° OHLCV Ð¸Ð· Redis TS (Ð¾Ð´Ð½Ð¸Ð¼ Ð±Ð°Ñ‚Ñ‡ÐµÐ¼) Ð¸ ÑÐ±Ð¾Ñ€ÐºÐ° DataFrame (Ñ memo)
async def load_ohlcv_df(redis, symbol: str, tf: str, end_ts_ms: int, bars: int = 800) -> Optional[pd.DataFrame]:
    # Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° memo
    memo_key = (symbol, tf, int(end_ts_ms), int(bars))
    rec = _DF_MEMO.get(memo_key)
    if rec:
        exp_ts, cached_df = rec
        if time.monotonic() <= exp_ts:
            # debug-Ð»Ð¾Ð³ Ð±ÐµÐ· ÑˆÑƒÐ¼Ð°
            log.debug("DF MEMO HIT %s/%s@%s bars=%d", symbol, tf, end_ts_ms, bars)
            return cached_df
        else:
            _DF_MEMO.pop(memo_key, None)

    if tf not in STEP_MS:
        return None

    step = STEP_MS[tf]
    start_ts = end_ts_ms - (bars - 1) * step

    fields = ["o", "h", "l", "c", "v"]
    keys = {f: f"{BB_TS_PREFIX}:{symbol}:{tf}:{f}" for f in fields}

    # Ð¾Ð´Ð¸Ð½ Ð±Ð°Ñ‚Ñ‡ Ð½Ð° 5 TS.RANGE
    tasks = {f: redis.execute_command("TS.RANGE", keys[f], start_ts, end_ts_ms) for f in fields}
    results = await asyncio.gather(*tasks.values(), return_exceptions=True)

    series = {}
    for f, res in zip(tasks.keys(), results):
        if isinstance(res, Exception):
            log.warning(f"[TS] RANGE {keys[f]} error: {res}")
            continue
        if res:
            try:
                series[f] = {int(ts): float(val) for ts, val in res if val is not None}
            except Exception as e:
                log.warning(f"[TS] parse {keys[f]} error: {e}")

    if not series or "c" not in series or not series["c"]:
        return None

    # Ð¾Ð±Ñ‰Ð¸Ð¹ Ð¸Ð½Ð´ÐµÐºÑ Ð¿Ð¾ Ð¼ÐµÑ‚ÐºÐ°Ð¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ (Ð¿Ð¾ close)
    idx = sorted(series["c"].keys())
    df = None
    for f in fields:
        col_map = series.get(f, {})
        s = pd.Series({ts: col_map.get(ts) for ts in idx})
        s.index = pd.to_datetime(s.index, unit="ms")
        s.name = f
        df = s.to_frame() if df is None else df.join(s, how="outer")

    if df is None or df.empty:
        return None

    df.index.name = "open_time"
    df = df.sort_index()

    # Ð½Ð¸Ð¶Ð½ÑÑ Ð³Ñ€Ð°Ð½Ð¸Ñ†Ð° Ñ€Ð°Ð·ÑƒÐ¼Ð½Ð¾ÑÑ‚Ð¸ (Ð¸Ð·Ð±ÐµÐ³Ð°ÐµÐ¼ ÐºÑÑˆÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Â«ÐºÑ€Ð¾Ñ…Ð¸Â»)
    if len(df) < min(bars // 2, 100):
        log.debug("load_ohlcv_df: too few rows (%d) for %s/%s", len(df), symbol, tf)
        return df  # Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ ÐºÐ°Ðº ÐµÑÑ‚ÑŒ, Ð½Ð¾ Ð½Ðµ ÐºÑÑˆÐ¸Ñ€ÑƒÐµÐ¼

    # Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ð¼ Ð² memo (TTL)
    _DF_MEMO[memo_key] = (time.monotonic() + DF_MEMO_TTL_SEC, df)
    return df

# ðŸ”¸ RSI: ÐºÐ¾Ñ€Ð·Ð¸Ð½Ð° (Ð½Ð¸Ð¶Ð½ÑÑ Ð³Ñ€Ð°Ð½Ð¸Ñ†Ð°, ÑˆÐ°Ð³ 5)
def rsi_bucket_low(value: float) -> int:
    x = max(0.0, min(99.9999, float(value)))
    return int((int(x) // 5) * 5)

# ðŸ”¸ RSI: Ð¿Ð¾Ñ€Ð¾Ð³Ð¸ Â«Ð¼ÐµÑ€Ñ‚Ð²Ð¾Ð³Ð¾ ÐºÐ¾Ñ€Ð¸Ð´Ð¾Ñ€Ð°Â» Ð¿Ð¾ TF (Ð°Ð±ÑÐ¾Ð»ÑŽÑ‚Ð½Ñ‹Ðµ Ð¿ÑƒÐ½ÐºÑ‚Ñ‹ RSI)
RSI_EPS = {"m5": 0.3, "m15": 0.4, "h1": 0.6}

# ðŸ”¸ RSI: ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ Ñ‚Ñ€ÐµÐ½Ð´Ð° Ð¿Ð¾ Ð°Ð±ÑÐ¾Ð»ÑŽÑ‚Ð½Ð¾Ð¹ Ð´ÐµÐ»ÑŒÑ‚Ðµ (up/flat/down)
def classify_abs_delta(delta: float, tf: str) -> str:
    eps = RSI_EPS.get(tf, 0.4)
    if delta >= eps:
        return "up"
    if delta <= -eps:
        return "down"
    return "flat"

# ðŸ”¸ ÐŸÑ€Ð¾Ñ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ Ð·Ð°ÐºÑ€Ñ‹Ñ‚Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ RSI Ð¸Ð· KV ind:{symbol}:{tf}:rsi{length}
async def get_closed_rsi(redis, symbol: str, tf: str, length: int) -> Optional[float]:
    key = f"{IND_KV_PREFIX}:{symbol}:{tf}:rsi{length}"
    try:
        s = await redis.get(key)
        return float(s) if s is not None else None
    except Exception:
        return None

# ðŸ”¸ Ð’ÑÐ¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ: ISO-Ð²Ñ€ÐµÐ¼Ñ Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚Ð¸Ñ Ð±Ð°Ñ€Ð° Ð¿Ð¾ ms
def bar_open_iso(bar_open_ms: int) -> str:
    return datetime.utcfromtimestamp(bar_open_ms / 1000).isoformat()