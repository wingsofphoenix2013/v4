import asyncio
import logging
from datetime import datetime, timedelta
from decimal import Decimal

import infra

log = logging.getLogger("REDIS_IO")

TF_SECONDS = {
    "m1": 60,
    "m5": 300,
    "m15": 900,
    "h1": 3600,
}

FIELDS = ["o", "h", "l", "c", "v"]


def clean_decimal(value) -> float:
    return float(Decimal(value).normalize())


# üî∏ –§–∏–∫—Å–∞—Ü–∏—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö —Ç–æ—á–µ–∫ –≤ Redis TS –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
async def fix_missing_ts_points():
    log.info("üîß [TS_FIX] –ó–∞–ø—É—Å–∫ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è Redis TimeSeries")

    semaphore = asyncio.Semaphore(10)
    tasks = []

    for symbol, ticker_data in infra.enabled_tickers.items():
        created_at = ticker_data.get("created_at")
        if not created_at:
            log.warning(f"‚è≥ [TS_FIX] –ü—Ä–æ–ø—É—â–µ–Ω —Ç–∏–∫–µ—Ä {symbol} ‚Äî –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç created_at")
            continue

        for tf, tf_sec in TF_SECONDS.items():
            tasks.append(process_symbol_tf(symbol, tf, tf_sec, created_at, semaphore))

    await asyncio.gather(*tasks)
    log.info("‚úÖ [TS_FIX] –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ Redis TS –∑–∞–≤–µ—Ä—à–µ–Ω–æ")

# üî∏ –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ Redis TS (–ø–æ –æ–¥–Ω–æ–º—É –¥–Ω—é, –∑–∞ –ø—Ä–µ–¥–µ–ª–∞–º–∏ 24 —á–∞—Å–æ–≤, –Ω–æ –Ω–µ –≥–ª—É–±–∂–µ 30 –¥–Ω–µ–π)
async def fix_missing_ts_historical_day():
    log.info("üï∞Ô∏è [TS_REBUILD] –ó–∞–ø—É—Å–∫ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –æ–¥–Ω–æ–≥–æ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–≥–æ –¥–Ω—è")

    semaphore = asyncio.Semaphore(10)
    tasks = []

    redis = infra.redis_client
    now = datetime.utcnow()

    # –ø—Ä–µ–¥–µ–ª 30 –¥–Ω–µ–π
    min_allowed_time = now - timedelta(days=30)

    # –ø–æ–ª—É—á–∞–µ–º offset –∏–∑ Redis –∏–ª–∏ –Ω–∞—á–∏–Ω–∞–µ–º —Å 1
    offset_key = "ts_restore_offset_days"
    raw_offset = await redis.get(offset_key)
    offset = int(raw_offset or 1)

    # —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º from_time / to_time (—Ä–æ–≤–Ω–æ 1 –¥–µ–Ω—å, –æ—Ç—Å—Ç–æ—è—â–∏–π –Ω–∞ offset –æ—Ç now - 24h)
    end_boundary = now - timedelta(hours=24)
    to_time = end_boundary - timedelta(days=offset - 1)
    from_time = to_time - timedelta(days=1)

    # –≤—ã—Ö–æ–¥ –∑–∞ –≥–ª–æ–±–∞–ª—å–Ω—É—é 30-–¥–Ω–µ–≤–Ω—É—é –≥—Ä–∞–Ω–∏—Ü—É ‚Äî –∑–∞–≤–µ—Ä—à–∏—Ç—å
    if from_time < min_allowed_time:
        log.info("üï∞Ô∏è [TS_REBUILD] –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ø—Ä–µ–¥–µ–ª 30 –¥–Ω–µ–π ‚Äî –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
        return

    log.info(f"üï∞Ô∏è [TS_REBUILD] –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞: {from_time} ‚Üí {to_time} (offset={offset})")

    for symbol, ticker_data in infra.enabled_tickers.items():
        created_at = ticker_data.get("created_at")
        if not created_at:
            log.warning(f"üï∞Ô∏è [TS_REBUILD] –ü—Ä–æ–ø—É—â–µ–Ω —Ç–∏–∫–µ—Ä {symbol} ‚Äî –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç created_at")
            continue

        if to_time <= created_at:
            log.info(f"üï∞Ô∏è [TS_REBUILD] {symbol} ‚Äî –ø—Ä–æ–ø—É—â–µ–Ω (–¥–∞–Ω–Ω—ã–µ –µ—â—ë –Ω–µ –Ω–∞—á–∏–Ω–∞–ª–∏—Å—å)")
            continue

        for tf, tf_sec in TF_SECONDS.items():
            tasks.append(
                process_symbol_tf_historical(symbol, tf, tf_sec, created_at, from_time, to_time, semaphore)
            )

    await asyncio.gather(*tasks)

    await redis.set(offset_key, offset + 1)
    log.info(f"‚úÖ [TS_REBUILD] –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ö–æ–¥ –∑–∞–≤–µ—Ä—à—ë–Ω (offset={offset}) ‚Üí offset={offset + 1}")
    
async def process_symbol_tf(symbol, tf, tf_sec, created_at, semaphore):
    async with semaphore:
        try:
            tf_ms = tf_sec * 1000
            now = datetime.utcnow()

            to_ts = int(now.timestamp()) // tf_sec * tf_sec - tf_sec
            from_time = max(created_at, now - timedelta(hours=24))
            from_ts = int(from_time.timestamp()) // tf_sec * tf_sec

            expected = {
                from_ts * 1000 + tf_ms * i
                for i in range((to_ts - from_ts) // tf_sec + 1)
            }

            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î
            table = f"ohlcv4_{tf}"
            async with infra.pg_pool.acquire() as conn:
                rows = await conn.fetch(
                    f"""
                    SELECT open_time, open, high, low, close, volume
                    FROM {table}
                    WHERE symbol = $1 AND open_time BETWEEN $2 AND $3
                    """,
                    symbol,
                    datetime.fromtimestamp(from_ts),
                    datetime.fromtimestamp(to_ts)
                )

            by_time = {
                int(row["open_time"].timestamp() * 1000): row
                for row in rows
            }

            redis = infra.redis_client
            added_counts = {f: 0 for f in FIELDS}

            # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–µ—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–∏ –∏–∑ Redis –ø–æ –∫–∞–∂–¥–æ–º—É –ø–æ–ª—é
            existing = {}
            for field in FIELDS:
                key = f"ts:{symbol}:{tf}:{field}"
                try:
                    results = await redis.execute_command("TS.RANGE", key, from_ts * 1000, to_ts * 1000)
                    existing[field] = {int(ts) for ts, _ in results}
                except Exception as e:
                    log.warning(f"[TS_FIX] –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {key}: {e}")
                    existing[field] = set()

            for ts in expected:
                if ts not in by_time:
                    continue

                row = by_time[ts]

                values = {
                    "o": clean_decimal(row["open"]),
                    "h": clean_decimal(row["high"]),
                    "l": clean_decimal(row["low"]),
                    "c": clean_decimal(row["close"]),
                    "v": clean_decimal(row["volume"]),
                }

                for field in FIELDS:
                    if ts in existing[field]:
                        continue
                    key = f"ts:{symbol}:{tf}:{field}"
                    try:
                        await redis.execute_command("TS.ADD", key, ts, values[field])
                        added_counts[field] += 1
                    except Exception as e:
                        log.warning(f"‚ùå [TS_FIX] –û—à–∏–±–∫–∞ TS.ADD {key} @ {ts}: {e}")

            summary = " ".join(f"{f}=+{added_counts[f]}" for f in FIELDS)
            log.debug(f"üîß [TS_FIX] {symbol} [{tf}] ‚Üí {summary}")

        except Exception:
            log.exception(f"‚ùå [TS_FIX] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {symbol} [{tf}]")

async def process_symbol_tf_historical(symbol, tf, tf_sec, created_at, from_time, to_time, semaphore):
    async with semaphore:
        try:
            if to_time <= created_at:
                log.info(f"üï∞Ô∏è [TS_REBUILD] {symbol} [{tf}] ‚Äî –ø—Ä–æ–ø—É—â–µ–Ω (created_at –ø–æ–∑–∂–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞)")
                return

            tf_ms = tf_sec * 1000
            from_ts = int(from_time.timestamp()) // tf_sec * tf_sec
            to_ts = int(to_time.timestamp()) // tf_sec * tf_sec

            expected = {
                from_ts * 1000 + tf_ms * i
                for i in range((to_ts - from_ts) // tf_sec + 1)
            }

            table = f"ohlcv4_{tf}"
            async with infra.pg_pool.acquire() as conn:
                rows = await conn.fetch(
                    f"""
                    SELECT open_time, open, high, low, close, volume
                    FROM {table}
                    WHERE symbol = $1 AND open_time BETWEEN $2 AND $3
                    """,
                    symbol,
                    datetime.fromtimestamp(from_ts),
                    datetime.fromtimestamp(to_ts)
                )

            by_time = {
                int(row["open_time"].timestamp() * 1000): row
                for row in rows
            }

            redis = infra.redis_client
            added_counts = {f: 0 for f in FIELDS}

            existing = {}
            for field in FIELDS:
                key = f"ts:{symbol}:{tf}:{field}"
                try:
                    results = await redis.execute_command("TS.RANGE", key, from_ts * 1000, to_ts * 1000)
                    existing[field] = {int(ts) for ts, _ in results}
                except Exception as e:
                    log.warning(f"[TS_REBUILD] –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {key}: {e}")
                    existing[field] = set()

            for ts in expected:
                if ts not in by_time:
                    continue

                row = by_time[ts]
                values = {
                    "o": clean_decimal(row["open"]),
                    "h": clean_decimal(row["high"]),
                    "l": clean_decimal(row["low"]),
                    "c": clean_decimal(row["close"]),
                    "v": clean_decimal(row["volume"]),
                }

                for field in FIELDS:
                    if ts in existing[field]:
                        continue
                    key = f"ts:{symbol}:{tf}:{field}"
                    try:
                        await redis.execute_command("TS.ADD", key, ts, values[field])
                        added_counts[field] += 1
                    except Exception as e:
                        log.warning(f"‚ùå [TS_REBUILD] TS.ADD {key} @ {ts}: {e}")

            summary = " ".join(f"{f}=+{added_counts[f]}" for f in FIELDS)
            log.debug(f"üï∞Ô∏è [TS_REBUILD] {symbol} [{tf}] ‚Üí {summary}")

        except Exception:
            log.exception(f"‚ùå [TS_REBUILD] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {symbol} [{tf}]")
