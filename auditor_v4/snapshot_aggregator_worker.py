# snapshot_aggregator_worker.py

import asyncio
import logging
from decimal import Decimal, ROUND_HALF_UP
from datetime import datetime

import infra

# ðŸ”¸ Ð›Ð¾Ð³Ð³ÐµÑ€
log = logging.getLogger("SNAPSHOT_AGGREGATOR")


# ðŸ”¸ ÐžÐºÑ€ÑƒÐ³Ð»ÐµÐ½Ð¸Ðµ decimal Ñ Ð·Ð°Ð´Ð°Ð½Ð½Ð¾Ð¹ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒÑŽ
def quantize(value: Decimal, places: int) -> Decimal:
    return value.quantize(Decimal(f"1e-{places}"), rounding=ROUND_HALF_UP)


# ðŸ”¸ ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ Ñ‚Ð¾Ñ‡ÐºÐ° Ð²Ñ…Ð¾Ð´Ð° Ð²Ð¾Ñ€ÐºÐµÑ€Ð°
async def run_snapshot_aggregator_worker():
    try:
        await process_batch()
    except Exception:
        log.exception("ÐžÑˆÐ¸Ð±ÐºÐ° Ð² snapshot_aggregator_worker")


# ðŸ”¸ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¾Ð´Ð½Ð¾Ð¹ Ð¿Ð¾Ñ€Ñ†Ð¸Ð¸ Ð½ÐµÐ¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ñ… Ð»Ð¾Ð³Ð¾Ð²
async def process_batch(batch_size: int = 200):
    async with infra.pg_pool.acquire() as conn:
        async with conn.transaction():
            rows = await conn.fetch(
                """
                SELECT * FROM emasnapshot_position_log
                WHERE aggregated_at IS NULL
                ORDER BY position_id
                LIMIT $1
                FOR UPDATE SKIP LOCKED
                """,
                batch_size
            )

            if not rows:
                log.info("ÐÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ñ… ÑÑ‚Ñ€Ð¾Ðº Ð´Ð»Ñ Ð°Ð³Ñ€ÐµÐ³Ð°Ñ†Ð¸Ð¸")
                return

            now = datetime.utcnow()
            snapshot_stats = {}  # ÐºÐ»ÑŽÑ‡: (tf, strategy_id, direction, emasnapshot_dict_id)
            pattern_stats = {}   # ÐºÐ»ÑŽÑ‡: (tf, strategy_id, direction, pattern_id)

            for r in rows:
                tf = r["tf"]
                sid = r["strategy_id"]
                dir_ = r["direction"]
                snap_id = r["emasnapshot_dict_id"]
                pattern_id = r["pattern_id"]
                pnl = Decimal(r["pnl"])

                key_s = (tf, sid, dir_, snap_id)
                key_p = (tf, sid, dir_, pattern_id)

                # ÐÐ³Ñ€ÐµÐ³Ð°Ñ†Ð¸Ñ Ð¿Ð¾ ÑÐ½Ð°Ð¿ÑˆÐ¾Ñ‚Ñƒ
                agg = snapshot_stats.setdefault(key_s, {
                    "num_trades": 0,
                    "num_wins": 0,
                    "num_losses": 0,
                    "total_pnl": Decimal(0)
                })
                agg["num_trades"] += 1
                agg["total_pnl"] += pnl
                if pnl > 0:
                    agg["num_wins"] += 1
                elif pnl < 0:
                    agg["num_losses"] += 1

                # ÐÐ³Ñ€ÐµÐ³Ð°Ñ†Ð¸Ñ Ð¿Ð¾ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ñƒ (ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ)
                if pattern_id is not None:
                    agg_p = pattern_stats.setdefault(key_p, {
                        "num_trades": 0,
                        "num_wins": 0,
                        "num_losses": 0,
                        "total_pnl": Decimal(0)
                    })
                    agg_p["num_trades"] += 1
                    agg_p["total_pnl"] += pnl
                    if pnl > 0:
                        agg_p["num_wins"] += 1
                    elif pnl < 0:
                        agg_p["num_losses"] += 1

            # ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ Ð°Ð³Ñ€ÐµÐ³Ð°Ñ‚Ð¾Ð² Ð¿Ð¾ ÑÐ½Ð°Ð¿ÑˆÐ¾Ñ‚Ð°Ð¼
            for (tf, sid, dir_, snap_id), data in snapshot_stats.items():
                table = f"positions_emasnapshot_{tf}_stat"
                await upsert_aggregation(conn, table, sid, dir_, snap_id, data)

            # ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ Ð°Ð³Ñ€ÐµÐ³Ð°Ñ‚Ð¾Ð² Ð¿Ð¾ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð°Ð¼
            for (tf, sid, dir_, pattern_id), data in pattern_stats.items():
                table = f"positions_emapattern_{tf}_stat"
                await upsert_aggregation(conn, table, sid, dir_, pattern_id, data, is_pattern=True)

            # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÑ‚Ð°Ñ‚ÑƒÑ ÑÑ‚Ñ€Ð¾Ðº ÐºÐ°Ðº Ð°Ð³Ñ€ÐµÐ³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ…
            ids = [(r["position_id"], r["tf"]) for r in rows]
            await conn.executemany(
                """
                UPDATE emasnapshot_position_log
                SET aggregated_at = $3
                WHERE position_id = $1 AND tf = $2
                """,
                [(pid, tf, now) for pid, tf in ids]
            )

            log.info(f"ÐÐ³Ñ€ÐµÐ³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾ ÑÑ‚Ñ€Ð¾Ðº: {len(rows)}")


# ðŸ”¸ Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ UPSERT Ð² Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ Ð°Ð³Ñ€ÐµÐ³Ð°Ñ†Ð¸Ð¸
async def upsert_aggregation(conn, table: str, strategy_id: int, direction: str, ref_id: int, data: dict, is_pattern=False):
    num_trades = data["num_trades"]
    num_wins = data["num_wins"]
    num_losses = data["num_losses"]
    total_pnl = data["total_pnl"]

    avg_pnl = quantize(total_pnl / num_trades, 4) if num_trades > 0 else Decimal("0.0000")
    winrate = quantize(Decimal(num_wins) / num_trades, 4) if num_trades > 0 else Decimal("0.0000")
    base_rating = quantize(winrate * avg_pnl, 6)

    col = "pattern_id" if is_pattern else "emasnapshot_dict_id"

    await conn.execute(
        f"""
        INSERT INTO {table} (
            strategy_id, direction, {col}, num_trades, num_wins, num_losses,
            total_pnl, avg_pnl, winrate, base_rating, last_updated
        ) VALUES (
            $1, $2, $3, $4, $5, $6,
            $7, $8, $9, $10, now()
        )
        ON CONFLICT (strategy_id, direction, {col}) DO UPDATE
        SET
            num_trades = {table}.num_trades + $4,
            num_wins = {table}.num_wins + $5,
            num_losses = {table}.num_losses + $6,
            total_pnl = {table}.total_pnl + $7,
            avg_pnl = ROUND((({table}.total_pnl + $7)::numeric / ({table}.num_trades + $4)), 4),
            winrate = ROUND((({table}.num_wins + $5)::numeric / ({table}.num_trades + $4)), 4),
            base_rating = ROUND(
                (({table}.num_wins + $5)::numeric / ({table}.num_trades + $4)) *
                (({table}.total_pnl + $7)::numeric / ({table}.num_trades + $4)), 6
            ),
            last_updated = now()
        """,
        strategy_id, direction, ref_id, num_trades, num_wins, num_losses,
        total_pnl, avg_pnl, winrate, base_rating
    )