# feed_and_aggregate.py ‚Äî –ø—Ä–∏—ë–º –∏ –∞–≥—Ä–µ–≥–∞—Ü–∏—è —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö - 22/05/2025 (–Ω–æ–≤—ã–π)

import logging
import asyncio
import websockets
import json
import aiohttp
from infra import setup_logging
from decimal import Decimal, ROUND_DOWN, InvalidOperation
import time
from datetime import datetime, timedelta

# –ü–æ–ª—É—á–∞–µ–º –ª–æ–≥–≥–µ—Ä –¥–ª—è –º–æ–¥—É–ª—è
log = logging.getLogger("FEED+AGGREGATOR")
# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è safe_ts_add
created_ts_keys = set()
# üî∏ –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Ç–∏–∫–µ—Ä–æ–≤, —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏ —Å—Ç–∞—Ç—É—Å–∞ –∏–∑ PostgreSQL
async def load_all_tickers(pg_pool):
    async with pg_pool.acquire() as conn:
        rows = await conn.fetch("""
            SELECT symbol, precision_price, precision_qty, status FROM tickers_v4
        """)
        tickers = {}
        active = set()
        for row in rows:
            tickers[row['symbol']] = {
                "precision_price": row["precision_price"],
                "precision_qty": row["precision_qty"]
            }
            if row['status'] == 'enabled':
                active.add(row['symbol'].lower())
        return tickers, active
# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–±—ã—Ç–∏–π –≤–∫–ª—é—á–µ–Ω–∏—è/–æ—Ç–∫–ª—é—á–µ–Ω–∏—è —Ç–∏–∫–µ—Ä–æ–≤ —á–µ—Ä–µ–∑ Redis Stream
async def handle_ticker_events(redis, state, pg, refresh_queue):
    group = "aggregator_group"
    stream = "tickers_status_stream"

    try:
        await redis.xgroup_create(stream, group, id="0", mkstream=True)
    except Exception:
        pass  # –≥—Ä—É–ø–ø–∞ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç

    while True:
        resp = await redis.xreadgroup(group, "aggregator", streams={stream: ">"}, count=50, block=1000)
        for _, messages in resp:
            for msg_id, data in messages:
                symbol = data.get("symbol")
                action = data.get("action")
                if not symbol or not action:
                    continue

                if symbol not in state["tickers"]:
                    async with pg.acquire() as conn:
                        row = await conn.fetchrow("""
                            SELECT precision_price, precision_qty FROM tickers_v4 WHERE symbol = $1
                        """, symbol)
                        if row:
                            state["tickers"][symbol] = {
                                "precision_price": row["precision_price"],
                                "precision_qty": row["precision_qty"]
                            }
                            log.info(f"–î–æ–±–∞–≤–ª–µ–Ω —Ç–∏–∫–µ—Ä –∏–∑ –ë–î: {symbol}")

                if action == "enabled" and symbol in state["tickers"]:
                    log.info(f"–ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω —Ç–∏–∫–µ—Ä: {symbol}")
                    state["active"].add(symbol.lower())
                    state["activated_at"][symbol] = datetime.utcnow()
                    await refresh_queue.put("refresh")

                    # –∑–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫–∞ markPrice –∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏
                    task = asyncio.create_task(watch_mark_price(symbol, redis, state))
                    state["markprice_tasks"][symbol] = task

                elif action == "disabled" and symbol in state["tickers"]:
                    log.info(f"–û—Ç–∫–ª—é—á—ë–Ω —Ç–∏–∫–µ—Ä: {symbol}")
                    state["active"].discard(symbol.lower())
                    await refresh_queue.put("refresh")

                    # –æ—Ç–º–µ–Ω–∞ –ø–æ—Ç–æ–∫–∞ markPrice, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
                    task = state["markprice_tasks"].pop(symbol, None)
                    if task:
                        task.cancel()

                await redis.xack(stream, group, msg_id)

# –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ RedisTimeSeries —Å –∫—ç—à–æ–º
async def safe_ts_add(redis, key, ts, value, field, symbol, interval):
    if key not in created_ts_keys:
        try:
            await redis.execute_command(
                "TS.CREATE", key,
                "RETENTION", 2592000000,
                "DUPLICATE_POLICY", "last",
                "LABELS",
                "symbol", symbol,
                "interval", interval,
                "field", field
            )
            created_ts_keys.add(key)
        except Exception as e:
            if "already exists" not in str(e):
                raise
    await redis.execute_command("TS.ADD", key, ts, value)
# üî∏ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–π —Å–≤–µ—á–∏ M1 –≤ RedisTimeSeries + Stream + Pub/Sub + —Ç—Ä–∏–≥–≥–µ—Ä—ã –Ω–∞ M5/M15
async def store_and_publish_m1(redis, symbol, open_time, kline, precision_price, precision_qty, state):
    ts = int(open_time.timestamp() * 1000)

    def r(val, precision):
        return float(Decimal(val).quantize(Decimal(f"1e-{precision}"), rounding=ROUND_DOWN))

    o = r(kline["o"], precision_price)
    h = r(kline["h"], precision_price)
    l = r(kline["l"], precision_price)
    c = r(kline["c"], precision_price)
    v = r(kline["v"], precision_qty)

    async def safe_ts_add(field_key, value, field_name):
        try:
            await redis.execute_command("TS.ADD", field_key, ts, value)
        except Exception as e:
            if "TSDB: the key does not exist" in str(e):
                await redis.execute_command(
                    "TS.CREATE", field_key,
                    "RETENTION", 2592000000,  # 30 –¥–Ω–µ–π
                    "DUPLICATE_POLICY", "last",
                    "LABELS",
                    "symbol", symbol,
                    "interval", "m1",
                    "field", field_name
                )
                await redis.execute_command("TS.ADD", field_key, ts, value)
            else:
                raise

    await safe_ts_add(f"ts:{symbol}:m1:o", o, "o")
    await safe_ts_add(f"ts:{symbol}:m1:h", h, "h")
    await safe_ts_add(f"ts:{symbol}:m1:l", l, "l")
    await safe_ts_add(f"ts:{symbol}:m1:c", c, "c")
    await safe_ts_add(f"ts:{symbol}:m1:v", v, "v")

    log.debug(f"[{symbol}] M1 TS —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: ts={ts} O={o} H={h} L={l} C={c} V={v}")

    # –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ Stream (–ø–æ–ª–Ω–∞—è —Å–≤–µ—á–∞)
    stream_event = {
        "symbol": symbol,
        "interval": "m1",
        "timestamp": str(ts),
        "o": str(o),
        "h": str(h),
        "l": str(l),
        "c": str(c),
        "v": str(v)
    }
    await redis.xadd("ohlcv_stream", stream_event)

    # –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ Pub/Sub (—Ç–æ–ª—å–∫–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ)
    pubsub_event = {
        "symbol": symbol,
        "interval": "m1",
        "timestamp": str(ts)
    }
    await redis.publish("ohlcv_channel", json.dumps(pubsub_event))

    # –¢—Ä–∏–≥–≥–µ—Ä—ã –Ω–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ M5/M15
    if open_time.minute % 5 == 4:
        base_m5 = open_time.replace(minute=(open_time.minute // 5) * 5, second=0, microsecond=0)
        await try_aggregate_m5(redis, symbol, base_m5, state)

    if open_time.minute % 15 == 14:
        base_m15 = open_time.replace(minute=(open_time.minute // 15) * 15, second=0, microsecond=0)
        await try_aggregate_m15(redis, symbol, base_m15, state)
# üî∏ –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å–≤–µ—á–∏ M5 –∏–∑ 5 M1 –≤ RedisTimeSeries
async def try_aggregate_m5(redis, symbol, base_time, state):
    end_ts = int(base_time.timestamp() * 1000) + 4 * 60_000 + 1
    ts_list = [end_ts - 1 - i * 60_000 for i in reversed(range(5))]
    candles = []

    for ts in ts_list:
        try:
            o, h, l, c, v = await asyncio.gather(
                redis.execute_command("TS.RANGE", f"ts:{symbol}:m1:o", ts, ts),
                redis.execute_command("TS.RANGE", f"ts:{symbol}:m1:h", ts, ts),
                redis.execute_command("TS.RANGE", f"ts:{symbol}:m1:l", ts, ts),
                redis.execute_command("TS.RANGE", f"ts:{symbol}:m1:c", ts, ts),
                redis.execute_command("TS.RANGE", f"ts:{symbol}:m1:v", ts, ts)
            )

            if not all([o, h, l, c, v]):
                raise ValueError("–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö")

            candles.append({
                "o": float(o[0][1]),
                "h": float(h[0][1]),
                "l": float(l[0][1]),
                "c": float(c[0][1]),
                "v": float(v[0][1]),
                "ts": ts
            })
        except Exception:
            log.warning(f"[{symbol}] –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å M5: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç M1 –¥–ª—è {base_time}")
            await m5_auditor(symbol, base_time, redis, state)
            return

    if not candles:
        return

    m5_ts = candles[0]["ts"]
    o = candles[0]["o"]
    h = max(c["h"] for c in candles)
    l = min(c["l"] for c in candles)
    c = candles[-1]["c"]
    v = sum(c["v"] for c in candles)

    precision_price = state["tickers"][symbol]["precision_price"]
    precision_qty = state["tickers"][symbol]["precision_qty"]

    def r(val, p):
        return float(Decimal(val).quantize(Decimal(f"1e-{p}"), rounding=ROUND_DOWN))

    o, h, l, c = map(lambda x: r(x, precision_price), [o, h, l, c])
    v = r(v, precision_qty)

    await safe_ts_add(redis, f"ts:{symbol}:m5:o", m5_ts, o, "o", symbol, "m5")
    await safe_ts_add(redis, f"ts:{symbol}:m5:h", m5_ts, h, "h", symbol, "m5")
    await safe_ts_add(redis, f"ts:{symbol}:m5:l", m5_ts, l, "l", symbol, "m5")
    await safe_ts_add(redis, f"ts:{symbol}:m5:c", m5_ts, c, "c", symbol, "m5")
    await safe_ts_add(redis, f"ts:{symbol}:m5:v", m5_ts, v, "v", symbol, "m5")

    log.debug(f"[{symbol}] –ü–æ—Å—Ç—Ä–æ–µ–Ω–∞ M5: {datetime.utcfromtimestamp(m5_ts / 1000)} O:{o} H:{h} L:{l} C:{c}")

    # Stream: –ø–æ–ª–Ω–∞—è —Å–≤–µ—á–∞
    stream_event = {
        "symbol": symbol,
        "interval": "m5",
        "timestamp": str(m5_ts),
        "o": str(o),
        "h": str(h),
        "l": str(l),
        "c": str(c),
        "v": str(v)
    }
    await redis.xadd("ohlcv_stream", stream_event)

    # Pub/Sub: —Ç–æ–ª—å–∫–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
    pubsub_event = {
        "symbol": symbol,
        "interval": "m5",
        "timestamp": str(m5_ts)
    }
    await redis.publish("ohlcv_channel", json.dumps(pubsub_event))
# üî∏ –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∞—É–¥–∏—Ç M5: –∂–¥—ë—Ç –ø–æ—è–≤–ª–µ–Ω–∏—è –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö M1 –∏ —Å–æ–±–∏—Ä–∞–µ—Ç M5
async def m5_auditor(symbol, base_time, redis, state):
    timeout = 300  # 5 –º–∏–Ω—É—Ç
    interval = 10  # –æ–ø—Ä–∞—à–∏–≤–∞—Ç—å –∫–∞–∂–¥—ã–µ 10 —Å–µ–∫—É–Ω–¥
    deadline = datetime.utcnow() + timedelta(seconds=timeout)

    ts_list = [int((base_time + timedelta(minutes=i)).timestamp() * 1000) for i in range(5)]

    while datetime.utcnow() < deadline:
        try:
            candles = []
            for ts in ts_list:
                o = await redis.execute_command("TS.RANGE", f"ts:{symbol}:m1:o", ts, ts)
                h = await redis.execute_command("TS.RANGE", f"ts:{symbol}:m1:h", ts, ts)
                l = await redis.execute_command("TS.RANGE", f"ts:{symbol}:m1:l", ts, ts)
                c = await redis.execute_command("TS.RANGE", f"ts:{symbol}:m1:c", ts, ts)
                v = await redis.execute_command("TS.RANGE", f"ts:{symbol}:m1:v", ts, ts)

                if not all([o, h, l, c, v]):
                    break  # –µ—â—ë –Ω–µ –≤—Å–µ –µ—Å—Ç—å

                candles.append({
                    "ts": ts,
                    "o": float(o[0][1]),
                    "h": float(h[0][1]),
                    "l": float(l[0][1]),
                    "c": float(c[0][1]),
                    "v": float(v[0][1])
                })

            if len(candles) == 5:
                m5_ts = candles[0]["ts"]
                o = candles[0]["o"]
                h = max(c["h"] for c in candles)
                l = min(c["l"] for c in candles)
                c = candles[-1]["c"]
                v = sum(c["v"] for c in candles)

                # –ü–æ —Ç–æ—á–Ω–æ—Å—Ç–∏ –æ–∫—Ä—É–≥–ª—è–µ–º
                precision_price = state["tickers"][symbol]["precision_price"]
                precision_qty = state["tickers"][symbol]["precision_qty"]

                def r(val, p):
                    return float(Decimal(val).quantize(Decimal(f"1e-{p}"), rounding=ROUND_DOWN))

                o, h, l, c = map(lambda x: r(x, precision_price), [o, h, l, c])
                v = r(v, precision_qty)

                await safe_ts_add(redis, f"ts:{symbol}:m5:o", m5_ts, o, "o", symbol, "m5")
                await safe_ts_add(redis, f"ts:{symbol}:m5:h", m5_ts, h, "h", symbol, "m5")
                await safe_ts_add(redis, f"ts:{symbol}:m5:l", m5_ts, l, "l", symbol, "m5")
                await safe_ts_add(redis, f"ts:{symbol}:m5:c", m5_ts, c, "c", symbol, "m5")
                await safe_ts_add(redis, f"ts:{symbol}:m5:v", m5_ts, v, "v", symbol, "m5")

                stream_event = {
                    "symbol": symbol,
                    "interval": "m5",
                    "timestamp": str(m5_ts),
                    "o": str(o),
                    "h": str(h),
                    "l": str(l),
                    "c": str(c),
                    "v": str(v)
                }
                await redis.xadd("ohlcv_stream", stream_event)

                log.info(f"[{symbol}] M5 –∞—É–¥–∏—Ç: –ø–æ—Å—Ç—Ä–æ–µ–Ω–∞ –ø–æ—Å–ª–µ –æ–∂–∏–¥–∞–Ω–∏—è ‚Äî {datetime.utcfromtimestamp(m5_ts / 1000)}")
                return

            await asyncio.sleep(interval)

        except Exception as e:
            log.error(f"[{symbol}] –û—à–∏–±–∫–∞ –≤ m5_auditor: {e}", exc_info=True)
            return

    log.warning(f"[{symbol}] M5 –∞—É–¥–∏—Ç: —Ç–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è –¥–ª—è {base_time}")
# üî∏ –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å–≤–µ—á–∏ M15 –∏–∑ 15 M1 –≤ RedisTimeSeries
async def try_aggregate_m15(redis, symbol, base_time, state):
    end_ts = int(base_time.timestamp() * 1000) + 14 * 60_000 + 1
    ts_list = [end_ts - 1 - i * 60_000 for i in reversed(range(15))]
    candles = []

    for ts in ts_list:
        try:
            o, h, l, c, v = await asyncio.gather(
                redis.execute_command("TS.RANGE", f"ts:{symbol}:m1:o", ts, ts),
                redis.execute_command("TS.RANGE", f"ts:{symbol}:m1:h", ts, ts),
                redis.execute_command("TS.RANGE", f"ts:{symbol}:m1:l", ts, ts),
                redis.execute_command("TS.RANGE", f"ts:{symbol}:m1:c", ts, ts),
                redis.execute_command("TS.RANGE", f"ts:{symbol}:m1:v", ts, ts)
            )

            if not all([o, h, l, c, v]):
                raise ValueError("–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö")

            candles.append({
                "o": float(o[0][1]),
                "h": float(h[0][1]),
                "l": float(l[0][1]),
                "c": float(c[0][1]),
                "v": float(v[0][1]),
                "ts": ts
            })
        except Exception:
            log.warning(f"[{symbol}] –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å M15: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç M1 –¥–ª—è {base_time}")
            await m15_auditor(symbol, base_time, redis, state)
            return

    if not candles:
        return

    m15_ts = candles[0]["ts"]
    o = candles[0]["o"]
    h = max(c["h"] for c in candles)
    l = min(c["l"] for c in candles)
    c = candles[-1]["c"]
    v = sum(c["v"] for c in candles)

    precision_price = state["tickers"][symbol]["precision_price"]
    precision_qty = state["tickers"][symbol]["precision_qty"]

    def r(val, p):
        return float(Decimal(val).quantize(Decimal(f"1e-{p}"), rounding=ROUND_DOWN))

    o, h, l, c = map(lambda x: r(x, precision_price), [o, h, l, c])
    v = r(v, precision_qty)

    await safe_ts_add(redis, f"ts:{symbol}:m15:o", m15_ts, o, "o", symbol, "m15")
    await safe_ts_add(redis, f"ts:{symbol}:m15:h", m15_ts, h, "h", symbol, "m15")
    await safe_ts_add(redis, f"ts:{symbol}:m15:l", m15_ts, l, "l", symbol, "m15")
    await safe_ts_add(redis, f"ts:{symbol}:m15:c", m15_ts, c, "c", symbol, "m15")
    await safe_ts_add(redis, f"ts:{symbol}:m15:v", m15_ts, v, "v", symbol, "m15")

    log.debug(f"[{symbol}] –ü–æ—Å—Ç—Ä–æ–µ–Ω–∞ M15: {datetime.utcfromtimestamp(m15_ts / 1000)} O:{o} H:{h} L:{l} C:{c}")

    stream_event = {
        "symbol": symbol,
        "interval": "m15",
        "timestamp": str(m15_ts),
        "o": str(o),
        "h": str(h),
        "l": str(l),
        "c": str(c),
        "v": str(v)
    }
    await redis.xadd("ohlcv_stream", stream_event)

    pubsub_event = {
        "symbol": symbol,
        "interval": "m15",
        "timestamp": str(m15_ts)
    }
    await redis.publish("ohlcv_channel", json.dumps(pubsub_event))
# üî∏ –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∞—É–¥–∏—Ç M15: –∂–¥—ë—Ç –ø–æ—è–≤–ª–µ–Ω–∏—è –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö M1 –∏ —Å–æ–±–∏—Ä–∞–µ—Ç M15
async def m15_auditor(symbol, base_time, redis, state):
    timeout = 300  # 5 –º–∏–Ω—É—Ç
    interval = 10  # –∫–∞–∂–¥—ã–µ 10 —Å–µ–∫—É–Ω–¥
    deadline = datetime.utcnow() + timedelta(seconds=timeout)

    ts_list = [int((base_time + timedelta(minutes=i)).timestamp() * 1000) for i in range(15)]

    while datetime.utcnow() < deadline:
        try:
            candles = []
            for ts in ts_list:
                o = await redis.execute_command("TS.RANGE", f"ts:{symbol}:m1:o", ts, ts)
                h = await redis.execute_command("TS.RANGE", f"ts:{symbol}:m1:h", ts, ts)
                l = await redis.execute_command("TS.RANGE", f"ts:{symbol}:m1:l", ts, ts)
                c = await redis.execute_command("TS.RANGE", f"ts:{symbol}:m1:c", ts, ts)
                v = await redis.execute_command("TS.RANGE", f"ts:{symbol}:m1:v", ts, ts)

                if not all([o, h, l, c, v]):
                    break

                candles.append({
                    "ts": ts,
                    "o": float(o[0][1]),
                    "h": float(h[0][1]),
                    "l": float(l[0][1]),
                    "c": float(c[0][1]),
                    "v": float(v[0][1])
                })

            if len(candles) == 15:
                m15_ts = candles[0]["ts"]
                o = candles[0]["o"]
                h = max(c["h"] for c in candles)
                l = min(c["l"] for c in candles)
                c = candles[-1]["c"]
                v = sum(c["v"] for c in candles)

                precision_price = state["tickers"][symbol]["precision_price"]
                precision_qty = state["tickers"][symbol]["precision_qty"]

                def r(val, p):
                    return float(Decimal(val).quantize(Decimal(f"1e-{p}"), rounding=ROUND_DOWN))

                o, h, l, c = map(lambda x: r(x, precision_price), [o, h, l, c])
                v = r(v, precision_qty)

                await safe_ts_add(redis, f"ts:{symbol}:m15:o", m15_ts, o, "o", symbol, "m15")
                await safe_ts_add(redis, f"ts:{symbol}:m15:h", m15_ts, h, "h", symbol, "m15")
                await safe_ts_add(redis, f"ts:{symbol}:m15:l", m15_ts, l, "l", symbol, "m15")
                await safe_ts_add(redis, f"ts:{symbol}:m15:c", m15_ts, c, "c", symbol, "m15")
                await safe_ts_add(redis, f"ts:{symbol}:m15:v", m15_ts, v, "v", symbol, "m15")

                stream_event = {
                    "symbol": symbol,
                    "interval": "m15",
                    "timestamp": str(m15_ts),
                    "o": str(o),
                    "h": str(h),
                    "l": str(l),
                    "c": str(c),
                    "v": str(v)
                }
                await redis.xadd("ohlcv_stream", stream_event)

                log.info(f"[{symbol}] M15 –∞—É–¥–∏—Ç: –ø–æ—Å—Ç—Ä–æ–µ–Ω–∞ –ø–æ—Å–ª–µ –æ–∂–∏–¥–∞–Ω–∏—è ‚Äî {datetime.utcfromtimestamp(m15_ts / 1000)}")
                return

            await asyncio.sleep(interval)

        except Exception as e:
            log.error(f"[{symbol}] –û—à–∏–±–∫–∞ –≤ m15_auditor: {e}", exc_info=True)
            return

    log.warning(f"[{symbol}] M15 –∞—É–¥–∏—Ç: —Ç–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è –¥–ª—è {base_time}")
# üî∏ –ü–æ–∏—Å–∫ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö M1 –∏ –∑–∞–ø–∏—Å—å –≤ missing_m1_log_v4 + system_log_v4
# –ü–æ–∏—Å–∫ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö M1 –∏ –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ Binance API
async def detect_missing_m1(redis, pg, symbol, now_ts, state):
    depth_minutes = 15
    missing = []

    for i in range(1, depth_minutes + 1):
        ts = now_ts - i * 60_000
        open_time = datetime.utcfromtimestamp(ts / 1000)

        if open_time < state["activated_at"].get(symbol, datetime.min):
            continue

        try:
            result = await redis.execute_command("TS.RANGE", f"ts:{symbol}:m1:o", ts, ts)
            if not result:
                missing.append((ts, open_time))
        except Exception:
            missing.append((ts, open_time))

    async with pg.acquire() as conn:
        for ts, open_time in missing:
            try:
                await conn.execute(
                    "INSERT INTO missing_m1_log_v4 (symbol, open_time) VALUES ($1, $2) ON CONFLICT DO NOTHING",
                    symbol, open_time
                )
                await conn.execute(
                    "INSERT INTO system_log_v4 (module, level, message, details) VALUES ($1, $2, $3, $4)",
                    "AGGREGATOR", "WARNING", "M1 missing",
                    json.dumps({"symbol": symbol, "open_time": str(open_time)})
                )
                log.warning(f"[{symbol}] –ü—Ä–æ–ø—É—â–µ–Ω–∞ —Å–≤–µ—á–∞: {open_time}")
            except Exception as e:
                log.error(f"[{symbol}] –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –ø—Ä–æ–ø—É—Å–∫–∞: {e}")
                continue  # –Ω–µ –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º, –µ—Å–ª–∏ –Ω–µ —Å–º–æ–≥–ª–∏ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å

            # –í—ã–∑–æ–≤ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ —Ñ–∏–∫—Å–∞—Ü–∏–∏
            try:
                precision_price = state["tickers"][symbol]["precision_price"]
                precision_qty = state["tickers"][symbol]["precision_qty"]
                await restore_missing_m1(symbol, open_time, redis, pg, precision_price, precision_qty)
            except Exception as e:
                log.error(f"[{symbol}] –û—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ restore_missing_m1: {e}", exc_info=True)
# –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–¥–Ω–æ–π M1-—Å–≤–µ—á–∏ —á–µ—Ä–µ–∑ Binance API
async def restore_missing_m1(symbol, open_time, redis, pg, precision_price, precision_qty):
    ts = int(open_time.timestamp() * 1000)
    end_ts = ts + 60_000

    url = "https://fapi.binance.com/fapi/v1/klines"
    params = {
        "symbol": symbol.upper(),
        "interval": "1m",
        "startTime": ts,
        "endTime": end_ts,
        "limit": 1
    }

    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(url, params=params) as resp:
                if resp.status != 200:
                    log.error(f"[{symbol}] Binance API –æ—à–∏–±–∫–∞: {resp.status}")
                    return False

                raw = await resp.json()
                if not raw:
                    log.warning(f"[{symbol}] Binance API –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ –¥–ª—è {open_time}")
                    return False

                k = raw[0]
                o, h, l, c, v = k[1:6]

                def r(val, p):
                    return float(Decimal(val).quantize(Decimal(f"1e-{p}"), rounding=ROUND_DOWN))

                o = r(o, precision_price)
                h = r(h, precision_price)
                l = r(l, precision_price)
                c = r(c, precision_price)
                v = r(v, precision_qty)

                await safe_ts_add(redis, f"ts:{symbol}:m1:o", ts, o, "o", symbol, "m1")
                await safe_ts_add(redis, f"ts:{symbol}:m1:h", ts, h, "h", symbol, "m1")
                await safe_ts_add(redis, f"ts:{symbol}:m1:l", ts, l, "l", symbol, "m1")
                await safe_ts_add(redis, f"ts:{symbol}:m1:c", ts, c, "c", symbol, "m1")
                await safe_ts_add(redis, f"ts:{symbol}:m1:v", ts, v, "v", symbol, "m1")

                # –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ Stream
                stream_event = {
                    "symbol": symbol,
                    "interval": "m1",
                    "timestamp": str(ts),
                    "o": str(o),
                    "h": str(h),
                    "l": str(l),
                    "c": str(c),
                    "v": str(v)
                }
                await redis.xadd("ohlcv_stream", stream_event)

                # –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ Pub/Sub
                pubsub_event = {
                    "symbol": symbol,
                    "interval": "m1",
                    "timestamp": str(ts)
                }
                await redis.publish("ohlcv_channel", json.dumps(pubsub_event))

                async with pg.acquire() as conn:
                    await conn.execute(
                        "UPDATE missing_m1_log_v4 SET fixed = true, fixed_at = NOW() WHERE symbol = $1 AND open_time = $2",
                        symbol, open_time
                    )
                    await conn.execute(
                        "INSERT INTO system_log_v4 (module, level, message, details) VALUES ($1, $2, $3, $4)",
                        "AGGREGATOR", "INFO", "M1 restored",
                        json.dumps({"symbol": symbol, "open_time": str(open_time)})
                    )

                log.info(f"[{symbol}] –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ M1: {open_time}")
                return True

    except Exception as e:
        log.error(f"[{symbol}] –û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è —Å–≤–µ—á–∏: {e}", exc_info=True)
        return False
# üî∏ –°–ª—É—à–∞–µ—Ç WebSocket Binance –∏ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Ç–∏–∫–µ—Ä–æ–≤
async def listen_kline_stream(redis, state, refresh_queue):

    while True:
        if not state["active"]:
            log.debug("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤ –¥–ª—è –ø–æ–¥–ø–∏—Å–∫–∏")
            await asyncio.sleep(10)
            continue

        symbols = sorted(state["active"])
        streams = [f"{s}@kline_1m" for s in symbols]
        stream_url = f"wss://fstream.binance.com/stream?streams={'/'.join(streams)}"

        try:
            async with websockets.connect(stream_url) as ws:
                log.info(f"–ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ WebSocket Binance: {len(symbols)} —Ç–∏–∫–µ—Ä–æ–≤")

                async def reader():
                    try:
                        async for msg in ws:
                            data = json.loads(msg)
                            if "data" not in data or "k" not in data["data"]:
                                continue
                            kline = data["data"]["k"]
                            if not kline["x"]:
                                continue
                            symbol = kline["s"]
                            open_time = datetime.utcfromtimestamp(kline["t"] / 1000)

                            await store_and_publish_m1(
                                redis,
                                symbol,
                                open_time,
                                kline,
                                state["tickers"][symbol]["precision_price"],
                                state["tickers"][symbol]["precision_qty"],
                                state
                            )

                    except Exception as e:
                        log.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è WebSocket: {e}", exc_info=True)

                async def watcher():
                    await refresh_queue.get()
                    log.info("–ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è WebSocket")
                    await ws.close()

                reader_task = asyncio.create_task(reader())
                watcher_task = asyncio.create_task(watcher())
                await asyncio.wait([reader_task, watcher_task], return_when=asyncio.FIRST_COMPLETED)

        except Exception as e:
            log.error(f"–û—à–∏–±–∫–∞ WebSocket: {e}", exc_info=True)
            await asyncio.sleep(5)
# üî∏ –ü–æ—Ç–æ–∫ markPrice –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–∏–∫–µ—Ä–∞ —Å fstream.binance.com
async def watch_mark_price(symbol, redis, state):
    log.debug(f"[{symbol}] DEBUG | type(state): {type(state)}, keys: {list(state.keys())}")

    url = f"wss://fstream.binance.com/ws/{symbol.lower()}@markPrice@1s"
    last_update = 0

    while True:
        try:
            async with websockets.connect(url) as ws:
                log.info(f"[{symbol}] –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ø–æ—Ç–æ–∫—É markPrice (futures)")
                async for msg in ws:
                    try:
                        data = json.loads(msg)
                        price = data.get("p")
                        if not price:
                            continue

                        now = time.time()
                        if now - last_update < 1:
                            continue

                        last_update = now
                        precision = state["tickers"][symbol]["precision_price"]
                        rounded = str(
                            Decimal(price).quantize(Decimal(f"1e-{precision}"), rounding=ROUND_DOWN)
                        )
                        await redis.set(f"price:{symbol}", rounded)
                        log.debug(f"[{symbol}] –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ markPrice: {rounded}")

                    except (InvalidOperation, ValueError, TypeError) as e:
                        log.warning(f"[{symbol}] –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ markPrice: {type(e)}")

        except Exception as e:
            log.error(f"[{symbol}] –û—à–∏–±–∫–∞ WebSocket markPrice (futures): {e}", exc_info=True)
            await asyncio.sleep(5)
# –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—É—Å–∫ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ —Å —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º —Ç–∞—Å–∫–∞–º–∏
async def run_feed_and_aggregator(pg, redis):

    # –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Ç–∏–∫–µ—Ä–æ–≤ (enabled + disabled)
    tickers, active = await load_all_tickers(pg)
    log.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ç–∏–∫–µ—Ä–æ–≤: {len(tickers)} ‚Üí {list(tickers.keys())}")

    for s in tickers:
        if s.lower() in active:
            log.info(f"–ê–∫—Ç–∏–≤–µ–Ω –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {s}")
        else:
            log.info(f"–í—ã–∫–ª—é—á–µ–Ω –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {s}")

    # –û–±—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    state = {
        "tickers": tickers,            # symbol -> {precision_price, precision_qty}
        "active": active,              # set of lowercase symbols
        "markprice_tasks": {},         # symbol -> asyncio.Task
        "tasks": set(),                # –≤—Å–µ —Ñ–æ–Ω–æ–≤—ã–µ —Ç–∞—Å–∫–∏
        "activated_at": {}             # symbol -> datetime.utcnow()
    }

    # –û—á–µ—Ä–µ–¥—å —Å–∏–≥–Ω–∞–ª–æ–≤ –Ω–∞ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ WebSocket
    refresh_queue = asyncio.Queue()

    # –•–µ–ª–ø–µ—Ä –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã—Ö —Ç–∞—Å–æ–∫
    def create_tracked_task(coro, name):
        task = asyncio.create_task(coro)
        state["tasks"].add(task)
        def on_done(t):
            try:
                t.result()
            except asyncio.CancelledError:
                log.info(f"[{name}] Task cancelled")
            except Exception as e:
                log.exception(f"[{name}] Task crashed: {e}")
            finally:
                state["tasks"].discard(t)
        task.add_done_callback(on_done)
        return task

    # –ó–∞–ø—É—Å–∫ –ø–æ–¥–ø–∏—Å–∫–∏ –Ω–∞ Redis Stream
    create_tracked_task(handle_ticker_events(redis, state, pg, refresh_queue), "ticker_events")

    # –ó–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫–æ–≤ markPrice –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ç–∏–∫–µ—Ä–∞ (—Ñ—å—é—á–µ—Ä—Å–Ω—ã–π —Ä—ã–Ω–æ–∫)
    for symbol in state["active"]:
        upper_symbol = symbol.upper()
        if upper_symbol in state["tickers"]:
            task = create_tracked_task(
                watch_mark_price(upper_symbol, redis, state),
                f"markprice_{upper_symbol}"
            )
            state["markprice_tasks"][upper_symbol] = task

    # –§–æ–Ω–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö M1-—Å–≤–µ—á–µ–π
    async def recovery_loop():
        while True:
            now_ts = int((datetime.utcnow() - timedelta(minutes=1)).replace(second=0, microsecond=0).timestamp() * 1000)
            for symbol in state["active"]:
                await detect_missing_m1(redis, pg, symbol.upper(), now_ts, state)
            await asyncio.sleep(60)

    create_tracked_task(recovery_loop(), "recovery_loop")

    # –ü–æ—Å—Ç–æ—è–Ω–Ω—ã–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Å–ª—É—à–∞—Ç–µ–ª—è WebSocket
    async def loop_listen():
        while True:
            await listen_kline_stream(redis, state, refresh_queue)

    create_tracked_task(loop_listen(), "listen_kline")

    # –¶–∏–∫–ª –æ–∂–∏–¥–∞–Ω–∏—è (–º–æ–∂–Ω–æ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ watchdog –∏–ª–∏ —Ç–æ—á–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è)
    try:
        while True:
            await asyncio.sleep(5)
    except asyncio.CancelledError:
        log.info("Aggregator shutdown requested, cancelling tasks...")
        for t in list(state["tasks"]):
            t.cancel()
        await asyncio.gather(*state["tasks"], return_exceptions=True)
        log.info("All tasks shut down cleanly.")