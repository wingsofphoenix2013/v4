# feed_and_aggregate.py ‚Äî –ø—Ä–∏—ë–º –∏ –∞–≥—Ä–µ–≥–∞—Ü–∏—è —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö - 22/05/2025 (–Ω–æ–≤—ã–π)

import logging
import asyncio
import websockets
import json
import aiohttp
from infra import setup_logging
from decimal import Decimal, ROUND_DOWN, InvalidOperation
import time
from datetime import datetime, timedelta

# –ü–æ–ª—É—á–∞–µ–º –ª–æ–≥–≥–µ—Ä –¥–ª—è –º–æ–¥—É–ª—è
log = logging.getLogger("FEED+AGGREGATOR")

# üî∏ –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Ç–∏–∫–µ—Ä–æ–≤, —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏ —Å—Ç–∞—Ç—É—Å–∞ –∏–∑ PostgreSQL
async def load_all_tickers(pg_pool):
    async with pg_pool.acquire() as conn:
        rows = await conn.fetch("""
            SELECT symbol, precision_price, precision_qty, status FROM tickers_v4
        """)
        tickers = {}
        active = set()
        for row in rows:
            tickers[row['symbol']] = {
                "precision_price": row["precision_price"],
                "precision_qty": row["precision_qty"]
            }
            if row['status'] == 'enabled':
                active.add(row['symbol'].lower())
        return tickers, active
# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–±—ã—Ç–∏–π –≤–∫–ª—é—á–µ–Ω–∏—è/–æ—Ç–∫–ª—é—á–µ–Ω–∏—è —Ç–∏–∫–µ—Ä–æ–≤ —á–µ—Ä–µ–∑ Redis Stream
async def handle_ticker_events(redis, state, pg, refresh_queue):
    group = "aggregator_group"
    stream = "tickers_status_stream"

    try:
        await redis.xgroup_create(stream, group, id="0", mkstream=True)
    except Exception:
        pass  # –≥—Ä—É–ø–ø–∞ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç

    while True:
        resp = await redis.xreadgroup(group, "aggregator", streams={stream: ">"}, count=50, block=1000)
        for _, messages in resp:
            for msg_id, data in messages:
                symbol = data.get("symbol")
                action = data.get("action")
                if not symbol or not action:
                    continue

                if symbol not in state["tickers"]:
                    async with pg.acquire() as conn:
                        row = await conn.fetchrow("""
                            SELECT precision_price, precision_qty FROM tickers_v4 WHERE symbol = $1
                        """, symbol)
                        if row:
                            state["tickers"][symbol] = {
                                "precision_price": row["precision_price"],
                                "precision_qty": row["precision_qty"]
                            }
                            log.info(f"–î–æ–±–∞–≤–ª–µ–Ω —Ç–∏–∫–µ—Ä –∏–∑ –ë–î: {symbol}")

                if action == "enabled" and symbol in state["tickers"]:
                    log.info(f"–ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω —Ç–∏–∫–µ—Ä: {symbol}")
                    state["active"].add(symbol.lower())
                    state["activated_at"][symbol] = datetime.utcnow()
                    await refresh_queue.put("refresh")

                    # –∑–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫–∞ markPrice –∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏
                    task = asyncio.create_task(watch_mark_price(symbol, redis, state))
                    state["markprice_tasks"][symbol] = task

                elif action == "disabled" and symbol in state["tickers"]:
                    log.info(f"–û—Ç–∫–ª—é—á—ë–Ω —Ç–∏–∫–µ—Ä: {symbol}")
                    state["active"].discard(symbol.lower())
                    await refresh_queue.put("refresh")

                    # –æ—Ç–º–µ–Ω–∞ –ø–æ—Ç–æ–∫–∞ markPrice, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
                    task = state["markprice_tasks"].pop(symbol, None)
                    if task:
                        task.cancel()

                await redis.xack(stream, group, msg_id)
# üî∏ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–π —Å–≤–µ—á–∏ M1 –≤ RedisTimeSeries + Stream + Pub/Sub
async def store_and_publish_m1(redis, symbol, open_time, kline, precision_price, precision_qty):
    ts = int(open_time.timestamp() * 1000)

    def r(val, precision):
        return float(Decimal(val).quantize(Decimal(f"1e-{precision}"), rounding=ROUND_DOWN))

    o = r(kline["o"], precision_price)
    h = r(kline["h"], precision_price)
    l = r(kline["l"], precision_price)
    c = r(kline["c"], precision_price)
    v = r(kline["v"], precision_qty)

    async def safe_ts_add(field_key, value, field_name):
        try:
            await redis.execute_command("TS.ADD", field_key, ts, value)
        except Exception as e:
            if "TSDB: the key does not exist" in str(e):
                await redis.execute_command(
                    "TS.CREATE", field_key,
                    "RETENTION", 2592000000,  # 30 –¥–Ω–µ–π
                    "DUPLICATE_POLICY", "last",
                    "LABELS",
                    "symbol", symbol,
                    "interval", "m1",
                    "field", field_name
                )
                await redis.execute_command("TS.ADD", field_key, ts, value)
            else:
                raise

    await safe_ts_add(f"ts:{symbol}:m1:o", o, "o")
    await safe_ts_add(f"ts:{symbol}:m1:h", h, "h")
    await safe_ts_add(f"ts:{symbol}:m1:l", l, "l")
    await safe_ts_add(f"ts:{symbol}:m1:c", c, "c")
    await safe_ts_add(f"ts:{symbol}:m1:v", v, "v")

    log.info(f"[{symbol}] M1 TS —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: ts={ts} O={o} H={h} L={l} C={c} V={v}")

    event = {
        "symbol": symbol,
        "interval": "m1",
        "timestamp": str(ts)
    }

    await redis.xadd("ohlcv_stream", event)
    await redis.publish("ohlcv_channel", json.dumps(event))
# üî∏ –ü–æ–ø—ã—Ç–∫–∞ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å —Å–≤–µ—á—É M5 –∏–∑ 5 M1 –≤ RedisTimeSeries
async def try_aggregate_m5(redis, symbol, base_time, state):
    end_ts = int(base_time.timestamp() * 1000) + 4 * 60_000
    ts_list = [end_ts - i * 60_000 for i in reversed(range(5))]
    candles = []

    for ts in ts_list:
        try:
            o = await redis.execute_command("TS.GET", f"ts:{symbol}:m1:o", ts)
            h = await redis.execute_command("TS.GET", f"ts:{symbol}:m1:h", ts)
            l = await redis.execute_command("TS.GET", f"ts:{symbol}:m1:l", ts)
            c = await redis.execute_command("TS.GET", f"ts:{symbol}:m1:c", ts)
            v = await redis.execute_command("TS.GET", f"ts:{symbol}:m1:v", ts)

            if not all([o, h, l, c, v]):
                return

            candles.append({
                "o": float(o[1]),
                "h": float(h[1]),
                "l": float(l[1]),
                "c": float(c[1]),
                "v": float(v[1]),
                "ts": ts
            })
        except Exception:
            return

    if not candles:
        return

    m5_ts = ts_list[0]
    o = candles[0]["o"]
    h = max(c["h"] for c in candles)
    l = min(c["l"] for c in candles)
    c = candles[-1]["c"]
    v = sum(c["v"] for c in candles)

    # –û–∫—Ä—É–≥–ª–µ–Ω–∏–µ –ø–æ —Ç–æ—á–Ω–æ—Å—Ç–∏
    precision_price = state["tickers"][symbol]["precision_price"]
    precision_qty = state["tickers"][symbol]["precision_qty"]

    def r(val, p):
        return float(Decimal(val).quantize(Decimal(f"1e-{p}"), rounding=ROUND_DOWN))

    o, h, l, c = map(lambda x: r(x, precision_price), [o, h, l, c])
    v = r(v, precision_qty)

    async def safe_ts_add(key, value, field):
        try:
            await redis.execute_command("TS.ADD", key, m5_ts, value)
        except Exception as e:
            if "TSDB: the key does not exist" in str(e):
                await redis.execute_command(
                    "TS.CREATE", key,
                    "RETENTION", 2592000000,
                    "DUPLICATE_POLICY", "last",
                    "LABELS",
                    "symbol", symbol,
                    "interval", "m5",
                    "field", field
                )
                await redis.execute_command("TS.ADD", key, m5_ts, value)
            else:
                raise

    await safe_ts_add(f"ts:{symbol}:m5:o", o, "o")
    await safe_ts_add(f"ts:{symbol}:m5:h", h, "h")
    await safe_ts_add(f"ts:{symbol}:m5:l", l, "l")
    await safe_ts_add(f"ts:{symbol}:m5:c", c, "c")
    await safe_ts_add(f"ts:{symbol}:m5:v", v, "v")

    log.info(f"[{symbol}] –ü–æ—Å—Ç—Ä–æ–µ–Ω–∞ M5: {datetime.utcfromtimestamp(m5_ts / 1000)} O:{o} H:{h} L:{l} C:{c}")
# üî∏ –§–æ–Ω–æ–≤–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è M5
async def aggregate_m5_loop(redis, state):
    while True:
        now = datetime.utcnow()
        if now.minute % 5 == 0:
            now -= timedelta(minutes=1)

        base_minute = (now.minute // 5) * 5
        base_time = now.replace(minute=base_minute, second=0, microsecond=0)

        for symbol in state["active"]:
            await try_aggregate_m5(redis, symbol.upper(), base_time, state)

        await asyncio.sleep(60)
# üî∏ –ü–æ–ø—ã—Ç–∫–∞ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å —Å–≤–µ—á—É M15 –∏–∑ 15 M1 –≤ RedisTimeSeries
async def try_aggregate_m15(redis, symbol, base_time, state):
    end_ts = int(base_time.timestamp() * 1000) + 14 * 60_000
    ts_list = [end_ts - i * 60_000 for i in reversed(range(15))]
    candles = []

    for ts in ts_list:
        try:
            o = await redis.execute_command("TS.GET", f"ts:{symbol}:m1:o", ts)
            h = await redis.execute_command("TS.GET", f"ts:{symbol}:m1:h", ts)
            l = await redis.execute_command("TS.GET", f"ts:{symbol}:m1:l", ts)
            c = await redis.execute_command("TS.GET", f"ts:{symbol}:m1:c", ts)
            v = await redis.execute_command("TS.GET", f"ts:{symbol}:m1:v", ts)

            if not all([o, h, l, c, v]):
                return

            candles.append({
                "o": float(o[1]),
                "h": float(h[1]),
                "l": float(l[1]),
                "c": float(c[1]),
                "v": float(v[1]),
                "ts": ts
            })
        except Exception:
            return

    if not candles:
        return

    m15_ts = ts_list[0]
    o = candles[0]["o"]
    h = max(c["h"] for c in candles)
    l = min(c["l"] for c in candles)
    c = candles[-1]["c"]
    v = sum(c["v"] for c in candles)

    # –û–∫—Ä—É–≥–ª–µ–Ω–∏–µ
    precision_price = state["tickers"][symbol]["precision_price"]
    precision_qty = state["tickers"][symbol]["precision_qty"]

    def r(val, p):
        return float(Decimal(val).quantize(Decimal(f"1e-{p}"), rounding=ROUND_DOWN))

    o, h, l, c = map(lambda x: r(x, precision_price), [o, h, l, c])
    v = r(v, precision_qty)

    async def safe_ts_add(key, value, field):
        try:
            await redis.execute_command("TS.ADD", key, m15_ts, value)
        except Exception as e:
            if "TSDB: the key does not exist" in str(e):
                await redis.execute_command(
                    "TS.CREATE", key,
                    "RETENTION", 2592000000,
                    "DUPLICATE_POLICY", "last",
                    "LABELS",
                    "symbol", symbol,
                    "interval", "m15",
                    "field", field
                )
                await redis.execute_command("TS.ADD", key, m15_ts, value)
            else:
                raise

    await safe_ts_add(f"ts:{symbol}:m15:o", o, "o")
    await safe_ts_add(f"ts:{symbol}:m15:h", h, "h")
    await safe_ts_add(f"ts:{symbol}:m15:l", l, "l")
    await safe_ts_add(f"ts:{symbol}:m15:c", c, "c")
    await safe_ts_add(f"ts:{symbol}:m15:v", v, "v")

    log.info(f"[{symbol}] –ü–æ—Å—Ç—Ä–æ–µ–Ω–∞ M15: {datetime.utcfromtimestamp(m15_ts / 1000)} O:{o} H:{h} L:{l} C:{c}")
# üî∏ –§–æ–Ω–æ–≤–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è M15
async def aggregate_m15_loop(redis, state):
    while True:
        now = datetime.utcnow()
        if now.minute % 15 == 0:
            now -= timedelta(minutes=1)

        base_minute = (now.minute // 15) * 15
        base_time = now.replace(minute=base_minute, second=0, microsecond=0)

        for symbol in state["active"]:
            await try_aggregate_m15(redis, symbol.upper(), base_time, state)

        await asyncio.sleep(60)
# üî∏ –ü–æ–∏—Å–∫ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö M1 –∏ –∑–∞–ø–∏—Å—å –≤ missing_m1_log_v4 + system_log_v4
async def detect_missing_m1(redis, pg, symbol, now_ts, state):
    missing = []

    for i in range(1, 16):  # –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 15 –º–∏–Ω—É—Ç
        ts = now_ts - i * 60 * 1000
        open_time = datetime.utcfromtimestamp(ts / 1000)

        # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å, –µ—Å–ª–∏ —Å–≤–µ—á–∞ —Ä–∞–Ω—å—à–µ –º–æ–º–µ–Ω—Ç–∞ –≤–∫–ª—é—á–µ–Ω–∏—è —Ç–∏–∫–µ—Ä–∞
        if open_time < state["activated_at"].get(symbol, datetime.min):
            continue

        try:
            exists = await redis.execute_command("TS.GET", f"ts:{symbol}:m1:o", ts)
            if not exists:
                missing.append(ts)
        except Exception:
            missing.append(ts)

    async with pg.acquire() as conn:
        for ts in missing:
            open_time = datetime.utcfromtimestamp(ts / 1000)
            try:
                await conn.execute(
                    "INSERT INTO missing_m1_log_v4 (symbol, open_time) VALUES ($1, $2) ON CONFLICT DO NOTHING",
                    symbol, open_time
                )
                await conn.execute(
                    "INSERT INTO system_log_v4 (module, level, message, details) VALUES ($1, $2, $3, $4)",
                    "AGGREGATOR", "WARNING", "M1 missing",
                    json.dumps({"symbol": symbol, "open_time": str(open_time)})
                )
                log.warning(f"[{symbol}] –ü—Ä–æ–ø—É—â–µ–Ω–∞ —Å–≤–µ—á–∞: {open_time}")
            except Exception as e:
                log.error(f"[{symbol}] –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –ø—Ä–æ–ø—É—Å–∫–∞: {e}")
# üî∏ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–¥–Ω–æ–π M1 —Å–≤–µ—á–∏ —á–µ—Ä–µ–∑ Binance API + Redis TS + –æ—Ç–º–µ—Ç–∫–∞ –≤ –ë–î
async def restore_missing_m1(symbol, open_time, redis, pg, precision_price, precision_qty):
    ts = int(open_time.timestamp() * 1000)
    end_ts = ts + 60_000

    url = "https://fapi.binance.com/fapi/v1/klines"
    params = {
        "symbol": symbol.upper(),
        "interval": "1m",
        "startTime": ts,
        "endTime": end_ts,
        "limit": 1
    }

    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(url, params=params) as resp:
                if resp.status != 200:
                    log.error(f"[{symbol}] Binance API error: {resp.status}")
                    return False

                raw = await resp.json()
                if not raw:
                    log.warning(f"[{symbol}] Binance API –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
                    return False

                data = raw[0]
                o, h, l, c, v = data[1:6]
                timestamp = int(data[0])

                def r(val, p):
                    return float(Decimal(val).quantize(Decimal(f"1e-{p}"), rounding=ROUND_DOWN))

                await redis.execute_command("TS.ADD", f"ts:{symbol}:m1:o", timestamp, r(o, precision_price))
                await redis.execute_command("TS.ADD", f"ts:{symbol}:m1:h", timestamp, r(h, precision_price))
                await redis.execute_command("TS.ADD", f"ts:{symbol}:m1:l", timestamp, r(l, precision_price))
                await redis.execute_command("TS.ADD", f"ts:{symbol}:m1:c", timestamp, r(c, precision_price))
                await redis.execute_command("TS.ADD", f"ts:{symbol}:m1:v", timestamp, r(v, precision_qty))

                async with pg.acquire() as conn:
                    await conn.execute(
                        "UPDATE missing_m1_log_v4 SET fixed = true, fixed_at = NOW() WHERE symbol = $1 AND open_time = $2",
                        symbol, open_time
                    )
                    await conn.execute(
                        "INSERT INTO system_log_v4 (module, level, message, details) VALUES ($1, $2, $3, $4)",
                        "AGGREGATOR", "INFO", "M1 restored",
                        json.dumps({"symbol": symbol, "open_time": str(open_time)})
                    )

                log.info(f"[{symbol}] –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ M1: {open_time}")
                return True

    except Exception as e:
        log.error(f"[{symbol}] –û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è —á–µ—Ä–µ–∑ API: {e}", exc_info=True)
        return False
# üî∏ –°–ª—É—à–∞–µ—Ç WebSocket Binance –∏ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Ç–∏–∫–µ—Ä–æ–≤
async def listen_kline_stream(redis, state, refresh_queue):

    while True:
        if not state["active"]:
            log.info("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤ –¥–ª—è –ø–æ–¥–ø–∏—Å–∫–∏")
            await asyncio.sleep(10)
            continue

        symbols = sorted(state["active"])
        streams = [f"{s}@kline_1m" for s in symbols]
        stream_url = f"wss://fstream.binance.com/stream?streams={'/'.join(streams)}"

        try:
            async with websockets.connect(stream_url) as ws:
                log.info(f"–ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ WebSocket Binance: {len(symbols)} —Ç–∏–∫–µ—Ä–æ–≤")

                async def reader():
                    try:
                        async for msg in ws:
                            data = json.loads(msg)
                            if "data" not in data or "k" not in data["data"]:
                                continue
                            kline = data["data"]["k"]
                            if not kline["x"]:
                                continue
                            symbol = kline["s"]
                            open_time = datetime.utcfromtimestamp(kline["t"] / 1000)

                            await store_and_publish_m1(
                                redis,
                                symbol,
                                open_time,
                                kline,
                                state["tickers"][symbol]["precision_price"],
                                state["tickers"][symbol]["precision_qty"]
                            )

                    except Exception as e:
                        log.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è WebSocket: {e}", exc_info=True)

                async def watcher():
                    await refresh_queue.get()
                    log.info("–ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è WebSocket")
                    await ws.close()

                reader_task = asyncio.create_task(reader())
                watcher_task = asyncio.create_task(watcher())
                await asyncio.wait([reader_task, watcher_task], return_when=asyncio.FIRST_COMPLETED)

        except Exception as e:
            log.error(f"–û—à–∏–±–∫–∞ WebSocket: {e}", exc_info=True)
            await asyncio.sleep(5)
# üî∏ –ü–æ—Ç–æ–∫ markPrice –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–∏–∫–µ—Ä–∞ —Å fstream.binance.com
async def watch_mark_price(symbol, redis, state):
    log.debug(f"[{symbol}] DEBUG | type(state): {type(state)}, keys: {list(state.keys())}")

    url = f"wss://fstream.binance.com/ws/{symbol.lower()}@markPrice@1s"
    last_update = 0

    while True:
        try:
            async with websockets.connect(url) as ws:
                log.info(f"[{symbol}] –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ø–æ—Ç–æ–∫—É markPrice (futures)")
                async for msg in ws:
                    try:
                        data = json.loads(msg)
                        price = data.get("p")
                        if not price:
                            continue

                        now = time.time()
                        if now - last_update < 1:
                            continue

                        last_update = now
                        precision = state["tickers"][symbol]["precision_price"]
                        rounded = str(
                            Decimal(price).quantize(Decimal(f"1e-{precision}"), rounding=ROUND_DOWN)
                        )
                        await redis.set(f"price:{symbol}", rounded)
                        log.debug(f"[{symbol}] –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ markPrice: {rounded}")

                    except (InvalidOperation, ValueError, TypeError) as e:
                        log.warning(f"[{symbol}] –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ markPrice: {type(e)}")

        except Exception as e:
            log.error(f"[{symbol}] –û—à–∏–±–∫–∞ WebSocket markPrice (futures): {e}", exc_info=True)
            await asyncio.sleep(5)
# üî∏ –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—É—Å–∫ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ —Å —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º —Ç–∞—Å–∫–∞–º–∏
async def run_feed_and_aggregator(pg, redis):

    # –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Ç–∏–∫–µ—Ä–æ–≤ (enabled + disabled)
    tickers, active = await load_all_tickers(pg)
    log.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ç–∏–∫–µ—Ä–æ–≤: {len(tickers)} ‚Üí {list(tickers.keys())}")

    for s in tickers:
        if s.lower() in active:
            log.info(f"–ê–∫—Ç–∏–≤–µ–Ω –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {s}")
        else:
            log.info(f"–í—ã–∫–ª—é—á–µ–Ω –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {s}")

    # –û–±—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    state = {
        "tickers": tickers,            # symbol -> {precision_price, precision_qty}
        "active": active,              # set of lowercase symbols
        "markprice_tasks": {},         # symbol -> asyncio.Task
        "tasks": set(),                # –≤—Å–µ —Ñ–æ–Ω–æ–≤—ã–µ —Ç–∞—Å–∫–∏
        "activated_at": {}             # symbol -> datetime.utcnow()
    }

    # –û—á–µ—Ä–µ–¥—å —Å–∏–≥–Ω–∞–ª–æ–≤ –Ω–∞ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ WebSocket
    refresh_queue = asyncio.Queue()

    # –•–µ–ª–ø–µ—Ä –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã—Ö —Ç–∞—Å–æ–∫
    def create_tracked_task(coro, name):
        task = asyncio.create_task(coro)
        state["tasks"].add(task)
        def on_done(t):
            try:
                t.result()
            except asyncio.CancelledError:
                log.info(f"[{name}] Task cancelled")
            except Exception as e:
                log.exception(f"[{name}] Task crashed: {e}")
            finally:
                state["tasks"].discard(t)
        task.add_done_callback(on_done)
        return task

    # –ó–∞–ø—É—Å–∫ –ø–æ–¥–ø–∏—Å–∫–∏ –Ω–∞ Redis Stream
    create_tracked_task(handle_ticker_events(redis, state, pg, refresh_queue), "ticker_events")

    # –ó–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫–æ–≤ markPrice –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ç–∏–∫–µ—Ä–∞ (—Ñ—å—é—á–µ—Ä—Å–Ω—ã–π —Ä—ã–Ω–æ–∫)
    for symbol in state["active"]:
        upper_symbol = symbol.upper()
        if upper_symbol in state["tickers"]:
            task = create_tracked_task(
                watch_mark_price(upper_symbol, redis, state),
                f"markprice_{upper_symbol}"
            )
            state["markprice_tasks"][upper_symbol] = task

    # üî∏ –§–æ–Ω–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö M1-—Å–≤–µ—á–µ–π
    async def recovery_loop():
        while True:
            now_ts = int((datetime.utcnow() - timedelta(minutes=1)).replace(second=0, microsecond=0).timestamp() * 1000)
            for symbol in state["active"]:
                await detect_missing_m1(redis, pg, symbol.upper(), now_ts, state)
            await asyncio.sleep(60)

    create_tracked_task(recovery_loop(), "recovery_loop")
    
    # üî∏ –§–æ–Ω–æ–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ú5
    create_tracked_task(aggregate_m5_loop(redis, state), "aggregate_m5_loop")
    
    # üî∏ –§–æ–Ω–æ–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ú15
    create_tracked_task(aggregate_m15_loop(redis, state), "aggregate_m15_loop")
    
    # üî∏ –§–æ–Ω–æ–≤–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö M1 —á–µ—Ä–µ–∑ Binance API
    async def restore_loop():
        while True:
            async with pg.acquire() as conn:
                rows = await conn.fetch("""
                    SELECT symbol, open_time FROM missing_m1_log_v4
                    WHERE fixed IS NOT true
                    ORDER BY open_time ASC
                """)

            for row in rows:
                symbol = row["symbol"]
                open_time = row["open_time"]
                try:
                    precision_price = state["tickers"][symbol]["precision_price"]
                    precision_qty   = state["tickers"][symbol]["precision_qty"]
                except KeyError:
                    continue  # —Å–∏–º–≤–æ–ª –Ω–µ –≤ state ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º

                await restore_missing_m1(symbol, open_time, redis, pg, precision_price, precision_qty)

            await asyncio.sleep(60)

    create_tracked_task(restore_loop(), "restore_loop")
    
    # –ü–æ—Å—Ç–æ—è–Ω–Ω—ã–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Å–ª—É—à–∞—Ç–µ–ª—è WebSocket
    async def loop_listen():
        while True:
            await listen_kline_stream(redis, state, refresh_queue)

    create_tracked_task(loop_listen(), "listen_kline")

    # –¶–∏–∫–ª –æ–∂–∏–¥–∞–Ω–∏—è (–º–æ–∂–Ω–æ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ watchdog –∏–ª–∏ —Ç–æ—á–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è)
    try:
        while True:
            await asyncio.sleep(5)
    except asyncio.CancelledError:
        log.info("Aggregator shutdown requested, cancelling tasks...")
        for t in list(state["tasks"]):
            t.cancel()
        await asyncio.gather(*state["tasks"], return_exceptions=True)
        log.info("All tasks shut down cleanly.")