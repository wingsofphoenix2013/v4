# feed_and_aggregate.py ‚Äî –ø—Ä–∏—ë–º –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ M1 –∏ M5 —Å–≤–µ—á–µ–π —Å —Ä–µ–∞–∫—Ç–∏–≤–Ω—ã–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º
import asyncio
import logging
import time
import json
from asyncpg import Pool
from redis.asyncio import Redis
from datetime import datetime
from websockets import connect
from itertools import islice
from decimal import Decimal, ROUND_DOWN

log = logging.getLogger("FEED+AGGREGATOR")

# üî∏ –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Ç–∏–∫–µ—Ä–æ–≤ –∏–∑ –ë–î
async def load_all_tickers(pg: Pool):
    async with pg.acquire() as conn:
        rows = await conn.fetch("SELECT symbol, precision_price, precision_qty, status FROM tickers_v4")

    now = time.time()
    tickers = {}
    active = set()
    activated_at = {}

    for row in rows:
        symbol = row["symbol"]
        tickers[symbol] = {
            "precision_price": row["precision_price"],
            "precision_qty": row["precision_qty"]
        }

        if row["status"] == "enabled":
            active.add(symbol)
            activated_at[symbol] = now
            log.info(f"[{symbol}] –ê–∫—Ç–∏–≤–µ–Ω –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî activated_at={datetime.utcfromtimestamp(now).isoformat()}Z")
        else:
            log.info(f"[{symbol}] –ù–µ–∞–∫—Ç–∏–≤–µ–Ω –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")

    return tickers, active, activated_at

# üî∏ –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –≤–∫–ª—é—á–µ–Ω–∏—è/–≤—ã–∫–ª—é—á–µ–Ω–∏—è —Ç–∏–∫–µ—Ä–æ–≤ —á–µ—Ä–µ–∑ Redis Stream
async def handle_ticker_events(
    redis: Redis,
    state: dict,
    pg: Pool,
    refresh_queue_m1: asyncio.Queue,
    refresh_queue_m5: asyncio.Queue,
    refresh_queue_m15: asyncio.Queue,
    refresh_queue_h1: asyncio.Queue
):
    group = "aggregator_group"
    stream = "tickers_status_stream"

    try:
        await redis.xgroup_create(stream, group, id='0', mkstream=True)
    except Exception:
        pass

    while True:
        resp = await redis.xreadgroup(group, "aggregator", streams={stream: '>'}, count=50, block=1000)
        for _, messages in resp:
            for msg_id, data in messages:
                symbol = data.get("symbol")
                action = data.get("action")

                if not symbol or not action:
                    continue

                if symbol not in state["tickers"]:
                    async with pg.acquire() as conn:
                        row = await conn.fetchrow(
                            "SELECT precision_price, precision_qty FROM tickers_v4 WHERE symbol = $1",
                            symbol
                        )
                        if row:
                            state["tickers"][symbol] = {
                                "precision_price": row["precision_price"],
                                "precision_qty": row["precision_qty"]
                            }
                            log.debug(f"[{symbol}] –î–æ–±–∞–≤–ª–µ–Ω —Ç–∏–∫–µ—Ä –∏–∑ –ë–î")

                if action == "enabled" and symbol in state["tickers"]:
                    state["active"].add(symbol)
                    ts = time.time()
                    state["activated_at"][symbol] = ts
                    log.info(f"[{symbol}] –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω —Ç–∏–∫–µ—Ä ‚Äî activated_at={datetime.utcfromtimestamp(ts).isoformat()}Z")
                    await refresh_queue_m1.put("refresh")
                    await refresh_queue_m5.put("refresh")
                    await refresh_queue_m15.put("refresh")
                    await refresh_queue_h1.put("refresh")

                elif action == "disabled" and symbol in state["active"]:
                    state["active"].remove(symbol)
                    log.info(f"[{symbol}] –î–µ–∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω —Ç–∏–∫–µ—Ä")
                    await refresh_queue_m1.put("refresh")
                    await refresh_queue_m5.put("refresh")
                    await refresh_queue_m15.put("refresh")
                    await refresh_queue_h1.put("refresh")

# üî∏ –†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–∏–∫–µ—Ä–æ–≤ –Ω–∞ –≥—Ä—É–ø–ø—ã
def chunked(iterable, size):
    it = iter(iterable)
    while chunk := list(islice(it, size)):
        yield chunk

# üî∏ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ WebSocket Binance –ø–æ –≥—Ä—É–ø–ø–µ —Ç–∏–∫–µ—Ä–æ–≤
async def listen_kline_stream(group_key, symbols, queue, interval="1m"):
    stream_names = [f"{s.lower()}@kline_{interval}" for s in symbols]
    stream_url = f"wss://fstream.binance.com/stream?streams={'/'.join(stream_names)}"

    while True:
        try:
            async with connect(
                stream_url,
                ping_interval=None,  # –æ—Ç–∫–ª—é—á–∞–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ ping/pong
                close_timeout=5
            ) as ws:
                log.info(f"[KLINE:{group_key}] –ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ WebSocket: {stream_url}")

                # üü° Keep-alive —á–µ—Ä–µ–∑ —Ä—É—á–Ω–æ–π pong
                async def keep_alive():
                    try:
                        while True:
                            await ws.pong()
                            log.debug(f"[KLINE:{group_key}] ‚Üí pong (keepalive)")
                            await asyncio.sleep(180)
                    except asyncio.CancelledError:
                        log.debug(f"[KLINE:{group_key}] keep_alive –∑–∞–≤–µ—Ä—à—ë–Ω")
                    except Exception as e:
                        log.warning(f"[KLINE:{group_key}] –û—à–∏–±–∫–∞ keep_alive: {e}")

                pong_task = asyncio.create_task(keep_alive())

                try:
                    async for msg in ws:
                        data = json.loads(msg)
                        kline = data.get("data", {}).get("k")
                        if not kline or not kline.get("x"):
                            continue
                        await queue.put(kline)
                finally:
                    pong_task.cancel()

        except Exception as e:
            log.error(f"[KLINE:{group_key}] –û—à–∏–±–∫–∞ WebSocket: {e}", exc_info=True)
            log.info(f"[KLINE:{group_key}] –ü–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ 5 —Å–µ–∫—É–Ω–¥...")
            await asyncio.sleep(5)

# üî∏ –í–æ—Ä–∫–µ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–≤–µ—á–µ–π
async def kline_worker(queue, state, redis, interval="M1"):
    while True:
        kline = await queue.get()
        try:
            symbol = kline["s"]
            open_time = datetime.utcfromtimestamp(kline["t"] / 1000)

            precision_price = state["tickers"][symbol]["precision_price"]
            precision_qty = state["tickers"][symbol]["precision_qty"]

            await store_and_publish_kline(
                redis=redis,
                symbol=symbol,
                open_time=open_time,
                kline=kline,
                interval=interval.lower(),
                precision_price=precision_price,
                precision_qty=precision_qty
            )
        except Exception as e:
            log.warning(f"[{interval}] –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–≤–µ—á–∏ {symbol}: {e}", exc_info=True)

# üî∏ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ Redis
async def store_and_publish_kline(redis, symbol, open_time, kline, interval, precision_price, precision_qty):
    ts = int(open_time.timestamp() * 1000)

    o = float(kline["o"])
    h = float(kline["h"])
    l = float(kline["l"])
    c = float(kline["c"])
    v = float(Decimal(kline["v"]).quantize(Decimal(f"1e-{precision_qty}"), rounding=ROUND_DOWN))

    async def safe_ts_add(field_key, value, field_name):
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º: —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –∫–ª—é—á
            try:
                await redis.execute_command("TS.INFO", field_key)
            except Exception:
                # –ï—Å–ª–∏ –Ω–µ—Ç ‚Äî —Å–æ–∑–¥–∞—ë–º
                await redis.execute_command(
                    "TS.CREATE", field_key,
                    "RETENTION", 5184000000,  # 2 –º–µ—Å—è—Ü–∞
                    "DUPLICATE_POLICY", "last",
                    "LABELS",
                    "symbol", symbol,
                    "interval", interval,
                    "field", field_name
                )

            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
            await redis.execute_command("TS.ADD", field_key, ts, value)

        except Exception as e:
            log.warning(f"[{symbol}] –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ TS.ADD {field_key}: {e}")

    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∑–∞–ø–∏—Å—å –≤—Å–µ—Ö –ø–æ–ª–µ–π
    await asyncio.gather(
        safe_ts_add(f"ts:{symbol}:{interval}:o", o, "o"),
        safe_ts_add(f"ts:{symbol}:{interval}:h", h, "h"),
        safe_ts_add(f"ts:{symbol}:{interval}:l", l, "l"),
        safe_ts_add(f"ts:{symbol}:{interval}:c", c, "c"),
        safe_ts_add(f"ts:{symbol}:{interval}:v", v, "v"),
    )

    log.debug(f"[{symbol}] {interval.upper()} TS –∑–∞–ø–∏—Å–∞–Ω–∞: open_time={open_time}, –∑–∞–≤–µ—Ä—à–µ–Ω–æ={datetime.utcnow()}")

    # –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ Redis Stream
    await redis.xadd("ohlcv_stream", {
        "symbol": symbol,
        "interval": interval,
        "timestamp": str(ts),
        "o": str(o),
        "h": str(h),
        "l": str(l),
        "c": str(c),
        "v": str(v),
    })
    log.debug(f"[{symbol}] {interval.upper()} –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ –≤ Redis Stream: open_time={open_time}, –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ={datetime.utcnow()}")

    # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ Pub/Sub
    await redis.publish("ohlcv_channel", json.dumps({
        "symbol": symbol,
        "interval": interval,
        "timestamp": str(ts)
    }))
# üî∏ M1: –†–µ–∞–∫—Ç–∏–≤–Ω—ã–π –∑–∞–ø—É—Å–∫ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ WebSocket-–≥—Ä—É–ø–ø–∞–º–∏
async def run_feed_and_aggregator(state, redis: Redis, pg: Pool, refresh_queue: asyncio.Queue):
    log.debug("üî∏ –ó–∞–ø—É—Å–∫ –ø—Ä–∏—ë–º–∞ M1 —Å–≤–µ—á–µ–π —Å —Ä–µ–∞–∫—Ç–∏–≤–Ω—ã–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º")
    queue = asyncio.Queue()
    state["kline_tasks"] = {}

    for _ in range(5):
        asyncio.create_task(kline_worker(queue, state, redis, interval="M1"))

    await refresh_queue.put("initial")

    while True:
        await refresh_queue.get()
        log.debug("üîÅ –ü–µ—Ä–µ—Å–±–æ—Ä–∫–∞ –≥—Ä—É–ø–ø WebSocket –ø–æ—Å–ª–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤")

        active_symbols = sorted(state["active"])
        log.info(f"[M1] –í—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤: {len(active_symbols)} ‚Üí {active_symbols}")
        new_groups = {
            f"M1:{','.join(group)}": group
            for group in chunked(active_symbols, 3)
        }
        current_groups = set(state["kline_tasks"].keys())
        desired_groups = set(new_groups.keys())

        for group_key in desired_groups - current_groups:
            group_symbols = new_groups[group_key]
            task = asyncio.create_task(listen_kline_stream(group_key, group_symbols, queue, interval="1m"))
            state["kline_tasks"][group_key] = task

        for group_key in current_groups - desired_groups:
            task = state["kline_tasks"].pop(group_key)
            task.cancel()
            log.debug(f"[KLINE:{group_key}] –ü–æ—Ç–æ–∫ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Äî —Ç–∏–∫–µ—Ä—ã –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã")

# üî∏ M5: –†–µ–∞–∫—Ç–∏–≤–Ω—ã–π –∑–∞–ø—É—Å–∫ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ M5 —Å–≤–µ—á–µ–π
async def run_feed_and_aggregator_m5(state, redis: Redis, pg: Pool, refresh_queue: asyncio.Queue):
    log.debug("üî∏ –ó–∞–ø—É—Å–∫ –ø—Ä–∏—ë–º–∞ M5 —Å–≤–µ—á–µ–π")
    queue = asyncio.Queue()
    state["m5_tasks"] = {}

    for _ in range(2):
        asyncio.create_task(kline_worker(queue, state, redis, interval="M5"))

    await refresh_queue.put("initial-m5")

    while True:
        await refresh_queue.get()
        log.debug("üîÅ [M5] –ü–µ—Ä–µ—Å–±–æ—Ä–∫–∞ –≥—Ä—É–ø–ø WebSocket")

        active_symbols = sorted(state["active"])
        log.info(f"[M5] –í—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤: {len(active_symbols)} ‚Üí {active_symbols}")
        new_groups = {
            f"M5:{','.join(group)}": group
            for group in chunked(active_symbols, 3)
        }
        current_groups = set(state["m5_tasks"].keys())
        desired_groups = set(new_groups.keys())

        for group_key in desired_groups - current_groups:
            group_symbols = new_groups[group_key]
            task = asyncio.create_task(listen_kline_stream(group_key, group_symbols, queue, interval="5m"))
            state["m5_tasks"][group_key] = task

        for group_key in current_groups - desired_groups:
            task = state["m5_tasks"].pop(group_key)
            task.cancel()
            log.debug(f"[KLINE:M5:{group_key}] –ü–æ—Ç–æ–∫ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Äî —Ç–∏–∫–µ—Ä—ã –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã")

# üî∏ M15: –†–µ–∞–∫—Ç–∏–≤–Ω—ã–π –∑–∞–ø—É—Å–∫ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ M15 —Å–≤–µ—á–µ–π
async def run_feed_and_aggregator_m15(state, redis: Redis, pg: Pool, refresh_queue: asyncio.Queue):
    log.debug("üî∏ –ó–∞–ø—É—Å–∫ –ø—Ä–∏—ë–º–∞ M15 —Å–≤–µ—á–µ–π")
    queue = asyncio.Queue()
    state["m15_tasks"] = {}

    for _ in range(2):
        asyncio.create_task(kline_worker(queue, state, redis, interval="M15"))

    await refresh_queue.put("initial-m15")

    while True:
        await refresh_queue.get()
        log.debug("üîÅ [M15] –ü–µ—Ä–µ—Å–±–æ—Ä–∫–∞ –≥—Ä—É–ø–ø WebSocket")

        active_symbols = sorted(state["active"])
        log.info(f"[M15] –í—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤: {len(active_symbols)} ‚Üí {active_symbols}")

        new_groups = {
            f"M15:{','.join(group)}": group
            for group in chunked(active_symbols, 3)
        }
        current_groups = set(state["m15_tasks"].keys())
        desired_groups = set(new_groups.keys())

        for group_key in desired_groups - current_groups:
            group_symbols = new_groups[group_key]
            task = asyncio.create_task(listen_kline_stream(group_key, group_symbols, queue, interval="15m"))
            state["m15_tasks"][group_key] = task

        for group_key in current_groups - desired_groups:
            task = state["m15_tasks"].pop(group_key)
            task.cancel()
            log.debug(f"[KLINE:M15:{group_key}] –ü–æ—Ç–æ–∫ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Äî —Ç–∏–∫–µ—Ä—ã –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã")
# üî∏ H1: –†–µ–∞–∫—Ç–∏–≤–Ω—ã–π –∑–∞–ø—É—Å–∫ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ H1 —Å–≤–µ—á–µ–π
async def run_feed_and_aggregator_h1(state, redis: Redis, pg: Pool, refresh_queue: asyncio.Queue):
    log.debug("üî∏ –ó–∞–ø—É—Å–∫ –ø—Ä–∏—ë–º–∞ H1 —Å–≤–µ—á–µ–π")
    queue = asyncio.Queue()
    state["h1_tasks"] = {}

    for _ in range(2):
        asyncio.create_task(kline_worker(queue, state, redis, interval="H1"))

    await refresh_queue.put("initial-h1")

    while True:
        await refresh_queue.get()
        log.debug("üîÅ [H1] –ü–µ—Ä–µ—Å–±–æ—Ä–∫–∞ –≥—Ä—É–ø–ø WebSocket")

        active_symbols = sorted(state["active"])
        log.info(f"[H1] –í—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤: {len(active_symbols)} ‚Üí {active_symbols}")

        new_groups = {
            f"H1:{','.join(group)}": group
            for group in chunked(active_symbols, 3)
        }
        current_groups = set(state["h1_tasks"].keys())
        desired_groups = set(new_groups.keys())

        for group_key in desired_groups - current_groups:
            group_symbols = new_groups[group_key]
            task = asyncio.create_task(listen_kline_stream(group_key, group_symbols, queue, interval="1h"))
            state["h1_tasks"][group_key] = task

        for group_key in current_groups - desired_groups:
            task = state["h1_tasks"].pop(group_key)
            task.cancel()
            log.debug(f"[KLINE:H1:{group_key}] –ü–æ—Ç–æ–∫ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Äî —Ç–∏–∫–µ—Ä—ã –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã")
            