# indicator_position_snapshot.py ‚Äî –≤–æ—Ä–∫–µ—Ä —Å–Ω–∏–º–∫–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –Ω–∞ –º–æ–º–µ–Ω—Ç –æ—Ç–∫—Ä—ã—Ç–∏—è –ø–æ–∑–∏—Ü–∏–∏ (—ç—Ç–∞–ø 1: m5, param_type=indicator)

import asyncio
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List, Tuple, Optional

# üî∏ –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã —Å—Ç—Ä–∏–º–æ–≤ –∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫
POSITIONS_OPEN_STREAM = "positions_open_stream"      # –≤—Ö–æ–¥–Ω–æ–π —Å—Ç—Ä–∏–º –≤–Ω–µ—à–Ω–µ–≥–æ –º–æ–¥—É–ª—è (–æ—Ç–∫—Ä—ã—Ç–∏–µ –ø–æ–∑–∏—Ü–∏–∏)

IND_REQ_STREAM   = "indicator_request"               # on-demand –∑–∞–ø—Ä–æ—Å—ã –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
IND_RESP_STREAM  = "indicator_response"              # on-demand –æ—Ç–≤–µ—Ç—ã –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ (–æ–±—â–∏–π —Å—Ç—Ä–∏–º —Å–∏—Å—Ç–µ–º—ã)
RESP_GROUP       = "ips_resp_group"                  # –Ω–∞—à–∞ consumer-group –Ω–∞ –æ—Ç–≤–µ—Ç–∞—Ö (—Ç–æ–ª—å–∫–æ —ç—Ç–æ—Ç –≤–æ—Ä–∫–µ—Ä)
RESP_CONSUMER    = "ips_resp_consumer_1"

IPS_GROUP        = "ips_group"                       # consumer-group –¥–ª—è –ø–æ–∑–∏—Ü–∏–π
IPS_CONSUMER     = "ips_consumer_1"

# üî∏ –¢–∞–π–º–∏–Ω–≥–∏/–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
READ_BLOCK_MS             = 1500                     # –±–ª–æ–∫–∏—Ä—É—é—â–µ–µ —á—Ç–µ–Ω–∏–µ –∏–∑ —Å—Ç—Ä–∏–º–æ–≤ (–º—Å)
REQ_RESPONSE_TIMEOUT_MS   = 5000                     # –æ–±—â–∏–π —Ç–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ (–º—Å) –Ω–∞ –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞
SECOND_TRY_TIMEOUT_MS     = 3000                     # —Ç–∞–π–º–∞—É—Ç –≤—Ç–æ—Ä–æ–π –ø–æ–ø—ã—Ç–∫–∏ (–º—Å) –ø—Ä–∏ –ø–µ—Ä–≤–∏—á–Ω–æ–º timeout
PARALLEL_REQUESTS_LIMIT   = 20                       # –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã on-demand
BATCH_INSERT_MAX          = 500                      # –º–∞–∫—Å. —Ä–∞–∑–º–µ—Ä –ø–∞—á–∫–∏ –¥–ª—è INSERT

# üî∏ –¢–∞–π–º—à–∞–≥–∏ TF (—ç—Ç–∞–ø 1 ‚Äî —Ç–æ–ª—å–∫–æ m5)
STEP_MIN = {"m5": 5}
STEP_MS  = {k: v * 60_000 for k, v in STEP_MIN.items()}

# üî∏ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–æ—É—Ç–µ—Ä–∞ –æ—Ç–≤–µ—Ç–æ–≤
PENDING_TTL_SEC           = 15                       # TTL –¥–ª—è ¬´–æ–∂–∏–¥–∞—é—â–∏—Ö¬ª —Å–æ–æ–±—â–µ–Ω–∏–π (–≤ –ø–∞–º—è—Ç–∏)
XAUTOCLAIM_MIN_IDLE_MS    = 2000                     # —Å–æ–æ–±—â–µ–Ω–∏—è —Å—Ç–∞—Ä—à–µ —ç—Ç–æ–≥–æ idle —Å—á–∏—Ç–∞–µ–º ¬´–ø—Ä–æ—Ç—É—Ö—à–∏–º–∏¬ª –∏ –∑–∞–±–∏—Ä–∞–µ–º
XAUTOCLAIM_BATCH          = 200                      # –∑–∞ —Ä–∞–∑ –ø–æ–¥–±–∏—Ä–∞—Ç—å –Ω–µ –±–æ–ª—å—à–µ N —Å–æ–æ–±—â–µ–Ω–∏–π
PENDING_MAX_IN_MEMORY     = 20000                    # –º—è–≥–∫–∏–π –ª–∏–º–∏—Ç –Ω–∞ –±—É—Ñ–µ—Ä pending

# üî∏ –õ–æ–≥–≥–µ—Ä
log = logging.getLogger("IND_POSSTAT")


# üî∏ –£—Ç–∏–ª–∏—Ç—ã –≤—Ä–µ–º–µ–Ω–∏/–ø–∞—Ä—Å–∏–Ω–≥–∞
def floor_to_bar(ts_ms: int, tf: str) -> int:
    step = STEP_MS[tf]
    return (ts_ms // step) * step

def parse_iso_to_ms(iso_str: str) -> Optional[int]:
    try:
        dt = datetime.fromisoformat(iso_str)  # UTC-naive ISO –æ–∂–∏–¥–∞–µ—Ç—Å—è —Å–∏—Å—Ç–µ–º–æ–π
        return int(dt.timestamp() * 1000)
    except Exception:
        return None

def to_float_safe(s: str) -> Optional[float]:
    try:
        return float(s)
    except Exception:
        return None

# üî∏ –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑–æ–≤–æ–≥–æ –∏–º–µ–Ω–∏ –¥–ª—è param_type='indicator'
def indicator_base_from_param_name(param_name: str) -> str:
    """
    –ü—Ä–∞–≤–∏–ª–æ: –≤ param_base –¥–ª—è indicators –ø–∏—à–µ–º —É–∫–æ—Ä–æ—á–µ–Ω–Ω—ã–π —Ç–∏–ø –±–µ–∑ –¥–ª–∏–Ω—ã:
      ema21 -> ema, rsi14 -> rsi, atr14 -> atr, kama30 -> kama,
      bb20_2_0_upper -> bb, macd12_macd -> macd, adx_dmi21_plus_di -> adx_dmi, lr50_angle -> lr.
    """
    if param_name.startswith("adx_dmi"):
        return "adx_dmi"
    for prefix in ("ema", "rsi", "mfi", "atr", "kama", "macd", "bb", "lr"):
        if param_name.startswith(prefix):
            return prefix
    return param_name.split("_", 1)[0]

def indicator_base_from_instance(inst: Dict[str, Any]) -> str:
    ind = str(inst.get("indicator", "indicator"))
    return "adx_dmi" if ind.startswith("adx_dmi") else ind


# üî∏ –†–æ—É—Ç–µ—Ä –æ—Ç–≤–µ—Ç–æ–≤ indicator_response (–≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–æ—Å—Ç–∞–≤–∫–∞ –±–µ–∑ –ø–æ—Ç–µ—Ä—å)
class IndicatorResponseRouter:
    """
    –û–¥–∏–Ω —Ñ–æ–Ω–æ–≤–æ–π —á–∏—Ç–∞—Ç–µ–ª—å XREADGROUP –ø–æ IND_RESP_STREAM/RESP_GROUP.
    –î–∏—Å–ø–µ—Ç—á–µ—Ä–∏–∑—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ req_id –≤ asyncio.Queue.
    –í–ê–ñ–ù–û: ¬´–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ¬ª req_id –Ω–µ ACK-–∞–µ–º; —Å–∫–ª–∞–¥—ã–≤–∞–µ–º –≤ pending –∏
    –æ—Ç–¥–∞—ë–º –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—é –ø—Ä–∏ register(req_id), –ø–æ—Å–ª–µ —á–µ–≥–æ ACK.
    –¢–∞–∫–∂–µ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –∑–∞–±–∏—Ä–∞–µ–º ¬´–ø—Ä–æ—Ç—É—Ö—à–∏–µ¬ª —Å–æ–æ–±—â–µ–Ω–∏—è —á–µ—Ä–µ–∑ XAUTOCLAIM.
    """
    def __init__(self, redis):
        self.redis = redis
        self._queues: Dict[str, asyncio.Queue] = {}                 # req_id -> Queue
        self._pending: Dict[str, Tuple[str, Dict[str, Any], float]] = {}  # req_id -> (msg_id, data, put_time_monotonic)
        self._reader_task: Optional[asyncio.Task] = None
        self._reclaimer_task: Optional[asyncio.Task] = None
        self._janitor_task: Optional[asyncio.Task] = None
        self._started = False
        self._lock = asyncio.Lock()

    async def start(self):
        if self._started:
            return
        # —Å–æ–∑–¥–∞—Ç—å –≥—Ä—É–ø–ø—É (–∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ)
        try:
            await self.redis.xgroup_create(IND_RESP_STREAM, RESP_GROUP, id="$", mkstream=True)
        except Exception as e:
            if "BUSYGROUP" not in str(e):
                log.warning(f"xgroup_create (resp) error: {e}")
        self._reader_task   = asyncio.create_task(self._reader_loop())
        self._reclaimer_task= asyncio.create_task(self._reclaim_loop())
        self._janitor_task  = asyncio.create_task(self._janitor_loop())
        self._started = True
        log.debug("IND_POSSTAT: response router started")

    async def _reader_loop(self):
        while True:
            try:
                resp = await self.redis.xreadgroup(
                    groupname=RESP_GROUP,
                    consumername=RESP_CONSUMER,
                    streams={IND_RESP_STREAM: ">"},
                    count=200,
                    block=READ_BLOCK_MS
                )
                if not resp:
                    continue

                ack_ids: List[str] = []
                now_mono = asyncio.get_event_loop().time()

                for _, messages in resp:
                    for msg_id, data in messages:
                        req_id = data.get("req_id")
                        if not req_id:
                            # –Ω–µ—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ ‚Äî ACK —Å—Ä–∞–∑—É
                            ack_ids.append(msg_id)
                            continue

                        q = self._queues.get(req_id)
                        if q is not None:
                            # –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å —É–∂–µ –∂–¥—ë—Ç ‚Äî –¥–æ—Å—Ç–∞–≤–ª—è–µ–º –∏ ACK
                            try:
                                q.put_nowait((msg_id, data))
                                ack_ids.append(msg_id)
                            except Exception:
                                # –æ—á–µ—Ä–µ–¥—å –∑–∞–∫—Ä—ã—Ç–∞/–ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∞ ‚Äî –±—É—Ñ–µ—Ä–∏–∑—É–µ–º –±–µ–∑ ACK
                                self._pending[req_id] = (msg_id, data, now_mono)
                        else:
                            # –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å –µ—â—ë –Ω–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–ª—Å—è ‚Äî –±—É—Ñ–µ—Ä–∏–∑—É–µ–º –±–µ–∑ ACK
                            if len(self._pending) < PENDING_MAX_IN_MEMORY:
                                self._pending[req_id] = (msg_id, data, now_mono)
                            else:
                                # –º—è–≥–∫–∏–π –Ω–∞–ø–æ–º–∏–Ω–∞—Ç–µ–ª—å –≤ –ª–æ–≥–∞—Ö; –Ω–µ ACK-–∞–µ–º, —á—Ç–æ–±—ã –Ω–µ –ø–æ—Ç–µ—Ä—è—Ç—å
                                log.warning("IND_POSSTAT: pending buffer full, message buffered without ACK; size=%d", len(self._pending))
                                self._pending[req_id] = (msg_id, data, now_mono)

                if ack_ids:
                    await self.redis.xack(IND_RESP_STREAM, RESP_GROUP, *ack_ids)

            except Exception as e:
                log.error(f"IND_POSSTAT: resp router read error: {e}", exc_info=True)
                await asyncio.sleep(0.3)

    async def _reclaim_loop(self):
        """
        –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –ø–æ–¥–±–∏—Ä–∞–µ–º ¬´–ø—Ä–æ—Ç—É—Ö—à–∏–µ¬ª —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ PEL (–ø–æ—Å–ª–µ —Ä–µ—Å—Ç–∞—Ä—Ç–æ–≤/—Å–±–æ–µ–≤).
        """
        last_id = "0-0"
        while True:
            try:
                # XAUTOCLAIM —Å min-idle ‚Äî –≤–µ—Ä–Ω—ë—Ç –Ω–∞–º —Å–æ–æ–±—â–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –¥–∞–≤–Ω–æ –ª–µ–∂–∞—Ç –≤ PEL
                claimed = await self.redis.execute_command(
                    "XAUTOCLAIM", IND_RESP_STREAM, RESP_GROUP, RESP_CONSUMER,
                    XAUTOCLAIM_MIN_IDLE_MS, last_id, "COUNT", XAUTOCLAIM_BATCH
                )
                # –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞: [<next-id>, [[msg_id, {field:val...}], ...]]
                next_id, entries = claimed[0], claimed[1]
                now_mono = asyncio.get_event_loop().time()
                for msg_id, data in entries:
                    req_id = data.get("req_id")
                    if not req_id:
                        # –Ω–µ–∫–æ—Ä—Ä–µ–ª–∏—Ä—É–µ–º—ã–µ ‚Äî —Å—Ä–∞–∑—É ACK
                        await self.redis.xack(IND_RESP_STREAM, RESP_GROUP, msg_id)
                        continue
                    if req_id in self._queues:
                        # –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å —É–∂–µ –∂–¥—ë—Ç ‚Äî –¥—Ä–æ–ø–∞–µ–º –≤ –æ—á–µ—Ä–µ–¥—å –∏ ACK
                        try:
                            self._queues[req_id].put_nowait((msg_id, data))
                            await self.redis.xack(IND_RESP_STREAM, RESP_GROUP, msg_id)
                        except Exception:
                            self._pending[req_id] = (msg_id, data, now_mono)
                    else:
                        # –±—É—Ñ–µ—Ä–∏–∑—É–µ–º –±–µ–∑ ACK (–¥–æ—Å—Ç–∞–≤–∏–º –∏ ACK-–Ω–µ–º –ø—Ä–∏ register)
                        self._pending[req_id] = (msg_id, data, now_mono)

                last_id = next_id or last_id
            except Exception as e:
                log.warning(f"IND_POSSTAT: resp router reclaim error: {e}", exc_info=True)
            finally:
                await asyncio.sleep(1.0)

    async def _janitor_loop(self):
        """
        –£–±–æ—Ä—â–∏–∫ —Å–∏–ª—å–Ω–æ –ø—Ä–æ—Ç—É—Ö—à–∏—Ö pending: –ª–æ–≥–∏—Ä—É–µ–º –∏ –ø—Ä–æ–¥–ª–µ–≤–∞–µ–º –∂–∏–∑–Ω—å.
        –ù–µ ACK-–∞–µ–º –¥–æ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏, —á—Ç–æ–±—ã –Ω–µ —Ç–µ—Ä—è—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è.
        """
        while True:
            try:
                now_mono = asyncio.get_event_loop().time()
                stale = [rid for rid, (_, _, put_ts) in self._pending.items()
                         if now_mono - put_ts > PENDING_TTL_SEC]
                if stale:
                    log.warning("IND_POSSTAT: pending entries stale=%d (kept unacked, waiting for register)", len(stale))
                # –ù–∏—á–µ–≥–æ –Ω–µ —É–¥–∞–ª—è–µ–º –∏ –Ω–µ ACK-–∞–µ–º ‚Äî –∂–¥—ë–º —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–π
            except Exception:
                pass
            finally:
                await asyncio.sleep(5.0)

    async def register(self, req_id: str) -> asyncio.Queue:
        async with self._lock:
            q = asyncio.Queue(maxsize=1)
            self._queues[req_id] = q
            # –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç —É–∂–µ –ø—Ä–∏—à—ë–ª –∏ –ª–µ–∂–∏—Ç –≤ pending ‚Äî –æ—Ç–¥–∞—ë–º –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ –∏ ACK
            pending = self._pending.pop(req_id, None)
            if pending:
                msg_id, data, _ = pending
                try:
                    q.put_nowait((msg_id, data))
                    await self.redis.xack(IND_RESP_STREAM, RESP_GROUP, msg_id)
                except Exception:
                    # –µ—Å–ª–∏ –æ—á–µ—Ä–µ–¥—å –Ω–µ –ø—Ä–∏–Ω—è–ª–∞ ‚Äî –≤–µ—Ä–Ω—ë–º –æ–±—Ä–∞—Ç–Ω–æ –≤ pending –±–µ–∑ ACK
                    self._pending[req_id] = (msg_id, data, asyncio.get_event_loop().time())
            return q

    async def unregister(self, req_id: str):
        async with self._lock:
            self._queues.pop(req_id, None)


# üî∏ –û—Ç–ø—Ä–∞–≤–∫–∞ on-demand –∑–∞–ø—Ä–æ—Å–∞ –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ –æ–±—â–∏–π —Ä–æ—É—Ç–µ—Ä (—Å 1 —Ä–µ—Ç—Ä–∞–µ–º)
async def request_indicator_snapshot(
    redis,
    router: IndicatorResponseRouter,
    *,
    symbol: str,
    timeframe: str,
    instance_id: int,
    timestamp_ms: int
) -> Tuple[str, Dict[str, Any]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (status, payload), –≥–¥–µ:
      - status: "ok" –∏–ª–∏ —É–∑–∫–∏–π –∫–æ–¥ –æ—à–∏–±–∫–∏ ("timeout","no_ohlcv","instance_not_active",
                "symbol_not_active","before_enabled_at","no_values","bad_request","exception","stream_error")
      - payload: –ø—Ä–∏ ok ‚Üí {"open_time": <iso>, "results": {param_name: str_value, ...}}
    """
    async def one_try(wait_ms: int) -> Tuple[str, Dict[str, Any]]:
        fields = {
            "symbol": symbol,
            "timeframe": timeframe,
            "instance_id": str(instance_id),
            "timestamp_ms": str(timestamp_ms),
        }
        try:
            req_id = await redis.xadd(IND_REQ_STREAM, fields)
        except Exception:
            log.warning("stream_error: XADD indicator_request failed", exc_info=True)
            return "stream_error", {}

        q = await router.register(req_id)
        try:
            try:
                msg_id, data = await asyncio.wait_for(q.get(), timeout=wait_ms / 1000.0)
            except asyncio.TimeoutError:
                return "timeout", {}

            status = data.get("status", "error")
            if status != "ok":
                return data.get("error", "exception"), {}

            try:
                open_time = data.get("open_time") or ""
                results_raw = data.get("results") or "{}"
                results = json.loads(results_raw)
                return "ok", {"open_time": open_time, "results": results}
            except Exception:
                return "exception", {}
        finally:
            await router.unregister(req_id)

    # –ø–µ—Ä–≤–∞—è –ø–æ–ø—ã—Ç–∫–∞
    st, pl = await one_try(REQ_RESPONSE_TIMEOUT_MS)
    if st != "timeout":
        return st, pl
    # –≤—Ç–æ—Ä–∞—è –ø–æ–ø—ã—Ç–∫–∞ –Ω–∞ —Å–ª—É—á–∞–π —Ä–µ–¥–∫–æ–π –∑–∞–¥–µ—Ä–∂–∫–∏
    log.info("IND_POSSTAT: retry on timeout for instance_id=%s symbol=%s tf=%s", instance_id, symbol, timeframe)
    return await one_try(SECOND_TRY_TIMEOUT_MS)


# üî∏ –°–±–æ—Ä —Å—Ç—Ä–æ–∫ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–Ω—Å—Ç–∞–Ω—Å–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞ (—ç—Ç–∞–ø 1: —Ç–æ–ª—å–∫–æ m5)
async def build_rows_for_instance(
    redis,
    router: IndicatorResponseRouter,
    *,
    symbol: str,
    tf: str,
    instance: Dict[str, Any],
    bar_open_ms: int,
    strategy_id: int,
    position_uid: str
) -> List[Tuple]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ –≤ indicator_position_stat.
    –ü–æ—Ä—è–¥–æ–∫ –ø–æ–ª–µ–π –∫–æ—Ä—Ç–µ–∂–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç VALUES ($1..$12) –≤ run_insert_batch().
    """
    instance_id = int(instance["id"])
    status, payload = await request_indicator_snapshot(
        redis,
        router,
        symbol=symbol,
        timeframe=tf,
        instance_id=instance_id,
        timestamp_ms=bar_open_ms
    )

    rows: List[Tuple] = []

    if status != "ok":
        # –ø—Ä–∏ –æ—à–∏–±–∫–µ –ø–∏—à–µ–º –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É —Å —É–∫–æ—Ä–æ—á–µ–Ω–Ω–æ–π –±–∞–∑–æ–π (–±–µ–∑ –¥–ª–∏–Ω—ã)
        base_short = indicator_base_from_instance(instance)
        open_time_dt = datetime.utcfromtimestamp(bar_open_ms / 1000)
        rows.append((
            position_uid,                 # position_uid
            strategy_id,                  # strategy_id
            symbol,                       # symbol
            tf,                           # timeframe
            "indicator",                  # param_type
            base_short,                   # param_base (–±–µ–∑ –¥–ª–∏–Ω—ã)
            base_short,                   # param_name (–Ω–∞ –æ—à–∏–±–∫–µ –º–æ–∂–Ω–æ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å –±–∞–∑—É)
            None,                         # value_num
            status,                       # value_text (–∫–æ–¥ –æ—à–∏–±–∫–∏)
            open_time_dt,                 # open_time (datetime)
            "error",                      # status
            status                        # error_code
        ))
        return rows

    # —É—Å–ø–µ—Ö: open_time ‚Üí datetime, —Ä–∞–∑–ª–æ–∂–∏—Ç—å –≤—Å–µ –ø–∞—Ä—ã {param_name: str_value}
    ot_raw = payload.get("open_time")
    try:
        open_time_dt = datetime.fromisoformat(ot_raw) if ot_raw else datetime.utcfromtimestamp(bar_open_ms / 1000)
    except Exception:
        open_time_dt = datetime.utcfromtimestamp(bar_open_ms / 1000)

    results: Dict[str, str] = payload.get("results", {})
    for param_name, str_value in results.items():
        base_short = indicator_base_from_param_name(param_name)
        fval = to_float_safe(str_value)

        rows.append((
            position_uid,                                  # position_uid
            strategy_id,                                   # strategy_id
            symbol,                                        # symbol
            tf,                                            # timeframe
            "indicator",                                   # param_type
            base_short,                                    # param_base (–±–µ–∑ –¥–ª–∏–Ω—ã)
            param_name,                                    # param_name (–ø–æ–ª–Ω—ã–π –∫–∞–Ω–æ–Ω, —Å –¥–ª–∏–Ω–æ–π)
            fval if fval is not None else None,            # value_num
            None if fval is not None else str_value,       # value_text
            open_time_dt,                                  # open_time (datetime)
            "ok",                                          # status
            None                                           # error_code
        ))

    return rows


# üî∏ –ü–∞–∫–µ—Ç–Ω–∞—è –∑–∞–ø–∏—Å—å –≤ PostgreSQL
async def run_insert_batch(pg, rows: List[Tuple]) -> None:
    if not rows:
        return
    sql = """
        INSERT INTO indicator_position_stat
        (position_uid, strategy_id, symbol, timeframe, param_type, param_base, param_name, value_num, value_text, open_time, status, error_code)
        VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12)
        ON CONFLICT (position_uid, timeframe, param_type, param_base, param_name)
        DO UPDATE SET
          value_num   = EXCLUDED.value_num,
          value_text  = EXCLUDED.value_text,
          open_time   = EXCLUDED.open_time,
          status      = EXCLUDED.status,
          error_code  = EXCLUDED.error_code,
          captured_at = NOW()
    """
    async with pg.acquire() as conn:
        async with conn.transaction():
            await conn.executemany(sql, rows)


# üî∏ –û—Å–Ω–æ–≤–Ω–æ–π –≤–æ—Ä–∫–µ—Ä —Å–Ω–∏–º–∫–∞ (—ç—Ç–∞–ø 1: —Ç–æ–ª—å–∫–æ m5 + indicators, –±–µ–∑ —Ç–∞–π–º–∞—É—Ç–æ–≤ –Ω–∞ –æ—Ç–≤–µ—Ç–∞—Ö)
async def run_indicator_position_snapshot(pg, redis, get_instances_by_tf):
    log.info("IND_POSSTAT: –≤–æ—Ä–∫–µ—Ä –∑–∞–ø—É—â–µ–Ω (phase=1 m5/indicator)")

    # —Å–æ–∑–¥–∞—Ç—å consumer-group –¥–ª—è –ø–æ–∑–∏—Ü–∏–π (–∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ)
    try:
        await redis.xgroup_create(POSITIONS_OPEN_STREAM, IPS_GROUP, id="$", mkstream=True)
    except Exception as e:
        if "BUSYGROUP" not in str(e):
            log.warning(f"xgroup_create (positions) error: {e}")

    # –ø–æ–¥–Ω—è—Ç—å —Ä–æ—É—Ç–µ—Ä –æ—Ç–≤–µ—Ç–æ–≤ –∏ –µ–≥–æ consumer-group
    router = IndicatorResponseRouter(redis)
    await router.start()

    sem = asyncio.Semaphore(PARALLEL_REQUESTS_LIMIT)

    async def process_position(msg_id: str, data: Dict[str, Any]) -> Optional[str]:
        # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏
        position_uid = data.get("position_uid")
        strategy_id_s = data.get("strategy_id")
        symbol = data.get("symbol")
        created_at_iso = data.get("created_at")

        if not position_uid or not strategy_id_s or not symbol or not created_at_iso:
            log.info(f"IND_POSSTAT: bad_event msg_id={msg_id} data_keys={list(data.keys())}")
            return msg_id  # ACK –º—É—Å–æ—Ä–∞

        try:
            strategy_id = int(strategy_id_s)
        except Exception:
            strategy_id = 0

        ts_ms = parse_iso_to_ms(created_at_iso)
        if ts_ms is None:
            log.info(f"IND_POSSTAT: bad_event_time position_uid={position_uid}")
            return msg_id

        # bar-open –¥–ª—è m5
        tf = "m5"
        bar_open_ms = floor_to_bar(ts_ms, tf)

        # —Å–æ–±—Ä–∞—Ç—å –∏–Ω—Å—Ç–∞–Ω—Å—ã –¥–ª—è m5
        instances = [i for i in get_instances_by_tf(tf)]
        if not instances:
            log.info(f"IND_POSSTAT: no_instances_m5 symbol={symbol}")
            return msg_id

        # –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–Ω—Å—Ç–∞–Ω—Å–æ–≤ —Å –ª–∏–º–∏—Ç–æ–º
        t0 = asyncio.get_event_loop().time()
        rows_all: List[Tuple] = []

        async def run_one(inst):
            async with sem:
                try:
                    r = await build_rows_for_instance(
                        redis,
                        router,
                        symbol=symbol,
                        tf=tf,
                        instance=inst,
                        bar_open_ms=bar_open_ms,
                        strategy_id=strategy_id,
                        position_uid=position_uid
                    )
                    return r
                except Exception:
                    log.warning("IND_POSSTAT: exception in build_rows_for_instance", exc_info=True)
                    base_short = indicator_base_from_instance(inst)
                    open_time_dt = datetime.utcfromtimestamp(bar_open_ms / 1000)
                    return [(
                        position_uid, strategy_id, symbol, tf,
                        "indicator", base_short, base_short,
                        None, "exception",
                        open_time_dt, "error", "exception"
                    )]

        tasks = [asyncio.create_task(run_one(inst)) for inst in instances]
        results_batches = await asyncio.gather(*tasks, return_exceptions=False)
        for batch in results_batches:
            rows_all.extend(batch)

        # –∑–∞–ø–∏—Å—å –ø–∞—á–∫–æ–π (—á–∞—Å—Ç—è–º–∏, –µ—Å–ª–∏ –æ—á–µ–Ω—å –º–Ω–æ–≥–æ)
        for i in range(0, len(rows_all), BATCH_INSERT_MAX):
            await run_insert_batch(pg, rows_all[i:i + BATCH_INSERT_MAX])

        t1 = asyncio.get_event_loop().time()
        log.info(
            f"IND_POSSTAT: m5 indicators done position_uid={position_uid} "
            f"symbol={symbol} rows={len(rows_all)} elapsed_ms={int((t1 - t0) * 1000)}"
        )

        return msg_id

    # üî∏ –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —á—Ç–µ–Ω–∏—è –ø–æ–∑–∏—Ü–∏–π: –ø–∞—á–∫–æ–π + –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ + –±–∞—Ç—á-ACK
    while True:
        try:
            resp = await redis.xreadgroup(
                groupname=IPS_GROUP,
                consumername=IPS_CONSUMER,
                streams={POSITIONS_OPEN_STREAM: ">"},
                count=100,
                block=2000
            )
        except Exception as e:
            log.error(f"IND_POSSTAT: read error: {e}", exc_info=True)
            await asyncio.sleep(0.5)
            continue

        if not resp:
            continue

        try:
            tasks = []
            for _, messages in resp:
                for msg_id, data in messages:
                    tasks.append(asyncio.create_task(process_position(msg_id, data)))

            done_ids = await asyncio.gather(*tasks, return_exceptions=False)
            ack_ids = [mid for mid in done_ids if mid]
            if ack_ids:
                await redis.xack(POSITIONS_OPEN_STREAM, IPS_GROUP, *ack_ids)
        except Exception as e:
            log.error(f"IND_POSSTAT: batch error: {e}", exc_info=True)
            await asyncio.sleep(0.5)