# indicator_position_snapshot.py â€” Ð²Ð¾Ñ€ÐºÐµÑ€ ÑÐ½Ð¸Ð¼ÐºÐ° Ð¸Ð½Ð´Ð¸ÐºÐ°Ñ‚Ð¾Ñ€Ð¾Ð² Ð½Ð° Ð¼Ð¾Ð¼ÐµÐ½Ñ‚ Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚Ð¸Ñ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸ (ÑÑ‚Ð°Ð¿ 1: m5, param_type=indicator)

import asyncio
import json
import logging
from datetime import datetime
from typing import Dict, Any, List, Tuple, Optional

# ðŸ”¸ Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ñ‹ Ð¸Ð½Ñ„Ñ€Ð°ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñ‹
# (Ð²Ð¾Ñ€ÐºÐµÑ€ Ð²ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°ÐµÑ‚ÑÑ Ð² Ð¾Ð±Ñ‰Ð¸Ð¹ Ð¾Ñ€ÐºÐµÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€ Ñ‡ÐµÑ€ÐµÐ· oracle_v4_main.py / indicators_v4_main.py)
# from infra import run_safe_loop  # Ð½Ðµ Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ Ð² ÑÑ‚Ð¾Ð¼ Ð¼Ð¾Ð´ÑƒÐ»Ðµ Ð½Ð°Ð¿Ñ€ÑÐ¼ÑƒÑŽ

# ðŸ”¸ ÐšÐ¾Ð½ÑÑ‚Ð°Ð½Ñ‚Ñ‹ ÑÑ‚Ñ€Ð¸Ð¼Ð¾Ð² Ð¸ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐº
POSITIONS_OPEN_STREAM = "positions_open_stream"   # Ð²Ñ…Ð¾Ð´Ð½Ð¾Ð¹ ÑÑ‚Ñ€Ð¸Ð¼ Ð²Ð½ÐµÑˆÐ½ÐµÐ³Ð¾ Ð¼Ð¾Ð´ÑƒÐ»Ñ
IND_REQ_STREAM        = "indicator_request"       # on-demand Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹ Ð¸Ð½Ð´Ð¸ÐºÐ°Ñ‚Ð¾Ñ€Ð¾Ð²
IND_RESP_STREAM       = "indicator_response"      # on-demand Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹ Ð¸Ð½Ð´Ð¸ÐºÐ°Ñ‚Ð¾Ñ€Ð¾Ð²

IPS_GROUP    = "ips_group"                        # consumer-group Ð´Ð»Ñ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¹
IPS_CONSUMER = "ips_consumer_1"

# ðŸ”¸ Ð¢Ð°Ð¹Ð¼Ð¸Ð½Ð³Ð¸/Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ñ
READ_BLOCK_MS            = 1500                   # Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ðµ Ð² XREAD (Ð¼Ñ)
REQ_RESPONSE_TIMEOUT_MS  = 2000                   # Ð¾Ð±Ñ‰Ð¸Ð¹ Ñ‚Ð°Ð¹Ð¼Ð°ÑƒÑ‚ Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð° (Ð¼Ñ) Ð½Ð° Ð¾Ð´Ð¸Ð½ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð¸Ð½Ð´Ð¸ÐºÐ°Ñ‚Ð¾Ñ€Ð°
PARALLEL_REQUESTS_LIMIT  = 20                     # Ð¾Ð´Ð½Ð¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹ on-demand
BATCH_INSERT_MAX         = 500                    # Ð¼Ð°ÐºÑ. Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð¿Ð°Ñ‡ÐºÐ¸ Ð´Ð»Ñ INSERT

# ðŸ”¸ Ð¢Ð°Ð¹Ð¼ÑˆÐ°Ð³Ð¸ TF (ÑÑ‚Ð°Ð¿ 1 â€” Ñ‚Ð¾Ð»ÑŒÐºÐ¾ m5)
STEP_MIN = {"m5": 5}
STEP_MS  = {k: v * 60_000 for k, v in STEP_MIN.items()}

# ðŸ”¸ Ð›Ð¾Ð³Ð³ÐµÑ€
log = logging.getLogger("IND_POSSTAT")


# ðŸ”¸ Ð’ÑÐ¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸/Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð°
def floor_to_bar(ts_ms: int, tf: str) -> int:
    step = STEP_MS[tf]
    return (ts_ms // step) * step

def parse_iso_to_ms(iso_str: str) -> Optional[int]:
    try:
        # Ð¾Ð¶Ð¸Ð´Ð°ÐµÑ‚ÑÑ UTC-naive ISO; Ð¿Ð°Ñ€ÑÐ¸Ð¼ ÐºÐ°Ðº naive Ð¸ ÑÑ‡Ð¸Ñ‚Ð°ÐµÐ¼, Ñ‡Ñ‚Ð¾ ÑÑ‚Ð¾ UTC
        dt = datetime.fromisoformat(iso_str)
        return int(dt.timestamp() * 1000)
    except Exception:
        return None

def derive_base_from_param_name(param_name: str) -> str:
    # ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ '_' â†’ base = Ð²ÑÑ‘ Ð´Ð¾ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐ³Ð¾ '_', Ð¸Ð½Ð°Ñ‡Ðµ base = param_name
    # Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð¸Ñ‚ Ð´Ð»Ñ bb20_2_0_{center,upper,lower}, macd12_{macd,macd_signal,macd_hist},
    # adx_dmi14_{adx,plus_di,minus_di}, lr50_{angle,center,upper,lower}
    if "_" in param_name:
        return param_name.rsplit("_", 1)[0]
    return param_name

def to_float_safe(s: str) -> Optional[float]:
    try:
        return float(s)
    except Exception:
        return None


# ðŸ”¸ ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° on-demand Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ð¸ Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¿Ð¾ req_id
async def request_indicator_snapshot(redis, *, symbol: str, timeframe: str, instance_id: int, timestamp_ms: int) -> Tuple[str, Dict[str, Any]]:
    """
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ (status, payload), Ð³Ð´Ðµ:
      - status: "ok" Ð¸Ð»Ð¸ ÐºÐ¾Ð´ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ ("timeout","no_ohlcv","instance_not_active",
                "symbol_not_active","before_enabled_at","no_values","bad_request","exception","stream_error")
      - payload: Ð¿Ñ€Ð¸ ok â†’ {"open_time": <iso>, "results": {param_name: str_value, ...}}
    """
    # Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
    fields = {
        "symbol": symbol,
        "timeframe": timeframe,
        "instance_id": str(instance_id),
        "timestamp_ms": str(timestamp_ms),
    }
    try:
        req_id = await redis.xadd(IND_REQ_STREAM, fields)
    except Exception:
        log.warning("stream_error: XADD indicator_request failed", exc_info=True)
        return "stream_error", {}

    # Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¿Ð¾ req_id
    deadline = asyncio.get_event_loop().time() + (REQ_RESPONSE_TIMEOUT_MS / 1000.0)
    last_id = "0-0"

    while True:
        timeout = max(0.0, deadline - asyncio.get_event_loop().time())
        if timeout == 0.0:
            return "timeout", {}

        try:
            resp = await redis.xread({IND_RESP_STREAM: last_id}, block=min(int(timeout * 1000), READ_BLOCK_MS), count=200)
        except Exception:
            log.warning("stream_error: XREAD indicator_response failed", exc_info=True)
            return "stream_error", {}

        if not resp:
            # Ñ‚Ð°Ð¹Ð¼Ð°ÑƒÑ‚ Ð±Ð»Ð¾ÐºÐ°; Ñ†Ð¸ÐºÐ» Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð¸Ñ‚ÑÑ, ÐµÑÐ»Ð¸ Ð¾Ð±Ñ‰Ð¸Ð¹ Ð´ÐµÐ´Ð»Ð°Ð¹Ð½ Ð½Ðµ Ð²Ñ‹ÑˆÐµÐ»
            continue

        # Ð¿ÐµÑ€ÐµÐ±Ð¸Ñ€Ð°ÐµÐ¼ Ð·Ð°Ð¿Ð¸ÑÐ¸, Ð¸Ñ‰ÐµÐ¼ Ð½Ð°ÑˆÑƒ Ð¿Ð¾ req_id
        for _, messages in resp:
            for msg_id, data in messages:
                last_id = msg_id
                if data.get("req_id") != req_id:
                    continue
                status = data.get("status", "error")
                if status != "ok":
                    return data.get("error", "exception"), {}
                # ÑƒÑÐ¿ÐµÑ…: ÑÐ¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ open_time Ð¸ results
                try:
                    open_time = data.get("open_time") or ""
                    results_raw = data.get("results") or "{}"
                    results = json.loads(results_raw)
                    return "ok", {"open_time": open_time, "results": results}
                except Exception:
                    return "exception", {}

        # ÐµÑÐ»Ð¸ ÑÐ²Ð¾Ñ Ð·Ð°Ð¿Ð¸ÑÑŒ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð° â€” Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð°ÐµÐ¼ Ð´Ð¾ Ð´ÐµÐ´Ð»Ð°Ð¹Ð½Ð°


# ðŸ”¸ Ð¡Ð±Ð¾Ñ€ ÑÑ‚Ñ€Ð¾Ðº Ð´Ð»Ñ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð¸Ð½ÑÑ‚Ð°Ð½ÑÐ° Ð¸Ð½Ð´Ð¸ÐºÐ°Ñ‚Ð¾Ñ€Ð° (ÑÑ‚Ð°Ð¿ 1: Ñ‚Ð¾Ð»ÑŒÐºÐ¾ m5)
async def build_rows_for_instance(
    redis,
    *,
    symbol: str,
    tf: str,
    instance: Dict[str, Any],
    bar_open_ms: int,
    strategy_id: int,
    position_uid: str
) -> List[Tuple]:
    """
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº ÐºÐ¾Ñ€Ñ‚ÐµÐ¶ÐµÐ¹ Ð´Ð»Ñ Ð²ÑÑ‚Ð°Ð²ÐºÐ¸ Ð² indicator_position_stat.
    Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° ÐºÐ¾Ñ€Ñ‚ÐµÐ¶Ð° ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ INSERT Ð² run_insert_batch().
    """
    instance_id = int(instance["id"])
    status, payload = await request_indicator_snapshot(
        redis,
        symbol=symbol,
        timeframe=tf,
        instance_id=instance_id,
        timestamp_ms=bar_open_ms
    )

    rows: List[Tuple] = []

    if status != "ok":
        # Ð¾Ð´Ð½Ð° ÑÑ‚Ñ€Ð¾ÐºÐ° Ð¾Ð± Ð¾ÑˆÐ¸Ð±ÐºÐµ Ð¿Ð¾ Ð±Ð°Ð·Ð¾Ð²Ð¾Ð¼Ñƒ Ð¸Ð¼ÐµÐ½Ð¸
        # Ð±Ð°Ð·Ñƒ Ð²Ð¾ÑÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð¸Ð· Ñ‚Ð¸Ð¿Ð° Ð¸Ð½Ð´Ð¸ÐºÐ°Ñ‚Ð¾Ñ€Ð° Ð¸ ÐµÐ³Ð¾ params
        try:
            indicator = instance["indicator"]
            params = instance.get("params", {})
            if indicator == "macd":
                base = f"macd{params.get('fast')}"
            elif indicator == "bb":
                std_raw = str(round(float(params.get("std", 2.0)), 2)).replace(".", "_")
                base = f"bb{int(params.get('length', 20))}_{std_raw}"
            elif "length" in params:
                base = f"{indicator}{int(params['length'])}"
            else:
                base = indicator
        except Exception:
            base = "unknown"

        # Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚Ð¸Ðµ Ð±Ð°Ñ€Ð° â€” Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‘Ð¼ Ð² Ð‘Ð” Ð¸Ð¼ÐµÐ½Ð½Ð¾ datetime, Ð° Ð½Ðµ ISO-ÑÑ‚Ñ€Ð¾ÐºÑƒ
        open_time_dt = datetime.utcfromtimestamp(bar_open_ms / 1000)

        rows.append((
            position_uid,                # position_uid
            strategy_id,                 # strategy_id
            symbol,                      # symbol
            tf,                          # timeframe
            "indicator",                 # param_type
            base,                        # param_base
            base,                        # param_name (ÑƒÐ½Ð¸Ñ„Ð¸Ñ†Ð¸Ñ€ÑƒÐµÐ¼ Ð½Ð° base Ð¿Ñ€Ð¸ Ð¾ÑˆÐ¸Ð±ÐºÐµ)
            None,                        # value_num
            status,                      # value_text (ÐºÐ¾Ð´ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ ÐºÐ°Ðº Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ)
            open_time_dt,                # open_time (datetime)
            "error",                     # status
            status                       # error_code
        ))
        return rows

    # ÑƒÑÐ¿ÐµÑ…: Ñ€Ð°Ð·Ð»Ð¾Ð¶Ð¸Ñ‚ÑŒ Ð²ÑÐµ Ð¿Ð°Ñ€Ñ‹ {param_name: str_value} Ð² ÑÑ‚Ñ€Ð¾ÐºÐ¸
    ot_raw = payload.get("open_time")
    try:
        open_time_dt = datetime.fromisoformat(ot_raw) if ot_raw else datetime.utcfromtimestamp(bar_open_ms / 1000)
    except Exception:
        open_time_dt = datetime.utcfromtimestamp(bar_open_ms / 1000)

    results: Dict[str, str] = payload.get("results", {})

    for param_name, str_value in results.items():
        base = derive_base_from_param_name(param_name)
        fval = to_float_safe(str_value)

        rows.append((
            position_uid,                                  # position_uid
            strategy_id,                                   # strategy_id
            symbol,                                        # symbol
            tf,                                            # timeframe
            "indicator",                                   # param_type
            base,                                          # param_base
            param_name,                                    # param_name
            fval if fval is not None else None,            # value_num
            None if fval is not None else str_value,       # value_text (Ð½Ð° ÑÐ»ÑƒÑ‡Ð°Ð¹ Ð½ÐµÑ‡Ð¸ÑÐ»Ð¾Ð²Ñ‹Ñ…)
            open_time_dt,                                  # open_time (datetime)
            "ok",                                          # status
            None                                           # error_code
        ))

    return rows


# ðŸ”¸ ÐŸÐ°ÐºÐµÑ‚Ð½Ð°Ñ Ð·Ð°Ð¿Ð¸ÑÑŒ Ð² PostgreSQL
async def run_insert_batch(pg, rows: List[Tuple]) -> None:
    if not rows:
        return
    # Ð¿Ð¾Ñ€ÑÐ´Ð¾Ðº Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð² Ð´Ð¾Ð»Ð¶ÐµÐ½ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¾Ð²Ð°Ñ‚ÑŒ VALUES ($1..$12)
    sql = """
        INSERT INTO indicator_position_stat
        (position_uid, strategy_id, symbol, timeframe, param_type, param_base, param_name, value_num, value_text, open_time, status, error_code)
        VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12)
        ON CONFLICT (position_uid, timeframe, param_type, param_base, param_name)
        DO UPDATE SET
          value_num = EXCLUDED.value_num,
          value_text = EXCLUDED.value_text,
          open_time = EXCLUDED.open_time,
          status = EXCLUDED.status,
          error_code = EXCLUDED.error_code,
          captured_at = NOW()
    """
    async with pg.acquire() as conn:
        async with conn.transaction():
            await conn.executemany(sql, rows)


# ðŸ”¸ ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð²Ð¾Ñ€ÐºÐµÑ€ ÑÐ½Ð¸Ð¼ÐºÐ° (ÑÑ‚Ð°Ð¿ 1: Ñ‚Ð¾Ð»ÑŒÐºÐ¾ m5 + indicators)
async def run_indicator_position_snapshot(pg, redis, get_instances_by_tf):
    log.info("IND_POSSTAT: Ð²Ð¾Ñ€ÐºÐµÑ€ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½ (phase=1 m5/indicator)")

    # ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ consumer-group Ð´Ð»Ñ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¹ (Ð¸Ð´ÐµÐ¼Ð¿Ð¾Ñ‚ÐµÐ½Ñ‚Ð½Ð¾)
    try:
        await redis.xgroup_create(POSITIONS_OPEN_STREAM, IPS_GROUP, id="$", mkstream=True)
    except Exception as e:
        if "BUSYGROUP" not in str(e):
            log.warning(f"xgroup_create error: {e}")

    sem = asyncio.Semaphore(PARALLEL_REQUESTS_LIMIT)

    async def process_position(msg_id: str, data: Dict[str, Any]) -> Optional[str]:
        # ÑƒÑÐ»Ð¾Ð²Ð¸Ñ Ð´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸
        position_uid = data.get("position_uid")
        strategy_id_s = data.get("strategy_id")
        symbol = data.get("symbol")
        created_at_iso = data.get("created_at")

        if not position_uid or not strategy_id_s or not symbol or not created_at_iso:
            log.info(f"IND_POSSTAT: bad_event msg_id={msg_id} data_keys={list(data.keys())}")
            return msg_id  # ACK, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ð·Ð°ÑÑ‚Ñ€ÐµÐ²Ð°Ñ‚ÑŒ; ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹Ð½Ñ‹Ð¹ Ð¼ÑƒÑÐ¾Ñ€ Ð½Ðµ Ð´ÐµÑ€Ð¶Ð¸Ð¼

        try:
            strategy_id = int(strategy_id_s)
        except Exception:
            strategy_id = 0

        ts_ms = parse_iso_to_ms(created_at_iso)
        if ts_ms is None:
            log.info(f"IND_POSSTAT: bad_event_time position_uid={position_uid}")
            return msg_id

        # bar_open Ð´Ð»Ñ m5
        tf = "m5"
        bar_open_ms = floor_to_bar(ts_ms, tf)

        # ÑÐ¾Ð±Ñ€Ð°Ñ‚ÑŒ Ð¸Ð½ÑÑ‚Ð°Ð½ÑÑ‹ Ð½Ð° m5
        instances = [i for i in get_instances_by_tf(tf)]
        if not instances:
            log.info(f"IND_POSSTAT: no_instances_m5 symbol={symbol}")
            return msg_id

        # Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¸Ð½ÑÑ‚Ð°Ð½ÑÐ¾Ð² Ñ Ð»Ð¸Ð¼Ð¸Ñ‚Ð¾Ð¼
        t0 = asyncio.get_event_loop().time()
        rows_all: List[Tuple] = []

        async def run_one(inst):
            # Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð¸Ð½ÑÑ‚Ð°Ð½ÑÐ° Ð¿Ð¾Ð´ ÑÐµÐ¼Ð°Ñ„Ð¾Ñ€Ð¾Ð¼
            async with sem:
                try:
                    r = await build_rows_for_instance(
                        redis,
                        symbol=symbol,
                        tf=tf,
                        instance=inst,
                        bar_open_ms=bar_open_ms,
                        strategy_id=strategy_id,
                        position_uid=position_uid
                    )
                    return r
                except Exception:
                    log.warning("IND_POSSTAT: exception in build_rows_for_instance", exc_info=True)
                    # Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ ÐµÐ´Ð¸Ð½ÑÑ‚Ð²ÐµÐ½Ð½ÑƒÑŽ Ð¾ÑˆÐ¸Ð±Ð¾Ñ‡Ð½ÑƒÑŽ ÑÑ‚Ñ€Ð¾ÐºÑƒ Ð½Ð° base Ð¸Ð½ÑÑ‚Ð°Ð½ÑÐ°
                    indicator = inst.get("indicator", "unknown")
                    params = inst.get("params", {})
                    if indicator == "macd":
                        base = f"macd{params.get('fast')}"
                    elif indicator == "bb":
                        try:
                            std_raw = str(round(float(params.get("std", 2.0)), 2)).replace(".", "_")
                        except Exception:
                            std_raw = "2_0"
                        try:
                            length_i = int(params.get("length", 20))
                        except Exception:
                            length_i = 20
                        base = f"bb{length_i}_{std_raw}"
                    elif "length" in params:
                        try:
                            base = f"{indicator}{int(params['length'])}"
                        except Exception:
                            base = indicator
                    else:
                        base = indicator
                    open_time_dt = datetime.utcfromtimestamp(bar_open_ms / 1000)
                    return [(
                        position_uid, strategy_id, symbol, tf,
                        "indicator", base, base,
                        None, "exception",
                        open_time_dt, "error", "exception"
                    )]

        tasks = [asyncio.create_task(run_one(inst)) for inst in instances]
        results_batches = await asyncio.gather(*tasks, return_exceptions=False)
        for batch in results_batches:
            rows_all.extend(batch)

        # Ð·Ð°Ð¿Ð¸ÑÑŒ Ð¿Ð°Ñ‡ÐºÐ¾Ð¹ (Ñ‡Ð°ÑÑ‚ÑÐ¼Ð¸, ÐµÑÐ»Ð¸ Ð¾Ñ‡ÐµÐ½ÑŒ Ð¼Ð½Ð¾Ð³Ð¾)
        for i in range(0, len(rows_all), BATCH_INSERT_MAX):
            await run_insert_batch(pg, rows_all[i:i + BATCH_INSERT_MAX])

        t1 = asyncio.get_event_loop().time()
        log.info(
            f"IND_POSSTAT: m5 indicators done position_uid={position_uid} "
            f"symbol={symbol} rows={len(rows_all)} elapsed_ms={int((t1 - t0) * 1000)}"
        )

        return msg_id

    # ðŸ”¸ ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ñ†Ð¸ÐºÐ» Ñ‡Ñ‚ÐµÐ½Ð¸Ñ ÑÑ‚Ñ€Ð¸Ð¼Ð°: Ð¿Ð°Ñ‡ÐºÐ¾Ð¹ + Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° + Ð±Ð°Ñ‚Ñ‡-ACK
    while True:
        try:
            resp = await redis.xreadgroup(
                groupname=IPS_GROUP,
                consumername=IPS_CONSUMER,
                streams={POSITIONS_OPEN_STREAM: ">"},
                count=100,
                block=2000
            )
        except Exception as e:
            log.error(f"IND_POSSTAT: read error: {e}", exc_info=True)
            await asyncio.sleep(0.5)
            continue

        if not resp:
            continue

        try:
            tasks = []
            for _, messages in resp:
                for msg_id, data in messages:
                    tasks.append(asyncio.create_task(process_position(msg_id, data)))

            done_ids = await asyncio.gather(*tasks, return_exceptions=False)
            ack_ids = [mid for mid in done_ids if mid]
            if ack_ids:
                await redis.xack(POSITIONS_OPEN_STREAM, IPS_GROUP, *ack_ids)
        except Exception as e:
            log.error(f"IND_POSSTAT: batch error: {e}", exc_info=True)
            await asyncio.sleep(0.5)