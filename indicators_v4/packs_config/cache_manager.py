# packs_config/cache_manager.py ‚Äî –∫–µ—à–∏/—Ä–µ–µ—Å—Ç—Ä ind_pack + init winners-cache (labels_v2) + reload rules on postproc_ready_v2 (winner-driven) + signal direction masks

from __future__ import annotations

# üî∏ Imports
import asyncio
import logging
from typing import Any

from packs_config.db_loaders import (
    load_adaptive_bins_for_pair,
    load_analysis_instances,
    load_analysis_parameters,
    load_enabled_packs,
    load_static_bins_dict,
    load_winners_from_labels_v2,
    load_signal_direction_masks,
)
from packs_config.models import PackRuntime, BinRule
from packs_config.registry import build_pack_registry


# üî∏ –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã Redis (–ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –±–µ–∫—Ç–µ—Å—Ç–∞ ‚Üí —Å–∏–≥–Ω–∞–ª –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è winner/rules)
POSTPROC_STREAM_KEY = "bt:analysis:postproc_ready_v2"
POSTPROC_GROUP = "ind_pack_postproc_group_v4_v2"
POSTPROC_CONSUMER = "ind_pack_postproc_1"


# üî∏ –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Ä–µ–µ—Å—Ç—Ä pack-–∏–Ω—Å—Ç–∞–Ω—Å–æ–≤, –≥–æ—Ç–æ–≤—ã—Ö –∫ —Ä–∞–±–æ—Ç–µ
pack_registry: dict[tuple[str, str], list[PackRuntime]] = {}
# key: (timeframe_from_stream, indicator_from_stream) -> list[PackRuntime]


# üî∏ –ö–µ—à–∏ –ø—Ä–∞–≤–∏–ª (winner-driven, –∏–∑ bt_analysis_bin_dict_adaptive)
adaptive_bins_cache: dict[tuple[int, int, int, str, str], list[BinRule]] = {}
adaptive_quantiles_cache: dict[tuple[int, int, int, str, str], list[BinRule]] = {}
# key: (analysis_id, scenario_id, signal_id, timeframe, direction)


# üî∏ –ö–µ—à –ø–æ–±–µ–¥–∏—Ç–µ–ª–µ–π (winner-driven, –∏–∑ bt_analysis_bins_labels_v2)
winners_by_pair: dict[tuple[int, int], dict[str, Any]] = {}
# key: (scenario_id, signal_id) -> {"run_id": int, "analysis_id": int, "winner_param": str|None, "timeframe": str|None}


# üî∏ –ö–µ—à –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π —Å–∏–≥–Ω–∞–ª–æ–≤ (mono-direction): signal_id -> 'long'|'short'|...
signal_direction_mask: dict[int, str] = {}
signal_dir_lock = asyncio.Lock()


# üî∏ –ù–∞–±–æ—Ä ‚Äú–∏–Ω—Ç–µ—Ä–µ—Å—É—é—â–∏—Ö‚Äù –ø–∞—Ä (–±–µ—Ä—ë—Ç—Å—è –∏–∑ bins_policy.pairs –≤–∫–ª—é—á—ë–Ω–Ω—ã—Ö pack-–∏–Ω—Å—Ç–∞–Ω—Å–æ–≤)
configured_pairs_set: set[tuple[int, int]] = set()

# üî∏ –ê–∫—Ç–∏–≤–Ω—ã–µ m5-—Ç—Ä–∏–≥–≥–µ—Ä—ã (indicator_stream.indicator), –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω—ã —Ç–µ–∫—É—â–∏–º winner‚Äô–∞–º
active_trigger_keys_m5: set[str] = set()
triggers_lock = asyncio.Lock()

# üî∏ Locks –∏ —Ñ–ª–∞–≥–∏ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∫–µ—à–µ–π
adaptive_lock = asyncio.Lock()
winners_lock = asyncio.Lock()

caches_ready = {
    "registry": False,
    "winners": False,
    "adaptive_bins": False,
    "quantiles": False,
}


# üî∏ –°—Ç–∞—Ç—É—Å—ã –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏ –ø–∞—Ä (–¥–ª—è –≤–Ω–µ—à–Ω–∏—Ö –º–æ–¥—É–ª–µ–π/–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏)
reloading_pairs_bins: set[tuple[int, int]] = set()
reloading_pairs_quantiles: set[tuple[int, int]] = set()
reloading_pairs_labels: set[tuple[int, int]] = set()  # legacy name: –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ ‚Äúwinner reload‚Äù


# üî∏ Consumer-group helper
async def ensure_stream_group(redis: Any, stream: str, group: str):
    log = logging.getLogger("PACK_STREAM")
    try:
        await redis.xgroup_create(stream, group, id="$", mkstream=True)
    except Exception as e:
        if "BUSYGROUP" not in str(e):
            log.warning("xgroup_create error for %s/%s: %s", stream, group, e)


# üî∏ Helpers: winner getters
def get_winner_meta(scenario_id: int, signal_id: int) -> dict[str, Any] | None:
    try:
        return winners_by_pair.get((int(scenario_id), int(signal_id)))
    except Exception:
        return None


def get_winner_analysis_id(scenario_id: int, signal_id: int) -> int | None:
    m = get_winner_meta(scenario_id, signal_id)
    if not m:
        return None
    try:
        return int(m.get("analysis_id"))
    except Exception:
        return None


def get_winner_run_id(scenario_id: int, signal_id: int) -> int | None:
    m = get_winner_meta(scenario_id, signal_id)
    if not m:
        return None
    try:
        return int(m.get("run_id"))
    except Exception:
        return None


# üî∏ Helpers: signal directions
def get_allowed_directions(signal_id: int) -> list[str]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π –¥–ª—è signal_id –Ω–∞ –æ—Å–Ω–æ–≤–µ bt_signals_parameters.direction_mask.
    –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é (–µ—Å–ª–∏ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ) ‚Äî ['long','short'].
    """
    try:
        dm = str(signal_direction_mask.get(int(signal_id), "") or "").strip().lower()
    except Exception:
        dm = ""

    if dm == "long":
        return ["long"]
    if dm == "short":
        return ["short"]

    # –Ω–∞ –±—É–¥—É—â–µ–µ: –µ—Å–ª–∏ –∫–æ–≥–¥–∞-—Ç–æ –ø–æ—è–≤–∏—Ç—Å—è –º—É–ª—å—Ç–∏-–º–∞—Å–∫–∞
    if dm in ("both", "all", "long,short", "short,long"):
        return ["long", "short"]

    return ["long", "short"]


# üî∏ Helpers: active m5 trigger keys (winner-driven)
async def _rebuild_active_triggers_m5():
    log = logging.getLogger("PACK_INIT")

    # —Å–æ–±–µ—Ä—ë–º –º–Ω–æ–∂–µ—Å—Ç–≤–æ analysis_id —Ç–µ–∫—É—â–∏—Ö –ø–æ–±–µ–¥–∏—Ç–µ–ª–µ–π
    winner_aids: set[int] = set()
    for meta in winners_by_pair.values():
        try:
            winner_aids.add(int(meta.get("analysis_id")))
        except Exception:
            continue

    # –ø—Ä–æ–π–¥—ë–º –ø–æ registry –∏ –Ω–∞–π–¥—ë–º –∫–ª—é—á–∏ (m5, indicator), –≥–¥–µ –µ—Å—Ç—å runtime –ø–æ–±–µ–¥–∏—Ç–µ–ª—è
    new_set: set[str] = set()
    for (tf, ind_key), rts in pack_registry.items():
        if str(tf) != "m5":
            continue
        for rt in rts:
            try:
                if int(rt.analysis_id) in winner_aids:
                    new_set.add(str(ind_key))
                    break
            except Exception:
                continue

    async with triggers_lock:
        active_trigger_keys_m5.clear()
        active_trigger_keys_m5.update(new_set)

    log.info("PACK_INIT: active m5 triggers rebuilt ‚Äî winners=%s, triggers=%s", len(winner_aids), len(new_set))


def get_active_trigger_keys_m5() -> set[str]:
    # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–ø–∏—é, —á—Ç–æ–±—ã —Å–Ω–∞—Ä—É–∂–∏ –Ω–µ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–ª–∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π set
    return set(active_trigger_keys_m5)


# üî∏ LEGACY helper: current run by signal (–æ—Å—Ç–∞–≤–ª–µ–Ω–æ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å—Ç–∞—Ä—ã—Ö –≤—ã–∑–æ–≤–æ–≤)
def get_current_run_id(signal_id: int) -> int | None:
    try:
        sid = int(signal_id)
    except Exception:
        return None

    # –≤—ã–±–∏—Ä–∞–µ–º –ª—é–±–æ–π run_id –∏–∑ winners –ø–æ —ç—Ç–æ–º—É signal_id (–≤ —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏ —Å–∏–≥–Ω–∞–ª –æ–±—ã—á–Ω–æ –∏–º–µ–µ—Ç –æ–¥–∏–Ω –∞–∫—Ç—É–∞–ª—å–Ω—ã–π run)
    best: int | None = None
    for (sc, sg), meta in winners_by_pair.items():
        if int(sg) != sid:
            continue
        try:
            rid = int(meta.get("run_id"))
        except Exception:
            continue
        if best is None or rid > best:
            best = rid
    return best


# üî∏ Get adaptive rules (winner-driven)
def get_adaptive_rules(analysis_id: int, scenario_id: int, signal_id: int, timeframe: str, direction: str) -> list[BinRule]:
    return adaptive_bins_cache.get((int(analysis_id), int(scenario_id), int(signal_id), str(timeframe), str(direction)), [])


def get_adaptive_quantiles(analysis_id: int, scenario_id: int, signal_id: int, timeframe: str, direction: str) -> list[BinRule]:
    return adaptive_quantiles_cache.get((int(analysis_id), int(scenario_id), int(signal_id), str(timeframe), str(direction)), [])


# üî∏ Cache init: registry + configured_pairs + signal directions + winners + rules (winner-driven)
async def init_pack_runtime(pg: Any):
    global pack_registry, configured_pairs_set

    log = logging.getLogger("PACK_INIT")

    caches_ready["registry"] = False
    caches_ready["winners"] = False
    caches_ready["adaptive_bins"] = False
    caches_ready["quantiles"] = False

    # –æ—á–∏—Å—Ç–∫–∞ –∫–µ—à–µ–π –∏ —Ñ–ª–∞–≥–æ–≤ reload –Ω–∞ —Å—Ç–∞—Ä—Ç–µ
    adaptive_bins_cache.clear()
    adaptive_quantiles_cache.clear()

    winners_by_pair.clear()
    configured_pairs_set.clear()

    reloading_pairs_bins.clear()
    reloading_pairs_quantiles.clear()
    reloading_pairs_labels.clear()

    async with signal_dir_lock:
        signal_direction_mask.clear()

    # 1) –∑–∞–≥—Ä—É–∑–∫–∞ pack-–∫–æ–Ω—Ñ–∏–≥–∞ –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ registry
    packs = await load_enabled_packs(pg)
    analysis_ids = sorted({int(p["analysis_id"]) for p in packs})

    analysis_meta = await load_analysis_instances(pg, analysis_ids)
    analysis_params = await load_analysis_parameters(pg, analysis_ids)
    static_bins_dict = await load_static_bins_dict(pg, analysis_ids)

    new_registry = build_pack_registry(packs, analysis_meta, analysis_params, static_bins_dict)

    pack_registry.clear()
    pack_registry.update(new_registry)
    caches_ready["registry"] = True

    # 2) —Å–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ç–µ—Ä–µ—Å—É—é—â–∏–µ –ø–∞—Ä—ã –∏–∑ –≤–∫–ª—é—á—ë–Ω–Ω—ã—Ö runtime (–≤ —Ç–≤–æ—ë–º —Å–ª—É—á–∞–µ —ç—Ç–æ MTF-–ø–∞–∫–∏)
    all_runtimes: list[PackRuntime] = []
    for lst in pack_registry.values():
        all_runtimes.extend(lst)

    mtf_runtimes = 0

    for rt in all_runtimes:
        if rt.is_mtf and rt.mtf_pairs:
            mtf_runtimes += 1
            for pair in rt.mtf_pairs:
                configured_pairs_set.add((int(pair[0]), int(pair[1])))

    pairs_total = len(configured_pairs_set)
    log.info("PACK_INIT: mtf runtimes=%s, configured_pairs=%s", mtf_runtimes, pairs_total)

    # 2.1) –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤ (direction_mask)
    signal_ids = sorted({int(sig) for (_, sig) in configured_pairs_set})
    dm = await load_signal_direction_masks(pg, signal_ids)
    async with signal_dir_lock:
        signal_direction_mask.update(dm)

    # 3) –∑–∞–≥—Ä—É–∑–∫–∞ winners –∏–∑ labels_v2 (–∞–∫—Ç—É–∞–ª—å–Ω—ã–π —Å–Ω–∏–º–æ–∫)
    winners = await load_winners_from_labels_v2(pg, sorted(list(configured_pairs_set)))

    async with winners_lock:
        for (sc, sg), meta in winners.items():
            winners_by_pair[(int(sc), int(sg))] = {
                "run_id": int(meta.get("run_id")),
                "analysis_id": int(meta.get("analysis_id")),
                "winner_param": meta.get("indicator_param"),
                "timeframe": meta.get("timeframe"),
            }

    caches_ready["winners"] = True

    # 4) –∑–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–∞–≤–∏–ª –∏–∑ bt_analysis_bin_dict_adaptive –ø–æ winner (bins + quantiles)
    bins_rules_total = 0
    quant_rules_total = 0
    winners_found = len(winners_by_pair)
    winners_missing = max(0, pairs_total - winners_found)

    async with adaptive_lock:
        for (scenario_id, signal_id), meta in winners_by_pair.items():
            try:
                run_id = int(meta["run_id"])
                winner_aid = int(meta["analysis_id"])
            except Exception:
                continue

            # bins
            loaded_bins = await load_adaptive_bins_for_pair(pg, int(run_id), [int(winner_aid)], int(scenario_id), int(signal_id), "bins")
            for (aid, tf, direction), rules in loaded_bins.items():
                adaptive_bins_cache[(int(aid), int(scenario_id), int(signal_id), str(tf), str(direction))] = rules
                bins_rules_total += len(rules)

            # quantiles
            loaded_q = await load_adaptive_bins_for_pair(pg, int(run_id), [int(winner_aid)], int(scenario_id), int(signal_id), "quantiles")
            for (aid, tf, direction), rules in loaded_q.items():
                adaptive_quantiles_cache[(int(aid), int(scenario_id), int(signal_id), str(tf), str(direction))] = rules
                quant_rules_total += len(rules)

    caches_ready["adaptive_bins"] = True
    caches_ready["quantiles"] = True

    # –∏—Ç–æ–≥–æ–≤—ã–π –ª–æ–≥ —Å—Ç–∞—Ä—Ç–∞
    log.info(
        "PACK_INIT: winners cache ready ‚Äî pairs=%s, found=%s, missing=%s; rules loaded ‚Äî bins=%s, quantiles=%s; signal_dirs=%s",
        pairs_total,
        winners_found,
        winners_missing,
        bins_rules_total,
        quant_rules_total,
        len(signal_direction_mask),
    )

    # –ø–µ—Ä–µ—Å–æ–±–∏—Ä–∞–µ–º –∞–∫—Ç–∏–≤–Ω—ã–µ m5-—Ç—Ä–∏–≥–≥–µ—Ä—ã –ø–æ–±–µ–¥–∏—Ç–µ–ª–µ–π
    await _rebuild_active_triggers_m5()


# üî∏ Reload on postproc_ready_v2: –æ–±–Ω–æ–≤–ª—è–µ–º winner –ø–æ –ø–∞—Ä–µ + –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º rules –∏–∑ bt_analysis_bin_dict_adaptive
async def watch_postproc_ready(pg: Any, redis: Any):
    log = logging.getLogger("PACK_POSTPROC")
    sem = asyncio.Semaphore(50)

    async def _reload_pair(
        run_id: int,
        scenario_id: int,
        signal_id: int,
        winner_analysis_id: int,
        winner_param: str | None,
    ):
        async with sem:
            pair = (int(scenario_id), int(signal_id))

            reloading_pairs_bins.add(pair)
            reloading_pairs_quantiles.add(pair)
            reloading_pairs_labels.add(pair)

            try:
                # –æ–±–Ω–æ–≤–∏–º winner cache
                async with winners_lock:
                    winners_by_pair[pair] = {
                        "run_id": int(run_id),
                        "analysis_id": int(winner_analysis_id),
                        "winner_param": (str(winner_param) if winner_param is not None else None),
                        "timeframe": "mtf",
                    }

                # –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏–º rules (bins + quantiles) —Ç–æ–ª—å–∫–æ –¥–ª—è winner
                bins_loaded = 0
                quant_loaded = 0

                async with adaptive_lock:
                    # —É–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ rules –ø–æ –ø–∞—Ä–µ (–ª—é–±—ã—Ö analysis_id)
                    to_del_bins = [k for k in list(adaptive_bins_cache.keys()) if k[1] == int(scenario_id) and k[2] == int(signal_id)]
                    for k in to_del_bins:
                        adaptive_bins_cache.pop(k, None)

                    to_del_q = [k for k in list(adaptive_quantiles_cache.keys()) if k[1] == int(scenario_id) and k[2] == int(signal_id)]
                    for k in to_del_q:
                        adaptive_quantiles_cache.pop(k, None)

                    loaded_bins = await load_adaptive_bins_for_pair(pg, int(run_id), [int(winner_analysis_id)], int(scenario_id), int(signal_id), "bins")
                    for (aid, tf, direction), rules in loaded_bins.items():
                        adaptive_bins_cache[(int(aid), int(scenario_id), int(signal_id), str(tf), str(direction))] = rules
                        bins_loaded += len(rules)

                    loaded_q = await load_adaptive_bins_for_pair(pg, int(run_id), [int(winner_analysis_id)], int(scenario_id), int(signal_id), "quantiles")
                    for (aid, tf, direction), rules in loaded_q.items():
                        adaptive_quantiles_cache[(int(aid), int(scenario_id), int(signal_id), str(tf), str(direction))] = rules
                        quant_loaded += len(rules)

                log.info(
                    "PACK_WINNER: updated (scenario_id=%s, signal_id=%s, run_id=%s, winner_analysis_id=%s, winner_param=%s, bins_rules=%s, quantiles_rules=%s)",
                    scenario_id,
                    signal_id,
                    run_id,
                    winner_analysis_id,
                    winner_param,
                    bins_loaded,
                    quant_loaded,
                )

                # –ø–æ–±–µ–¥–∏—Ç–µ–ª—å –º–æ–≥ –ø–æ–º–µ–Ω—è—Ç—å—Å—è ‚Üí –ø–µ—Ä–µ—Å–æ–±–∏—Ä–∞–µ–º –∞–∫—Ç–∏–≤–Ω—ã–µ m5-—Ç—Ä–∏–≥–≥–µ—Ä—ã
                await _rebuild_active_triggers_m5()

            finally:
                reloading_pairs_bins.discard(pair)
                reloading_pairs_quantiles.discard(pair)
                reloading_pairs_labels.discard(pair)

    while True:
        try:
            resp = await redis.xreadgroup(
                POSTPROC_GROUP,
                POSTPROC_CONSUMER,
                streams={POSTPROC_STREAM_KEY: ">"},
                count=200,
                block=2000,
            )
            if not resp:
                continue

            to_ack = []
            scheduled = 0
            ignored = 0
            bad = 0

            for _, messages in resp:
                for msg_id, data in messages:
                    to_ack.append(msg_id)

                    # –ø–∞—Ä—Å–∏–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
                    try:
                        run_id = int(data.get("run_id"))
                        scenario_id = int(data.get("scenario_id"))
                        signal_id = int(data.get("signal_id"))
                        winner_analysis_id = int(data.get("winner_analysis_id"))
                        winner_param = data.get("winner_param")
                    except Exception:
                        bad += 1
                        continue

                    pair = (int(scenario_id), int(signal_id))
                    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏: —Ä–∞–±–æ—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–æ –∏–Ω—Ç–µ—Ä–µ—Å—É—é—â–∏–º –ø–∞—Ä–∞–º
                    if pair not in configured_pairs_set:
                        ignored += 1
                        continue

                    # –ø–ª–∞–Ω–∏—Ä—É–µ–º reload (–Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π loop)
                    asyncio.create_task(_reload_pair(int(run_id), int(scenario_id), int(signal_id), int(winner_analysis_id), winner_param))
                    scheduled += 1

            if to_ack:
                await redis.xack(POSTPROC_STREAM_KEY, POSTPROC_GROUP, *to_ack)

            # —Å—É–º–º–∏—Ä—É—é—â–∏–π –ª–æ–≥ –ø–æ –±–∞—Ç—á—É
            if scheduled or ignored or bad:
                log.info(
                    "PACK_POSTPROC: batch handled (scheduled=%s, ignored=%s, bad=%s, ack=%s)",
                    scheduled,
                    ignored,
                    bad,
                    len(to_ack),
                )

        except Exception as e:
            log.error("PACK_POSTPROC loop error: %s", e, exc_info=True)
            await asyncio.sleep(2)