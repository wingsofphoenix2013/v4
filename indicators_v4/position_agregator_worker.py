# position_agregator_worker.py ‚Äî –≤–æ—Ä–∫–µ—Ä –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –ø–æ–∑–∏—Ü–∏–π (—à–∞–≥ 1: —á—Ç–µ–Ω–∏–µ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∑–∞–∫—Ä—ã—Ç–∏–π)

import asyncio
import logging
import json
from datetime import datetime

log = logging.getLogger("IND_AGG")

STREAM   = "positions_update_stream"
GROUP    = "indicators_agg_group"
CONSUMER = "ind_agg_1"

READ_COUNT = 50
READ_BLOCK_MS = 2000

RETRY_MAX = 3
RETRY_BACKOFF = [0.5, 1.0, 2.0]


# üî∏ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä ISO-—Å—Ç—Ä–æ–∫ (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç 'Z' –∏ —Å–º–µ—â–µ–Ω–∏—è)
def _parse_iso(dt: str) -> datetime:
    s = dt.strip()
    if s.endswith("Z"):
        s = s[:-1] + "+00:00"
    return datetime.fromisoformat(s)


# üî∏ –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ–∑–∏—Ü–∏–∏ –ø–æ uid –∏–∑ positions_v4
async def _fetch_position(pg, position_uid: str):
    async with pg.acquire() as conn:
        row = await conn.fetchrow(
            """
            SELECT
                position_uid,
                strategy_id,
                symbol,
                direction,
                status,
                created_at,
                closed_at,
                pnl,
                audited
            FROM positions_v4
            WHERE position_uid = $1
            """,
            position_uid,
        )
        return row


# üî∏ –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ–∑–∏—Ü–∏–∏ —Å –∫–æ—Ä–æ—Ç–∫–∏–º–∏ —Ä–µ—Ç—Ä–∞—è–º–∏ (–Ω–∞ —Å–ª—É—á–∞–π –≥–æ–Ω–∫–∏ –∑–∞–ø–∏—Å–∏)
async def _fetch_position_with_retry(pg, position_uid: str):
    for attempt, delay in enumerate([0.0] + RETRY_BACKOFF):
        if delay:
            await asyncio.sleep(delay)
        row = await _fetch_position(pg, position_uid)
        if row:
            return row
        log.info(f"[RETRY] position {position_uid} not found (attempt {attempt+1}/{RETRY_MAX+1})")
        if attempt >= RETRY_MAX:
            break
    return None


# üî∏ –û—Å–Ω–æ–≤–Ω–æ–π –≤–æ—Ä–∫–µ—Ä: –ø–æ–∫–∞ —Ç–æ–ª—å–∫–æ —á—Ç–µ–Ω–∏–µ —Å—Ç—Ä–∏–º–∞ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏–π –∑–∞–∫—Ä—ã—Ç–∏—è
async def run_position_aggregator_worker(pg, redis):
    try:
        await redis.xgroup_create(STREAM, GROUP, id="$", mkstream=True)
        log.info(f"–ì—Ä—É–ø–ø–∞ {GROUP} —Å–æ–∑–¥–∞–Ω–∞ –¥–ª—è {STREAM}")
    except Exception as e:
        if "BUSYGROUP" in str(e):
            log.info(f"–ì—Ä—É–ø–ø–∞ {GROUP} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        else:
            log.exception("–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è consumer group")
            return

    while True:
        try:
            resp = await redis.xreadgroup(
                groupname=GROUP,
                consumername=CONSUMER,
                streams={STREAM: ">"},
                count=READ_COUNT,
                block=READ_BLOCK_MS,
            )
            if not resp:
                continue

            to_ack = []
            for _, messages in resp:
                for msg_id, data in messages:
                    to_ack.append(msg_id)
                    try:
                        payload = data.get("data")
                        if not payload:
                            log.info("[SKIP] empty 'data' in message")
                            continue

                        try:
                            event = json.loads(payload)
                        except Exception:
                            log.warning("[SKIP] bad JSON in 'data'")
                            continue

                        if event.get("event_type") != "closed":
                            continue

                        uid = event.get("position_uid")
                        if not uid:
                            log.warning("[SKIP] closed event without position_uid")
                            continue

                        row = await _fetch_position_with_retry(pg, uid)
                        if not row:
                            log.warning(f"[SKIP] position not found in DB: uid={uid}")
                            continue

                        status = row["status"]
                        pnl = row["pnl"]
                        audited = row["audited"]
                        strategy_id = row["strategy_id"]
                        closed_at = row["closed_at"]

                        if status != "closed":
                            log.info(f"[SKIP] uid={uid} status={status} (not closed)")
                            continue
                        if pnl is None:
                            log.info(f"[SKIP] uid={uid} pnl is NULL")
                            continue
                        if audited:
                            log.info(f"[SKIP] uid={uid} already audited")
                            continue

                        log.info(f"[READY] uid={uid} strategy={strategy_id} pnl={pnl} closed_at={closed_at} ‚Üí –≥–æ—Ç–æ–≤–æ –∫ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ RSI")

                    except Exception:
                        log.exception("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è positions_update_stream")

            if to_ack:
                await redis.xack(STREAM, GROUP, *to_ack)

        except Exception as e:
            log.error(f"–û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ IND_AGG: {e}", exc_info=True)
            await asyncio.sleep(2)