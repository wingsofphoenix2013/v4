# indicator_position_stat.py ‚Äî –≤–æ—Ä–∫–µ—Ä on-demand —Å–Ω–∏–º–∫–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –ø—Ä–∏ –æ—Ç–∫—Ä—ã—Ç–∏–∏ –ø–æ–∑–∏—Ü–∏–∏ (—ç—Ç–∞–ø 1: —Ç–æ–ª—å–∫–æ ¬´—Å—ã—Ä—ã–µ¬ª –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –ø–æ m5; –∞–Ω—Ç–∏–¥—É–±–ª–∏, –ø—Ä–∏–≤—è–∑–∫–∞ –æ—Ç–≤–µ—Ç–æ–≤ –ø–æ req_id)

import asyncio
import json
import logging
from datetime import datetime, timedelta

# üî∏ –£—Ç–∏–ª–∏—Ç—ã –≤—Ä–µ–º–µ–Ω–∏ TF (floor –∫ –Ω–∞—á–∞–ª—É –±–∞—Ä–∞)
from packs.pack_utils import STEP_MS, floor_to_bar

# üî∏ –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã —Å—Ç—Ä–∏–º–æ–≤ –∏ —Ç–∞–±–ª–∏—Ü
POSITIONS_OPEN_STREAM = "positions_open_stream"
INDICATOR_REQ_STREAM = "indicator_request"
INDICATOR_RESP_STREAM = "indicator_response"
TARGET_TABLE = "indicator_position_stat"

# üî∏ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–æ—Ä–∫–µ—Ä–∞ (—ç—Ç–∞–ø 1)
REQUIRED_TFS = ("m5",)          # –Ω–∞ —ç—Ç–æ–º —ç—Ç–∞–ø–µ —Å—á–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ m5
POLL_INTERVAL_SEC = 1           # —á–∞—Å—Ç–æ—Ç–∞ —Ä–µ—Ç—Ä–∞–µ–≤ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
GLOBAL_TIMEOUT_SEC = 600        # 10 –º–∏–Ω—É—Ç –Ω–∞ –ø–æ–∑–∏—Ü–∏—é
BATCH_SIZE_POS_OPEN = 20        # —Å–∫–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ–∑–∏—Ü–∏–π —á–∏—Ç–∞–µ–º –∑–∞ —Ä–∞–∑
BATCH_SIZE_RESP_READ = 200      # —Å–∫–æ–ª—å–∫–æ –æ—Ç–≤–µ—Ç–æ–≤ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ —á–∏—Ç–∞–µ–º –∑–∞ —Ä–∞–∑
CONCURRENCY_PER_TF = 50         # –ª–æ–∫–∞–ª—å–Ω—ã–π –ª–∏–º–∏—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ per TF

# üî∏ –õ–æ–≥–≥–µ—Ä
log = logging.getLogger("IND_POS_STAT")


# üî∏ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–æ–µ: –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–∏ –∫ open_time –±–∞—Ä–∞ TF (ms)
def to_bar_open_ms(created_at_iso: str, tf: str) -> int:
    dt = datetime.fromisoformat(created_at_iso)
    ts_ms = int(dt.timestamp() * 1000)
    return floor_to_bar(ts_ms, tf)


# üî∏ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–æ–µ: —Ä–∞–∑–æ–±—Ä–∞—Ç—å ISO –≤ datetime
def parse_iso(s: str) -> datetime:
    return datetime.fromisoformat(s)


# üî∏ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–æ–µ: –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ INSERT –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–¥–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞
def build_rows_for_indicator_response(position_uid: str,
                                      strategy_id: int,
                                      symbol: str,
                                      tf: str,
                                      indicator_name: str,
                                      open_time_iso: str,
                                      results_json: str) -> list[tuple]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π –¥–ª—è executemany INSERT –≤ indicator_position_stat.
    param_type='indicator', param_base=<–∫–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞>, param_name=<–∫–∞–Ω–æ–Ω. –∏–º—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞>.
    value_num ‚Äî float, value_text ‚Äî NULL; status='ok'.
    """
    rows = []
    try:
        results = json.loads(results_json)
    except Exception:
        results = {}

    if not isinstance(results, dict) or not results:
        return rows

    open_time = parse_iso(open_time_iso)

    for param_name, str_val in results.items():
        try:
            value_num = float(str_val)
        except Exception:
            # –Ω–∞ —ç—Ç–∞–ø–µ 1 —Ö—Ä–∞–Ω–∏–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            continue

        rows.append((
            position_uid,                 # position_uid
            strategy_id,                  # strategy_id
            symbol,                       # symbol
            tf,                           # timeframe
            "indicator",                  # param_type
            indicator_name,               # param_base (–∫–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞)
            param_name,                   # param_name (–∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–π param)
            value_num,                    # value_num
            None,                         # value_text
            open_time,                    # open_time
            "ok",                         # status
            None                          # error_code
        ))
    return rows


# üî∏ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–æ–µ: INSERT –ø–∞—á–∫–∏ —Å—Ç—Ä–æ–∫ –≤ PG (UPSERT –ø–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–º—É –∫–ª—é—á—É)
async def insert_rows_pg(pg, rows: list[tuple]) -> tuple[int, int]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (upsert_count, unique_count).
    upsert_count ‚Äî —Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ –æ—Ç–ø—Ä–∞–≤–∏–ª–∏ –≤ executemany (–ø–æ—Å–ª–µ –ª–æ–∫–∞–ª—å–Ω–æ–π –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏),
    unique_count ‚Äî —Å–∫–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö (–ø–æ –∫–ª—é—á—É) —Å—Ç—Ä–æ–∫ —Ä–µ–∞–ª—å–Ω–æ —Ö—Ä–∞–Ω–∏—Ç—Å—è –ø–æ—Å–ª–µ –æ–ø–µ—Ä–∞—Ü–∏–∏.
    """
    if not rows:
        return 0, 0

    async with pg.acquire() as conn:
        async with conn.transaction():
            await conn.executemany(f"""
                INSERT INTO {TARGET_TABLE}
                (position_uid, strategy_id, symbol, timeframe, param_type, param_base, param_name,
                 value_num, value_text, open_time, status, error_code, captured_at)
                VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12, NOW())
                ON CONFLICT (position_uid, timeframe, param_type, param_base, param_name)
                DO UPDATE SET
                    value_num = EXCLUDED.value_num,
                    value_text = EXCLUDED.value_text,
                    open_time = EXCLUDED.open_time,
                    status = EXCLUDED.status,
                    error_code = EXCLUDED.error_code,
                    captured_at = NOW()
            """, rows)

            # —Å—á–∏—Ç–∞–µ–º —Ä–µ–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–æ–∫ –ø–æ –ø–æ–∑–∏—Ü–∏–∏
            # (—ç—Ç–æ –Ω–µ–¥–æ—Ä–æ–≥–æ: –æ–¥–Ω–∞ –∞–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –Ω—É–∂–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏; –∏—Å–ø–æ–ª—å–∑—É–µ–º DISTINCT ON –∫–ª—é—á–µ)
            sample = rows[0]
            position_uid = sample[0]
            rec = await conn.fetchrow(f"""
                SELECT COUNT(*) AS cnt
                FROM {TARGET_TABLE}
                WHERE position_uid = $1
            """, position_uid)
            unique_count = int(rec["cnt"]) if rec else 0

    return len(rows), unique_count


# üî∏ –û—Å–Ω–æ–≤–Ω–æ–π –≤–æ—Ä–∫–µ—Ä: —á–∏—Ç–∞–µ–º –æ—Ç–∫—Ä—ã—Ç–∏—è –ø–æ–∑–∏—Ü–∏–π –∏ —Å–Ω–∏–º–∞–µ–º ¬´—Å—ã—Ä—ã–µ¬ª –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –ø–æ m5 (—Å –∞–Ω—Ç–∏–¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∑–∞–ø—Ä–æ—Å–æ–≤/–æ—Ç–≤–µ—Ç–æ–≤)
async def run_indicator_position_stat(pg, redis, get_instances_by_tf, get_precision):
    """
    –≠—Ç–∞–ø 1:
    - –ü–æ–¥–ø–∏—Å—ã–≤–∞–µ–º—Å—è –Ω–∞ positions_open_stream —Å–≤–æ–µ–π consumer-group.
    - –ù–∞ —Å–æ–±—ã—Ç–∏–µ ¬´opened¬ª: –¥–ª—è –∫–∞–∂–¥–æ–≥–æ TF –∏–∑ REQUIRED_TFS (–ø–æ–∫–∞ —Ç–æ–ª—å–∫–æ m5)
      –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º indicator_request –ø–æ –≤—Å–µ–º –∞–∫—Ç–∏–≤–Ω—ã–º –∏–Ω—Å—Ç–∞–Ω—Å–∞–º TF.
    - –ò–∑–±–µ–≥–∞–µ–º –¥—É–±–ª–µ–π: –æ–¥–∏–Ω –∞–∫—Ç–∏–≤–Ω—ã–π –∑–∞–ø—Ä–æ—Å –Ω–∞ instance; –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –æ—Ç–≤–µ—Ç—ã —Å –Ω–∞—à–∏–º–∏ req_id.
    - –†–µ—Ç—Ä–∞–∏–º –æ—Ç–≤–µ—Ç—ã –∫–∞–∂–¥—ã–µ 1—Å –¥–æ –ø–æ–ª–Ω–æ–π –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –ª–∏–±–æ –¥–æ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —Ç–∞–π–º–∞—É—Ç–∞ 10 –º–∏–Ω—É—Ç.
    - –ü–∏—à–µ–º —Ç–æ–ª—å–∫–æ param_type='indicator' —Å—Ç—Ä–æ–∫–∏ –≤ indicator_position_stat.
    - –õ–æ–≥–∏ –ø–æ –∏—Ç–æ–≥–∞–º ‚Äî log.info.
    """
    group = "iv4_possnap_group"
    consumer = "iv4_possnap_1"

    # —Å–æ–∑–¥–∞—Ç—å consumer-group (–∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ)
    try:
        await redis.xgroup_create(POSITIONS_OPEN_STREAM, group, id="$", mkstream=True)
    except Exception as e:
        if "BUSYGROUP" not in str(e):
            log.warning(f"xgroup_create error: {e}")

    # –ª–æ–∫–∞–ª—å–Ω—ã–π –æ—Ñ—Ñ—Å–µ—Ç –¥–ª—è —á—Ç–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–æ–≤ indicator_response (XREAD –±–µ–∑ –≥—Ä—É–ø–ø—ã ‚Äî –Ω–µ –¥–µ—Ä–∂–∏–º PEL –∏ –Ω–µ –º–µ—à–∞–µ–º –¥—Ä—É–≥–∏–º)
    last_resp_id = "0-0"

    # üî∏ –ü—É–ª —Å–µ–º–∞—Ñ–æ—Ä–æ–≤ –ø–æ TF –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞
    tf_semaphores = {tf: asyncio.Semaphore(CONCURRENCY_PER_TF) for tf in REQUIRED_TFS}

    while True:
        try:
            resp = await redis.xreadgroup(
                groupname=group,
                consumername=consumer,
                streams={POSITIONS_OPEN_STREAM: ">"},
                count=BATCH_SIZE_POS_OPEN,
                block=2000
            )
            if not resp:
                continue

            to_ack: list[str] = []

            # –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–∑–∏—Ü–∏–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ (m5 –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –≤–Ω—É—Ç—Ä–∏ –ø–æ–∑–∏—Ü–∏–∏)
            for _, messages in resp:
                for msg_id, data in messages:
                    try:
                        if (data.get("event_type") or "").lower() != "opened":
                            to_ack.append(msg_id)
                            continue

                        position_uid = data["position_uid"]
                        strategy_id = int(data["strategy_id"])
                        symbol = data["symbol"]
                        created_at_iso = data.get("created_at") or data.get("received_at")
                        if not created_at_iso:
                            log.info(f"[SKIP] position {position_uid}: no created_at/received_at")
                            to_ack.append(msg_id)
                            continue

                        # –∞–∫—Ç–∏–≤–Ω—ã–µ –∏–Ω—Å—Ç–∞–Ω—Å—ã per TF (—Ç–æ–ª—å–∫–æ m5 –Ω–∞ —ç—Ç–∞–ø–µ 1)
                        instances_by_tf = {tf: [i for i in get_instances_by_tf(tf)] for tf in REQUIRED_TFS}

                        # –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ–∂–∏–¥–∞–Ω–∏—è: –ø–æ –∫–∞–∂–¥–æ–º—É instance ‚Äî inflight, req_ids, state, last_err, last_req_at
                        ctx = {
                            tf: {
                                inst["id"]: {
                                    "inflight": False,
                                    "req_ids": set(),
                                    "state": "pending",    # pending|ok|error
                                    "last_err": None,
                                    "last_req_at": None,
                                } for inst in instances
                            } for tf, instances in instances_by_tf.items()
                        }

                        start_ts = datetime.utcnow()
                        deadline = start_ts + timedelta(seconds=GLOBAL_TIMEOUT_SEC)
                        bar_open_ms_by_tf = {tf: to_bar_open_ms(created_at_iso, tf) for tf in REQUIRED_TFS}

                        # helper: —Ä–µ—Ç—Ä–∞–∏–±–µ–ª—å–Ω–∞ –ª–∏ –æ—à–∏–±–∫–∞
                        def is_retriable(err: str) -> bool:
                            return err not in ("instance_not_active", "exception")

                        # helper: –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–Ω—Å—Ç–∞–Ω—Å–∞ (–µ—Å–ª–∏ –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ)
                        async def request_one(tf: str, inst: dict):
                            s = ctx[tf][inst["id"]]
                            if s["inflight"]:
                                return
                            async with tf_semaphores[tf]:
                                rid = await redis.xadd(INDICATOR_REQ_STREAM, {
                                    "symbol": symbol,
                                    "timeframe": tf,
                                    "instance_id": str(inst["id"]),
                                    "timestamp_ms": str(bar_open_ms_by_tf[tf])
                                })
                            s["inflight"] = True
                            s["req_ids"].add(rid)
                            s["last_req_at"] = datetime.utcnow()

                        # helper: –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –≤—Å–µ—Ö pending –ø–æ TF
                        async def request_all_pending(tf: str, first_round: bool):
                            tasks = []
                            for inst in instances_by_tf[tf]:
                                s = ctx[tf][inst["id"]]
                                if s["state"] != "pending":
                                    continue
                                # –Ω–∞ –ø–µ—Ä–≤–æ–π –≤–æ–ª–Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ–º; –¥–∞–ª–µ–µ ‚Äî —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–∞—è –ø–æ–ø—ã—Ç–∫–∞ –¥–∞–ª–∞ retriable –æ—à–∏–±–∫—É –∏ –∑–∞–ø—Ä–æ—Å –Ω–µ –≤ –ø–æ–ª—ë—Ç–µ
                                if first_round or ((s["last_err"] is not None) and is_retriable(s["last_err"]) and not s["inflight"]):
                                    tasks.append(asyncio.create_task(request_one(tf, inst)))
                            if tasks:
                                await asyncio.gather(*tasks, return_exceptions=True)

                        # helper: —á—Ç–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ indicator_response (—Ç–æ–ª—å–∫–æ –Ω–∞—à–∏ req_id), –±–µ–∑ –∑–∞—Ö–≤–∞—Ç–∞ —á—É–∂–∏—Ö
                        async def drain_indicator_responses():
                            nonlocal last_resp_id
                            try:
                                got = await redis.xread(
                                    streams={INDICATOR_RESP_STREAM: last_resp_id},
                                    count=BATCH_SIZE_RESP_READ,
                                    block=1000
                                )
                            except Exception:
                                return []
                            if not got:
                                return []
                            out = []
                            for _, msgs in got:
                                for rid, payload in msgs:
                                    out.append((rid, payload))
                                    last_resp_id = rid
                            return out

                        # helper: —Å–æ–±—Ä–∞—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è PG (–ª–æ–∫–∞–ª—å–Ω–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ –∫–ª—é—á—É)
                        def dedup_rows(rows: list[tuple]) -> list[tuple]:
                            seen = set()
                            out = []
                            for r in rows:
                                key = (r[0], r[3], r[4], r[5], r[6])  # (position_uid, timeframe, param_type, param_base, param_name)
                                if key in seen:
                                    continue
                                seen.add(key)
                                out.append(r)
                            return out

                        # –≥–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª —Ä–µ—Ç—Ä–∞–µ–≤ ‚Äî –¥–æ –ø–æ–ª–Ω–æ–π –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ m5 –∏–ª–∏ —Ç–∞–π–º–∞—É—Ç–∞
                        total_upserts = 0
                        unique_after = 0
                        first_round = True
                        while True:
                            now = datetime.utcnow()
                            if now >= deadline:
                                # —Ç–∞–π–º–∞—É—Ç ‚Äî –ª–æ–≥–∏—Ä—É–µ–º –Ω–µ–∑–∞–∫—Ä—ã—Ç—ã–µ
                                for tf in REQUIRED_TFS:
                                    for inst in instances_by_tf[tf]:
                                        s = ctx[tf][inst["id"]]
                                        if s["state"] == "pending":
                                            log.info(f"[TIMEOUT] position {position_uid} {symbol}/{tf} inst_id={inst['id']} indicator={inst['indicator']} last_err={s['last_err']}")
                                break

                            # 1) –æ—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤: m5 —Å–Ω–∞—á–∞–ª–∞
                            if "m5" in REQUIRED_TFS:
                                await request_all_pending("m5", first_round)
                            # –¥—Ä—É–≥–∏–µ TF –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–∞ —ç—Ç–∞–ø–µ 1
                            first_round = False

                            # 2) —Å–æ–±–∏—Ä–∞–µ–º –æ—Ç–≤–µ—Ç—ã –≤ —Ç–µ—á–µ–Ω–∏–µ POLL_INTERVAL_SEC
                            end_wait = now + timedelta(seconds=POLL_INTERVAL_SEC)
                            collected_rows: list[tuple] = []

                            while datetime.utcnow() < end_wait:
                                batch = await drain_indicator_responses()
                                if not batch:
                                    await asyncio.sleep(0.05)
                                    continue

                                for resp_id, payload in batch:
                                    status = payload.get("status")
                                    req_id = payload.get("req_id")
                                    r_symbol = payload.get("symbol")
                                    tf = payload.get("timeframe")
                                    instance_id_raw = payload.get("instance_id")

                                    # —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Å–∏–º–≤–æ–ª—É/TF/instance –∏ strict –ø–æ –Ω–∞—à–µ–º—É req_id
                                    if tf not in ctx or r_symbol != symbol or not instance_id_raw or not req_id:
                                        continue
                                    iid = int(instance_id_raw)
                                    if iid not in ctx[tf]:
                                        continue
                                    s = ctx[tf][iid]
                                    if req_id not in s["req_ids"]:
                                        # —ç—Ç–æ –Ω–µ –æ—Ç–≤–µ—Ç –Ω–∞ –Ω–∞—à –∑–∞–ø—Ä–æ—Å ‚Äî –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º
                                        continue

                                    # —ç—Ç–æ—Ç req_id –æ–±—Ä–∞–±–æ—Ç–∞–Ω ‚Äî —Å–Ω–∏–º–∞–µ–º inflight-—Ñ–ª–∞–≥
                                    s["req_ids"].discard(req_id)
                                    s["inflight"] = False

                                    if status == "ok":
                                        inst = next((i for i in instances_by_tf[tf] if i["id"] == iid), None)
                                        if not inst:
                                            continue
                                        rows = build_rows_for_indicator_response(
                                            position_uid=position_uid,
                                            strategy_id=strategy_id,
                                            symbol=symbol,
                                            tf=tf,
                                            indicator_name=inst["indicator"],
                                            open_time_iso=payload.get("open_time"),
                                            results_json=payload.get("results", "{}"),
                                        )
                                        collected_rows.extend(rows)
                                        s["state"] = "ok"
                                        s["last_err"] = None
                                    elif status == "error":
                                        err = payload.get("error") or "unknown"
                                        s["last_err"] = err
                                        if err in ("instance_not_active", "exception"):
                                            s["state"] = "error"
                                        # –∏–Ω–∞—á–µ –æ—Å—Ç–∞—ë—Ç—Å—è pending ‚Äî –ø–µ—Ä–µ–∑–∞–ø—Ä–æ—Å–∏–º –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–º —Ç–∏–∫–µ

                                await asyncio.sleep(0.01)

                            # 3) –ª–æ–∫–∞–ª—å–Ω–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∏ –∑–∞–ø–∏—Å—å –≤ PG
                            if collected_rows:
                                deduped = dedup_rows(collected_rows)
                                upserts, unique_cnt = await insert_rows_pg(pg, deduped)
                                total_upserts += upserts
                                unique_after = unique_cnt  # —Ä–µ–∞–ª—å–Ω–æ–µ —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∫–æ–ª-–≤–æ —Å—Ç—Ä–æ–∫ –ø–æ –ø–æ–∑–∏—Ü–∏–∏ –ø–æ—Å–ª–µ —ç—Ç–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏

                            # 4) –ø—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ m5
                            all_done = True
                            for tf in REQUIRED_TFS:
                                states = [ctx[tf][inst["id"]]["state"] for inst in instances_by_tf[tf]]
                                # ¬´–Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –≤—Å–µ¬ª: –Ω–µ—Ç pending –∏ –Ω–µ—Ç error
                                if any(s in ("pending", "error") for s in states):
                                    all_done = False
                            if all_done:
                                elapsed_ms = int((datetime.utcnow() - start_ts).total_seconds() * 1000)
                                ok_cnt = sum(1 for tf in REQUIRED_TFS for inst in instances_by_tf[tf] if ctx[tf][inst["id"]]["state"] == "ok")
                                log.info(
                                    f"IND_POS_STAT: position={position_uid} {symbol} m5 snapshot complete: "
                                    f"ok_instances={ok_cnt}, rows_upserted={total_upserts}, unique_rows={unique_after}, elapsed_ms={elapsed_ms}"
                                )
                                break

                        # –ø–æ–∑–∏—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –Ω–∞ —ç—Ç–∞–ø–µ 1 –ø–æ—Å–ª–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ m5 –∏–ª–∏ —Ç–∞–π–º–∞—É—Ç–∞
                        to_ack.append(msg_id)

                    except Exception as e:
                        log.error(f"position handling error: {e}", exc_info=True)
                        # –Ω–µ ACK ‚Äî —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É

            # –±–∞—Ç—á–µ–≤—ã–π ACK –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö
            if to_ack:
                await redis.xack(POSITIONS_OPEN_STREAM, group, *to_ack)

        except Exception as e:
            log.error(f"run loop error: {e}", exc_info=True)
            await asyncio.sleep(0.5)