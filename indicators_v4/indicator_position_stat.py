# indicator_position_stat.py ‚Äî –≤–æ—Ä–∫–µ—Ä on-demand —Å–Ω–∏–º–∫–∞ –ø—Ä–∏ –æ—Ç–∫—Ä—ã—Ç–∏–∏ –ø–æ–∑–∏—Ü–∏–∏ (—ç—Ç–∞–ø 2: m5 –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã + packs + marketwatch, –∞–Ω—Ç–∏–¥—É–±–ª–∏, –±—ã—Å—Ç—Ä—ã–π —Å–±–æ—Ä –æ—Ç–≤–µ—Ç–æ–≤)

import asyncio
import json
import logging
from datetime import datetime, timedelta

# üî∏ –í—Ä–µ–º—è –±–∞—Ä–∞ –∏ —à–∞–≥–∏ TF
from packs.pack_utils import floor_to_bar, STEP_MS

# üî∏ –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã —Å—Ç—Ä–∏–º–æ–≤ –∏ —Ç–∞–±–ª–∏—Ü
POSITIONS_OPEN_STREAM = "positions_open_stream"
INDICATOR_REQ_STREAM = "indicator_request"
INDICATOR_RESP_STREAM = "indicator_response"
GW_REQ_STREAM = "indicator_gateway_request"
GW_RESP_STREAM = "indicator_gateway_response"
TARGET_TABLE = "indicator_position_stat"

# üî∏ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–æ—Ä–∫–µ—Ä–∞
REQUIRED_TFS = ("m5",)             # —ç—Ç–∞–ø 2 ‚Äî —Ç–æ–ª—å–∫–æ m5
POLL_INTERVAL_SEC = 1              # —á–∞—Å—Ç–æ—Ç–∞ —Ä–µ—Ç—Ä–∞–µ–≤ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π
RESP_BLOCK_MS = 300                # –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –∫–æ—Ä–æ—Ç–∫–∏–π –±–ª–æ–∫ –Ω–∞ —á—Ç–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ (~0.3—Å)
GLOBAL_TIMEOUT_SEC = 600           # 10 –º–∏–Ω—É—Ç –Ω–∞ –ø–æ–∑–∏—Ü–∏—é
BATCH_SIZE_POS_OPEN = 20           # —á—Ç–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π –ø–æ–∑–∏—Ü–∏–π
BATCH_SIZE_RESP_READ = 200         # —á—Ç–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ (indicator/gateway)
CONCURRENCY_PER_TF = 50            # –ª–∏–º–∏—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö on-demand –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ TF

# üî∏ –ù–∞–±–æ—Ä—ã –ø–∞–∫–æ–≤ –∏ MW
PACK_INDS = ("ema", "rsi", "mfi", "lr", "atr", "adx_dmi", "macd", "bb")
MW_KINDS = ("trend", "volatility", "momentum", "extremes")

# üî∏ –õ–æ–≥–≥–µ—Ä
log = logging.getLogger("IND_POS_STAT")


# üî∏ –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è created_at ‚Üí open_time –±–∞—Ä–∞ (ms)
def to_bar_open_ms(created_at_iso: str, tf: str) -> int:
    dt = datetime.fromisoformat(created_at_iso)
    return floor_to_bar(int(dt.timestamp() * 1000), tf)


# üî∏ –ü–∞—Ä—Å ISO ‚Üí datetime
def parse_iso(s: str) -> datetime:
    return datetime.fromisoformat(s)


# üî∏ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å—Ç—Ä–æ–∫ –¥–ª—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ (param_type='indicator')
def build_rows_for_indicator_response(position_uid: str,
                                      strategy_id: int,
                                      symbol: str,
                                      tf: str,
                                      indicator_name: str,
                                      open_time_iso: str,
                                      results_json: str) -> list[tuple]:
    rows = []
    try:
        results = json.loads(results_json)
    except Exception:
        results = {}

    if not isinstance(results, dict) or not results:
        return rows

    open_time = parse_iso(open_time_iso)

    for param_name, str_val in results.items():
        try:
            value_num = float(str_val)
        except Exception:
            continue
        rows.append((
            position_uid, strategy_id, symbol, tf,
            "indicator",                   # param_type
            indicator_name,                # param_base (–∫–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞: ema/lr/...)
            param_name,                    # param_name (–∫–∞–Ω–æ–Ω–∏–∫–∞: ema9, lr50_angle, ...)
            value_num, None,               # value_num, value_text
            open_time,                     # open_time
            "ok", None                     # status, error_code
        ))
    return rows


# üî∏ –£—Ç–∏–ª–∏—Ç–∞: ¬´–ø–ª–æ—Å–∫–∏–π¬ª –æ–±—Ö–æ–¥ —Å–ª–æ–≤–∞—Ä—è pack['pack']
def flatten_pack_dict(d: dict, prefix=""):
    for k, v in d.items():
        if k in ("open_time", "ref"):  # –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø–∞–∫–æ–≤ –Ω–µ –ø–∏—à–µ–º –∫–∞–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            continue
        name = f"{prefix}{k}" if not prefix else f"{prefix}.{k}"
        if isinstance(v, dict):
            # –≤–ª–æ–∂–µ–Ω–Ω—ã–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, deltas.*)
            yield from flatten_pack_dict(v, name)
        else:
            yield (name, v)


# üî∏ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å—Ç—Ä–æ–∫ –¥–ª—è –ø–∞–∫–æ–≤ (param_type='pack')
def build_rows_for_pack_response(position_uid: str,
                                 strategy_id: int,
                                 symbol: str,
                                 tf: str,
                                 base: str,
                                 open_time_iso: str,
                                 pack_payload: dict) -> list[tuple]:
    rows = []
    open_time = parse_iso(open_time_iso)
    for pname, pval in flatten_pack_dict(pack_payload):
        # —á–∏—Å–ª–∞ ‚Üí value_num, —Å—Ç—Ä–æ–∫–∏/–±—É–ª–µ–≤—ã ‚Üí value_text
        val_num = None
        val_text = None
        if isinstance(pval, (int, float)):
            val_num = float(pval)
        else:
            # —Å—Ç—Ä–æ–∫–∏ –≤–∏–¥–∞ "0.04" —Ç–æ–∂–µ —Å—á–∏—Ç–∞–µ–º —á–∏—Å–ª–∞–º–∏
            try:
                val_num = float(pval)
            except Exception:
                if isinstance(pval, bool):
                    val_text = "true" if pval else "false"
                else:
                    # –µ—Å–ª–∏ —Å–ø–∏—Å–æ–∫/None ‚Äî —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º –∫—Ä–∞—Ç–∫–æ –≤ —Ç–µ–∫—Å—Ç
                    if pval is None:
                        val_text = None  # –ø—Ä–æ–ø—É—Å—Ç–∏–º —Ç–∞–∫–∏–µ
                        continue
                    if isinstance(pval, (list, tuple)):
                        try:
                            val_text = json.dumps(pval)
                        except Exception:
                            continue
                    else:
                        val_text = str(pval)

        rows.append((
            position_uid, strategy_id, symbol, tf,
            "pack",          # param_type
            base,            # param_base (–Ω–∞–ø—Ä–∏–º–µ—Ä: ema50, bb20_2_0, macd12, trend ...)
            pname,           # param_name (–Ω–∞–ø—Ä–∏–º–µ—Ä: dist_pct, dynamic_smooth, deltas.d_adx)
            val_num, val_text,
            open_time,
            "ok", None
        ))
    return rows


# üî∏ –í—Å—Ç–∞–≤–∫–∞ –ø–∞—á–∫–∏ —Å—Ç—Ä–æ–∫ –≤ PG (UPSERT); –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (upsert_count, unique_count)
async def insert_rows_pg(pg, rows: list[tuple]) -> tuple[int, int]:
    if not rows:
        return 0, 0
    async with pg.acquire() as conn:
        async with conn.transaction():
            await conn.executemany(f"""
                INSERT INTO {TARGET_TABLE}
                (position_uid, strategy_id, symbol, timeframe, param_type, param_base, param_name,
                 value_num, value_text, open_time, status, error_code, captured_at)
                VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12, NOW())
                ON CONFLICT (position_uid, timeframe, param_type, param_base, param_name)
                DO UPDATE SET
                    value_num = EXCLUDED.value_num,
                    value_text = EXCLUDED.value_text,
                    open_time = EXCLUDED.open_time,
                    status = EXCLUDED.status,
                    error_code = EXCLUDED.error_code,
                    captured_at = NOW()
            """, rows)
            # —Ä–µ–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–æ–∫ –ø–æ –ø–æ–∑–∏—Ü–∏–∏
            sample = rows[0]
            position_uid = sample[0]
            rec = await conn.fetchrow(f"""
                SELECT COUNT(*) AS cnt
                FROM {TARGET_TABLE}
                WHERE position_uid = $1
            """, position_uid)
            unique_count = int(rec["cnt"]) if rec else 0
    return len(rows), unique_count


# üî∏ –ê–Ω—Ç–∏–¥—É–±–ª–∏: –ª–æ–∫–∞–ª—å–Ω–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∫–æ—Ä—Ç–µ–∂–µ–π –ø–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–º—É –∫–ª—é—á—É —Ç–∞–±–ª–∏—Ü—ã
def dedup_rows(rows: list[tuple]) -> list[tuple]:
    seen = set()
    out = []
    for r in rows:
        key = (r[0], r[3], r[4], r[5], r[6])  # position_uid,timeframe,param_type,param_base,param_name
        if key in seen:
            continue
        seen.add(key)
        out.append(r)
    return out


# üî∏ –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –æ–∂–∏–¥–∞–µ–º—ã–µ –±–∞–∑—ã –ø–∞–∫–æ–≤ –∏–∑ —Å–ø–∏—Å–∫–∞ –∏–Ω—Å—Ç–∞–Ω—Å–æ–≤ (–ø–æ TF)
def build_expected_pack_bases(instances: list[dict]) -> dict[str, set[str]]:
    expected: dict[str, set[str]] = {ind: set() for ind in PACK_INDS}
    for inst in instances:
        ind = inst["indicator"]
        params = inst["params"]
        if ind not in expected:
            continue
        if ind in ("ema", "rsi", "mfi", "atr", "adx_dmi", "lr"):
            try:
                L = int(params["length"])
                expected[ind].add(f"{ind}{L}")
            except Exception:
                pass
        elif ind == "macd":
            try:
                F = int(params["fast"])
                expected[ind].add(f"macd{F}")
            except Exception:
                pass
        elif ind == "bb":
            try:
                L = int(params["length"])
                S = round(float(params["std"]), 2)
                std_str = str(S).replace(".", "_")
                expected[ind].add(f"bb{L}_{std_str}")
            except Exception:
                pass
    return expected


# üî∏ –û—Å–Ω–æ–≤–Ω–æ–π –≤–æ—Ä–∫–µ—Ä: –ø–æ–∑–∏—Ü–∏–∏ ‚Üí m5 –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã + packs + MW (—Ä–µ—Ç—Ä–∞–∏ 1—Å, –±—ã—Å—Ç—Ä—ã–π —Å–±–æ—Ä –æ—Ç–≤–µ—Ç–æ–≤)
async def run_indicator_position_stat(pg, redis, get_instances_by_tf, get_precision):
    group = "iv4_possnap_group"
    consumer = "iv4_possnap_1"

    # —Å–æ–∑–¥–∞—Ç—å —Å–≤–æ—é consumer-group –¥–ª—è –≤—Ö–æ–¥–Ω–æ–≥–æ —Å—Ç—Ä–∏–º–∞
    try:
        await redis.xgroup_create(POSITIONS_OPEN_STREAM, group, id="$", mkstream=True)
    except Exception as e:
        if "BUSYGROUP" not in str(e):
            log.warning(f"xgroup_create error: {e}")

    # –æ—Ñ—Ñ—Å–µ—Ç—ã –¥–ª—è XREAD (–±–µ–∑ –≥—Ä—É–ø–ø) –ø–æ –æ—Ç–≤–µ—Ç–∞–º
    last_ind_resp_id = "0-0"
    last_gw_resp_id = "0-0"

    # –ª–∏–º–∏—Ç–µ—Ä –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ TF
    tf_semaphores = {tf: asyncio.Semaphore(CONCURRENCY_PER_TF) for tf in REQUIRED_TFS}

    # helper: —Ä–µ—Ç—Ä–∞–∏–±–µ–ª—å–Ω—ã–µ –æ—à–∏–±–∫–∏ on-demand
    def is_retriable(err: str) -> bool:
        return err not in ("instance_not_active", "exception")

    # helper: —á—Ç–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
    async def drain_indicator_responses():
        nonlocal last_ind_resp_id
        try:
            got = await redis.xread(streams={INDICATOR_RESP_STREAM: last_ind_resp_id},
                                    count=BATCH_SIZE_RESP_READ, block=RESP_BLOCK_MS)
        except Exception:
            return []
        if not got:
            return []
        out = []
        for _, msgs in got:
            for rid, payload in msgs:
                out.append((rid, payload))
                last_ind_resp_id = rid
        return out

    # helper: —á—Ç–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ gateway
    async def drain_gateway_responses():
        nonlocal last_gw_resp_id
        try:
            got = await redis.xread(streams={GW_RESP_STREAM: last_gw_resp_id},
                                    count=BATCH_SIZE_RESP_READ, block=RESP_BLOCK_MS)
        except Exception:
            return []
        if not got:
            return []
        out = []
        for _, msgs in got:
            for rid, payload in msgs:
                out.append((rid, payload))
                last_gw_resp_id = rid
        return out

    while True:
        try:
            resp = await redis.xreadgroup(groupname=group, consumername=consumer,
                                          streams={POSITIONS_OPEN_STREAM: ">"},
                                          count=BATCH_SIZE_POS_OPEN, block=2000)
            if not resp:
                continue

            to_ack = []

            for _, messages in resp:
                for msg_id, data in messages:
                    try:
                        if (data.get("event_type") or "").lower() != "opened":
                            to_ack.append(msg_id)
                            continue

                        position_uid = data["position_uid"]
                        strategy_id = int(data["strategy_id"])
                        symbol = data["symbol"]
                        created_at_iso = data.get("created_at") or data.get("received_at")
                        if not created_at_iso:
                            log.info(f"[SKIP] position {position_uid}: no created_at/received_at")
                            to_ack.append(msg_id)
                            continue

                        # –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ TF (—ç—Ç–∞–ø 2 ‚Äî —Ç–æ–ª—å–∫–æ m5)
                        instances_by_tf = {tf: [i for i in get_instances_by_tf(tf)] for tf in REQUIRED_TFS}
                        expected_bases_by_tf = {
                            tf: build_expected_pack_bases(instances_by_tf[tf]) for tf in REQUIRED_TFS
                        }
                        bar_open_ms_by_tf = {tf: to_bar_open_ms(created_at_iso, tf) for tf in REQUIRED_TFS}

                        # —Å–æ—Å—Ç–æ—è–Ω–∏—è
                        start_ts = datetime.utcnow()
                        deadline = start_ts + timedelta(seconds=GLOBAL_TIMEOUT_SEC)

                        # –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (per instance)
                        ind_ctx = {
                            tf: {
                                inst["id"]: {
                                    "inflight": False,
                                    "req_ids": set(),
                                    "state": "pending",  # pending|ok|error
                                    "last_err": None
                                } for inst in instances_by_tf[tf]
                            } for tf in REQUIRED_TFS
                        }

                        # –ø–∞–∫–∏ (per indicator base) ‚Äî —Å—Ç—Ä–æ–∏–º –æ–∂–∏–¥–∞–µ–º—ã–µ –±–∞–∑—ã –∏–∑ –∞–∫—Ç–∏–≤–Ω—ã—Ö –∏–Ω—Å—Ç–∞–Ω—Å–æ–≤
                        pack_ctx = {
                            tf: {
                                ind: {
                                    "inflight": False,
                                    "req_ids": set(),
                                    "state": "pending",      # pending|ok_part|ok|error
                                    "done_bases": set(),     # –∫–∞–∫–∏–µ –±–∞–∑—ã —É–∂–µ –ø–æ–ª—É—á–∏–ª–∏ –∏ –∑–∞–ø–∏—Å–∞–ª–∏
                                    "expected_bases": set(expected_bases_by_tf[tf].get(ind, set())),
                                    "last_err": None
                                } for ind in PACK_INDS if expected_bases_by_tf[tf].get(ind)
                            } for tf in REQUIRED_TFS
                        }

                        # marketwatch (four kinds)
                        mw_ctx = {
                            tf: {
                                kind: {
                                    "inflight": False,
                                    "req_ids": set(),
                                    "state": "pending",      # pending|ok|error
                                    "last_err": None
                                } for kind in MW_KINDS
                            } for tf in REQUIRED_TFS
                        }

                        # helpers: –æ—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ (–∏–Ω–¥/–ø–∞–∫/–º–≤)
                        async def request_indicator(tf: str, inst: dict):
                            s = ind_ctx[tf][inst["id"]]
                            if s["inflight"] or s["state"] != "pending":
                                return
                            async with tf_semaphores[tf]:
                                rid = await redis.xadd(INDICATOR_REQ_STREAM, {
                                    "symbol": symbol,
                                    "timeframe": tf,
                                    "instance_id": str(inst["id"]),
                                    "timestamp_ms": str(bar_open_ms_by_tf[tf])
                                })
                            s["inflight"] = True
                            s["req_ids"].add(rid)

                        async def request_pack(tf: str, ind: str):
                            s = pack_ctx[tf][ind]
                            if s["inflight"] or s["state"] not in ("pending", "ok_part"):
                                return
                            async with tf_semaphores[tf]:
                                rid = await redis.xadd(GW_REQ_STREAM, {
                                    "symbol": symbol,
                                    "timeframe": tf,
                                    "indicator": ind,
                                    # –Ω–µ —É–∫–∞–∑—ã–≤–∞–µ–º length/std/fast ‚Üí gateway –≤–µ—Ä–Ω—ë—Ç –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –±–∞–∑—ã
                                    "timestamp_ms": str(bar_open_ms_by_tf[tf])
                                })
                            s["inflight"] = True
                            s["req_ids"].add(rid)

                        async def request_mw(tf: str, kind: str):
                            s = mw_ctx[tf][kind]
                            if s["inflight"] or s["state"] != "pending":
                                return
                            async with tf_semaphores[tf]:
                                rid = await redis.xadd(GW_REQ_STREAM, {
                                    "symbol": symbol,
                                    "timeframe": tf,
                                    "indicator": kind,
                                    "timestamp_ms": str(bar_open_ms_by_tf[tf])
                                })
                            s["inflight"] = True
                            s["req_ids"].add(rid)

                        # —Ü–∏–∫–ª –¥–æ –ø–æ–ª–Ω–æ–π –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ m5 –∏–ª–∏ —Ç–∞–π–º–∞—É—Ç–∞
                        total_upserts = 0
                        unique_after = 0
                        first_round = True

                        while True:
                            now = datetime.utcnow()
                            if now >= deadline:
                                # –ª–æ–≥–∏—Ä—É–µ–º, —á—Ç–æ –Ω–µ —É—Å–ø–µ–ª–∏
                                for tf in REQUIRED_TFS:
                                    # –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
                                    for inst in instances_by_tf[tf]:
                                        s = ind_ctx[tf][inst["id"]]
                                        if s["state"] == "pending":
                                            log.info(f"[TIMEOUT] IND {symbol}/{tf} inst_id={inst['id']} {inst['indicator']} last_err={s['last_err']}")
                                    # –ø–∞–∫–∏
                                    for ind in pack_ctx[tf]:
                                        s = pack_ctx[tf][ind]
                                        if s["state"] in ("pending", "ok_part"):
                                            missing = sorted(list(s["expected_bases"] - s["done_bases"]))
                                            log.info(f"[TIMEOUT] PACK {symbol}/{tf} {ind} missing_bases={missing} last_err={s['last_err']}")
                                    # MW
                                    for kind in mw_ctx[tf]:
                                        s = mw_ctx[tf][kind]
                                        if s["state"] == "pending":
                                            log.info(f"[TIMEOUT] MW {symbol}/{tf} {kind} last_err={s['last_err']}")
                                break

                            # 1) –ø–µ—Ä–≤–∞—è –≤–æ–ª–Ω–∞ ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å—Ä–∞–∑—É –≤—Å—ë –ø–æ m5
                            if first_round:
                                if "m5" in REQUIRED_TFS:
                                    # –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
                                    await asyncio.gather(*[
                                        request_indicator("m5", inst) for inst in instances_by_tf["m5"]
                                    ])
                                    # –ø–∞–∫–∏ (—Ç–æ–ª—å–∫–æ —Ç–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å –æ–∂–∏–¥–∞–µ–º—ã–µ –±–∞–∑—ã)
                                    await asyncio.gather(*[
                                        request_pack("m5", ind) for ind in pack_ctx["m5"].keys()
                                    ])
                                    # MW
                                    await asyncio.gather(*[
                                        request_mw("m5", kind) for kind in MW_KINDS
                                    ])
                                first_round = False
                            else:
                                # 2) —Ä–µ—Ç—Ä–∞–∏: —Ç–æ–ª—å–∫–æ —Ç–µ, –∫—Ç–æ retriable –∏ –Ω–µ inflight
                                for tf in REQUIRED_TFS:
                                    # –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
                                    for inst in instances_by_tf[tf]:
                                        s = ind_ctx[tf][inst["id"]]
                                        if s["state"] == "pending" and not s["inflight"] and (s["last_err"] is None or is_retriable(s["last_err"])):
                                            await request_indicator(tf, inst)
                                    # –ø–∞–∫–∏
                                    for ind in pack_ctx[tf]:
                                        s = pack_ctx[tf][ind]
                                        if s["state"] in ("pending", "ok_part") and not s["inflight"] and (s["last_err"] is None or is_retriable(s["last_err"])):
                                            await request_pack(tf, ind)
                                    # MW
                                    for kind in mw_ctx[tf]:
                                        s = mw_ctx[tf][kind]
                                        if s["state"] == "pending" and not s["inflight"] and (s["last_err"] is None or is_retriable(s["last_err"])):
                                            await request_mw(tf, kind)

                            # 3) —Å–æ–±–∏—Ä–∞–µ–º –æ—Ç–≤–µ—Ç—ã ~RESP_BLOCK_MS, –ø–æ–≤—Ç–æ—Ä—è–µ–º –≤–Ω—É—Ç—Ä–∏ –æ–∫–Ω–∞ POLL_INTERVAL_SEC
                            end_wait = now + timedelta(seconds=POLL_INTERVAL_SEC)
                            collected_rows = []

                            while datetime.utcnow() < end_wait:
                                # –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
                                for rid, payload in await drain_indicator_responses():
                                    status = payload.get("status")
                                    req_id = payload.get("req_id")
                                    r_symbol = payload.get("symbol")
                                    tf = payload.get("timeframe")
                                    instance_id_raw = payload.get("instance_id")
                                    if tf not in ind_ctx or r_symbol != symbol or not instance_id_raw or not req_id:
                                        continue
                                    iid = int(instance_id_raw)
                                    if iid not in ind_ctx[tf]:
                                        continue
                                    s = ind_ctx[tf][iid]
                                    if req_id not in s["req_ids"]:
                                        continue
                                    # —Å–Ω—è—Ç—å inflight
                                    s["req_ids"].discard(req_id)
                                    s["inflight"] = False
                                    if status == "ok":
                                        inst = next((i for i in instances_by_tf[tf] if i["id"] == iid), None)
                                        if not inst:
                                            continue
                                        rows = build_rows_for_indicator_response(
                                            position_uid=position_uid,
                                            strategy_id=strategy_id,
                                            symbol=symbol,
                                            tf=tf,
                                            indicator_name=inst["indicator"],
                                            open_time_iso=payload.get("open_time"),
                                            results_json=payload.get("results", "{}"),
                                        )
                                        collected_rows.extend(rows)
                                        s["state"] = "ok"
                                        s["last_err"] = None
                                    else:
                                        err = payload.get("error") or "unknown"
                                        s["last_err"] = err
                                        if not is_retriable(err):
                                            s["state"] = "error"

                                # gateway (packs + MW)
                                for rid, payload in await drain_gateway_responses():
                                    status = payload.get("status")
                                    req_id = payload.get("req_id")
                                    r_symbol = payload.get("symbol")
                                    tf = payload.get("timeframe")
                                    ind = payload.get("indicator")
                                    if tf not in pack_ctx or r_symbol != symbol or not ind or not req_id:
                                        continue

                                    # —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å pack –∏–ª–∏ mw
                                    # –ø—Ä–æ–±—É–µ–º pack
                                    ctx_slot = None
                                    ctx_type = None
                                    if ind in pack_ctx[tf]:
                                        ctx_slot = pack_ctx[tf][ind]
                                        ctx_type = "pack"
                                    elif ind in MW_KINDS:
                                        ctx_slot = mw_ctx[tf][ind]
                                        ctx_type = "mw"
                                    else:
                                        continue

                                    if req_id not in ctx_slot["req_ids"]:
                                        continue
                                    # —Å–Ω—è—Ç—å inflight
                                    ctx_slot["req_ids"].discard(req_id)
                                    ctx_slot["inflight"] = False

                                    if status == "ok":
                                        try:
                                            results = json.loads(payload.get("results", "[]"))
                                        except Exception:
                                            results = []

                                        # packs: results ‚Äî —Å–ø–∏—Å–æ–∫ {base, pack}
                                        if ctx_type == "pack":
                                            if not isinstance(results, list):
                                                ctx_slot["last_err"] = "bad_results"
                                            else:
                                                for item in results:
                                                    try:
                                                        base = item.get("base")
                                                        p = item.get("pack", {})
                                                        if not base or not isinstance(p, dict):
                                                            continue
                                                        # open_time –±–µ—Ä—ë–º –∏–∑ —Å–∞–º–æ–≥–æ –ø–∞–∫–µ—Ç–∞ (ISO)
                                                        open_time_iso = p.get("open_time") or payload.get("open_time") \
                                                            or datetime.utcfromtimestamp(bar_open_ms_by_tf[tf] / 1000).isoformat()
                                                        rows = build_rows_for_pack_response(
                                                            position_uid, strategy_id, symbol, tf, base, open_time_iso, p
                                                        )
                                                        collected_rows.extend(rows)
                                                        ctx_slot["done_bases"].add(base)
                                                    except Exception:
                                                        continue
                                            # —Å–æ—Å—Ç–æ—è–Ω–∏–µ: ok, –µ—Å–ª–∏ –∑–∞–∫—Ä—ã–ª–∏ –≤—Å–µ –æ–∂–∏–¥–∞–µ–º—ã–µ –±–∞–∑—ã
                                            if ctx_slot["expected_bases"] <= ctx_slot["done_bases"]:
                                                ctx_slot["state"] = "ok"
                                            else:
                                                ctx_slot["state"] = "ok_part"
                                            ctx_slot["last_err"] = None

                                        # mw: results ‚Äî —Å–ø–∏—Å–æ–∫ –∏–∑ –æ–¥–Ω–æ–≥–æ {base="trend", pack={...}}
                                        else:
                                            if not isinstance(results, list) or not results:
                                                ctx_slot["last_err"] = "bad_results"
                                            else:
                                                item = results[0]
                                                base = item.get("base", ind)
                                                p = item.get("pack", {})
                                                open_time_iso = p.get("open_time") or datetime.utcfromtimestamp(bar_open_ms_by_tf[tf] / 1000).isoformat()
                                                rows = build_rows_for_pack_response(
                                                    position_uid, strategy_id, symbol, tf, base, open_time_iso, p
                                                )
                                                collected_rows.extend(rows)
                                                ctx_slot["state"] = "ok"
                                                ctx_slot["last_err"] = None
                                    else:
                                        err = payload.get("error") or "unknown"
                                        ctx_slot["last_err"] = err
                                        if not is_retriable(err):
                                            ctx_slot["state"] = "error"

                                await asyncio.sleep(0.01)

                            # 4) –∑–∞–ø–∏—Å—å –≤ –ë–î (—Å –ª–æ–∫–∞–ª—å–Ω–æ–π –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–µ–π)
                            if collected_rows:
                                deduped = dedup_rows(collected_rows)
                                upserts, unique_cnt = await insert_rows_pg(pg, deduped)
                                total_upserts += upserts
                                unique_after = unique_cnt

                            # 5) –∫—Ä–∏—Ç–µ—Ä–∏–π –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ m5: –≤—Å–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã, –≤—Å–µ –±–∞–∑—ã –ø–∞–∫–æ–≤, –≤—Å–µ 4 MW ‚Äî –±–µ–∑ pending/error
                            def all_done_tf(tf: str) -> bool:
                                # –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
                                if any(s["state"] in ("pending", "error") for s in ind_ctx[tf].values()):
                                    return False
                                # –ø–∞–∫–∏
                                for ind, s in pack_ctx[tf].items():
                                    if s["state"] == "error":
                                        return False
                                    # –¥–æ–ª–∂–Ω—ã –∑–∞–∫—Ä—ã—Ç—å –≤—Å–µ –æ–∂–∏–¥–∞–µ–º—ã–µ –±–∞–∑—ã
                                    if not (s["expected_bases"] <= s["done_bases"]):
                                        return False
                                # MW
                                if any(s["state"] in ("pending", "error") for s in mw_ctx[tf].values()):
                                    return False
                                return True

                            all_done = True
                            for tf in REQUIRED_TFS:
                                if not all_done_tf(tf):
                                    all_done = False

                            if all_done:
                                elapsed_ms = int((datetime.utcnow() - start_ts).total_seconds() * 1000)
                                ok_inst = sum(1 for tf in REQUIRED_TFS for s in ind_ctx[tf].values() if s["state"] == "ok")
                                ok_packs = sum(len(s["done_bases"]) for tf in REQUIRED_TFS for s in pack_ctx[tf].values())
                                ok_mw = sum(1 for tf in REQUIRED_TFS for s in mw_ctx[tf].values() if s["state"] == "ok")
                                log.info(
                                    f"IND_POS_STAT: position={position_uid} {symbol} m5 snapshot complete: "
                                    f"ok_instances={ok_inst}, ok_packs={ok_packs}, ok_mw={ok_mw}, "
                                    f"rows_upserted={total_upserts}, unique_rows={unique_after}, elapsed_ms={elapsed_ms}"
                                )
                                break

                        # –ø–æ–∑–∏—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è —ç—Ç–∞–ø–∞ 2
                        to_ack.append(msg_id)

                    except Exception as e:
                        log.error(f"position handling error: {e}", exc_info=True)
                        # –Ω–µ ACK ‚Äî —á—Ç–æ–±—ã –ø–æ–≤—Ç–æ—Ä–∏—Ç—å

            if to_ack:
                await redis.xack(POSITIONS_OPEN_STREAM, group, *to_ack)

        except Exception as e:
            log.error(f"run loop error: {e}", exc_info=True)
            await asyncio.sleep(0.5)