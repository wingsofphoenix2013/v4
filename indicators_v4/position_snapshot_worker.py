# position_snapshot_worker.py ‚Äî –≤–æ—Ä–∫–µ—Ä —Å–Ω–∞–ø—à–æ—Ç–æ–≤ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤/–ø–∞–∫–æ–≤/MW –ø–æ –æ—Ç–∫—Ä—ã—Ç—ã–º –ø–æ–∑–∏—Ü–∏—è–º (m5 –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç; TF –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ; –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–æ–ª–Ω–æ—Ç–∞ —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ —Å–±–æ—Ä–∞–º–∏; UPSERT –≤ indicator_position_stat —Å —Ç–∞–π–º–∞—É—Ç–∞–º–∏)

import asyncio
import json
import logging
from datetime import datetime, timezone
import uuid


# üî∏ –õ–æ–≥–≥–µ—Ä
log = logging.getLogger("POS_SNAPSHOT")

# üî∏ –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã/–Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–æ—Ä–∫–µ—Ä–∞ (–±–µ–∑ ENV)
REQ_STREAM_POSITIONS = "positions_open_stream"
GW_REQ_STREAM        = "indicator_gateway_request"
GW_RESP_STREAM       = "indicator_gateway_response"

POS_CONCURRENCY             = 5            # —Å–∫–æ–ª—å–∫–æ –ø–æ–∑–∏—Ü–∏–π –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
BATCH_INSERT_SIZE           = 400          # –±–∞—Ç—á –≤—Å—Ç–∞–≤–∫–∏ –≤ PG
POS_TFS_ORDER               = ["m5", "m15", "h1"]  # –ø–æ—Ä—è–¥–æ–∫ TF (m5 –≤—Å–µ–≥–¥–∞ –ø–µ—Ä–≤—ã–º)
POS_DRY_RUN                 = False        # True = –Ω–µ –ø–∏—à–µ–º –≤ PG, —Ç–æ–ª—å–∫–æ –ª–æ–≥–∏

# –±—é–¥–∂–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –û–î–ò–ù TF (—Å–µ–∫): –¥–µ–ª–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ü–∏–∫–ª–æ–≤ "send-all ‚Üí collect" –¥–æ –¥–µ–¥–ª–∞–π–Ω–∞
POS_REQ_TIMEOUT_SEC         = 60.0
RETRY_GAP_SEC               = 3.0          # –ø–∞—É–∑–∞ –º–µ–∂–¥—É —Ü–∏–∫–ª–∞–º–∏ –¥–æ–≥—Ä—É–∑–∫–∏ "missing"

# —Ç–∞–π–º–∞—É—Ç—ã –∑–∞—â–∏—Ç—ã –æ—Ç ¬´–∑–∞–ª–∏–ø–∞–Ω–∏—è¬ª —Å–ª–æ—Ç–æ–≤
POS_POSITION_TIMEOUT_SEC    = 120.0        # –æ–±—â–∏–π –¥–µ–¥–ª–∞–π–Ω –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É –æ–¥–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏ (–≤—Å–µ TF –ø–æ–¥—Ä—è–¥)
DB_UPSERT_TIMEOUT_SEC       = 15.0         # —Ç–∞–π–º–∞—É—Ç –Ω–∞ –æ–¥–∏–Ω –±–∞—Ç—á UPSERT –≤ –ë–î (—Å–µ–∫)

# üî∏ –ü–∞–∫–µ—Ç—ã: –∫–∞–∫–∏–µ –ø–æ–ª—è –ø–∏—Å–∞—Ç—å –≤ indicator_position_stat (param_type='pack')
PACK_WHITELIST = {
    "rsi":     ["bucket_low", "trend"],
    "mfi":     ["bucket_low", "trend"],
    "bb":      ["bucket", "bucket_delta", "bw_trend_strict", "bw_trend_smooth"],
    "lr":      ["bucket", "bucket_delta", "angle_trend"],
    "atr":     ["bucket", "bucket_delta"],
    "adx_dmi": ["adx_bucket_low", "adx_dynamic_strict", "adx_dynamic_smooth",
                "gap_bucket_low", "gap_dynamic_strict", "gap_dynamic_smooth"],
    "ema":     ["side", "dynamic", "dynamic_strict", "dynamic_smooth"],
    "macd":    ["mode", "cross", "zero_side", "hist_bucket_low_pct",
                "hist_trend_strict", "hist_trend_smooth"],
}

# üî∏ –°–ø–∏—Å–æ–∫ —Ç–∏–ø–æ–≤ –Ω–∞ TF (RAW / PACK / MW)
RAW_TYPES  = ["rsi","mfi","ema","atr","lr","adx_dmi","macd","bb"]
PACK_TYPES = ["rsi","mfi","ema","atr","lr","adx_dmi","macd","bb"]
MW_TYPES   = ["trend","volatility","momentum","extremes"]


# üî∏ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ: floor –∫ –Ω–∞—á–∞–ª—É –±–∞—Ä–∞ –ø–æ TF (ms ‚Üí ms)
def floor_to_bar_ms(ts_ms: int, tf: str) -> int:
    step_map = {"m5": 5, "m15": 15, "h1": 60}
    step = step_map.get(tf)
    if not step:
        raise ValueError(f"unsupported tf: {tf}")
    step_ms = step * 60_000
    return (ts_ms // step_ms) * step_ms

# üî∏ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ: ISO ‚Üí ms (UTC-naive input ‚Üí treat as UTC)
def iso_to_ms(iso_str: str) -> int:
    dt = datetime.fromisoformat(iso_str)
    if dt.tzinfo is None:
        dt = dt.replace(tzinfo=timezone.utc)
    return int(dt.timestamp() * 1000)

# üî∏ –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –≤ gateway (mode=raw|pack)
def make_gw_request(symbol: str, tf: str, indicator: str, now_ms: int, mode: str) -> dict:
    return {
        "symbol": symbol,
        "timeframe": tf,
        "indicator": indicator,
        "timestamp_ms": str(now_ms),
        "mode": mode,
    }

# üî∏ –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è TF –∏ ¬´—Ç–µ–≥–∏ –æ–∂–∏–¥–∞–Ω–∏—è¬ª (indicator, mode)
def build_tf_requests(symbol: str, tf: str, created_at_ms: int) -> tuple[list[dict], list[tuple[str,str]]]:
    reqs: list[dict] = []
    tags: list[tuple[str,str]] = []
    # —Å–Ω–∞—á–∞–ª–∞ RAW (—á–∞—Å—Ç—å –º–æ–∂–µ—Ç —Ñ–æ–ª–±—ç–∫–Ω—É—Ç—å –Ω–∞ prev-bar ‚Äî –±—ã—Å—Ç—Ä–µ–µ –æ—Ç–≤–µ—Ç)
    for ind in RAW_TYPES:
        reqs.append(make_gw_request(symbol, tf, ind, created_at_ms, mode="raw"))
        tags.append((ind, "raw"))
    # –∑–∞—Ç–µ–º PACK
    for ind in PACK_TYPES:
        reqs.append(make_gw_request(symbol, tf, ind, created_at_ms, mode="pack"))
        tags.append((ind, "pack"))
    # –∏ MW (–∫–∞–∫ pack)
    for ind in MW_TYPES:
        reqs.append(make_gw_request(symbol, tf, ind, created_at_ms, mode="pack"))
        tags.append((ind, "pack"))
    return reqs, tags

# üî∏ –û—Ç–ø—Ä–∞–≤–∏—Ç—å –í–°–ï –∑–∞–ø—Ä–æ—Å—ã TF –∏ —Å–æ–±—Ä–∞—Ç—å –æ—Ç–≤–µ—Ç—ã —á–µ—Ä–µ–∑ XREAD —Å baseline id (–±–µ–∑ consumer-group, –±–µ–∑ ACK)
async def gw_send_and_collect(redis, reqs: list[dict], time_left_sec: float) -> tuple[list[dict], set[str]]:
    # 1) –≤–∑—è—Ç—å –±–∞–∑–æ–≤—É—é –º–µ—Ç–∫—É –î–û –æ—Ç–ø—Ä–∞–≤–∫–∏ (–ø–æ—Å–ª–µ–¥–Ω–∏–π id –≤ —Å—Ç—Ä–∏–º–µ –∏–ª–∏ "0-0")
    since_id = "0-0"
    try:
        tail = await redis.execute_command("XREVRANGE", GW_RESP_STREAM, "+", "-", "COUNT", 1)
        if tail and len(tail) > 0:
            since_id = tail[0][0]  # –Ω–∞–ø—Ä–∏–º–µ—Ä "1716484845123-0"
    except Exception:
        pass

    # 2) –æ—Ç–ø—Ä–∞–≤–∫–∞ –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤, –∑–∞–ø–æ–º–Ω–∏—Ç—å –∏—Ö req_id (msg_id –∑–∞–ø—Ä–æ—Å–∞)
    req_ids = set()
    for payload in reqs:
        try:
            mid = await redis.xadd(GW_REQ_STREAM, payload)
            req_ids.add(mid)
        except Exception as e:
            log.warning(f"[GW] xadd req error: {e}")

    collected: dict[str, dict] = {}
    deadline = asyncio.get_event_loop().time() + max(0.0, time_left_sec)
    last_id = since_id  # –∫—É—Ä—Å–æ—Ä XREAD: —á–∏—Ç–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è —Å ID > last_id

    # 3) —á–∏—Ç–∞—Ç—å –æ—Ç–≤–µ—Ç—ã –¥–æ –¥–µ–¥–ª–∞–π–Ω–∞, —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ø–æ req_id
    while req_ids and asyncio.get_event_loop().time() < deadline:
        try:
            resp = await redis.xread(streams={GW_RESP_STREAM: last_id}, count=200, block=1000)
        except Exception as e:
            log.warning(f"[GW] xread resp error: {e}")
            await asyncio.sleep(0.2)
            continue

        if not resp:
            continue

        # resp: [(stream, [(msg_id, fields), ...])]
        for _, messages in resp:
            if messages:
                # –ø—Ä–æ–¥–≤–∏–≥–∞–µ–º –∫—É—Ä—Å–æ—Ä –Ω–∞ –ü–û–°–õ–ï–î–ù–ò–ô ID –∏–∑ –ø–∞–∫–µ—Ç–∞
                last_id = messages[-1][0]
            for msg_id, data in messages:
                rid = data.get("req_id")
                if rid in req_ids:
                    collected[rid] = data
                    req_ids.remove(rid)

    return list(collected.values()), req_ids
        
# üî∏ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ gateway (OK) ‚Üí —Å—Ç—Ä–æ–∫–∏ indicator_position_stat
def map_gateway_ok_to_rows(position_uid: str,
                           strategy_id: int,
                           symbol: str,
                           tf: str,
                           open_time_iso: str,
                           gw_resp: dict) -> tuple[list[tuple], list[tuple]]:
    ok_rows: list[tuple] = []
    err_rows: list[tuple] = []

    indicator = gw_resp.get("indicator")
    mode = gw_resp.get("mode")

    # –ø–∞—Ä—Å–∏–Ω–≥ json —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    try:
        results_json = gw_resp.get("results")
        items = json.loads(results_json) if results_json else []
    except Exception:
        # –æ—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ ‚Äî value_text –∑–∞–ø–æ–ª–Ω—è–µ–º, —á—Ç–æ–±—ã –ø—Ä–æ–π—Ç–∏ XOR
        err_rows.append((
            position_uid, strategy_id, symbol, tf,
            ("pack" if indicator in MW_TYPES or indicator in PACK_TYPES else "indicator"),
            indicator, "results_parse",
            None, "results_parse_error",
            datetime.fromisoformat(open_time_iso), "error", "results_parse_error"
        ))
        return ok_rows, err_rows

    # helper: –ø—É—à —Å—Ç—Ä–æ–∫–∏
    def push_row(param_type: str, pbase: str, pname: str, vnum, vtext, status: str = "ok", ecode: str | None = None):
        ok_rows.append((
            position_uid, strategy_id, symbol, tf,
            param_type, pbase, pname,
            vnum, vtext,
            datetime.fromisoformat(open_time_iso),
            status, ecode
        ))

    # —Ä–µ–∂–∏–º PACK (–≤–∫–ª—é—á–∞—è MW)
    if mode == "pack":
        if indicator in MW_TYPES:
            # marketwatch: —Ç–æ–ª—å–∫–æ state
            for it in items:
                pack = it.get("pack", {})
                state = pack.get("state")
                if state is not None:
                    push_row("marketwatch", indicator, "state", None, str(state))
                else:
                    err_rows.append((
                        position_uid, strategy_id, symbol, tf,
                        "marketwatch", indicator, "state",
                        None, "mw_no_state",
                        datetime.fromisoformat(open_time_iso), "error", "mw_no_state"
                    ))
            return ok_rows, err_rows

        # –æ–±—ã—á–Ω—ã–µ packs
        for it in items:
            base = it.get("base")
            pack = it.get("pack", {})
            kind = indicator
            fields = PACK_WHITELIST.get(kind, [])
            for pname in fields:
                val = pack.get(pname)
                if val is None:
                    continue
                vnum, vtext = None, None
                try:
                    vnum = float(val)
                except Exception:
                    vtext = str(val)
                push_row("pack", str(base), pname, vnum, vtext)
        return ok_rows, err_rows

    # —Ä–µ–∂–∏–º RAW (indicator)
    # items ‚Äî –º–∞—Å—Å–∏–≤ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ {"base": "...", "pack": {"results": {<k>:<v>, ...}}, "mode":"raw"}
    for it in items:
        pack = it.get("pack", {})
        results = pack.get("results", {})
        pbase = indicator  # —Ç–∏–ø –±–µ–∑ –¥–ª–∏–Ω—ã
        for k, v in results.items():
            pname = str(k)  # –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–π –∫–ª—é—á (—Å–æ –≤—Å–µ–º–∏ —Å—É—Ñ—Ñ–∏–∫—Å–∞–º–∏)
            vnum, vtext = None, None
            try:
                vnum = float(v)
            except Exception:
                vtext = str(v)
            ok_rows.append((
                position_uid, strategy_id, symbol, tf,
                "indicator", pbase, pname,
                vnum, vtext,
                datetime.fromisoformat(open_time_iso),
                "ok", None
            ))
    return ok_rows, err_rows

# üî∏ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ gateway (ERROR) ‚Üí —Å—Ç—Ä–æ–∫–∏ –æ—à–∏–±–æ–∫ (value_text –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ!)
def map_gateway_error_to_rows(position_uid: str,
                              strategy_id: int,
                              symbol: str,
                              tf: str,
                              open_time_iso: str,
                              gw_resp: dict) -> list[tuple]:
    indicator = gw_resp.get("indicator")
    mode = gw_resp.get("mode") or ("pack" if indicator in PACK_TYPES or indicator in MW_TYPES else "indicator")
    error = gw_resp.get("error") or "unknown"
    when = datetime.fromisoformat(open_time_iso)

    if mode == "pack":
        return [(
            position_uid, strategy_id, symbol, tf,
            ("marketwatch" if indicator in MW_TYPES else "pack"),
            indicator, "error",
            None, error,
            when, "error", error
        )]
    else:
        return [(
            position_uid, strategy_id, symbol, tf,
            "indicator", indicator, "error",
            None, error,
            when, "error", error
        )]

# üî∏ UPSERT —Å—Ç—Ä–æ–∫ –≤ indicator_position_stat (–±–∞—Ç—á–∞–º–∏) —Å statement_timeout
async def upsert_rows(pg, rows: list[tuple]):
    if not rows:
        return
    sql = """
    INSERT INTO indicator_position_stat
      (position_uid, strategy_id, symbol, timeframe, param_type, param_base, param_name, value_num, value_text, open_time, status, error_code)
    VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12)
    ON CONFLICT (position_uid, timeframe, param_type, param_base, param_name)
    DO UPDATE SET
      value_num = EXCLUDED.value_num,
      value_text = EXCLUDED.value_text,
      open_time = EXCLUDED.open_time,
      status = EXCLUDED.status,
      error_code = EXCLUDED.error_code,
      captured_at = NOW()
    """
    # –ø–æ–¥–≥–æ—Ç–æ–≤–∏–º —Å—Ç—Ä–æ–∫–æ–≤—ã–π timeout –¥–ª—è PG, –Ω–∞–ø—Ä–∏–º–µ—Ä '15s'
    pg_stmt_timeout = f"{int(DB_UPSERT_TIMEOUT_SEC)}s"

    i = 0
    total = len(rows)
    async with pg.acquire() as conn:
        while i < total:
            chunk = rows[i:i+BATCH_INSERT_SIZE]
            async with conn.transaction():
                # –ª–æ–∫–∞–ª—å–Ω—ã–π statement_timeout —Ç–æ–ª—å–∫–æ –Ω–∞ —ç—Ç—É —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é
                try:
                    await conn.execute(f"SET LOCAL statement_timeout = '{pg_stmt_timeout}'")
                except Exception:
                    pass
                await conn.executemany(sql, chunk)
            i += len(chunk)

# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ TF (send-all ‚Üí collect ‚Üí retry missing –¥–æ –¥–µ–¥–ª–∞–π–Ω–∞)
async def process_tf(pg, redis, position_uid: str, strategy_id: int, symbol: str, tf: str, created_at_ms: int):
    tf_t0 = asyncio.get_event_loop().time()

    # —Ñ–∏–∫—Å–∏—Ä—É–µ–º open_time TF –ø–æ created_at
    bar_open_ms = floor_to_bar_ms(created_at_ms, tf)
    open_time_iso = datetime.utcfromtimestamp(bar_open_ms / 1000).isoformat()

    # —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –æ–∂–∏–¥–∞–µ–º—ã—Ö —Ç–µ–≥–æ–≤
    full_reqs, tags_expected = build_tf_requests(symbol, tf, created_at_ms)
    expected = len(full_reqs)

    # –ø–µ—Ä–≤—ã–π —Ü–∏–∫–ª: –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≤—Å–µ, —Å–æ–±—Ä–∞—Ç—å –æ—Ç–≤–µ—Ç—ã
    resps, _ = await gw_send_and_collect(redis, full_reqs, time_left_sec=POS_REQ_TIMEOUT_SEC)

    # —Å—á—ë—Ç—á–∏–∫–∏ –ø–æ —Ç–µ–≥–∞–º (indicator, mode)
    from collections import Counter

    def resp_tag(resp):
        ind = resp.get("indicator")
        mode = resp.get("mode") or ("pack" if ind in PACK_TYPES or ind in MW_TYPES else "indicator")
        return (ind, mode)

    got = Counter(resp_tag(r) for r in resps)
    exp = Counter(tags_expected)

    # —Ü–∏–∫–ª –¥–æ–≥—Ä—É–∑–∫–∏: –ø–æ–∫–∞ –µ—Å—Ç—å missing –∏ –Ω–µ –≤—ã—à–ª–∏ –∑–∞ –¥–µ–¥–ª–∞–π–Ω, —à–ª—ë–º —Ç–æ–ª—å–∫–æ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ
    while True:
        missing_counter = exp - got
        missing = sum(missing_counter.values())
        now = asyncio.get_event_loop().time()
        time_left = POS_REQ_TIMEOUT_SEC - (now - tf_t0)
        if missing == 0 or time_left <= 0:
            break

        # –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ ¬´missing¬ª –∑–∞–ø—Ä–æ—Å—ã
        retry_reqs = []
        for (ind, mode), cnt in missing_counter.items():
            for _ in range(cnt):
                retry_reqs.append(make_gw_request(symbol, tf, ind, created_at_ms, mode))

        # –ø–∞—É–∑–∞ –º–µ–∂–¥—É —Ü–∏–∫–ª–∞–º–∏
        await asyncio.sleep(min(RETRY_GAP_SEC, max(0.0, time_left)))
        # –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∏ —Å–æ–±—Ä–∞—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω–æ
        res_try, _ = await gw_send_and_collect(
            redis,
            retry_reqs,
            time_left_sec=max(0.0, POS_REQ_TIMEOUT_SEC - (asyncio.get_event_loop().time() - tf_t0))
        )
        # —É—á–µ—Å—Ç—å –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ
        got.update(resp_tag(r) for r in res_try)
        resps.extend(res_try)

    # —Ä–∞–∑–±–æ—Ä –≤—Å–µ—Ö –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ ‚Üí —Å—Ç—Ä–æ–∫–∏
    ok_rows_all: list[tuple] = []
    err_rows_all: list[tuple] = []

    for resp in resps:
        status = resp.get("status")
        if status == "ok":
            oks, errs = map_gateway_ok_to_rows(position_uid, strategy_id, symbol, tf, open_time_iso, resp)
            ok_rows_all.extend(oks)
            err_rows_all.extend(errs)
        else:
            err_rows_all.extend(map_gateway_error_to_rows(position_uid, strategy_id, symbol, tf, open_time_iso, resp))

    # —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ missing
    got = Counter(resp_tag(r) for r in resps)
    missing_counter = Counter(tags_expected) - got
    missing = sum(missing_counter.values())

    # –¥–ª—è –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è missing —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å timeout-—Å—Ç—Ä–æ–∫–∏ (value_text="timeout" –¥–ª—è XOR)
    if missing:
        when = datetime.fromisoformat(open_time_iso)
        for (ind, mode), cnt in missing_counter.items():
            for _ in range(cnt):
                if mode == "pack":
                    err_rows_all.append((
                        position_uid, strategy_id, symbol, tf,
                        ("marketwatch" if ind in MW_TYPES else "pack"),
                        ind, "error",
                        None, "timeout",
                        when, "error", "timeout"
                    ))
                else:
                    err_rows_all.append((
                        position_uid, strategy_id, symbol, tf,
                        "indicator", ind, "error",
                        None, "timeout",
                        when, "error", "timeout"
                    ))

    tf_t1 = asyncio.get_event_loop().time()
    received = len(resps)
    log.info(f"[TF] {symbol}/{tf} ok={len(ok_rows_all)} err={len(err_rows_all)} expected={expected} received={received} missing={missing} elapsed_ms={int((tf_t1-tf_t0)*1000)}")

    return ok_rows_all, err_rows_all

# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏: TF –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ (m5 ‚Üí m15 ‚Üí h1) + –æ–±—â–∏–π —Ç–∞–π–º–∞—É—Ç –Ω–∞ –ø–æ–∑–∏—Ü–∏—é
async def process_position(pg, redis, get_strategy_mw, pos_payload: dict) -> None:
    pos_t0 = asyncio.get_event_loop().time()

    # –∏–∑–≤–ª–µ–∫–∞–µ–º –±–∞–∑–æ–≤—ã–µ –ø–æ–ª—è
    position_uid = pos_payload.get("position_uid")
    symbol = pos_payload.get("symbol")
    strategy_id = int(pos_payload.get("strategy_id")) if pos_payload.get("strategy_id") is not None else None
    created_at_iso = pos_payload.get("created_at")

    if not position_uid or not symbol or strategy_id is None or not created_at_iso:
        log.info(f"[SKIP] bad position payload: {pos_payload}")
        return

    # —Ñ–∏–ª—å—Ç—Ä –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º: —Ç–æ–ª—å–∫–æ —Ç–µ, –≥–¥–µ market_watcher=true
    try:
        if not get_strategy_mw(int(strategy_id)):
            log.info(f"[SKIP] strategy_id={strategy_id} market_watcher=false")
            return
    except Exception:
        log.info(f"[SKIP] strategy_id={strategy_id} (mw flag check failed)")
        return

    created_at_ms = iso_to_ms(created_at_iso)

    # –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ TF
    tfs = POS_TFS_ORDER[:] if POS_TFS_ORDER else ["m5","m15","h1"]
    if "m5" not in tfs:
        tfs.insert(0, "m5")

    total_ok = total_err = 0

    for tf in tfs:
        ok_rows, err_rows = await process_tf(pg, redis, position_uid, strategy_id, symbol, tf, created_at_ms)
        total_ok += len(ok_rows)
        total_err += len(err_rows)
        if not POS_DRY_RUN and (ok_rows or err_rows):
            try:
                await asyncio.wait_for(upsert_rows(pg, ok_rows + err_rows), timeout=DB_UPSERT_TIMEOUT_SEC)
            except asyncio.TimeoutError:
                log.warning(f"[POS] db_timeout uid={position_uid} sym={symbol} tf={tf}")

    pos_t1 = asyncio.get_event_loop().time()
    log.info(f"POS_SNAPSHOT OK uid={position_uid} sym={symbol} ok_rows={total_ok} err_rows={total_err} elapsed_ms={int((pos_t1-pos_t0)*1000)}")

# üî∏ –û—Å–Ω–æ–≤–Ω–æ–π –≤–æ—Ä–∫–µ—Ä: –ø–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ positions_open_stream, TF –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ, –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç m5; –æ–±—â–∏–π —Ç–∞–π–º–∞—É—Ç –Ω–∞ –ø–æ–∑–∏—Ü–∏—é
async def run_position_snapshot_worker(pg, redis, get_instances_by_tf, get_precision, get_strategy_mw):
    log.debug("POS_SNAPSHOT: –≤–æ—Ä–∫–µ—Ä –∑–∞–ø—É—â–µ–Ω")

    group = "possnap_group"
    consumer = "possnap_1"

    # —Å–æ–∑–¥–∞—Ç—å consumer-group (–∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ)
    try:
        await redis.xgroup_create(REQ_STREAM_POSITIONS, group, id="$", mkstream=True)
    except Exception as e:
        if "BUSYGROUP" not in str(e):
            log.warning(f"xgroup_create error: {e}")

    sem = asyncio.Semaphore(POS_CONCURRENCY)

    async def handle_one(msg_id: str, data: dict) -> str | None:
        # –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞ –ø–æ –ø–æ–∑–∏—Ü–∏—è–º
        async with sem:
            try:
                # –æ–±—â–∏–π —Ç–∞–π–º–∞—É—Ç –Ω–∞ –ø–æ–∑–∏—Ü–∏—é
                await asyncio.wait_for(
                    process_position(pg, redis, get_strategy_mw, data),
                    timeout=POS_POSITION_TIMEOUT_SEC
                )
            except asyncio.TimeoutError:
                try:
                    position_uid = data.get("position_uid")
                    symbol = data.get("symbol")
                    log.warning(f"[POS] position_timeout uid={position_uid} sym={symbol}")
                except Exception:
                    log.warning(f"[POS] position_timeout (payload logging failed)")
            except Exception as e:
                log.warning(f"[POS] error {e}", exc_info=True)
            return msg_id

    while True:
        try:
            resp = await redis.xreadgroup(
                groupname=group,
                consumername=consumer,
                streams={REQ_STREAM_POSITIONS: ">"},
                count=50,
                block=2000
            )
        except Exception as e:
            log.error(f"POS_SNAPSHOT read error: {e}", exc_info=True)
            await asyncio.sleep(0.5)
            continue

        if not resp:
            continue

        try:
            tasks = []
            to_ack = []
            for _, messages in resp:
                for msg_id, data in messages:
                    to_ack.append(msg_id)
                    tasks.append(asyncio.create_task(handle_one(msg_id, data)))

            done_ids = await asyncio.gather(*tasks, return_exceptions=False)
            ack_ids = [mid for mid in done_ids if mid]
            if ack_ids:
                await redis.xack(REQ_STREAM_POSITIONS, group, *ack_ids)
        except Exception as e:
            log.error(f"POS_SNAPSHOT batch error: {e}", exc_info=True)
            await asyncio.sleep(0.5)