# position_snapshot_worker.py ‚Äî —á—Ç–µ–Ω–∏–µ positions_open_stream –∏ on-demand —Å—Ä–µ–∑ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ + EMA-status + EMA-pattern

# üî∏ –ò–º–ø–æ—Ä—Ç—ã
import os
import asyncio
import logging
import json
from datetime import datetime

import pandas as pd
from indicators.compute_and_store import compute_snapshot_values_async
from indicators_ema_status import _classify_with_prev, EPS0, EPS1
from position_snapshot_sharedmemory import put_snapshot_tf

# üî∏ –õ–æ–≥–≥–µ—Ä
log = logging.getLogger("IND_POS_SNAPSHOT")

# üî∏ –ö–æ–Ω—Ñ–∏–≥ –ø–æ—Ç–æ–∫–æ–≤
STREAM   = "positions_open_stream"
GROUP    = "indicators_position_group"
CONSUMER = "ind_pos_1"

# üî∏ –û–±—â–∏–µ —Ç–∞–π–º–∏–Ω–≥–∏
STEP_MIN = {"m5": 5, "m15": 15, "h1": 60}
REQUIRED_BARS_DEFAULT = 800
STEP_MS = {"m5": 300_000, "m15": 900_000, "h1": 3_600_000}

# üî∏ –ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º on-demand —Ä–∞—Å—á—ë—Ç–æ–≤ (–Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ ENV)
SNAPSHOT_MAX_CONCURRENCY = int(os.getenv("SNAPSHOT_MAX_CONCURRENCY", "16"))

# üî∏ EMA-–ø–∞—Ç—Ç–µ—Ä–Ω: –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã, —Ñ–µ–π–∫–æ–≤—ã–µ instance_id –∏ –∫—ç—à —Å–ª–æ–≤–∞—Ä—è
EMA_NAMES  = ("ema9", "ema21", "ema50", "ema100", "ema200")
EMA_LEN    = {"ema9": 9, "ema21": 21, "ema50": 50, "ema100": 100, "ema200": 200}
EPSILON_REL = 0.0005  # –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ —Ä–∞–≤–µ–Ω—Å—Ç–≤–æ 0.05%

EMAPATTERN_INSTANCE_ID = {"m5": 1004, "m15": 1005, "h1": 1006}
_EMA_PATTERN_DICT: dict[str, int] = {}

# üî∏ –§–ª–æ—Ä –≤—Ä–µ–º–µ–Ω–∏ –∫ –Ω–∞—á–∞–ª—É –±–∞—Ä–∞ TF
def floor_to_bar_ms(ts_ms: int, tf: str) -> int:
    step_ms = STEP_MIN[tf] * 60_000
    return (ts_ms // step_ms) * step_ms

# üî∏ –ß—Ç–µ–Ω–∏–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –∏–∑ TS –≤ dict
async def ts_range_map(redis, key: str, start_ms: int, end_ms: int):
    if not key:
        return {}
    try:
        res = await redis.execute_command("TS.RANGE", key, start_ms, end_ms)
        return {int(ts): float(v) for ts, v in (res or [])}
    except Exception as e:
        log.debug(f"[TSERR] key={key} err={e}")
        return {}

# üî∏ –ß—Ç–µ–Ω–∏–µ –æ–¥–Ω–æ–π —Ç–æ—á–∫–∏ –ø–æ —Ç–æ—á–Ω–æ–º—É —à—Ç–∞–º–ø—É
async def ts_get_point(redis, key: str, ts_ms: int):
    m = await ts_range_map(redis, key, ts_ms, ts_ms)
    if not m:
        return None
    return m.get(ts_ms)

# üî∏ –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ —Ä–∞–≤–µ–Ω—Å—Ç–≤–æ –¥–ª—è EMA-–ø–∞—Ç—Ç–µ—Ä–Ω–∞
def _rel_equal(a: float, b: float) -> bool:
    m = max(abs(a), abs(b), 1e-12)
    return abs(a - b) <= EPSILON_REL * m

# üî∏ –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ EMA-–ø–∞—Ç—Ç–µ—Ä–Ω–∞ –∏–∑ entry_price –∏ 5 EMA
def _build_emapattern_text(entry_price: float, emas: dict[str, float]) -> str:
    pairs = [("PRICE", float(entry_price))]
    for name in EMA_NAMES:
        pairs.append((name.upper(), float(emas[name])))

    pairs.sort(key=lambda kv: kv[1], reverse=True)

    groups: list[list[str]] = []
    cur: list[tuple[str, float]] = []
    for token, val in pairs:
        if not cur:
            cur = [(token, val)]
            continue
        ref_val = cur[0][1]
        if _rel_equal(val, ref_val):
            cur.append((token, val))
        else:
            groups.append([t for t, _ in cur])
            cur = [(token, val)]
    if cur:
        groups.append([t for t, _ in cur])

    canon: list[list[str]] = []
    for g in groups:
        if "PRICE" in g:
            rest = [t for t in g if t != "PRICE"]
            rest.sort(key=lambda t: EMA_LEN[t.lower()])
            canon.append(["PRICE"] + rest)
        else:
            gg = list(g)
            gg.sort(key=lambda t: EMA_LEN[t.lower()])
            canon.append(gg)

    return " > ".join(" = ".join(g) for g in canon)

# üî∏ –†–∞–∑–æ–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å–ª–æ–≤–∞—Ä—è EMA-–ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ (pattern_text -> id)
async def _load_emapattern_dict(pg) -> None:
    global _EMA_PATTERN_DICT
    async with pg.acquire() as conn:
        rows = await conn.fetch("SELECT id, pattern_text FROM indicator_emapattern_dict")
    _EMA_PATTERN_DICT = {str(r["pattern_text"]): int(r["id"]) for r in rows}
    log.debug(f"[EMA_DICT] loaded={len(_EMA_PATTERN_DICT)}")

# üî∏ –ü–æ–¥–±–æ—Ä —Ç—Ä–µ–±—É–µ–º—ã—Ö –∏–Ω—Å—Ç–∞–Ω—Å–æ–≤ –Ω–∞ TF
def pick_required_instances(instances_tf: list, ema_lens: list[int] = None):
    ema_by_len = {}
    atr14 = None
    bb_20_2 = None
    macd12 = None
    adx_14_or_28 = None
    for inst in instances_tf:
        ind = inst.get("indicator")
        p = inst.get("params", {})
        try:
            if ind == "ema":
                L = int(p.get("length"))
                if ema_lens is None or L in ema_lens:
                    ema_by_len[L] = inst
            elif ind == "atr" and int(p.get("length", 0)) == 14 and atr14 is None:
                atr14 = inst
            elif ind == "bb" and int(p.get("length", 0)) == 20 and abs(float(p.get("std", 0)) - 2.0) < 1e-9 and bb_20_2 is None:
                bb_20_2 = inst
            elif ind == "macd" and int(p.get("fast", 0)) == 12 and macd12 is None:
                macd12 = inst
            elif ind == "adx_dmi" and adx_14_or_28 is None:
                adx_14_or_28 = inst  # –¥–ª–∏–Ω–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ TS-–∫–ª—é—á–∏/TF
        except Exception:
            continue
    return ema_by_len, atr14, bb_20_2, macd12, adx_14_or_28

# üî∏ –û—Å–Ω–æ–≤–Ω–æ–π –≤–æ—Ä–∫–µ—Ä
async def run_position_snapshot_worker(pg, redis, get_instances_by_tf, get_precision, get_strategy_mw=lambda _sid: True):
    # –ª–æ–∫–∞–ª—å–Ω—ã–π –∏–º–ø–æ—Ä—Ç –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ —Å–Ω–∞–ø—à–æ—Ç–æ–≤ TF –≤ –æ–±—â—É—é –ø–∞–º—è—Ç—å
    try:
        from position_snapshot_sharedmemory import put_snapshot_tf
    except Exception:
        put_snapshot_tf = None
        log.warning("position_snapshot_sharedmemory.put_snapshot_tf –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Äî –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞")

    # —Å–æ–∑–¥–∞–Ω–∏–µ consumer-group
    try:
        await redis.xgroup_create(STREAM, GROUP, id="$", mkstream=True)
        log.debug(f"–ì—Ä—É–ø–ø–∞ {GROUP} —Å–æ–∑–¥–∞–Ω–∞ –¥–ª—è {STREAM}")
    except Exception as e:
        if "BUSYGROUP" in str(e):
            log.debug(f"–ì—Ä—É–ø–ø–∞ {GROUP} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        else:
            log.exception("–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è consumer group")
            return

    # —Ä–∞–∑–æ–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å–ª–æ–≤–∞—Ä—è EMA-–ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    if not _EMA_PATTERN_DICT:
        try:
            await _load_emapattern_dict(pg)
        except Exception:
            log.exception("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–ª–æ–≤–∞—Ä—å EMA-–ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ (indicator_emapattern_dict)")

    sem = asyncio.Semaphore(SNAPSHOT_MAX_CONCURRENCY)

    while True:
        try:
            resp = await redis.xreadgroup(
                groupname=GROUP,
                consumername=CONSUMER,
                streams={STREAM: ">"},
                count=10,
                block=2000
            )
            if not resp:
                continue

            to_ack = []

            for _, messages in resp:
                for msg_id, data in messages:
                    to_ack.append(msg_id)
                    try:
                        uid         = data.get("position_uid")
                        sym         = data.get("symbol")
                        strat       = int(data.get("strategy_id"))
                        side        = data.get("direction")
                        created_iso = data.get("created_at")
                        log_uid     = data.get("log_uid")  # –≤–∞–∂–µ–Ω –¥–ª—è –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞

                        log.debug(f"[OPENED] uid={uid} {sym} strategy={strat} dir={side} created_at={created_iso}")

                        # üî∏ –§–∏–ª—å—Ç—Ä –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¢–û–õ–¨–ö–û –µ—Å–ª–∏ market_watcher = true
                        if not get_strategy_mw(strat):
                            log.debug(f"[SKIP_MW] uid={uid} strategy={strat} market_watcher=false ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É")
                            continue
                            
                        created_dt = datetime.fromisoformat(created_iso)
                        created_ms = int(created_dt.timestamp() * 1000)
                        precision  = get_precision(sym)

                        # entry_price: —Å–Ω–∞—á–∞–ª–∞ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è, –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ ‚Äî —Ñ–æ–ª–ª–±—ç–∫ –∫ –ë–î
                        entry_price = None
                        try:
                            ep_raw = data.get("entry_price")
                            if ep_raw is not None:
                                entry_price = float(ep_raw)
                        except Exception:
                            entry_price = None
                        if entry_price is None:
                            async with pg.acquire() as conn:
                                ep_row = await conn.fetchrow(
                                    "SELECT entry_price FROM positions_v4 WHERE position_uid = $1",
                                    uid
                                )
                            entry_price = float(ep_row["entry_price"]) if (ep_row and ep_row["entry_price"] is not None) else None
                        if entry_price is None:
                            log.debug(f"[SKIP_EMAPATTERN] uid={uid} –Ω–µ—Ç entry_price")

                        total_ind = 0
                        total_params = 0
                        rows_all = []

                        for tf in ("m5", "m15", "h1"):
                            instances = get_instances_by_tf(tf)
                            if not instances:
                                continue

                            bar_open_ms = floor_to_bar_ms(created_ms, tf)
                            step_ms = STEP_MS[tf]
                            start_ts = bar_open_ms - (REQUIRED_BARS_DEFAULT - 1) * step_ms

                            # –∑–∞–≥—Ä—É–∑–∫–∞ OHLCV
                            fields = ["o", "h", "l", "c", "v"]
                            keys = {f: f"ts:{sym}:{tf}:{f}" for f in fields}
                            tasks = {f: redis.execute_command("TS.RANGE", keys[f], start_ts, bar_open_ms) for f in fields}
                            res = await asyncio.gather(*tasks.values(), return_exceptions=True)

                            series = {}
                            for f, r in zip(tasks.keys(), res):
                                if isinstance(r, Exception):
                                    log.warning(f"TS.RANGE {keys[f]} error: {r}")
                                    continue
                                if r:
                                    series[f] = {int(ts): float(val) for ts, val in r if val is not None}

                            if not series or "c" not in series:
                                log.warning(f"[SKIP] uid={uid} TF={tf} –Ω–µ—Ç OHLCV –¥–ª—è —Å—Ä–µ–∑–∞")
                                continue

                            idx = sorted(series["c"].keys())
                            df = {f: [series.get(f, {}).get(ts) for ts in idx] for f in fields}
                            pdf = pd.DataFrame(df, index=pd.to_datetime(idx, unit="ms"))
                            pdf.index.name = "open_time"

                            tf_inst_count = 0
                            tf_param_count = 0
                            rows = []

                            close_t = float(pdf["c"].iloc[-1])
                            close_prev = float(pdf["c"].iloc[-2]) if len(pdf) > 1 else None

                            # –ª–æ–∫–∞–ª—å–Ω—ã–π –∫—ç—à t-–∑–Ω–∞—á–µ–Ω–∏–π –ø–æ –∏–Ω—Å—Ç–∞–Ω—Å–∞–º
                            tf_cache_values: dict[int, dict[str, str]] = {}

                            # –ø—Ä–æ–±–µ–≥ –ø–æ –∏–Ω—Å—Ç–∞–Ω—Å–∞–º
                            for inst in instances:
                                en = inst.get("enabled_at")
                                if en and bar_open_ms < int(en.replace(tzinfo=None).timestamp() * 1000):
                                    continue

                                async with sem:
                                    values = await compute_snapshot_values_async(inst, sym, pdf, precision)
                                if not values:
                                    continue

                                try:
                                    tf_cache_values[int(inst["id"])] = values
                                except Exception:
                                    pass

                                tf_inst_count += 1
                                tf_param_count += len(values)

                                kv = ", ".join(f"{k}={v}" for k, v in values.items())
                                log.debug(f"[SNAPSHOT] uid={uid} TF={tf} inst={inst['id']} {kv}")

                                bar_open_dt = datetime.utcfromtimestamp(bar_open_ms / 1000)
                                enabled_at = inst.get("enabled_at")
                                params_json = json.dumps(inst.get("params", {}))
                                for pname, vstr in values.items():
                                    try:
                                        vnum = float(vstr)
                                    except Exception:
                                        vnum = None
                                    rows.append((
                                        uid, strat, side, tf,
                                        int(inst["id"]), pname, vstr, vnum,
                                        bar_open_dt,
                                        enabled_at,
                                        params_json
                                    ))

                                # EMA-status
                                if inst.get("indicator") == "ema":
                                    try:
                                        L = int(inst["params"].get("length"))
                                    except Exception:
                                        continue

                                    ema_t = None
                                    vals = tf_cache_values.get(int(inst["id"]))
                                    if vals and f"ema{L}" in vals:
                                        try:
                                            ema_t = float(vals[f"ema{L}"])
                                        except Exception:
                                            ema_t = None

                                    ema_p = None
                                    prev_ms = bar_open_ms - STEP_MS[tf]
                                    try:
                                        ema_p = await ts_get_point(redis, f"ts_ind:{sym}:{tf}:ema{L}", prev_ms)
                                    except Exception:
                                        ema_p = None
                                    if ema_p is None and len(pdf) > 1:
                                        async with sem:
                                            prev_vals = await compute_snapshot_values_async(inst, sym, pdf.iloc[:-1], precision)
                                        if prev_vals and f"ema{L}" in prev_vals:
                                            try:
                                                ema_p = float(prev_vals[f"ema{L}"])
                                            except Exception:
                                                ema_p = None

                                    # scale: high-low
                                    scale_t = None
                                    scale_prev = None
                                    try:
                                        scale_t = float(pdf["h"].iloc[-1]) - float(pdf["l"].iloc[-1])
                                        if len(pdf) > 1:
                                            scale_prev = float(pdf["h"].iloc[-2]) - float(pdf["l"].iloc[-2])
                                    except Exception:
                                        pass

                                    cls = _classify_with_prev(close_t, close_prev, ema_t, ema_p, scale_t, scale_prev, EPS0, EPS1, None)
                                    if cls is not None:
                                        code, label, nd, d, delta_d = cls
                                        rows.append((
                                            uid, strat, side, tf,
                                            int(inst["id"]), f"ema{L}_status", str(code), code,
                                            bar_open_dt,
                                            enabled_at,
                                            params_json
                                        ))

                            # EMA-–ø–∞—Ç—Ç–µ—Ä–Ω
                            if entry_price is not None:
                                try:
                                    ema_map_for_tf: dict[str, float] = {}
                                    for inst in instances:
                                        if inst.get("indicator") != "ema":
                                            continue
                                        L = inst.get("params", {}).get("length")
                                        try:
                                            L = int(L)
                                        except Exception:
                                            continue
                                        if L not in (9, 21, 50, 100, 200):
                                            continue
                                        key = f"ema{L}"
                                        vals = tf_cache_values.get(int(inst["id"]))
                                        if vals and key in vals:
                                            try:
                                                ema_map_for_tf[key] = float(vals[key])
                                            except Exception:
                                                pass

                                    if all(name in ema_map_for_tf for name in EMA_NAMES):
                                        pattern_text = _build_emapattern_text(entry_price, ema_map_for_tf)
                                        pattern_id = _EMA_PATTERN_DICT.get(pattern_text)
                                        rows.append((
                                            uid, strat, side, tf,
                                            EMAPATTERN_INSTANCE_ID[tf], "emapattern",
                                            pattern_text,
                                            (pattern_id if pattern_id is not None else None),
                                            datetime.utcfromtimestamp(bar_open_ms / 1000),
                                            None,
                                            None
                                        ))
                                        tf_param_count += 1
                                        log.debug(f"[EMA_PATTERN] uid={uid} TF={tf} ‚Üí {pattern_text} (id={pattern_id})")
                                    else:
                                        log.debug(f"[EMA_PATTERN_SKIP] uid={uid} TF={tf} –Ω–µ–ø–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä EMA: {sorted(ema_map_for_tf.keys())}")
                                except Exception:
                                    log.exception(f"[EMA_PATTERN_ERR] uid={uid} TF={tf}")

                            # –ø—É–±–ª–∏–∫–∞—Ü–∏—è —Å–Ω–∞–ø—à–æ—Ç–∞ TF –≤ –æ–±—â—É—é –ø–∞–º—è—Ç—å –¥–ª—è –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∏
                            try:
                                if put_snapshot_tf is not None and rows:
                                    bar_iso = datetime.utcfromtimestamp(bar_open_ms / 1000).isoformat()
                                    payload_dict = {r[5]: r[6] for r in rows if r[5] and (r[6] is not None)}  # param_name -> value_str
                                    await put_snapshot_tf(
                                        position_uid=uid,
                                        log_uid=log_uid,
                                        strategy_id=strat,
                                        symbol=sym,
                                        direction=side,
                                        timeframe=tf,
                                        bar_open_time=bar_iso,
                                        payload=payload_dict,
                                        entry_price=entry_price
                                    )
                            except Exception:
                                log.exception(f"[SHM_PUT_ERR] uid={uid} TF={tf}")

                            # –Ω–∞–∫–æ–ø–∏—Ç—å —Å—Ç—Ä–æ–∫–∏ TF –≤ –æ–±—â–∏–π –±–∞—Ç—á –¥–ª—è PG
                            if rows:
                                rows_all.extend(rows)

                            bar_iso = datetime.utcfromtimestamp(bar_open_ms / 1000).isoformat()
                            log.debug(f"[SUMMARY] uid={uid} TF={tf} bar={bar_iso} indicators={tf_inst_count} params={tf_param_count}")
                            total_ind += tf_inst_count
                            total_params += tf_param_count

                        # –∑–∞–ø–∏—Å—å –≤ PG –æ–¥–Ω–∏–º –±–∞—Ç—á–µ–º
                        if rows_all:
                            async with pg.acquire() as conn:
                                async with conn.transaction():
                                    await conn.executemany(
                                        """
                                        INSERT INTO positions_indicators_stat
                                        (position_uid, strategy_id, direction, timeframe,
                                         instance_id, param_name, value_str, value_num,
                                         bar_open_time, enabled_at, params_json)
                                        VALUES
                                        ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11)
                                        ON CONFLICT (position_uid, timeframe, instance_id, param_name, bar_open_time)
                                        DO NOTHING
                                        """,
                                        rows_all
                                    )

                        log.debug(f"[SUMMARY_ALL] uid={uid} indicators_total={total_ind} params_total={total_params}")

                    except Exception:
                        log.exception("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–±—ã—Ç–∏—è positions_open_stream")

            if to_ack:
                await redis.xack(STREAM, GROUP, *to_ack)

        except Exception as e:
            log.error(f"–û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ IND_POS_SNAPSHOT: {e}", exc_info=True)
            await asyncio.sleep(2)