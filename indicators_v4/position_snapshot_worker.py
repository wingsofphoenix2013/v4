# position_snapshot_worker.py ‚Äî –≤–æ—Ä–∫–µ—Ä —Å–Ω–∞–ø—à–æ—Ç–æ–≤ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤/–ø–∞–∫–æ–≤/MW –ø–æ –æ—Ç–∫—Ä—ã—Ç—ã–º –ø–æ–∑–∏—Ü–∏—è–º (m5 –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç, –∑–∞—Ç–µ–º m15/h1; –∑–∞–ø—Ä–æ—Å—ã –≤ indicator_gateway; UPSERT –≤ indicator_position_stat)

import os
import asyncio
import json
import logging
from datetime import datetime, timezone, timedelta

# üî∏ –õ–æ–≥–≥–µ—Ä
log = logging.getLogger("POS_SNAPSHOT")

# üî∏ –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã/–Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–æ—Ä–∫–µ—Ä–∞
REQ_STREAM_POSITIONS = "positions_open_stream"
GW_REQ_STREAM        = "indicator_gateway_request"
GW_RESP_STREAM       = "indicator_gateway_response"

POS_CONCURRENCY     = 6           # —Å–∫–æ–ª—å–∫–æ –ø–æ–∑–∏—Ü–∏–π –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
BATCH_INSERT_SIZE   = 400         # –±–∞—Ç—á –≤—Å—Ç–∞–≤–∫–∏ –≤ PG
POS_TFS_ORDER       = ["m5"]  # –ø–æ—Ä—è–¥–æ–∫ TF (m5 –≤—Å–µ–≥–¥–∞ –ø–µ—Ä–≤—ã–º)
POS_DRY_RUN         = True       # True = –Ω–µ –ø–∏—à–µ–º –≤ PG, —Ç–æ–ª—å–∫–æ –ª–æ–≥–∏
POS_REQ_TIMEOUT_SEC = 15.0        # —Ç–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –∑–∞ –æ–¥–∏–Ω TF (—Å–µ–∫—É–Ω–¥—ã)

# üî∏ –ü–∞–∫–µ—Ç—ã: –∫–∞–∫–∏–µ –ø–æ–ª—è –ø–∏—Å–∞—Ç—å –≤ indicator_position_stat (param_type='pack')
PACK_WHITELIST = {
    "rsi":     ["bucket_low", "trend"],
    "mfi":     ["bucket_low", "trend"],
    "bb":      ["bucket", "bucket_delta", "bw_trend_strict", "bw_trend_smooth"],
    "lr":      ["bucket", "bucket_delta", "angle_trend"],
    "atr":     ["bucket", "bucket_delta"],
    "adx_dmi": ["adx_bucket_low", "adx_dynamic_strict", "adx_dynamic_smooth",
                "gap_bucket_low", "gap_dynamic_strict", "gap_dynamic_smooth"],
    "ema":     ["side", "dynamic", "dynamic_strict", "dynamic_smooth"],
    "macd":    ["mode", "cross", "zero_side", "hist_bucket_low_pct",
                "hist_trend_strict", "hist_trend_smooth"],
}

# üî∏ –°–ø–∏—Å–æ–∫ —Ç–∏–ø–æ–≤ –Ω–∞ TF (RAW/ PACK / MW)
RAW_TYPES = ["rsi","mfi","ema","atr","lr","adx_dmi","macd","bb"]
PACK_TYPES = ["rsi","mfi","ema","atr","lr","adx_dmi","macd","bb"]
MW_TYPES   = ["trend","volatility","momentum","extremes"]

# üî∏ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ: floor –∫ –Ω–∞—á–∞–ª—É –±–∞—Ä–∞ –ø–æ TF (ms ‚Üí ms)
def floor_to_bar_ms(ts_ms: int, tf: str) -> int:
    step_map = {"m5": 5, "m15": 15, "h1": 60}
    step = step_map.get(tf)
    if not step:
        raise ValueError(f"unsupported tf: {tf}")
    step_ms = step * 60_000
    return (ts_ms // step_ms) * step_ms

# üî∏ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ: ISO ‚Üí ms (UTC-naive input ‚Üí treat as UTC)
def iso_to_ms(iso_str: str) -> int:
    dt = datetime.fromisoformat(iso_str)
    if dt.tzinfo is None:
        dt = dt.replace(tzinfo=timezone.utc)
    return int(dt.timestamp() * 1000)

# üî∏ –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –≤ gateway (mode=raw|pack)
def make_gw_request(symbol: str, tf: str, indicator: str, now_ms: int, mode: str) -> dict:
    # –±–µ–∑ length/std: gateway –≤–µ—Ä–Ω—ë—Ç –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –∏–Ω—Å—Ç–∞–Ω—Å—ã —ç—Ç–æ–≥–æ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞ –Ω–∞ TF
    return {
        "symbol": symbol,
        "timeframe": tf,
        "indicator": indicator,
        "timestamp_ms": str(now_ms),
        "mode": mode,
    }

# üî∏ –û—Ç–ø—Ä–∞–≤–∏—Ç—å –ø–∞—á–∫—É –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ gateway –∏ –¥–æ–∂–¥–∞—Ç—å—Å—è –≤—Å–µ—Ö –æ—Ç–≤–µ—Ç–æ–≤ (–≤ —Å–≤–æ–µ–π consumer-group)
async def gw_send_and_collect(redis, reqs: list[dict], timeout_sec: float) -> list[dict]:
    group = "possnap_gw_group"
    consumer = "possnap_gw_1"

    # —Å–æ–∑–¥–∞—Ç—å consumer-group –¥–ª—è –æ—Ç–≤–µ—Ç–∞ (–∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ)
    try:
        await redis.xgroup_create(GW_RESP_STREAM, group, id="$", mkstream=True)
    except Exception as e:
        if "BUSYGROUP" not in str(e):
            log.warning(f"[GW] xgroup_create resp error: {e}")

    # –æ—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤
    req_ids = set()
    for payload in reqs:
        try:
            mid = await redis.xadd(GW_REQ_STREAM, payload)
            req_ids.add(mid)
        except Exception as e:
            log.warning(f"[GW] xadd req error: {e}")

    # —Å–±–æ—Ä –æ—Ç–≤–µ—Ç–æ–≤ –ø–æ req_id
    collected: dict[str, dict] = {}
    deadline = asyncio.get_event_loop().time() + timeout_sec

    # —á–∏—Ç–∞–µ–º —Ü–∏–∫–ª–æ–º, –ø–æ–∫–∞ –Ω–µ —Å–æ–±–µ—Ä—ë–º –≤—Å–µ req_id –∏–ª–∏ –Ω–µ –∏—Å—Ç–µ—á—ë—Ç —Ç–∞–π–º–∞—É—Ç
    while req_ids and asyncio.get_event_loop().time() < deadline:
        try:
            resp = await redis.xreadgroup(
                groupname=group,
                consumername=consumer,
                streams={GW_RESP_STREAM: ">"},
                count=200,
                block=1000
            )
        except Exception as e:
            log.warning(f"[GW] read resp error: {e}")
            await asyncio.sleep(0.2)
            continue

        if not resp:
            continue

        to_ack = []
        for _, messages in resp:
            for msg_id, data in messages:
                to_ack.append(msg_id)
                rid = data.get("req_id")
                if rid in req_ids:
                    # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç —Ü–µ–ª–∏–∫–æ–º (–≤–∫–ª—é—á–∞—è –æ—à–∏–±–∫–∏)
                    collected[rid] = data
                    req_ids.remove(rid)

        if to_ack:
            try:
                await redis.xack(GW_RESP_STREAM, group, *to_ack)
            except Exception:
                pass

    # –≤–µ—Ä–Ω—ë–º —Å–ø–∏—Å–æ–∫ –æ—Ç–≤–µ—Ç–æ–≤ (—Ç–µ, —á—Ç–æ –Ω–µ –ø—Ä–∏—à–ª–∏ –∫ –¥–µ–¥–ª–∞–π–Ω—É ‚Äî –ø—Ä–æ–ø–∞–¥—É—Ç; –æ–±—Ä–∞–±–æ—Ç–∞–µ–º –∫–∞–∫ timeout –Ω–∞ —É—Ä–æ–≤–Ω–µ TF)
    return list(collected.values())

# üî∏ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ gateway (OK) ‚Üí —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ –¥–ª—è indicator_position_stat
def map_gateway_ok_to_rows(position_uid: str,
                           strategy_id: int,
                           symbol: str,
                           tf: str,
                           open_time_iso: str,
                           gw_resp: dict) -> tuple[list[tuple], list[tuple]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (ok_rows, error_rows).
    –°—Ç—Ä–æ–∫–∞ ok_row: (position_uid, strategy_id, symbol, timeframe, param_type, param_base, param_name, value_num, value_text, open_time, status, error_code)
    """
    ok_rows: list[tuple] = []
    err_rows: list[tuple] = []

    indicator = gw_resp.get("indicator")
    mode = gw_resp.get("mode")
    try:
        results_json = gw_resp.get("results")
        items = json.loads(results_json) if results_json else []
    except Exception:
        # –ø–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ —É–¥–∞–ª—Å—è
        err_rows.append((
            position_uid, strategy_id, symbol, tf,
            ("pack" if indicator in MW_TYPES or indicator in PACK_TYPES else "indicator"),
            indicator, "results_parse",
            None, "error",
            datetime.fromisoformat(open_time_iso), "error", "results_parse_error"
        ))
        return ok_rows, err_rows

    # helper: –ø—É—à —Å—Ç—Ä–æ–∫–∏
    def push_row(param_type: str, pbase: str, pname: str, vnum, vtext, status: str = "ok", ecode: str | None = None):
        ok_rows.append((
            position_uid, strategy_id, symbol, tf,
            param_type, pbase, pname,
            vnum, vtext,
            datetime.fromisoformat(open_time_iso),
            status, ecode
        ))

    # —Ä–µ–∂–∏–º PACK (–≤–∫–ª—é—á–∞—è MW)
    if mode == "pack":
        if indicator in MW_TYPES:
            # marketwatch: —Ç–æ–ª—å–∫–æ state
            for it in items:
                base = it.get("base") or indicator
                pack = it.get("pack", {})
                state = pack.get("state")
                if state is not None:
                    push_row("marketwatch", indicator, "state", None, str(state))
                else:
                    err_rows.append((
                        position_uid, strategy_id, symbol, tf,
                        "marketwatch", indicator, "state",
                        None, None,
                        datetime.fromisoformat(open_time_iso), "error", "mw_no_state"
                    ))
            return ok_rows, err_rows

        # –æ–±—ã—á–Ω—ã–µ packs
        for it in items:
            base = it.get("base")
            pack = it.get("pack", {})
            # —Ç–∏–ø –ø–∞–∫–µ—Ç–∞ –ø–æ base: –ø–µ—Ä–≤—ã–µ –±—É–∫–≤—ã –¥–æ —Ü–∏—Ñ—Ä/–ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏–π
            kind = indicator  # gateway —É–∂–µ –ø—Ä–∏—Å–ª–∞–ª indicator
            fields = PACK_WHITELIST.get(kind, [])
            for pname in fields:
                val = pack.get(pname)
                if val is None:
                    # –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ø–æ–ª—è –Ω–µ —Å—á–∏—Ç–∞–µ–º –æ—à–∏–±–∫–æ–π ‚Äî –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                    continue
                # —á–∏—Å–ª–æ–≤–æ–µ/–∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–æ–µ
                vnum, vtext = None, None
                try:
                    # buckets/–ø—Ä–æ—Ü–µ–Ω—Ç—ã/—á–∏—Å–ª–∞ ‚Üí –∫–∞–∫ float; –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ ‚Üí —Å—Ç—Ä–æ–∫–æ–π
                    if isinstance(val, (int, float)):
                        vnum = float(val)
                    else:
                        # –º–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–≤—ã–π —á–∏—Å–ª–æ–≤–æ–π –≤–∏–¥
                        vnum = float(val)
                except Exception:
                    vtext = str(val)
                push_row("pack", str(base), pname, vnum, vtext)
        return ok_rows, err_rows

    # —Ä–µ–∂–∏–º RAW (indicator)
    # items ‚Äî –º–∞—Å—Å–∏–≤ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ {"base": "...", "pack": {"results": {<k>:<v>, ...}, ...}, "mode":"raw"}
    for it in items:
        base = it.get("base")  # –Ω–∞–ø—Ä–∏–º–µ—Ä ema21, rsi14, bb20_2_0
        pack = it.get("pack", {})
        results = pack.get("results", {})
        # param_base = —Ç–∏–ø –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞ –±–µ–∑ –¥–ª–∏–Ω—ã
        pbase = indicator
        for k, v in results.items():
            # param_name = –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–π –∫–ª—é—á (–∫–∞–∫ –≤ —Å–∏—Å—Ç–µ–º–µ), –Ω–∞–ø—Ä–∏–º–µ—Ä "ema21" –∏–ª–∏ "bb20_2_0_upper"
            pname = str(k)
            vnum, vtext = None, None
            try:
                vnum = float(v)
            except Exception:
                vtext = str(v)
            ok_rows.append((
                position_uid, strategy_id, symbol, tf,
                "indicator", pbase, pname,
                vnum, vtext,
                datetime.fromisoformat(open_time_iso),
                "ok", None
            ))
    return ok_rows, err_rows

# üî∏ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ gateway (ERROR) ‚Üí —Å—Ç—Ä–æ–∫–∏ –æ—à–∏–±–æ–∫
def map_gateway_error_to_rows(position_uid: str,
                              strategy_id: int,
                              symbol: str,
                              tf: str,
                              open_time_iso: str,
                              gw_resp: dict) -> list[tuple]:
    indicator = gw_resp.get("indicator")
    mode = gw_resp.get("mode") or ("pack" if indicator in PACK_TYPES or indicator in MW_TYPES else "indicator")
    error = gw_resp.get("error") or "unknown"
    # –ø–æ–¥–±–µ—Ä—ë–º –±–∞–∑—É/–∏–º—è –¥–ª—è –æ—à–∏–±–∫–∏
    if mode == "pack":
        # –¥–ª—è MW/pack –ø–æ–ª–æ–∂–∏–º –æ–¥–Ω—É "—Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é" —Å—Ç—Ä–æ–∫—É –æ—à–∏–±–∫–∏ –Ω–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä
        return [(
            position_uid, strategy_id, symbol, tf,
            ("marketwatch" if indicator in MW_TYPES else "pack"),
            (indicator if indicator in MW_TYPES else indicator),  # param_base
            "error",  # param_name
            None, None,
            datetime.fromisoformat(open_time_iso),
            "error", error
        )]
    else:
        return [(
            position_uid, strategy_id, symbol, tf,
            "indicator", indicator, "error",
            None, None,
            datetime.fromisoformat(open_time_iso),
            "error", error
        )]

# üî∏ –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ gateway-–∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è TF (m5 first policy –≤–Ω–µ —ç—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–∏)
def build_tf_requests(symbol: str, tf: str, created_at_ms: int) -> list[dict]:
    reqs: list[dict] = []
    # RAW
    for ind in RAW_TYPES:
        reqs.append(make_gw_request(symbol, tf, ind, created_at_ms, mode="raw"))
    # PACK
    for ind in PACK_TYPES:
        reqs.append(make_gw_request(symbol, tf, ind, created_at_ms, mode="pack"))
    # MW (–∫–∞–∫ pack)
    for ind in MW_TYPES:
        reqs.append(make_gw_request(symbol, tf, ind, created_at_ms, mode="pack"))
    return reqs

# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏: m5 ‚Üí (m15,h1) —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º m5
async def process_position(pg, redis, get_strategy_mw, pos_payload: dict) -> None:
    t0 = asyncio.get_event_loop().time()

    # –∏–∑–≤–ª–µ–∫–∞–µ–º –±–∞–∑–æ–≤—ã–µ –ø–æ–ª—è
    position_uid = pos_payload.get("position_uid")
    symbol = pos_payload.get("symbol")
    strategy_id = int(pos_payload.get("strategy_id")) if pos_payload.get("strategy_id") is not None else None
    created_at_iso = pos_payload.get("created_at")

    if not position_uid or not symbol or strategy_id is None or not created_at_iso:
        log.info(f"[SKIP] bad position payload: {pos_payload}")
        return

    # —Ñ–∏–ª—å—Ç—Ä –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º: —Ç–æ–ª—å–∫–æ —Ç–µ, –≥–¥–µ market_watcher=true
    try:
        if not get_strategy_mw(int(strategy_id)):
            log.info(f"[SKIP] strategy_id={strategy_id} market_watcher=false")
            return
    except Exception:
        log.info(f"[SKIP] strategy_id={strategy_id} (mw flag check failed)")
        return

    created_at_ms = iso_to_ms(created_at_iso)

    # –ø–æ—Ä—è–¥–æ–∫ TF: m5 –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–≤—ã–º
    tfs = POS_TFS_ORDER[:] if POS_TFS_ORDER else ["m5","m15","h1"]
    if "m5" not in tfs:
        tfs.insert(0, "m5")

    total_ok = total_err = 0

    # Stage A: m5
    if "m5" in tfs:
        ok_rows, err_rows = await process_tf(pg, redis, position_uid, strategy_id, symbol, "m5", created_at_ms)
        total_ok += len(ok_rows)
        total_err += len(err_rows)
        # –∑–∞–ø–∏—Å—å –≤ PG (–±–∞—Ç—á)
        if not POS_DRY_RUN:
            await upsert_rows(pg, ok_rows + err_rows)

    # Stage B: –æ—Å—Ç–∞–ª—å–Ω—ã–µ TF –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    tasks = []
    for tf in tfs:
        if tf == "m5":
            continue
        tasks.append(process_tf(pg, redis, position_uid, strategy_id, symbol, tf, created_at_ms))

    if tasks:
        tf_results = await asyncio.gather(*tasks, return_exceptions=True)
        batch_rows = []
        for res in tf_results:
            if isinstance(res, Exception):
                log.info(f"[TF] error {res}")
                continue
            ok_rows, err_rows = res
            total_ok += len(ok_rows)
            total_err += len(err_rows)
            batch_rows.extend(ok_rows)
            batch_rows.extend(err_rows)
        if batch_rows and not POS_DRY_RUN:
            await upsert_rows(pg, batch_rows)

    t1 = asyncio.get_event_loop().time()
    log.info(f"POS_SNAPSHOT OK uid={position_uid} sym={symbol} "
             f"ok_rows={total_ok} err_rows={total_err} elapsed_ms={int((t1-t0)*1000)}")

# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ TF (—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤ ‚Üí –æ–∂–∏–¥–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ ‚Üí –º–∞–ø–ø–∏–Ω–≥ —Å—Ç—Ä–æ–∫)
async def process_tf(pg, redis, position_uid: str, strategy_id: int, symbol: str, tf: str, created_at_ms: int):
    # —Ñ–∏–∫—Å–∏—Ä—É–µ–º open_time TF –ø–æ created_at
    bar_open_ms = floor_to_bar_ms(created_at_ms, tf)
    open_time_iso = datetime.utcfromtimestamp(bar_open_ms / 1000).isoformat()

    # —Å–æ–±–∏—Ä–∞–µ–º –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–∞—á–∫—É –∑–∞–ø—Ä–æ—Å–æ–≤
    reqs = build_tf_requests(symbol, tf, created_at_ms)
    gw_resps = await gw_send_and_collect(redis, reqs, timeout_sec=POS_REQ_TIMEOUT_SEC)

    ok_rows_all: list[tuple] = []
    err_rows_all: list[tuple] = []

    # –æ–∂–∏–¥–∞–µ–º –ø–æ —á–∏—Å–ª—É –∑–∞–ø—Ä–æ—Å–æ–≤; –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –Ω–µ –ø—Ä–∏—à–ª–æ ‚Äî —Å—á–∏—Ç–∞–µ–º —Ç–∞–π–º–∞—É—Ç–æ–º
    received = len(gw_resps)
    expected = len(reqs)
    if received < expected:
        # —Å–æ–∑–¥–∞–¥–∏–º –æ—à–∏–±–∫–∏ –Ω–∞ ¬´–ø—Ä–æ–ø–∞–≤—à–∏–µ¬ª –∑–∞–ø—Ä–æ—Å—ã ‚Äî –æ–±–æ–±—â—ë–Ω–Ω–æ (–º—ã –Ω–µ –∑–Ω–∞–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ req_id, –Ω–æ –∑–Ω–∞–µ–º –≤–∏–¥—ã)
        missing = expected - received
        log.info(f"[GW] TF {symbol}/{tf} missing={missing} expected={expected} received={received}")

    # —Ä–∞–∑–±–æ—Ä –ø—Ä–∏—à–µ–¥—à–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤
    for resp in gw_resps:
        status = resp.get("status")
        ind = resp.get("indicator")
        mode = resp.get("mode") or ("pack" if ind in PACK_TYPES or ind in MW_TYPES else "indicator")
        if status == "ok":
            oks, errs = map_gateway_ok_to_rows(position_uid, strategy_id, symbol, tf, open_time_iso, resp)
            ok_rows_all.extend(oks)
            err_rows_all.extend(errs)
        else:
            err_rows_all.extend(map_gateway_error_to_rows(position_uid, strategy_id, symbol, tf, open_time_iso, resp))

    return ok_rows_all, err_rows_all

# üî∏ UPSERT —Å—Ç—Ä–æ–∫ –≤ indicator_position_stat (–±–∞—Ç—á–∞–º–∏)
async def upsert_rows(pg, rows: list[tuple]):
    if not rows:
        return
    # –≤—Å—Ç–∞–≤–ª—è–µ–º –±–∞—Ç—á–∞–º–∏
    # –ø–æ—Ä—è–¥–æ–∫ –ø–æ–ª–µ–π:
    # (position_uid, strategy_id, symbol, timeframe, param_type, param_base, param_name, value_num, value_text, open_time, status, error_code)
    sql = """
    INSERT INTO indicator_position_stat
      (position_uid, strategy_id, symbol, timeframe, param_type, param_base, param_name, value_num, value_text, open_time, status, error_code)
    VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12)
    ON CONFLICT (position_uid, timeframe, param_type, param_base, param_name)
    DO UPDATE SET
      value_num = EXCLUDED.value_num,
      value_text = EXCLUDED.value_text,
      open_time = EXCLUDED.open_time,
      status = EXCLUDED.status,
      error_code = EXCLUDED.error_code,
      captured_at = NOW()
    """
    i = 0
    total = len(rows)
    async with pg.acquire() as conn:
        while i < total:
            chunk = rows[i:i+BATCH_INSERT_SIZE]
            async with conn.transaction():
                await conn.executemany(sql, chunk)
            i += len(chunk)

# üî∏ –û—Å–Ω–æ–≤–Ω–æ–π –≤–æ—Ä–∫–µ—Ä: –ø–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ positions_open_stream, –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç m5, –∑–∞—Ç–µ–º m15/h1
async def run_position_snapshot_worker(pg, redis, get_instances_by_tf, get_precision, get_strategy_mw):
    log.debug("POS_SNAPSHOT: –≤–æ—Ä–∫–µ—Ä –∑–∞–ø—É—â–µ–Ω")

    group = "possnap_group"
    consumer = "possnap_1"

    # —Å–æ–∑–¥–∞—Ç—å consumer-group –¥–ª—è –ø–æ–∑–∏—Ü–∏–π (–∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ)
    try:
        await redis.xgroup_create(REQ_STREAM_POSITIONS, group, id="$", mkstream=True)
    except Exception as e:
        if "BUSYGROUP" not in str(e):
            log.warning(f"xgroup_create error: {e}")

    sem = asyncio.Semaphore(POS_CONCURRENCY)

    async def handle_one(msg_id: str, data: dict) -> str | None:
        # –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞ –ø–æ –ø–æ–∑–∏—Ü–∏—è–º
        async with sem:
            try:
                await process_position(pg, redis, get_strategy_mw, data)
            except Exception as e:
                log.warning(f"[POS] error {e}", exc_info=True)
            return msg_id

    while True:
        try:
            resp = await redis.xreadgroup(
                groupname=group,
                consumername=consumer,
                streams={REQ_STREAM_POSITIONS: ">"},
                count=50,
                block=2000
            )
        except Exception as e:
            log.error(f"POS_SNAPSHOT read error: {e}", exc_info=True)
            await asyncio.sleep(0.5)
            continue

        if not resp:
            continue

        try:
            tasks = []
            to_ack = []
            for _, messages in resp:
                for msg_id, data in messages:
                    to_ack.append(msg_id)
                    tasks.append(asyncio.create_task(handle_one(msg_id, data)))

            done_ids = await asyncio.gather(*tasks, return_exceptions=False)
            ack_ids = [mid for mid in done_ids if mid]
            if ack_ids:
                await redis.xack(REQ_STREAM_POSITIONS, group, *ack_ids)
        except Exception as e:
            log.error(f"POS_SNAPSHOT batch error: {e}", exc_info=True)
            await asyncio.sleep(0.5)