# position_snapshot_worker.py ‚Äî –≤–æ—Ä–∫–µ—Ä —Å–Ω–∞–ø—à–æ—Ç–æ–≤ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤/–ø–∞–∫–æ–≤/MW –∏–∑ live-–∫–ª—é—á–µ–π Redis (–±–µ–∑ gateway, –±–µ–∑ —Ä–µ—Ç—Ä–∞–µ–≤/—Ç–∞–π–º–∞—É—Ç–æ–≤)

# üî∏ –ò–º–ø–æ—Ä—Ç—ã
import asyncio
import json
import logging
import re
from datetime import datetime, timezone

# üî∏ –õ–æ–≥–≥–µ—Ä
log = logging.getLogger("POS_SNAPSHOT")

# üî∏ –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã/–Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–æ—Ä–∫–µ—Ä–∞ (–±–µ–∑ ENV)
REQ_STREAM_POSITIONS = "positions_open_stream"   # –≤—Ö–æ–¥–Ω–æ–π —Å—Ç—Ä–∏–º –æ—Ç–∫—Ä—ã—Ç—ã—Ö –ø–æ–∑–∏—Ü–∏–π

POS_CONCURRENCY       = 5                         # —Å–∫–æ–ª—å–∫–æ –ø–æ–∑–∏—Ü–∏–π –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
BATCH_INSERT_SIZE     = 400                       # –±–∞—Ç—á –≤—Å—Ç–∞–≤–∫–∏ –≤ PG
POS_TFS_ORDER         = ["m5", "m15", "h1"]       # –ø–æ—Ä—è–¥–æ–∫ TF (m5 –≤—Å–µ–≥–¥–∞ –ø–µ—Ä–≤—ã–º)
POS_DRY_RUN           = False                     # True = –Ω–µ –ø–∏—à–µ–º –≤ PG, —Ç–æ–ª—å–∫–æ –ª–æ–≥–∏
DB_UPSERT_TIMEOUT_SEC = 15.0                      # —Ç–∞–π–º–∞—É—Ç –Ω–∞ –æ–¥–∏–Ω –±–∞—Ç—á UPSERT –≤ –ë–î (—Å–µ–∫)

# üî∏ –ü–∞–∫–µ—Ç—ã: –∫–∞–∫–∏–µ –ø–æ–ª—è –ø–∏—Å–∞—Ç—å –≤ indicator_position_stat (param_type='pack')
PACK_WHITELIST = {
    "rsi":     ["bucket_low", "trend"],
    "mfi":     ["bucket_low", "trend"],
    "bb":      ["bucket", "bucket_delta", "bw_trend_strict", "bw_trend_smooth"],
    "lr":      ["bucket", "bucket_delta", "angle_trend"],
    "atr":     ["bucket", "bucket_delta"],
    "adx_dmi": ["adx_bucket_low", "adx_dynamic_strict", "adx_dynamic_smooth",
                "gap_bucket_low", "gap_dynamic_strict", "gap_dynamic_smooth"],
    "ema":     ["side", "dynamic", "dynamic_strict", "dynamic_smooth"],
    "macd":    ["mode", "cross", "zero_side", "hist_bucket_low_pct",
                "hist_trend_strict", "hist_trend_smooth"],
}

# üî∏ –¢–∏–ø—ã MW –∏ –ø—Ä–µ—Ñ–∏–∫—Å—ã RAW
MW_TYPES = ("trend", "volatility", "momentum", "extremes")
RAW_PREFIXES = ("ema", "rsi", "mfi", "atr", "lr", "adx_dmi", "macd", "bb")
RAW_PREFIX_RE = re.compile(r'^(ema|rsi|mfi|atr|lr|adx_dmi|macd|bb)')

# üî∏ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ: floor –∫ –Ω–∞—á–∞–ª—É –±–∞—Ä–∞ –ø–æ TF (ms ‚Üí ms)
def floor_to_bar_ms(ts_ms: int, tf: str) -> int:
    step_map = {"m5": 5, "m15": 15, "h1": 60}
    step = step_map.get(tf)
    if not step:
        raise ValueError(f"unsupported tf: {tf}")
    step_ms = step * 60_000
    return (ts_ms // step_ms) * step_ms

# üî∏ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ: ISO ‚Üí ms (UTC-naive input ‚Üí treat as UTC)
def iso_to_ms(iso_str: str) -> int:
    dt = datetime.fromisoformat(iso_str)
    if dt.tzinfo is None:
        dt = dt.replace(tzinfo=timezone.utc)
    return int(dt.timestamp() * 1000)

# üî∏ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ: –∏–∑–≤–ª–µ—á—å –±–∞–∑—É RAW-–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞ –∏–∑ –∏–º–µ–Ω–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ (ema21 ‚Üí ema; lr50_angle ‚Üí lr)
def indicator_from_raw_name(pname: str) -> str:
    m = RAW_PREFIX_RE.match(pname)
    if m:
        return m.group(1)
    # fallback: –¥–æ –ø–µ—Ä–≤–æ–≥–æ "_"
    return pname.split("_", 1)[0]

# üî∏ UPSERT —Å—Ç—Ä–æ–∫ –≤ indicator_position_stat (–±–∞—Ç—á–∞–º–∏) —Å statement_timeout
async def upsert_rows(pg, rows: list[tuple]):
    if not rows:
        return
    sql = """
    INSERT INTO indicator_position_stat
      (position_uid, strategy_id, symbol, timeframe, param_type, param_base, param_name, value_num, value_text, open_time, status, error_code)
    VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12)
    ON CONFLICT (position_uid, timeframe, param_type, param_base, param_name)
    DO UPDATE SET
      value_num = EXCLUDED.value_num,
      value_text = EXCLUDED.value_text,
      open_time = EXCLUDED.open_time,
      status = EXCLUDED.status,
      error_code = EXCLUDED.error_code,
      captured_at = NOW()
    """
    # –ø–æ–¥–≥–æ—Ç–æ–≤–∏–º —Å—Ç—Ä–æ–∫–æ–≤—ã–π timeout –¥–ª—è PG, –Ω–∞–ø—Ä–∏–º–µ—Ä '15s'
    pg_stmt_timeout = f"{int(DB_UPSERT_TIMEOUT_SEC)}s"

    i = 0
    total = len(rows)
    async with pg.acquire() as conn:
        while i < total:
            chunk = rows[i:i+BATCH_INSERT_SIZE]
            async with conn.transaction():
                # –ª–æ–∫–∞–ª—å–Ω—ã–π statement_timeout —Ç–æ–ª—å–∫–æ –Ω–∞ —ç—Ç—É —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é
                try:
                    await conn.execute(f"SET LOCAL statement_timeout = '{pg_stmt_timeout}'")
                except Exception:
                    pass
                await conn.executemany(sql, chunk)
            i += len(chunk)

# üî∏ –°–±–æ—Ä RAW –∑–Ω–∞—á–µ–Ω–∏–π –∏–∑ ind_live:{symbol}:{tf}:*
async def collect_live_raw_rows(redis, position_uid: str, strategy_id: int, symbol: str, tf: str, open_time_iso: str) -> list[tuple]:
    rows: list[tuple] = []
    when = datetime.fromisoformat(open_time_iso)

    # —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∫–ª—é—á–∏ –æ–¥–Ω–∏–º SCAN –∏ —á–∏—Ç–∞–µ–º –ø–∞—á–∫–æ–π
    raw_keys = [k async for k in redis.scan_iter(f"ind_live:{symbol}:{tf}:*")]
    if not raw_keys:
        return rows

    values = await redis.mget(raw_keys)
    for k, v in zip(raw_keys, values):
        if v is None:
            continue
        # –∏–º—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ ‚Äî —Ö–≤–æ—Å—Ç –∫–ª—é—á–∞: ema21 / lr50_angle / bb20_2_0_upper ...
        pname = k.split(":", 3)[-1]
        pbase = indicator_from_raw_name(pname)
        # –ø–æ–ø—ã—Ç–∫–∞ –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ float; –∏–Ω–∞—á–µ –ø–∏—à–µ–º –∫–∞–∫ —Ç–µ–∫—Å—Ç
        try:
            vnum, vtext = float(v), None
        except Exception:
            vnum, vtext = None, str(v)
        rows.append((
            position_uid, strategy_id, symbol, tf,
            "indicator", pbase, pname,
            vnum, vtext,
            when, "ok", None
        ))
    return rows

# üî∏ –°–±–æ—Ä MW state –∏–∑ ind_mw_live:{symbol}:{tf}:{trend|volatility|momentum|extremes}
async def collect_live_mw_rows(redis, position_uid: str, strategy_id: int, symbol: str, tf: str, open_time_iso: str) -> list[tuple]:
    rows: list[tuple] = []
    when = datetime.fromisoformat(open_time_iso)

    for kind in MW_TYPES:
        payload = await redis.get(f"ind_mw_live:{symbol}:{tf}:{kind}")
        if not payload:
            # –ø–æ —É—Å–ª–æ–≤–∏—è–º (TTL 90s, –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π –ø–µ—Ä–µ—Å—á—ë—Ç) –∫–ª—é—á–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å; –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å—Ç–∏–º
            continue
        try:
            js = json.loads(payload)
            state = js.get("state")
            if state is None:
                continue
            rows.append((
                position_uid, strategy_id, symbol, tf,
                "marketwatch", kind, "state",
                None, str(state),
                when, "ok", None
            ))
        except Exception:
            # –æ—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º, —Ç–∞–∫ –∫–∞–∫ live-–∫–ª—é—á–∏ —Å—á–∏—Ç–∞—é—Ç—Å—è —Å—Ç–∞–±–∏–ª—å–Ω—ã–º–∏
            log.debug(f"[MW] parse skip {symbol}/{tf}/{kind}")
            continue
    return rows

# üî∏ –°–±–æ—Ä PACK –∑–Ω–∞—á–µ–Ω–∏–π –∏–∑ pack_live:{indicator}:{symbol}:{tf}:{base}
async def collect_live_pack_rows(redis, position_uid: str, strategy_id: int, symbol: str, tf: str, open_time_iso: str) -> list[tuple]:
    rows: list[tuple] = []
    when = datetime.fromisoformat(open_time_iso)

    for ind in PACK_WHITELIST.keys():
        # —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –±–∞–∑—ã –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞
        pack_keys = [k async for k in redis.scan_iter(f"pack_live:{ind}:{symbol}:{tf}:*")]
        if not pack_keys:
            continue

        pack_vals = await redis.mget(pack_keys)
        fields = PACK_WHITELIST.get(ind, [])
        for k, v in zip(pack_keys, pack_vals):
            if not v:
                continue
            base = k.split(":")[-1]  # –Ω–∞–ø—Ä. bb20_2_0 / ema21 / macd12
            try:
                js = json.loads(v)
                # –¥–æ–ø—É—Å–∫–∞–µ–º –∫–∞–∫ –ø–ª–æ—Å–∫–∏–π pack (–ø–æ–ª—è –Ω–∞ –≤–µ—Ä—Ö–Ω–µ–º —É—Ä–æ–≤–Ω–µ), —Ç–∞–∫ –∏ –≤–ª–æ–∂–µ–Ω–Ω—ã–π {"pack": {...}}
                pack = js.get("pack", js)
                for fname in fields:
                    if fname in pack:
                        val = pack[fname]
                        try:
                            vnum, vtext = float(val), None
                        except Exception:
                            vnum, vtext = None, str(val)
                        rows.append((
                            position_uid, strategy_id, symbol, tf,
                            "pack", base, fname,
                            vnum, vtext,
                            when, "ok", None
                        ))
            except Exception:
                log.debug(f"[PACK] parse skip {symbol}/{tf}/{ind}/{base}")
                continue
    return rows

# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ TF: —Å–±–æ—Ä RAW/MW/PACK –∏–∑ live-–∫–ª—é—á–µ–π –∏ UPSERT
async def process_tf_live(pg, redis, position_uid: str, strategy_id: int, symbol: str, tf: str, created_at_ms: int):
    # —Å—á–∏—Ç–∞–µ–º —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π open_time —Å–≤–µ—á–∏ –ø–æ TF
    bar_open_ms = floor_to_bar_ms(created_at_ms, tf)
    open_time_iso = datetime.utcfromtimestamp(bar_open_ms / 1000).isoformat()

    # —Å–æ–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –∏–∑ —Ç—Ä—ë—Ö —Å–µ–º–µ–π—Å—Ç–≤ live-–∫–ª—é—á–µ–π
    raw_rows  = await collect_live_raw_rows(redis, position_uid, strategy_id, symbol, tf, open_time_iso)
    mw_rows   = await collect_live_mw_rows(redis, position_uid, strategy_id, symbol, tf, open_time_iso)
    pack_rows = await collect_live_pack_rows(redis, position_uid, strategy_id, symbol, tf, open_time_iso)

    rows = raw_rows + mw_rows + pack_rows
    log.debug(f"[TF LIVE] {symbol}/{tf} rows={len(rows)} raw={len(raw_rows)} mw={len(mw_rows)} pack={len(pack_rows)}")

    if not POS_DRY_RUN and rows:
        await upsert_rows(pg, rows)

# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏: TF –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ (m5 ‚Üí m15 ‚Üí h1)
async def process_position(pg, redis, get_strategy_mw, pos_payload: dict) -> None:
    # –∏–∑–≤–ª–µ–∫–∞–µ–º –±–∞–∑–æ–≤—ã–µ –ø–æ–ª—è
    position_uid = pos_payload.get("position_uid")
    symbol = pos_payload.get("symbol")
    strategy_id = int(pos_payload.get("strategy_id")) if pos_payload.get("strategy_id") is not None else None
    created_at_iso = pos_payload.get("created_at")

    # –º–∏–º–Ω–∏–º–∞–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
    if not position_uid or not symbol or strategy_id is None or not created_at_iso:
        log.debug(f"[SKIP] bad position payload: {pos_payload}")
        return

    # —Ñ–∏–ª—å—Ç—Ä –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º: —Ç–æ–ª—å–∫–æ —Ç–µ, –≥–¥–µ market_watcher=true
    try:
        if not get_strategy_mw(int(strategy_id)):
            log.debug(f"[SKIP] strategy_id={strategy_id} market_watcher=false")
            return
    except Exception:
        log.debug(f"[SKIP] strategy_id={strategy_id} (mw flag check failed)")
        return

    created_at_ms = iso_to_ms(created_at_iso)

    # –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ TF
    tfs = POS_TFS_ORDER[:] if POS_TFS_ORDER else ["m5", "m15", "h1"]
    if "m5" not in tfs:
        tfs.insert(0, "m5")

    total_rows = 0
    for tf in tfs:
        await process_tf_live(pg, redis, position_uid, strategy_id, symbol, tf, created_at_ms)
        # —Å—á—ë—Ç—á–∏–∫–∏ –¥–ª—è –ª–æ–≥–∞ –Ω–∞ TF —É—Ä–æ–≤–Ω–µ —É–∂–µ –ø–∏—à—É—Ç—Å—è; –∑–¥–µ—Å—å –æ—Å—Ç–∞–≤–∏–º —Å—É–º–º–∞—Ä–Ω—ã–π —Ç–∞–π–º–µ—Ä –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏
        total_rows += 1  # —É—Å–ª–æ–≤–Ω—ã–π —Å—á—ë—Ç—á–∏–∫ –ø—Ä–æ–π–¥–µ–Ω–Ω—ã—Ö TF

    log.debug(f"POS_SNAPSHOT LIVE uid={position_uid} sym={symbol} tfs={total_rows}")

# üî∏ –û—Å–Ω–æ–≤–Ω–æ–π –≤–æ—Ä–∫–µ—Ä: –ø–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ positions_open_stream; TF –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ; –±–µ–∑ —Ä–µ—Ç—Ä–∞–µ–≤/—Ç–∞–π–º–∞—É—Ç–æ–≤
async def run_position_snapshot_worker(pg, redis, get_instances_by_tf, get_precision, get_strategy_mw):
    log.debug("POS_SNAPSHOT LIVE: –≤–æ—Ä–∫–µ—Ä –∑–∞–ø—É—â–µ–Ω")

    group = "possnap_group"
    consumer = "possnap_1"

    # —Å–æ–∑–¥–∞—Ç—å consumer-group (–∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ)
    try:
        await redis.xgroup_create(REQ_STREAM_POSITIONS, group, id="$", mkstream=True)
    except Exception as e:
        if "BUSYGROUP" not in str(e):
            log.warning(f"xgroup_create error: {e}")

    sem = asyncio.Semaphore(POS_CONCURRENCY)

    async def handle_one(msg_id: str, data: dict) -> str | None:
        # –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞ –ø–æ –ø–æ–∑–∏—Ü–∏—è–º
        async with sem:
            try:
                await process_position(pg, redis, get_strategy_mw, data)
            except Exception as e:
                log.warning(f"[POS] error {e}", exc_info=True)
            return msg_id

    while True:
        try:
            resp = await redis.xreadgroup(
                groupname=group,
                consumername=consumer,
                streams={REQ_STREAM_POSITIONS: ">"},
                count=50,
                block=2000
            )
        except Exception as e:
            log.error(f"POS_SNAPSHOT read error: {e}", exc_info=True)
            await asyncio.sleep(0.5)
            continue

        if not resp:
            continue

        try:
            tasks = []
            for _, messages in resp:
                for msg_id, data in messages:
                    # –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ –æ–±—Ä–∞–±–æ—Ç–∫—É –∏ –ø–æ—Å–ª–µ ‚Äî ACK
                    tasks.append(asyncio.create_task(handle_one(msg_id, data)))

            done_ids = await asyncio.gather(*tasks, return_exceptions=False)
            ack_ids = [mid for mid in done_ids if mid]
            if ack_ids:
                await redis.xack(REQ_STREAM_POSITIONS, group, *ack_ids)
        except Exception as e:
            log.error(f"POS_SNAPSHOT batch error: {e}", exc_info=True)
            await asyncio.sleep(0.5)