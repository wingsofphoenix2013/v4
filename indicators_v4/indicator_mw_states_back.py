# indicator_mw_states_back.py ‚Äî —Ä–∞–∑–æ–≤—ã–π –±—ç–∫–æ—Ñ–∏–ª–ª market_state –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 12 —Å—É—Ç–æ–∫ –∏–∑ MW-—Å–æ—Å—Ç–æ—è–Ω–∏–π

import asyncio
import json
import logging
from datetime import datetime, timedelta

# üî∏ –ò–º–ø–æ—Ä—Ç –ø—Ä–∞–≤–∏–ª –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –º–æ–¥—É–ª—è —Å–æ—Å—Ç–æ—è–Ω–∏–π
from indicator_mw_states import compute_direction_and_quality

# üî∏ –õ–æ–≥–≥–µ—Ä
log = logging.getLogger("MW_STATE_BACK")

# üî∏ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –±—ç–∫–æ—Ñ–∏–ª–ª–∞
BACKFILL_LOOKBACK_DAYS = 12             # –≥–ª—É–±–∏–Ω–∞ –æ–∫–Ω–∞ –≤ –¥–Ω—è—Ö
BACKFILL_SKIP_RECENT_HOURS = 1          # –Ω–µ —Ç—Ä–æ–≥–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å (live-–≤–æ—Ä–∫–µ—Ä —Å–∞–º –≤—Å—ë —Å–¥–µ–ª–∞–µ—Ç)
BACKFILL_BATCH_LIMIT = 50_000           # —Ä–∞–∑–º–µ—Ä –æ–¥–Ω–æ–π –ø–æ—Ä—Ü–∏–∏ –±—ç–∫–æ—Ñ–∏–ª–ª–∞

# üî∏ –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ TF
VALID_TF = {"m5", "m15", "h1"}


# üî∏ –í—ã–±–æ—Ä–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è –±—ç–∫–æ—Ñ–∏–ª–ª–∞ market_state
async def fetch_backfill_candidates(pg, start_dt: datetime, end_dt: datetime):
    """
    –ò—â–µ—Ç –±–∞—Ä—ã, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å –≤—Å–µ 4 MW-—Å–æ—Å—Ç–æ—è–Ω–∏—è (trend/volatility/momentum/extremes),
    –Ω–æ –µ—â—ë –Ω–µ—Ç kind='market_state'.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ dict:
      {
        "symbol": str,
        "timeframe": str,
        "open_time": datetime,
        "trend_state": str,
        "vol_state": str,
        "mom_state": str,
        "ext_state": str,
      }
    """
    log.debug(
        f"MW_STATE_BACK: –≤—ã–±–æ—Ä–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è –æ–∫–Ω–∞ "
        f"{start_dt.isoformat()} .. {end_dt.isoformat()}"
    )

    async with pg.acquire() as conn:
        rows = await conn.fetch(
            """
            SELECT
              symbol,
              timeframe,
              open_time,
              max(CASE WHEN kind = 'trend'      THEN state END) AS trend_state,
              max(CASE WHEN kind = 'volatility' THEN state END) AS vol_state,
              max(CASE WHEN kind = 'momentum'   THEN state END) AS mom_state,
              max(CASE WHEN kind = 'extremes'   THEN state END) AS ext_state,
              bool_or(kind = 'market_state')    AS has_market_state,
              count(DISTINCT kind)              AS kind_count
            FROM indicator_marketwatch_values
            WHERE
              open_time BETWEEN $1 AND $2
              AND timeframe = ANY($3::text[])
              AND kind IN ('trend','volatility','momentum','extremes','market_state')
            GROUP BY symbol, timeframe, open_time
            HAVING
              bool_or(kind = 'market_state') = false      -- —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ market_state –Ω–µ —Ç—Ä–æ–≥–∞–µ–º
              AND count(DISTINCT kind) >= 4               -- –µ—Å—Ç—å –≤—Å–µ 4 MW-–∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
            ORDER BY open_time ASC
            LIMIT $4
            """,
            start_dt,
            end_dt,
            list(VALID_TF),
            BACKFILL_BATCH_LIMIT,
        )

    candidates = []
    for r in rows:
        # —Å—Ç—Ä–∞—Ö–æ–≤–∫–∞ –æ—Ç NULL-—Å–æ—Å—Ç–æ—è–Ω–∏–π
        if not (r["trend_state"] and r["vol_state"] and r["mom_state"] and r["ext_state"]):
            continue
        candidates.append(
            {
                "symbol": r["symbol"],
                "timeframe": r["timeframe"],
                "open_time": r["open_time"],
                "trend_state": r["trend_state"],
                "vol_state": r["vol_state"],
                "mom_state": r["mom_state"],
                "ext_state": r["ext_state"],
            }
        )

    return candidates


# üî∏ –ó–∞–ø–∏—Å—å –±—ç–∫–∞–ø–Ω–æ–≥–æ market_state –≤ indicator_marketwatch_values
async def write_backfilled_states(pg, records: list[dict]):
    """
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –ø–æ—Å—á–∏—Ç–∞–Ω–Ω—ã—Ö market_state-–∑–∞–ø–∏—Å–µ–π –∏
    –ø–∏—à–µ—Ç –∏—Ö –≤ indicator_marketwatch_values —Å kind='market_state'.

    details —Å–æ–¥–µ—Ä–∂–∏—Ç direction, quality, score, components, open_time_iso.
    status = 'healed', source = 'backfill'.
    """
    if not records:
        return 0

    async with pg.acquire() as conn:
        async with conn.transaction():
            params = []
            for rec in records:
                symbol = rec["symbol"]
                tf = rec["timeframe"]
                open_time = rec["open_time"]
                direction = rec["direction"]
                details = {
                    "direction": rec["direction"],
                    "quality": rec["quality"],
                    "score": rec["score"],
                    "components": rec["components"],
                    "open_time_iso": rec["open_time_iso"],
                }
                params.append((symbol, tf, open_time, direction, json.dumps(details)))

            await conn.executemany(
                """
                INSERT INTO indicator_marketwatch_values
                  (symbol, timeframe, open_time, kind, state, status, details, version, source, computed_at, updated_at)
                VALUES ($1,$2,$3,'market_state',$4,'healed',$5,1,'backfill',NOW(),NOW())
                ON CONFLICT (symbol, timeframe, open_time, kind)
                DO NOTHING
                """,
                params,
            )

    return len(records)


# üî∏ –û–¥–∏–Ω –ø—Ä–æ—Ö–æ–¥ –±—ç–∫–æ—Ñ–∏–ª–ª–∞ –ø–æ –æ–∫–Ω—É [start_dt .. end_dt] (–æ–¥–Ω–∞ –ø–æ—Ä—Ü–∏—è –¥–æ BACKFILL_BATCH_LIMIT)
async def run_backfill_window(pg, start_dt: datetime, end_dt: datetime):
    candidates = await fetch_backfill_candidates(pg, start_dt, end_dt)
    if not candidates:
        log.info(
            f"MW_STATE_BACK: –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è –±—ç–∫–æ—Ñ–∏–ª–ª–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –æ–∫–Ω–µ "
            f"{start_dt.isoformat()} .. {end_dt.isoformat()}"
        )
        return 0, {}

    records_to_write = []
    per_tf = {tf: 0 for tf in VALID_TF}

    for c in candidates:
        symbol = c["symbol"]
        tf = c["timeframe"]
        ot = c["open_time"]
        trend_state = c["trend_state"]
        vol_state = c["vol_state"]
        mom_state = c["mom_state"]
        ext_state = c["ext_state"]

        direction, quality, score, components = compute_direction_and_quality(
            trend_state, vol_state, mom_state, ext_state
        )

        rec = {
            "symbol": symbol,
            "timeframe": tf,
            "open_time": ot,
            "direction": direction,
            "quality": quality,
            "score": round(float(score), 4),
            "components": components,
            "open_time_iso": ot.isoformat(),
        }
        records_to_write.append(rec)
        per_tf[tf] = per_tf.get(tf, 0) + 1

    written = await write_backfilled_states(pg, records_to_write)

    log.info(
        f"MW_STATE_BACK: –≤ –æ–∫–Ω–µ {start_dt.isoformat()} .. {end_dt.isoformat()} "
        f"–Ω–∞–π–¥–µ–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤={len(candidates)}, –∑–∞–ø–∏—Å–∞–Ω–æ={written} "
        f"(m5={per_tf.get('m5',0)}, m15={per_tf.get('m15',0)}, h1={per_tf.get('h1',0)})"
    )

    return written, per_tf


# üî∏ –û—Å–Ω–æ–≤–Ω–æ–π –≤–æ—Ä–∫–µ—Ä –±—ç–∫–æ—Ñ–∏–ª–ª–∞: –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–æ—Ö–æ–¥–æ–≤ –ø–æ –æ–∫–Ω—É, –ø–æ–∫–∞ –µ—Å—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç—ã
async def run_indicator_mw_states_back(pg, redis):
    log.info("MW_STATE_BACK: –≤–æ—Ä–∫–µ—Ä –∑–∞–ø—É—â–µ–Ω (—Ä–∞–∑–æ–≤—ã–π –±—ç–∫–æ—Ñ–∏–ª–ª market_state)")

    # –∑–∞–¥–∞—ë–º –æ–∫–Ω–æ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    now = datetime.utcnow()
    end_dt = now - timedelta(hours=BACKFILL_SKIP_RECENT_HOURS)
    start_dt = end_dt - timedelta(days=BACKFILL_LOOKBACK_DAYS)

    log.info(
        f"MW_STATE_BACK: —Å—Ç–∞—Ä—Ç –±—ç–∫–æ—Ñ–∏–ª–ª–∞ market_state –¥–ª—è –æ–∫–Ω–∞ "
        f"{start_dt.isoformat()} .. {end_dt.isoformat()} "
        f"(now={now.isoformat()}, skip_recent_hours={BACKFILL_SKIP_RECENT_HOURS})"
    )

    total_written = 0
    per_tf_total = {tf: 0 for tf in VALID_TF}

    while True:
        # –æ–¥–Ω–∞ –ø–æ—Ä—Ü–∏—è –¥–æ BACKFILL_BATCH_LIMIT
        written, per_tf = await run_backfill_window(pg, start_dt, end_dt)
        total_written += written
        for tf in VALID_TF:
            per_tf_total[tf] = per_tf_total.get(tf, 0) + per_tf.get(tf, 0)

        # –µ—Å–ª–∏ –∑–∞–ø–∏—Å–∞–ª–∏ –º–µ–Ω—å—à–µ –ª–∏–º–∏—Ç–∞ ‚Äî —ç—Ç–æ –±—ã–ª –ø–æ—Å–ª–µ–¥–Ω–∏–π batch
        if written < BACKFILL_BATCH_LIMIT:
            break

    log.info(
        f"MW_STATE_BACK: –±—ç–∫–æ—Ñ–∏–ª–ª –∑–∞–≤–µ—Ä—à—ë–Ω, –≤—Å–µ–≥–æ –∑–∞–ø–∏—Å–∞–Ω–æ={total_written} "
        f"(m5={per_tf_total.get('m5',0)}, m15={per_tf_total.get('m15',0)}, h1={per_tf_total.get('h1',0)})"
    )
    # –≤–æ—Ä–∫–µ—Ä –∑–∞–≤–µ—Ä—à–∞–µ—Ç—Å—è ‚Äî –µ–≥–æ –º–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –∫–∞–∫ –æ–¥–Ω–æ—Ä–∞–∑–æ–≤—ã–π