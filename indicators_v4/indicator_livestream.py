# indicator_livestream.py ‚Äî –≤–æ—Ä–∫–µ—Ä ¬´–∂–∏–≤—ã—Ö¬ª –∑–Ω–∞—á–µ–Ω–∏–π –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ (ind_live:*) –ø–æ (symbol, TF), —Ç–∏–∫ —Ä–∞–∑ –≤ 60—Å, TTL=90—Å

import asyncio
import json
import logging
import time
from datetime import datetime
import pandas as pd

# üî∏ –ò–º–ø–æ—Ä—Ç—ã –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—è —Å–Ω–∞–ø—à–æ—Ç–æ–≤
from indicators.compute_and_store import compute_snapshot_values_async

# üî∏ –õ–æ–≥–≥–µ—Ä –º–æ–¥—É–ª—è
log = logging.getLogger("IND_LIVESTREAM")

# üî∏ –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã TF, —à–∞–≥–∏ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã live-—Ç–∏–∫–µ—Ä–∞
STEP_MIN = {"m5": 5, "m15": 15, "h1": 60}
STEP_MS  = {"m5": 300_000, "m15": 900_000, "h1": 3_600_000}

LIVE_TICK_SEC   = 60        # –ø–µ—Ä–∏–æ–¥ live-–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
LIVE_TTL_SEC    = 90        # TTL ind_live:* (—Å –∑–∞–ø–∞—Å–æ–º > –ø–µ—Ä–∏–æ–¥–∞)
LIVE_DEPTH_BARS = 800       # –∑–∞–ø–∞—Å –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ ¬´–∂–∏–≤—ã—Ö¬ª –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
LIVE_CONCURRENCY = 10       # —Å–µ–º–∞—Ñ–æ—Ä –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –ø–æ –∏–Ω—Å—Ç–∞–Ω—Å–∞–º TF

# üî∏ –ü—Ä–µ—Ñ–∏–∫—Å—ã —Ö—Ä–∞–Ω–∏–ª–∏—â
BB_TS_PREFIX     = "bb:ts"       # bb:ts:{symbol}:{interval}:{field}
IND_LIVE_PREFIX  = "ind_live"    # ind_live:{symbol}:{tf}:{param}


# üî∏ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ: –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –Ω–∞—á–∞–ª–∞ –±–∞—Ä–∞ –∏ —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –≤ –º—Å (UTC)
def floor_to_bar(ts_ms: int, tf: str) -> int:
    step = STEP_MS[tf]
    return (ts_ms // step) * step


# üî∏ –ó–∞–≥—Ä—É–∑–∫–∞ OHLCV –∏–∑ Redis TS (–æ–¥–Ω–∏–º –±–∞—Ç—á–µ–º) –∏ —Å–±–æ—Ä–∫–∞ DataFrame
async def load_ohlcv_df(redis, symbol: str, tf: str, end_ts_ms: int, bars: int):
    if tf not in STEP_MS:
        return None

    step = STEP_MS[tf]
    start_ts = end_ts_ms - (bars - 1) * step

    fields = ["o", "h", "l", "c", "v"]
    keys = {f: f"{BB_TS_PREFIX}:{symbol}:{tf}:{f}" for f in fields}

    # –æ–¥–∏–Ω –±–∞—Ç—á –Ω–∞ 5 TS.RANGE
    tasks = {
        f: redis.execute_command("TS.RANGE", keys[f], start_ts, end_ts_ms)
        for f in fields
    }
    results = await asyncio.gather(*tasks.values(), return_exceptions=True)

    series = {}
    for f, res in zip(tasks.keys(), results):
        if isinstance(res, Exception):
            log.warning(f"[TS] RANGE {keys[f]} error: {res}")
            continue
        if res:
            try:
                series[f] = {int(ts): float(val) for ts, val in res if val is not None}
            except Exception as e:
                log.warning(f"[TS] parse {keys[f]} error: {e}")

    if not series or "c" not in series or not series["c"]:
        return None

    # –æ–±—â–∏–π –∏–Ω–¥–µ–∫—Å –ø–æ –º–µ—Ç–∫–∞–º –≤—Ä–µ–º–µ–Ω–∏
    idx = sorted(series["c"].keys())
    df = None
    for f in fields:
        col_map = series.get(f, {})
        s = pd.Series({ts: col_map.get(ts) for ts in idx})
        s.index = pd.to_datetime(s.index, unit="ms")
        s.name = f
        df = s.to_frame() if df is None else df.join(s, how="outer")

    if df is None or df.empty:
        return None

    df.index.name = "open_time"
    return df.sort_index()


# üî∏ –ú–µ–Ω–µ–¥–∂–µ—Ä —Ü–∏–∫–ª–æ–≤ –ø–æ (symbol, timeframe)
class TFManager:
    def __init__(self, pg, redis, get_instances_by_tf, get_precision, get_active_symbols):
        self.pg = pg
        self.redis = redis
        self.get_instances_by_tf = get_instances_by_tf
        self.get_precision = get_precision
        self.get_active_symbols = get_active_symbols

        # (symbol, tf) -> asyncio.Task
        self.tasks = {}

    def _key(self, symbol: str, tf: str):
        return (symbol, tf)

    def is_running(self, symbol: str, tf: str) -> bool:
        t = self.tasks.get(self._key(symbol, tf))
        return t is not None and not t.done()

    async def start_or_restart(self, symbol: str, tf: str):
        if tf not in STEP_MIN:
            return
        key = self._key(symbol, tf)

        # –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Ü–∏–∫–ª–∞, —á—Ç–æ–±—ã ¬´—Ñ–∞–∑–∞¬ª —à–ª–∞ –æ—Ç –∑–∞–∫—Ä—ã—Ç–∏—è —Å–≤–µ—á–∏ (+60—Å)
        prev = self.tasks.get(key)
        if prev and not prev.done():
            prev.cancel()
            try:
                await prev
            except Exception:
                pass

        task = asyncio.create_task(self._tf_loop(symbol, tf))
        self.tasks[key] = task
        log.info(f"[START] {symbol}/{tf}: live-—Ü–∏–∫–ª –∑–∞–ø—É—â–µ–Ω (–ø–µ—Ä–≤—ã–π —Ç–∏–∫ —á–µ—Ä–µ–∑ {LIVE_TICK_SEC}s)")

    async def stop_symbol(self, symbol: str):
        # –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤—Å–µ TF –ø–æ —Å–∏–º–≤–æ–ª—É
        to_stop = [k for k in self.tasks.keys() if k[0] == symbol]
        for key in to_stop:
            t = self.tasks.pop(key, None)
            if t:
                t.cancel()
                try:
                    await t
                except Exception:
                    pass
                log.info(f"[STOP] {key[0]}/{key[1]}: live-—Ü–∏–∫–ª –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

    async def _tf_loop(self, symbol: str, tf: str):
        # –Ω–∞—á–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞: 60—Å –ø–æ—Å–ª–µ ¬´–∑–∞–∫—Ä—ã—Ç–æ–≥–æ¬ª (–ø—Ä–∏–≤—è–∑–∫–∞ —Ñ–∞–∑—ã –∫ —Å–æ–±—ã—Ç–∏—é)
        try:
            await asyncio.sleep(LIVE_TICK_SEC)
            sem = asyncio.Semaphore(LIVE_CONCURRENCY)

            while True:
                t0 = time.monotonic()

                try:
                    # –ø—Ä–æ–≤–µ—Ä–∫–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Å–∏–º–≤–æ–ª–∞ (–µ—Å–ª–∏ —É –Ω–∞—Å –µ—Å—Ç—å —Ç–∞–∫–æ–π —Å–ø–∏—Å–æ–∫)
                    if symbol not in set(self.get_active_symbols()):
                        log.info(f"[SKIP] {symbol}/{tf}: —Å–∏–º–≤–æ–ª –Ω–µ–∞–∫—Ç–∏–≤–µ–Ω")
                        await asyncio.sleep(LIVE_TICK_SEC)
                        continue

                    # 1) –∑–∞–≥—Ä—É–∑–∫–∞ OHLCV
                    now_ms = int(datetime.utcnow().timestamp() * 1000)
                    bar_open_ms = floor_to_bar(now_ms, tf)

                    t_fetch0 = time.monotonic()
                    df = await load_ohlcv_df(self.redis, symbol, tf, bar_open_ms, LIVE_DEPTH_BARS)
                    t_fetch1 = time.monotonic()

                    if df is None or df.empty:
                        log.info(f"[SKIP] {symbol}/{tf}: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö OHLCV –¥–ª—è live-—Ç–∏–∫–∞")
                        await asyncio.sleep(LIVE_TICK_SEC)
                        continue

                    # 2) —Å–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç–∞–Ω—Å–æ–≤ TF (–∏–∑ in-memory –∫—ç—à–∞)
                    instances = self.get_instances_by_tf(tf)
                    if not instances:
                        log.info(f"[SKIP] {symbol}/{tf}: –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –∏–Ω—Å—Ç–∞–Ω—Å–æ–≤ TF")
                        await asyncio.sleep(LIVE_TICK_SEC)
                        continue

                    # 3) —Ä–∞—Å—á—ë—Ç –∑–Ω–∞—á–µ–Ω–∏–π –ø–æ –≤—Å–µ–º –∏–Ω—Å—Ç–∞–Ω—Å–∞–º TF (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ, –Ω–æ —Å —Å–µ–º–∞—Ñ–æ—Ä–æ–º)
                    precision = self.get_precision(symbol) or 8

                    async def run_one(inst):
                        # –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å–Ω–∞–ø—à–æ—Ç–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞ –ø–æ —Ç–µ–∫—É—â–µ–º—É df
                        async with sem:
                            return inst["id"], await compute_snapshot_values_async(inst, symbol, df, precision)

                    t_comp0 = time.monotonic()
                    results = await asyncio.gather(*[run_one(inst) for inst in instances], return_exceptions=True)
                    t_comp1 = time.monotonic()

                    # 4) –∑–∞–ø–∏—Å—å ind_live:* (–æ–¥–Ω–∏–º pipeline)
                    pipe = self.redis.pipeline()
                    params_written = 0

                    for item in results:
                        if isinstance(item, Exception):
                            continue
                        iid, values = item
                        if not values:
                            continue
                        for pname, sval in values.items():
                            rkey = f"{IND_LIVE_PREFIX}:{symbol}:{tf}:{pname}"
                            # –∑–∞–ø–∏—Å—å –∑–Ω–∞—á–µ–Ω–∏—è —Å TTL=90—Å
                            pipe.set(rkey, sval, ex=LIVE_TTL_SEC)
                            params_written += 1

                    t_write0 = time.monotonic()
                    if params_written > 0:
                        await pipe.execute()
                    t_write1 = time.monotonic()

                    # 5) –ª–æ–≥ –∏—Ç–æ–≥–∞ —Ç–∏–∫–∞
                    fetch_ms  = int((t_fetch1 - t_fetch0) * 1000)
                    comp_ms   = int((t_comp1  - t_comp0) * 1000)
                    write_ms  = int((t_write1 - t_write0) * 1000) if params_written > 0 else 0
                    total_ms  = int((time.monotonic() - t0) * 1000)

                    log.info(
                        f"[LIVE] {symbol}/{tf}: instances={len(instances)}, params_written={params_written}, "
                        f"fetch_ms={fetch_ms}, compute_ms={comp_ms}, write_ms={write_ms}, total_ms={total_ms}"
                    )

                except asyncio.CancelledError:
                    log.info(f"[CANCEL] {symbol}/{tf}: live-—Ü–∏–∫–ª –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
                    return
                except Exception as e:
                    log.warning(f"[ERR] {symbol}/{tf}: –æ—à–∏–±–∫–∞ live-–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {e}", exc_info=True)

                # –ø–∞—É–∑–∞ –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ live-—Ç–∏–∫–∞
                await asyncio.sleep(LIVE_TICK_SEC)

        except asyncio.CancelledError:
            log.info(f"[CANCEL:init] {symbol}/{tf}: live-—Ü–∏–∫–ª –Ω–µ –∑–∞–ø—É—â–µ–Ω/–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞ —Å—Ç–∞—Ä—Ç–µ")
            return


# üî∏ –û—Å–Ω–æ–≤–Ω–æ–π –≤–æ—Ä–∫–µ—Ä: —Å–ª—É—à–∞–µ—Ç iv4_inserted –∏ —É–ø—Ä–∞–≤–ª—è–µ—Ç —Ü–∏–∫–ª–∞–º–∏ –ø–æ (symbol, TF)
async def run_indicator_livestream(pg, redis, get_instances_by_tf, get_precision, get_active_symbols):
    log.debug("IND_LIVESTREAM: –≤–æ—Ä–∫–µ—Ä –∑–∞–ø—É—â–µ–Ω")

    mgr = TFManager(pg, redis, get_instances_by_tf, get_precision, get_active_symbols)

    stream = "iv4_inserted"
    group = "ind_live_tf_group"
    consumer = "ind_live_tf_1"

    # —Å–æ–∑–¥–∞—Ç—å consumer-group –¥–ª—è iv4_inserted
    try:
        await redis.xgroup_create(stream, group, id="$", mkstream=True)
    except Exception as e:
        if "BUSYGROUP" not in str(e):
            log.warning(f"xgroup_create error: {e}")

    while True:
        try:
            resp = await redis.xreadgroup(group, consumer, streams={stream: ">"}, count=200, block=2000)
            if not resp:
                continue

            to_ack = []

            for _, messages in resp:
                for msg_id, data in messages:
                    to_ack.append(msg_id)
                    try:
                        symbol = data.get("symbol")
                        interval = data.get("interval")  # m5/m15/h1

                        # –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
                        if not symbol or interval not in STEP_MIN:
                            continue

                        # –∑–∞–ø—É—Å–∫/–ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Ü–∏–∫–ª–∞ –ø–æ (symbol, TF)
                        await mgr.start_or_restart(symbol, interval)

                    except Exception as e:
                        log.warning(f"[STREAM] parse iv4_inserted error: {e}")

            if to_ack:
                await redis.xack(stream, group, *to_ack)

        except Exception as e:
            log.error(f"[STREAM] iv4_inserted loop error: {e}", exc_info=True)
            await asyncio.sleep(2)