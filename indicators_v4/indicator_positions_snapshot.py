# indicator_positions_snapshot.py ‚Äî on-demand —Å–Ω–∏–º–æ–∫ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤/–¥–∏–Ω–∞–º–∏–∫/MW –ø—Ä–∏ –æ—Ç–∫—Ä—ã—Ç–∏–∏ –ø–æ–∑–∏—Ü–∏–∏ (m5/m15/h1)

import asyncio
import json
import logging
from datetime import datetime
from typing import Dict, Any, List, Optional

# üî∏ –ò–º–ø–æ—Ä—Ç—ã packs –∏ —É—Ç–∏–ª–∏—Ç
from packs.pack_utils import floor_to_bar, load_ohlcv_df
from packs.rsi_pack import build_rsi_pack
from packs.mfi_pack import build_mfi_pack
from packs.bb_pack import build_bb_pack
from packs.lr_pack import build_lr_pack
from packs.atr_pack import build_atr_pack
from packs.ema_pack import build_ema_pack
from packs.adx_dmi_pack import build_adx_dmi_pack
from packs.macd_pack import build_macd_pack
from packs.trend_pack import build_trend_pack
from packs.volatility_pack import build_volatility_pack
from packs.momentum_pack import build_momentum_pack
from packs.extremes_pack import build_extremes_pack

# üî∏ –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã —Å—Ç—Ä–∏–º–∞ –∏ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞
STREAM_POSITIONS_OPEN = "positions_open_stream"
GROUP_SNAPSHOT = "pos_snap_group"
CONSUMER_SNAPSHOT = "pos_snap_1"
TF_LIST = ("m5", "m15", "h1")
MAX_CONCURRENCY = 8

# üî∏ –õ–æ–≥–≥–µ—Ä
log = logging.getLogger("POS_SNAPSHOT")


# üî∏ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ: –∫—ç—à–∏—Ä—É–µ–º—ã–π –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å compute_fn –Ω–∞ –æ–¥–∏–Ω TF/—Å–∏–º–≤–æ–ª
def _make_compute_cached(
    compute_snapshot_values_async,
    symbol: str,
    tf: str,
    bar_open_ms: int,
    df,
    precision: int
):
    memo: Dict[Any, Dict[str, str]] = {}

    async def _compute(inst: dict) -> Dict[str, str]:
        # –∫—ç—à-–∫–ª—é—á –ø–æ –∫–æ–Ω—Ç—Ä–∞–∫—Ç—É –∏–Ω—Å—Ç–∞–Ω—Å–∞
        key = (
            inst.get("indicator"),
            tuple(sorted((inst.get("params") or {}).items())),
            symbol,
            tf,
            bar_open_ms,
            precision,
        )
        if key in memo:
            return memo[key]
        res = await compute_snapshot_values_async(inst, symbol, df, precision)
        memo[key] = res or {}
        return memo[key]

    return _compute


# üî∏ –°–æ–±—Ä–∞—Ç—å packs –¥–ª—è –æ–¥–Ω–æ–≥–æ TF
async def _build_packs_for_tf(
    symbol: str,
    tf: str,
    now_ms: int,
    precision: int,
    redis,
    compute_fn_cached
) -> Dict[str, List[dict]]:
    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏
    packs: Dict[str, List[dict]] = {
        "rsi": [],
        "mfi": [],
        "ema": [],
        "lr": [],
        "bb": [],
        "atr": [],
        "adx_dmi": [],
        "macd": [],
    }

    # RSI / MFI
    for L in (14, 21):
        p = await build_rsi_pack(symbol, tf, L, now_ms, precision, redis, compute_fn_cached)
        if p: packs["rsi"].append(p)
        p = await build_mfi_pack(symbol, tf, L, now_ms, precision, redis, compute_fn_cached)
        if p: packs["mfi"].append(p)

    # EMA
    for L in (21, 50, 200):
        p = await build_ema_pack(symbol, tf, L, now_ms, precision, redis, compute_fn_cached)
        if p: packs["ema"].append(p)

    # LR
    for L in (50, 100):
        p = await build_lr_pack(symbol, tf, L, now_ms, precision, redis, compute_fn_cached)
        if p: packs["lr"].append(p)

    # BB (20, 2.0)
    p = await build_bb_pack(symbol, tf, 20, 2.0, now_ms, precision, redis, compute_fn_cached)
    if p: packs["bb"].append(p)

    # ATR(14)
    p = await build_atr_pack(symbol, tf, 14, now_ms, precision, redis, compute_fn_cached)
    if p: packs["atr"].append(p)

    # ADX/DMI
    for L in (14, 21):
        p = await build_adx_dmi_pack(symbol, tf, L, now_ms, precision, redis, compute_fn_cached)
        if p: packs["adx_dmi"].append(p)

    # MACD (fast 12, 5)
    for F in (12, 5):
        p = await build_macd_pack(symbol, tf, F, now_ms, precision, redis, compute_fn_cached)
        if p: packs["macd"].append(p)

    return packs


# üî∏ –°–æ–±—Ä–∞—Ç—å MW packs (4 –∫–æ–º–ø–æ–∑–∏—Ç–∞) –¥–ª—è TF
async def _build_mw_for_tf(
    symbol: str,
    tf: str,
    now_ms: int,
    precision: int,
    redis,
    compute_fn_cached
) -> Dict[str, Optional[dict]]:
    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏
    trend = await build_trend_pack(symbol, tf, now_ms, precision, redis, compute_fn_cached)
    vol   = await build_volatility_pack(symbol, tf, now_ms, precision, redis, compute_fn_cached)
    mom   = await build_momentum_pack(symbol, tf, now_ms, precision, redis, compute_fn_cached)
    ext   = await build_extremes_pack(symbol, tf, now_ms, precision, redis, compute_fn_cached)

    # –≤ payload –∫–ª–∞–¥—ë–º —Ç–æ–ª—å–∫–æ "pack"-—á–∞—Å—Ç—å
    return {
        "trend":      (trend or {}).get("pack") if trend else None,
        "volatility": (vol   or {}).get("pack") if vol   else None,
        "momentum":   (mom   or {}).get("pack") if mom   else None,
        "extremes":   (ext   or {}).get("pack") if ext   else None,
    }


# üî∏ –û—Å–Ω–æ–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è (—Å–Ω–∏–º–æ–∫ –ø–æ 3 TF)
async def _handle_snapshot_for_position(
    pg,
    redis,
    data: dict,
    get_instances_by_tf,
    get_precision,
    get_strategy_mw,
    compute_snapshot_values_async
):
    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏
    try:
        strategy_id = int(data["strategy_id"])
        symbol      = data["symbol"]
        position_uid= data["position_uid"]
        direction   = data.get("direction")
        entry_price = data.get("entry_price")
        log_uid     = data.get("log_uid")
        route       = data.get("route")
        created_at  = data.get("created_at")
    except Exception:
        log.exception("‚ùå –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π payload positions_open_stream")
        return

    # —Ñ–∏–ª—å—Ç—Ä –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º —Å market_watcher
    if not get_strategy_mw(strategy_id):
        log.info(f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫ —Å–Ω–∏–º–∫–∞: strategy_id={strategy_id} (market_watcher=false) pos={position_uid}")
        return

    precision = get_precision(symbol) or 8
    now_ms = int(datetime.utcnow().timestamp() * 1000)

    # –ø–æ –∫–∞–∂–¥–æ–º—É TF —Å–Ω–∏–º–∞–µ–º raw + packs + MW
    for tf in TF_LIST:
        try:
            bar_open_ms = floor_to_bar(now_ms, tf)
            df = await load_ohlcv_df(redis, symbol, tf, bar_open_ms, 800)
            if df is None or df.empty:
                log.info(f"‚ö†Ô∏è  DF –ø—É—Å—Ç–æ–π: {symbol}/{tf} pos={position_uid}")
                # –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º, –≤—Å—ë —Ä–∞–≤–Ω–æ –∑–∞—Ñ–∏–∫—Å–∏—Ä—É–µ–º ¬´–ø—É—Å—Ç–æ–π¬ª values/packs/mw
            compute_cached = _make_compute_cached(
                compute_snapshot_values_async, symbol, tf, bar_open_ms, df, precision
            )

            # raw –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ –≤—Å–µ–º –∞–∫—Ç–∏–≤–Ω—ã–º –∏–Ω—Å—Ç–∞–Ω—Å–∞–º TF
            values: Dict[str, str] = {}
            instances = get_instances_by_tf(tf)
            for inst in instances:
                vals = await compute_cached(inst)
                if vals:
                    values.update(vals)

            # packs
            packs = await _build_packs_for_tf(symbol, tf, now_ms, precision, redis, compute_cached)

            # MW
            mw = await _build_mw_for_tf(symbol, tf, now_ms, precision, redis, compute_cached)

            # payload
            bar_open_iso = datetime.utcfromtimestamp(bar_open_ms / 1000).isoformat()
            payload = {
                "meta": {
                    "position_uid": position_uid,
                    "strategy_id": strategy_id,
                    "symbol": symbol,
                    "direction": direction,
                    "entry_price": entry_price,
                    "precision": precision,
                    "log_uid": log_uid,
                    "route": route,
                    "created_at": created_at,
                    "bar_open_iso": bar_open_iso,
                },
                "indicators": {
                    "values": values,
                    "instances": [
                        {
                            "id": iid,
                            "indicator": inst["indicator"],
                            "timeframe": inst["timeframe"],
                            "enabled_at": inst.get("enabled_at").isoformat() if inst.get("enabled_at") else None,
                            "params": inst.get("params", {}),
                        }
                        for iid, inst in getattr(instances, "items", lambda: [])()
                    ] if isinstance(instances, dict) else [
                        {
                            "id": inst_id if isinstance(inst, tuple) else inst.get("id"),
                            "indicator": (inst[1]["indicator"] if isinstance(inst, tuple) else inst["indicator"]),
                            "timeframe": (inst[1]["timeframe"] if isinstance(inst, tuple) else inst["timeframe"]),
                            "enabled_at": (
                                inst[1].get("enabled_at").isoformat()
                                if isinstance(inst, tuple) and inst[1].get("enabled_at")
                                else (inst.get("enabled_at").isoformat() if inst.get("enabled_at") else None)
                            ),
                            "params": (inst[1].get("params", {}) if isinstance(inst, tuple) else inst.get("params", {})),
                        }
                        for (inst_id, inst) in enumerate(instances)  # instances –∏–∑ indicators_v4_main.py ‚Äî list[dict]
                    ],
                },
                "packs": {k: [p for p in v if p] for k, v in packs.items()},
                "mw": mw,
            }

            # –≤—Å—Ç–∞–≤–∫–∞ –≤ PG (–æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞ –Ω–∞ TF)
            await pg.execute(
                """
                INSERT INTO position_open_snapshots_v1
                (position_uid, strategy_id, symbol, timeframe, bar_open_time, snapshot_time, source, payload)
                VALUES ($1,$2,$3,$4,$5,$6,$7,$8)
                ON CONFLICT (position_uid, timeframe) DO UPDATE
                SET payload = EXCLUDED.payload, snapshot_time = EXCLUDED.snapshot_time, source = EXCLUDED.source
                """,
                position_uid,
                strategy_id,
                symbol,
                tf,
                datetime.utcfromtimestamp(bar_open_ms / 1000),
                datetime.utcnow(),
                "on_demand",
                json.dumps(payload),
            )

            # –ª–æ–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–æ TF
            packs_count = {k: len(v) for k, v in payload["packs"].items()}
            values_count = len(values)
            log.info(
                f"‚úÖ SNAPSHOT pos={position_uid} {symbol}/{tf} "
                f"values={values_count} packs={packs_count} mw="
                f"{','.join([k for k,v in mw.items() if v]) or 'none'}"
            )

        except Exception:
            log.exception(f"‚ùå –û—à–∏–±–∫–∞ —Å–Ω–∏–º–∫–∞ pos={position_uid} {symbol}/{tf}")


# üî∏ –û–±—ë—Ä—Ç–∫–∞ –¥–ª—è ack
async def _wrap_and_ack(
    pg,
    redis,
    record_id: str,
    data: dict,
    get_instances_by_tf,
    get_precision,
    get_strategy_mw,
    compute_snapshot_values_async
):
    try:
        await _handle_snapshot_for_position(
            pg,
            redis,
            data,
            get_instances_by_tf,
            get_precision,
            get_strategy_mw,
            compute_snapshot_values_async,
        )
    finally:
        # ack –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –∏—Å—Ö–æ–¥–∞ ‚Äî —Å–æ–±—ã—Ç–∏–µ –æ—Ç–∫—Ä—ã—Ç–∏—è –Ω–µ –¥–æ–ª–∂–Ω–æ –∑–∞–≤–∏—Å–∞—Ç—å
        try:
            await redis.xack(STREAM_POSITIONS_OPEN, GROUP_SNAPSHOT, record_id)
        except Exception:
            log.exception(f"‚ùå ACK error id={record_id}")


# üî∏ –ì–ª–∞–≤–Ω—ã–π –≤–æ—Ä–∫–µ—Ä: —Å–ª—É—à–∞–µ—Ç positions_open_stream –∏ –¥–µ–ª–∞–µ—Ç —Å–Ω–∏–º–∫–∏
async def run_indicator_positions_snapshot(
    pg,
    redis,
    get_instances_by_tf,
    get_precision,
    get_strategy_mw,
    compute_snapshot_values_async
):
    # —Å–æ–∑–¥–∞—Ç—å consumer group
    try:
        await redis.xgroup_create(STREAM_POSITIONS_OPEN, GROUP_SNAPSHOT, id="$", mkstream=True)
        log.debug(f"üîß –ì—Ä—É–ø–ø–∞ {GROUP_SNAPSHOT} —Å–æ–∑–¥–∞–Ω–∞ –¥–ª—è {STREAM_POSITIONS_OPEN}")
    except Exception as e:
        if "BUSYGROUP" in str(e):
            log.debug(f"‚ÑπÔ∏è –ì—Ä—É–ø–ø–∞ {GROUP_SNAPSHOT} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        else:
            log.exception("‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è Consumer Group –¥–ª—è positions_open_stream")
            return

    # —Å–µ–º–∞—Ñ–æ—Ä –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö —Å–Ω–∏–º–∫–æ–≤
    sem = asyncio.Semaphore(MAX_CONCURRENCY)

    log.debug(f"üì° –ü–æ–¥–ø–∏—Å–∫–∞ —á–µ—Ä–µ–∑ Consumer Group: {STREAM_POSITIONS_OPEN} ‚Üí {GROUP_SNAPSHOT}")

    while True:
        try:
            entries = await redis.xreadgroup(
                groupname=GROUP_SNAPSHOT,
                consumername=CONSUMER_SNAPSHOT,
                streams={STREAM_POSITIONS_OPEN: ">"},
                count=20,
                block=1000
            )

            if not entries:
                continue

            for _, records in entries:
                for record_id, data in records:
                    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏
                    if not isinstance(data, dict):
                        try:
                            await redis.xack(STREAM_POSITIONS_OPEN, GROUP_SNAPSHOT, record_id)
                        except Exception:
                            log.exception(f"‚ùå ACK error (non-dict) id={record_id}")
                        continue

                    async def _run(record_id=record_id, data=data):
                        # –≤–ª–æ–∂–µ–Ω–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å: –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ—Å—Ç–∏
                        async with sem:
                            await _wrap_and_ack(
                                pg,
                                redis,
                                record_id,
                                data,
                                get_instances_by_tf,
                                get_precision,
                                get_strategy_mw,
                                compute_snapshot_values_async,
                            )

                    asyncio.create_task(_run())

        except Exception:
            log.exception("‚ùå –û—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ run_indicator_positions_snapshot")
            await asyncio.sleep(1)