# indicator_gateway.py â€” on-demand ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ð¾Ñ€ (RSI + MFI + BB + LR + ATR + EMA + ADX/DMI) c Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¾Ð¹ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹

import asyncio
import json
import logging
import time
from datetime import datetime

# ðŸ”¸ Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ñ‹ pack-Ð±Ð¸Ð»Ð´ÐµÑ€Ð¾Ð²
from packs.rsi_pack import build_rsi_pack
from packs.mfi_pack import build_mfi_pack
from packs.bb_pack  import build_bb_pack
from packs.lr_pack  import build_lr_pack
from packs.atr_pack import build_atr_pack
from packs.ema_pack import build_ema_pack
from packs.adx_dmi_pack import build_adx_dmi_pack
from packs.macd_pack import build_macd_pack
from packs.trend_pack import build_trend_pack
from packs.volatility_pack import build_volatility_pack
from packs.momentum_pack import build_momentum_pack
from packs.extremes_pack import build_extremes_pack
from packs.pack_utils import floor_to_bar

# ðŸ”¸ Ð›Ð¾Ð³Ð³ÐµÑ€
log = logging.getLogger("IND_GATEWAY")

# ðŸ”¸ Streams
REQ_STREAM  = "indicator_gateway_request"
RESP_STREAM = "indicator_gateway_response"

# ðŸ”¸ TTL Ð±Ð°Ñ€Ð½Ð¾Ð³Ð¾ ÐºÑÑˆÐ°/Ð¿ÑƒÐ±Ð»Ð¸Ñ‡Ð½Ð¾Ð³Ð¾ Ð¿Ð°ÐºÐµÑ‚Ð°
LIVE_TTL_SEC = 30

# ðŸ”¸ ÐŸÐ°Ñ€Ð°Ð»Ð»ÐµÐ»Ð¸Ð·Ð¼ Ð¸ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð¿Ð°Ñ‡ÐºÐ¸
GATEWAY_CONCURRENCY = 20
GATEWAY_BATCH_SIZE  = 100

# ðŸ”¸ ÐšÐ»ÑŽÑ‡Ð¸ ÐºÑÑˆÐ°/Ð¿ÑƒÐ±Ð»Ð¸Ñ‡Ð½Ñ‹Ñ… Ð¿Ð°ÐºÐµÑ‚Ð¾Ð²
def cache_key(indicator: str, symbol: str, tf: str, base_or_len: str, bar_open_ms: int) -> str:
    return f"gw_cache:{indicator}:{symbol}:{tf}:{base_or_len}:{bar_open_ms}"

def public_key(indicator: str, symbol: str, tf: str, base: str) -> str:
    if indicator == "bb":
        return f"bbpos_pack:{symbol}:{tf}:{base}"
    if indicator == "lr":
        return f"lrpos_pack:{symbol}:{tf}:{base}"
    if indicator == "atr":
        return f"atr_pack:{symbol}:{tf}:{base}"
    if indicator == "adx_dmi":
        return f"adx_dmi_pack:{symbol}:{tf}:{base}"
    if indicator == "macd":
        return f"macd_pack:{symbol}:{tf}:{base}"
    # ema/rsi/mfi â†’ Ð¾Ð±Ñ‰Ð¸Ð¹ ÑˆÐ°Ð±Ð»Ð¾Ð½
    return f"{indicator}_pack:{symbol}:{tf}:{base}"

# ðŸ”¸ Ð Ð°Ð·Ð±Ð¾Ñ€ std Ð¸Ð· ÑÑ‚Ñ€Ð¾ÐºÐ¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° (2 Ð·Ð½Ð°ÐºÐ° Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸)
def parse_std(std_raw) -> float | None:
    try:
        return round(float(std_raw), 2)
    except Exception:
        return None

# ðŸ”¸ ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð²Ð¾Ñ€ÐºÐµÑ€ gateway (RSI + MFI + BB + LR + ATR + EMA + ADX/DMI)
async def run_indicator_gateway(pg, redis, get_instances_by_tf, get_precision, compute_snapshot_values_async):
    log.debug("IND_GATEWAY: Ð²Ð¾Ñ€ÐºÐµÑ€ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½")

    group = "gw_group"
    consumer = "gw_consumer"

    # ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ consumer-group (Ð¸Ð´ÐµÐ¼Ð¿Ð¾Ñ‚ÐµÐ½Ñ‚Ð½Ð¾)
    try:
        await redis.xgroup_create(REQ_STREAM, group, id="$", mkstream=True)
    except Exception as e:
        if "BUSYGROUP" not in str(e):
            log.warning(f"xgroup_create error: {e}")

    sem = asyncio.Semaphore(GATEWAY_CONCURRENCY)

    async def process_one(msg_id: str, data: dict) -> str | None:
        # Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¾Ð´Ð½Ð¾Ð³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ñ Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸ÐµÐ¼ Ð¿Ð¾ ÑÐµÐ¼Ð°Ñ„Ð¾Ñ€Ñƒ
        async with sem:
            t0 = time.monotonic()
            try:
                symbol   = data.get("symbol")
                tf       = data.get("timeframe")
                ind      = data.get("indicator")
                length_s = data.get("length")     # Ð´Ð»Ñ rsi/mfi/ema/lr/atr/adx_dmi/bb
                std_s    = data.get("std")        # Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð´Ð»Ñ bb
                ts_raw   = data.get("timestamp_ms")

                # Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ
                valid_inds = ("rsi","mfi","bb","lr","atr","ema","adx_dmi","macd","trend","volatility","momentum","extremes")
                if not symbol or tf not in ("m5","m15","h1") or ind not in valid_inds:
                    await redis.xadd(RESP_STREAM, {"req_id": msg_id, "status":"error", "error":"bad_request"})
                    return msg_id

                now_ms = int(ts_raw) if ts_raw else int(datetime.utcnow().timestamp() * 1000)
                bar_open_ms = floor_to_bar(now_ms, tf)

                # Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð¸Ð½ÑÑ‚Ð°Ð½ÑÑ‹
                if ind not in ("trend", "volatility", "momentum", "extremes"):
                    instances = [i for i in get_instances_by_tf(tf) if i["indicator"] == ind]
                    if not instances:
                        await redis.xadd(RESP_STREAM, {
                            "req_id": msg_id,
                            "status": "error",
                            "error": "instance_not_found"
                        })
                        return msg_id
                else:
                    # trend/volatility Ð½Ðµ Ð¸Ð¼ÐµÑŽÑ‚ ÑÐ¾Ð±ÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ñ… Ð¸Ð½ÑÑ‚Ð°Ð½ÑÐ¾Ð² â€” Ð°Ð³Ñ€ÐµÐ³Ð¸Ñ€ÑƒÐµÐ¼ Ð¸Ð· Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ñ… Ð¸Ð½Ð´Ð¸ÐºÐ°Ñ‚Ð¾Ñ€Ð¾Ð²
                    instances = []

                precision = get_precision(symbol) or 8
                results = []

                # ðŸ”¸ RSI / MFI / EMA
                if ind in ("rsi", "mfi", "ema"):
                    if length_s:
                        try:
                            L = int(length_s)
                        except Exception:
                            await redis.xadd(RESP_STREAM, {"req_id": msg_id, "status": "error", "error": "bad_length"})
                            return msg_id
                        if not any(int(i["params"]["length"]) == L for i in instances):
                            await redis.xadd(RESP_STREAM, {"req_id": msg_id, "status": "error", "error": "instance_not_found"})
                            return msg_id
                        lengths = [L]
                    else:
                        lengths = sorted({int(i["params"]["length"]) for i in instances})

                    for L in lengths:
                        base = f"{ind}{L}"
                        # Ð´Ð»Ñ rsi/mfi ÐºÑÑˆ-ÐºÐ»ÑŽÑ‡ ÑÑ‚Ñ€Ð¾Ð¸Ð¼ Ð¿Ð¾ Ð´Ð»Ð¸Ð½Ðµ, Ð´Ð»Ñ ema â€” Ð¿Ð¾ base (ÐµÐ´Ð¸Ð½Ñ‹Ð¹ ÑÑ‚Ð¸Ð»ÑŒ Ñ Ð¿ÑƒÐ±Ð»Ð¸Ñ‡Ð½Ñ‹Ð¼ ÐºÐ»ÑŽÑ‡Ð¾Ð¼)
                        ckey = cache_key(ind, symbol, tf, (str(L) if ind in ("rsi", "mfi") else base), bar_open_ms)
                        pkey = public_key(ind, symbol, tf, base)

                        cached = await redis.get(ckey)
                        if cached:
                            try:
                                results.append(json.loads(cached))
                                continue
                            except Exception:
                                pass

                        if ind == "rsi":
                            pack = await build_rsi_pack(symbol, tf, L, now_ms, precision, redis, compute_snapshot_values_async)
                        elif ind == "mfi":
                            pack = await build_mfi_pack(symbol, tf, L, now_ms, precision, redis, compute_snapshot_values_async)
                        else:  # ema
                            pack = await build_ema_pack(symbol, tf, L, now_ms, precision, redis, compute_snapshot_values_async)

                        if pack:
                            js = json.dumps(pack)
                            await redis.set(ckey, js, ex=LIVE_TTL_SEC)
                            await redis.set(pkey, js, ex=LIVE_TTL_SEC)
                            results.append(pack)

                # ðŸ”¸ MACD (base Ð¿Ð¾ fast)
                elif ind == "macd":
                    # Ð´Ð»Ð¸Ð½Ð° Ð² Ð·Ð°Ð¿Ñ€Ð¾ÑÐµ Ñ‚Ñ€Ð°ÐºÑ‚ÑƒÐµÐ¼ ÐºÐ°Ðº fast
                    if length_s:
                        try:
                            F = int(length_s)
                        except Exception:
                            await redis.xadd(RESP_STREAM, {"req_id": msg_id, "status": "error", "error": "bad_length"})
                            return msg_id
                        # Ð² Ð¸Ð½ÑÑ‚Ð°Ð½ÑÐ°Ñ… MACD fast Ð»ÐµÐ¶Ð¸Ñ‚ Ð² params["fast"]
                        if not any(int(i["params"]["fast"]) == F for i in instances):
                            await redis.xadd(RESP_STREAM, {"req_id": msg_id, "status": "error", "error": "instance_not_found"})
                            return msg_id
                        fasts = [F]
                    else:
                        fasts = sorted({int(i["params"]["fast"]) for i in instances})

                    for F in fasts:
                        base = f"macd{F}"
                        ckey = cache_key(ind, symbol, tf, base, bar_open_ms)
                        pkey = public_key(ind, symbol, tf, base)

                        cached = await redis.get(ckey)
                        if cached:
                            try:
                                results.append(json.loads(cached))
                                continue
                            except Exception:
                                pass

                        pack = await build_macd_pack(symbol, tf, F, now_ms, precision, redis, compute_snapshot_values_async)

                        if pack:
                            js = json.dumps(pack)
                            await redis.set(ckey, js, ex=LIVE_TTL_SEC)
                            await redis.set(pkey, js, ex=LIVE_TTL_SEC)
                            results.append(pack)

                # ðŸ”¸ BB
                elif ind == "bb":
                    # ÑÐ¾Ð±Ñ€Ð°Ñ‚ÑŒ Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ðµ (length, std)
                    active_pairs = []
                    for i in instances:
                        try:
                            L = int(i["params"]["length"])
                            S = round(float(i["params"]["std"]), 2)
                            active_pairs.append((L, S))
                        except Exception:
                            pass

                    if length_s and std_s:
                        try:
                            L = int(length_s)
                            S = parse_std(std_s)
                        except Exception:
                            L, S = None, None
                        if (L, S) not in active_pairs:
                            await redis.xadd(RESP_STREAM, {"req_id": msg_id, "status":"error", "error":"instance_not_found"})
                            return msg_id
                        pairs = [(L, S)]
                    elif length_s and not std_s:
                        try:
                            L = int(length_s)
                        except Exception:
                            await redis.xadd(RESP_STREAM, {"req_id": msg_id, "status":"error", "error":"bad_length"})
                            return msg_id
                        pairs = [(L, S) for (L2, S) in active_pairs if L2 == L]
                        if not pairs:
                            await redis.xadd(RESP_STREAM, {"req_id": msg_id, "status":"error", "error":"instance_not_found"})
                            return msg_id
                    elif std_s and not length_s:
                        S = parse_std(std_s)
                        pairs = [(L, S) for (L, S2) in active_pairs if S2 == S]
                        if not pairs:
                            await redis.xadd(RESP_STREAM, {"req_id": msg_id, "status":"error", "error":"instance_not_found"})
                            return msg_id
                    else:
                        pairs = sorted(set(active_pairs))

                    for (L, S) in pairs:
                        std_str = str(round(float(S), 2)).replace(".", "_")
                        base = f"bb{int(L)}_{std_str}"
                        ckey = cache_key(ind, symbol, tf, base, bar_open_ms)
                        pkey = public_key(ind, symbol, tf, base)

                        cached = await redis.get(ckey)
                        if cached:
                            try:
                                results.append(json.loads(cached))
                                continue
                            except Exception:
                                pass

                        pack = await build_bb_pack(symbol, tf, L, S, now_ms, precision, redis, compute_snapshot_values_async)
                        if pack:
                            js = json.dumps(pack)
                            await redis.set(ckey, js, ex=LIVE_TTL_SEC)
                            await redis.set(pkey, js, ex=LIVE_TTL_SEC)
                            results.append(pack)

                # ðŸ”¸ LR
                elif ind == "lr":
                    if length_s:
                        try:
                            L = int(length_s)
                        except Exception:
                            await redis.xadd(RESP_STREAM, {"req_id": msg_id, "status":"error", "error":"bad_length"})
                            return msg_id
                        if not any(int(i["params"]["length"]) == L for i in instances):
                            await redis.xadd(RESP_STREAM, {"req_id": msg_id, "status":"error", "error":"instance_not_found"})
                            return msg_id
                        lengths = [L]
                    else:
                        lengths = sorted({int(i["params"]["length"]) for i in instances})

                    for L in lengths:
                        base = f"lr{L}"
                        ckey = cache_key(ind, symbol, tf, base, bar_open_ms)
                        pkey = public_key(ind, symbol, tf, base)

                        cached = await redis.get(ckey)
                        if cached:
                            try:
                                results.append(json.loads(cached))
                                continue
                            except Exception:
                                pass

                        pack = await build_lr_pack(symbol, tf, L, now_ms, precision, redis, compute_snapshot_values_async)
                        if pack:
                            js = json.dumps(pack)
                            await redis.set(ckey, js, ex=LIVE_TTL_SEC)
                            await redis.set(pkey, js, ex=LIVE_TTL_SEC)
                            results.append(pack)

                # ðŸ”¸ ATR
                elif ind == "atr":
                    if length_s:
                        try:
                            L = int(length_s)
                        except Exception:
                            await redis.xadd(RESP_STREAM, {"req_id": msg_id, "status":"error", "error":"bad_length"})
                            return msg_id
                        if not any(int(i["params"]["length"]) == L for i in instances):
                            await redis.xadd(RESP_STREAM, {"req_id": msg_id, "status":"error", "error":"instance_not_found"})
                            return msg_id
                        lengths = [L]
                    else:
                        lengths = sorted({int(i["params"]["length"]) for i in instances})

                    for L in lengths:
                        base = f"atr{L}"
                        ckey = cache_key(ind, symbol, tf, base, bar_open_ms)
                        pkey = public_key(ind, symbol, tf, base)

                        cached = await redis.get(ckey)
                        if cached:
                            try:
                                results.append(json.loads(cached))
                                continue
                            except Exception:
                                pass

                        pack = await build_atr_pack(symbol, tf, L, now_ms, precision, redis, compute_snapshot_values_async)
                        if pack:
                            js = json.dumps(pack)
                            await redis.set(ckey, js, ex=LIVE_TTL_SEC)
                            await redis.set(pkey, js, ex=LIVE_TTL_SEC)
                            results.append(pack)

                # ðŸ”¸ TREND (live Ð½Ð° Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¼ Ð±Ð°Ñ€Ðµ)
                elif ind == "trend":
                    base = "trend"
                    ckey = cache_key(ind, symbol, tf, base, bar_open_ms)
                    pkey = public_key(ind, symbol, tf, base)

                    cached = await redis.get(ckey)
                    if cached:
                        try:
                            results.append(json.loads(cached))
                        except Exception:
                            pass
                    else:
                        pack = await build_trend_pack(symbol, tf, now_ms, precision, redis, compute_snapshot_values_async)
                        if pack:
                            js = json.dumps(pack)
                            await redis.set(ckey, js, ex=LIVE_TTL_SEC)
                            await redis.set(pkey, js, ex=LIVE_TTL_SEC)
                            results.append(pack)
                            
                # ðŸ”¸ VOLATILITY (live Ð½Ð° Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¼ Ð±Ð°Ñ€Ðµ)
                elif ind == "volatility":
                    base = "volatility"
                    ckey = cache_key(ind, symbol, tf, base, bar_open_ms)
                    pkey = public_key(ind, symbol, tf, base)

                    cached = await redis.get(ckey)
                    if cached:
                        try:
                            results.append(json.loads(cached))
                        except Exception:
                            pass
                    else:
                        pack = await build_volatility_pack(symbol, tf, now_ms, precision, redis, compute_snapshot_values_async)
                        if pack:
                            js = json.dumps(pack)
                            await redis.set(ckey, js, ex=LIVE_TTL_SEC)
                            await redis.set(pkey, js, ex=LIVE_TTL_SEC)
                            results.append(pack)

                # ðŸ”¸ MOMENTUM (live Ð½Ð° Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¼ Ð±Ð°Ñ€Ðµ)
                elif ind == "momentum":
                    base = "momentum"
                    ckey = cache_key(ind, symbol, tf, base, bar_open_ms)
                    pkey = public_key(ind, symbol, tf, base)

                    cached = await redis.get(ckey)
                    if cached:
                        try:
                            results.append(json.loads(cached))
                        except Exception:
                            pass
                    else:
                        pack = await build_momentum_pack(symbol, tf, now_ms, precision, redis, compute_snapshot_values_async)
                        if pack:
                            js = json.dumps(pack)
                            await redis.set(ckey, js, ex=LIVE_TTL_SEC)
                            await redis.set(pkey, js, ex=LIVE_TTL_SEC)
                            results.append(pack)

                # ðŸ”¸ EXTREMES (live Ð½Ð° Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¼ Ð±Ð°Ñ€Ðµ)
                elif ind == "extremes":
                    base = "extremes"
                    ckey = cache_key(ind, symbol, tf, base, bar_open_ms)
                    pkey = public_key(ind, symbol, tf, base)

                    cached = await redis.get(ckey)
                    if cached:
                        try:
                            results.append(json.loads(cached))
                        except Exception:
                            pass
                    else:
                        pack = await build_extremes_pack(symbol, tf, now_ms, precision, redis, compute_snapshot_values_async)
                        if pack:
                            js = json.dumps(pack)
                            await redis.set(ckey, js, ex=LIVE_TTL_SEC)
                            await redis.set(pkey, js, ex=LIVE_TTL_SEC)
                            results.append(pack)
                                      
                # ðŸ”¸ ADX/DMI
                else:  # ind == "adx_dmi"
                    if length_s:
                        try:
                            L = int(length_s)
                        except Exception:
                            await redis.xadd(RESP_STREAM, {"req_id": msg_id, "status":"error", "error":"bad_length"})
                            return msg_id
                        if not any(int(i["params"]["length"]) == L for i in instances):
                            await redis.xadd(RESP_STREAM, {"req_id": msg_id, "status":"error", "error":"instance_not_found"})
                            return msg_id
                        lengths = [L]
                    else:
                        lengths = sorted({int(i["params"]["length"]) for i in instances})

                    for L in lengths:
                        base = f"adx_dmi{L}"
                        ckey = cache_key(ind, symbol, tf, base, bar_open_ms)
                        pkey = public_key(ind, symbol, tf, base)

                        cached = await redis.get(ckey)
                        if cached:
                            try:
                                results.append(json.loads(cached))
                                continue
                            except Exception:
                                pass

                        pack = await build_adx_dmi_pack(symbol, tf, L, now_ms, precision, redis, compute_snapshot_values_async)
                        if pack:
                            js = json.dumps(pack)
                            await redis.set(ckey, js, ex=LIVE_TTL_SEC)
                            await redis.set(pkey, js, ex=LIVE_TTL_SEC)
                            results.append(pack)

                # ðŸ”¸ ÐžÑ‚Ð²ÐµÑ‚
                if results:
                    await redis.xadd(RESP_STREAM, {
                        "req_id": msg_id,
                        "status": "ok",
                        "symbol": symbol,
                        "timeframe": tf,
                        "indicator": ind,
                        "results": json.dumps(results),
                    })
                else:
                    await redis.xadd(RESP_STREAM, {"req_id": msg_id, "status":"error", "error":"no_results"})

                t1 = time.monotonic()
                log.debug(f"[DONE] IND_GATEWAY {ind.upper()} {symbol}/{tf} elapsed_ms={int((t1-t0)*1000)} results={len(results)}")
                return msg_id

            except Exception as e:
                log.warning(f"[GW] error: {e}", exc_info=True)
                try:
                    await redis.xadd(RESP_STREAM, {"req_id": msg_id, "status":"error", "error":"exception"})
                except Exception:
                    pass
                return msg_id

    # ðŸ”¸ ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ñ†Ð¸ÐºÐ» Ñ‡Ñ‚ÐµÐ½Ð¸Ñ ÑÑ‚Ñ€Ð¸Ð¼Ð°: Ð¿Ð°Ñ‡ÐºÐ¾Ð¹ + Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° + Ð±Ð°Ñ‚Ñ‡-ACK
    while True:
        try:
            resp = await redis.xreadgroup(
                group, consumer,
                streams={REQ_STREAM: ">"},
                count=GATEWAY_BATCH_SIZE,
                block=2000
            )
        except Exception as e:
            log.error(f"IND_GATEWAY read error: {e}", exc_info=True)
            await asyncio.sleep(0.5)
            continue

        if not resp:
            continue

        try:
            tasks = []
            for _, messages in resp:
                for msg_id, data in messages:
                    tasks.append(asyncio.create_task(process_one(msg_id, data)))

            done_ids = await asyncio.gather(*tasks, return_exceptions=False)
            ack_ids = [mid for mid in done_ids if mid]
            if ack_ids:
                await redis.xack(REQ_STREAM, group, *ack_ids)
        except Exception as e:
            log.error(f"IND_GATEWAY batch error: {e}", exc_info=True)
            await asyncio.sleep(0.5)