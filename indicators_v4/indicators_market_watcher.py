# ðŸ”¸ indicators_market_watcher.py â€” Ð­Ñ‚Ð°Ð¿ 4: Ð·Ð°Ð¿Ð¸ÑÑŒ Ð² Redis KV/TS Ð¸ PG (indicator_marketwatcher_v4)

import os
import asyncio
import json
import logging
from datetime import datetime
from statistics import median

# ðŸ”¸ ÐšÐ¾Ð½ÑÑ‚Ð°Ð½Ñ‚Ñ‹ Ð¸ ÐºÐ¾Ð½Ñ„Ð¸Ð³
READY_STREAM = "indicator_stream"
GROUP_NAME = os.getenv("MRW_GROUP", "mrw_v1_group")
CONSUMER_NAME = os.getenv("MRW_CONSUMER", "mrw_1")
REQUIRED_TFS = {"m5", "m15", "h1"}

DEBOUNCE_MS = int(os.getenv("MRW_DEBOUNCE_MS", "250"))
MAX_CONCURRENCY = int(os.getenv("MRW_MAX_CONCURRENCY", "64"))
MAX_PER_SYMBOL = int(os.getenv("MRW_MAX_PER_SYMBOL", "4"))
XREAD_BLOCK_MS = int(os.getenv("MRW_BLOCK_MS", "1000"))
XREAD_COUNT = int(os.getenv("MRW_COUNT", "50"))

N_PCT = int(os.getenv("MRW_N_PCT", "200"))     # Ð¾ÐºÐ½Ð¾ Ð´Ð»Ñ p30/p70
N_ACC = int(os.getenv("MRW_N_ACC", "50"))      # Ð¾ÐºÐ½Ð¾ Ð´Ð»Ñ z-score Î”hist
EPS_Z = float(os.getenv("MRW_EPS_Z", "0.5"))   # Ð¿Ð¾Ñ€Ð¾Ð³ ÑƒÑÐºÐ¾Ñ€ÐµÐ½Ð¸Ñ

RETENTION_TS_MS = 14 * 24 * 60 * 60 * 1000     # 14 ÑÑƒÑ‚Ð¾Ðº
REGIME_VERSION = 1                              # Ð²ÐµÑ€ÑÐ¸Ñ Ð¿Ñ€Ð°Ð²Ð¸Ð»
REGIME_PARAM = "regime9_code"                   # Ð¸Ð¼Ñ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð° Ð² KV/TS

# ðŸ”¸ Ð“Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ñ‹Ðµ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñ‹ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»Ð¸Ð·Ð¼Ð°
task_gate = asyncio.Semaphore(MAX_CONCURRENCY)
symbol_semaphores: dict[str, asyncio.Semaphore] = {}
bucket_tasks: dict[tuple, asyncio.Task] = {}


# ðŸ”¸ Ð£Ñ‚Ð¸Ð»Ð¸Ñ‚Ñ‹
def _iso_to_ms(iso_str: str) -> int:
    dt = datetime.fromisoformat(iso_str)
    return int(dt.timestamp() * 1000)

def _tf_step_ms(tf: str) -> int:
    return 300_000 if tf == "m5" else (900_000 if tf == "m15" else 3_600_000)

def _p30(vals: list[float]) -> float:
    if not vals:
        return float("nan")
    k = max(0, int(0.30 * (len(vals) - 1)))
    return sorted(vals)[k]

def _p70(vals: list[float]) -> float:
    if not vals:
        return float("nan")
    k = max(0, int(0.70 * (len(vals) - 1)))
    return sorted(vals)[k]

def _mad(vals: list[float]) -> float:
    if not vals:
        return 0.0
    m = median(vals)
    dev = [abs(x - m) for x in vals]
    return median(dev) or 1e-9  # Ð·Ð°Ñ‰Ð¸Ñ‚Ð° Ð¾Ñ‚ Ð´ÐµÐ»ÐµÐ½Ð¸Ñ Ð½Ð° Ð½Ð¾Ð»ÑŒ

def _zscore(x: float, vals: list[float]) -> float:
    m = median(vals)
    s = _mad(vals)
    return (x - m) / s


# ðŸ”¸ Ð§Ñ‚ÐµÐ½Ð¸Ðµ Ñ„Ð¸Ñ‡ Ð½Ð° Ð±Ð°Ñ€: Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑ‚ Ð¸ Ð¿Ð¾Ð´Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¾ÐºÐ½Ð°
async def fetch_features_for_bar(redis, symbol: str, tf: str, open_time_ms: int) -> dict | None:
    log = logging.getLogger("MRW")

    adx_key = f"ts_ind:{symbol}:{tf}:adx_dmi14_adx" if tf in {"m5", "m15"} else f"ts_ind:{symbol}:{tf}:adx_dmi28_adx"
    ema_key = f"ts_ind:{symbol}:{tf}:ema21"
    macd_key = f"ts_ind:{symbol}:{tf}:macd12_macd_hist"
    bb_u = f"ts_ind:{symbol}:{tf}:bb20_2_0_upper"
    bb_l = f"ts_ind:{symbol}:{tf}:bb20_2_0_lower"
    bb_c = f"ts_ind:{symbol}:{tf}:bb20_2_0_center"
    atr_key = f"ts_ind:{symbol}:{tf}:atr14" if tf in {"m5", "m15"} else None

    keys_now = [adx_key, ema_key, macd_key, bb_u, bb_l, bb_c] + ([atr_key] if atr_key else [])
    now_calls = [redis.execute_command("TS.RANGE", k, open_time_ms, open_time_ms) for k in keys_now]
    now_results = await asyncio.gather(*now_calls, return_exceptions=True)
    for k, r in zip(keys_now, now_results):
        if isinstance(r, Exception) or not r or int(r[0][0]) != open_time_ms:
            logging.getLogger("MRW").debug(f"[INCOMPLETE] {symbol}/{tf} @ {open_time_ms} â†’ missing {k}")
            return None

    step_ms = _tf_step_ms(tf)
    t_prev = open_time_ms - step_ms
    t_start_pct = open_time_ms - (N_PCT - 1) * step_ms
    t_start_acc = open_time_ms - N_ACC * step_ms

    window_calls = [
        redis.execute_command("TS.RANGE", ema_key, t_prev, open_time_ms),
        redis.execute_command("TS.RANGE", macd_key, t_start_acc, open_time_ms),
        redis.execute_command("TS.RANGE", adx_key, t_start_pct, open_time_ms),
        redis.execute_command("TS.RANGE", bb_u,   t_start_pct, open_time_ms),
        redis.execute_command("TS.RANGE", bb_l,   t_start_pct, open_time_ms),
        redis.execute_command("TS.RANGE", bb_c,   t_start_pct, open_time_ms),
    ]
    if atr_key:
        window_calls.append(redis.execute_command("TS.RANGE", atr_key, t_start_pct, open_time_ms))

    out = await asyncio.gather(*window_calls, return_exceptions=True)

    def _vals(series):
        return [float(v) for _, v in series] if series and not isinstance(series, Exception) else []

    ema_vals  = _vals(out[0])
    macd_vals = _vals(out[1])
    adx_vals  = _vals(out[2])
    bbu_vals  = _vals(out[3])
    bbl_vals  = _vals(out[4])
    bbc_vals  = _vals(out[5])
    atr_vals  = _vals(out[6]) if (atr_key and len(out) > 6) else None

    logging.getLogger("MRW").debug(
        f"[FEATURES] {symbol}/{tf} @ {open_time_ms} â†’ "
        f"ema={len(ema_vals)} macd={len(macd_vals)} adx={len(adx_vals)} "
        f"bb(u/l/c)={[len(bbu_vals), len(bbl_vals), len(bbc_vals)]} "
        f"atr={'-' if atr_vals is None else len(atr_vals)}"
    )

    return {
        "ema_vals": ema_vals,
        "macd_vals": macd_vals,
        "adx_vals": adx_vals,
        "bb_u": bbu_vals,
        "bb_l": bbl_vals,
        "bb_c": bbc_vals,
        "atr_vals": atr_vals,
    }


# ðŸ”¸ ÐšÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ Ð±Ð°Ñ€Ð° â†’ code 0..8 Ð¸ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ°
def classify_bar(tf: str, features: dict) -> tuple[int, dict]:
    ema_t1, ema_t = features["ema_vals"][-2], features["ema_vals"][-1]
    ema_slope = ema_t - ema_t1

    macd_hist_t1, macd_hist_t = features["macd_vals"][-2], features["macd_vals"][-1]
    d_hist = macd_hist_t - macd_hist_t1
    z_vals = [features["macd_vals"][i+1] - features["macd_vals"][i] for i in range(len(features["macd_vals"]) - 1)]
    z_d_hist = _zscore(d_hist, z_vals[-N_ACC:]) if z_vals else 0.0

    adx = features["adx_vals"][-1]
    adx_low_p = _p30(features["adx_vals"])
    adx_high_p = _p70(features["adx_vals"])
    adx_low = max(adx_low_p, 15.0)
    adx_high = min(adx_high_p, 30.0)

    bb_width_series = []
    for u, l, c in zip(features["bb_u"], features["bb_l"], features["bb_c"]):
        bb_width_series.append(0.0 if c == 0 else (u - l) / c)
    bb_width = bb_width_series[-1]
    bb_low = _p30(bb_width_series)
    bb_high = _p70(bb_width_series)

    atr = atr_low = atr_high = None
    if tf in {"m5", "m15"} and features.get("atr_vals"):
        atr = features["atr_vals"][-1]
        atr_low = _p30(features["atr_vals"])
        atr_high = _p70(features["atr_vals"])

    is_trend = adx >= adx_high
    is_flat = adx <= adx_low

    if is_flat:
        if bb_width <= bb_low and (atr is None or atr <= atr_low):
            code = 0  # F_CONS
        elif bb_width >= bb_high:
            code = 1  # F_EXP
        else:
            code = 2  # F_DRIFT
    else:
        direction_up = ema_slope > 0.0
        if z_d_hist > +EPS_Z:
            accel = 0  # ACCEL
        elif abs(z_d_hist) <= EPS_Z:
            accel = 1  # STABLE
        else:
            accel = 2  # DECEL
        code = (3 + accel) if direction_up else (6 + accel)

    diag = {
        "adx": adx, "adx_low": adx_low, "adx_high": adx_high,
        "bb_width": bb_width, "bb_low": bb_low, "bb_high": bb_high,
        "atr": atr, "atr_low": atr_low, "atr_high": atr_high,
        "ema_slope": ema_slope, "macd_hist": macd_hist_t,
        "d_hist": d_hist, "z_d_hist": z_d_hist
    }
    return code, diag


# ðŸ”¸ Ð—Ð°Ð¿Ð¸ÑÑŒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°: Redis KV/TS + PostgreSQL (indicator_marketwatcher_v4)
async def publish_regime(redis, pg, symbol: str, tf: str, open_time_ms: int, code: int, diag: dict):
    open_time_iso = datetime.utcfromtimestamp(open_time_ms / 1000).isoformat()

    # KV Ð¸ TS
    kv_key = f"ind:{symbol}:{tf}:{REGIME_PARAM}"
    ts_key = f"ts_ind:{symbol}:{tf}:{REGIME_PARAM}"

    kv = redis.set(kv_key, str(code))
    ts = redis.execute_command(
        "TS.ADD", ts_key, open_time_ms, str(code),
        "RETENTION", RETENTION_TS_MS,
        "DUPLICATE_POLICY", "last"
    )

    # PG upsert
    async with pg.acquire() as conn:
        await conn.execute("""
            INSERT INTO indicator_marketwatcher_v4
              (symbol, timeframe, open_time, regime_code, version_id,
               adx, adx_low, adx_high,
               bb_width, bb_low, bb_high,
               atr, atr_low, atr_high,
               ema_slope, macd_hist, d_hist, z_d_hist)
            VALUES
              ($1, $2, $3, $4, $5,
               $6, $7, $8,
               $9, $10, $11,
               $12, $13, $14,
               $15, $16, $17, $18)
            ON CONFLICT (symbol, timeframe, open_time)
            DO UPDATE SET
              regime_code = EXCLUDED.regime_code,
              version_id  = EXCLUDED.version_id,
              adx         = EXCLUDED.adx,
              adx_low     = EXCLUDED.adx_low,
              adx_high    = EXCLUDED.adx_high,
              bb_width    = EXCLUDED.bb_width,
              bb_low      = EXCLUDED.bb_low,
              bb_high     = EXCLUDED.bb_high,
              atr         = EXCLUDED.atr,
              atr_low     = EXCLUDED.atr_low,
              atr_high    = EXCLUDED.atr_high,
              ema_slope   = EXCLUDED.ema_slope,
              macd_hist   = EXCLUDED.macd_hist,
              d_hist      = EXCLUDED.d_hist,
              z_d_hist    = EXCLUDED.z_d_hist,
              updated_at  = NOW()
        """,
        symbol, tf, datetime.fromisoformat(open_time_iso), code, REGIME_VERSION,
        diag.get("adx"), diag.get("adx_low"), diag.get("adx_high"),
        diag.get("bb_width"), diag.get("bb_low"), diag.get("bb_high"),
        diag.get("atr"), diag.get("atr_low"), diag.get("atr_high"),
        diag.get("ema_slope"), diag.get("macd_hist"), diag.get("d_hist"), diag.get("z_d_hist"))

    await asyncio.gather(kv, ts, return_exceptions=True)


# ðŸ”¸ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð±Ð°ÐºÐµÑ‚Ð°: debounce â†’ Ñ„Ð¸Ñ‡Ð¸ â†’ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ â†’ Ð·Ð°Ð¿Ð¸ÑÑŒ
async def handle_bucket(symbol: str, tf: str, open_time_ms: int, redis, pg):
    log = logging.getLogger("MRW")
    await asyncio.sleep(DEBOUNCE_MS / 1000)

    for attempt in range(2):
        feats = await fetch_features_for_bar(redis, symbol, tf, open_time_ms)
        if feats is not None:
            code, diag = classify_bar(tf, feats)
            await publish_regime(redis, pg, symbol, tf, open_time_ms, code, diag)
            log.info(f"[REGIME] {symbol}/{tf} @ {open_time_ms} â†’ code={code} "
                     f"(adx={diag['adx']:.2f}/{diag['adx_low']:.2f}-{diag['adx_high']:.2f}, "
                     f"bbw={diag['bb_width']:.4f}/{diag['bb_low']:.4f}-{diag['bb_high']:.4f}, "
                     f"zÎ”={diag['z_d_hist']:.2f})")
            return
        await asyncio.sleep(0.15)

    log.debug(f"[SKIP] features incomplete: {symbol}/{tf} @ {open_time_ms}")


# ðŸ”¸ ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ñ†Ð¸ÐºÐ» ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð° (XREADGROUP). Ð›Ð¾Ð³Ð¸ ÑÑ‚Ð°Ð¿Ð¾Ð² 1â€“2 Ð¿ÐµÑ€ÐµÐ²ÐµÐ´ÐµÐ½Ñ‹ Ð½Ð° debug
async def run_market_watcher(pg, redis):
    log = logging.getLogger("MRW")
    log.info("market_watcher starting: XGROUP init")

    try:
        await redis.xgroup_create(READY_STREAM, GROUP_NAME, id="$", mkstream=True)
        log.debug(f"consumer group '{GROUP_NAME}' created on '{READY_STREAM}'")
    except Exception as e:
        if "BUSYGROUP" in str(e):
            log.debug(f"consumer group '{GROUP_NAME}' already exists")
        else:
            log.error(f"XGROUP CREATE error: {e}", exc_info=True)

    while True:
        try:
            resp = await redis.xreadgroup(
                groupname=GROUP_NAME,
                consumername=CONSUMER_NAME,
                streams={READY_STREAM: ">"},
                count=XREAD_COUNT,
                block=XREAD_BLOCK_MS
            )
            if not resp:
                continue

            to_ack = []
            for _, messages in resp:
                for msg_id, data in messages:
                    try:
                        symbol = data.get("symbol")
                        tf = data.get("timeframe") or data.get("interval")
                        status = data.get("status")
                        open_time_iso = data.get("open_time")

                        if not symbol or tf not in REQUIRED_TFS or status != "ready" or not open_time_iso:
                            to_ack.append(msg_id)
                            continue

                        open_time_ms = _iso_to_ms(open_time_iso)
                        bucket = (symbol, tf, open_time_ms)

                        if bucket in bucket_tasks and not bucket_tasks[bucket].done():
                            to_ack.append(msg_id)
                            continue

                        if symbol not in symbol_semaphores:
                            symbol_semaphores[symbol] = asyncio.Semaphore(MAX_PER_SYMBOL)

                        log.debug(f"[READY] {symbol}/{tf} @ {open_time_iso} â†’ schedule bucket")

                        async def bucket_runner():
                            async with task_gate:
                                async with symbol_semaphores[symbol]:
                                    await handle_bucket(symbol, tf, open_time_ms, redis, pg)

                        bucket_tasks[bucket] = asyncio.create_task(bucket_runner())
                        to_ack.append(msg_id)

                    except Exception as parse_err:
                        to_ack.append(msg_id)
                        log.error(f"message parse error: {parse_err}", exc_info=True)

            if to_ack:
                await redis.xack(READY_STREAM, GROUP_NAME, *to_ack)

        except Exception as e:
            log.error(f"XREADGROUP loop error: {e}", exc_info=True)
            await asyncio.sleep(1)