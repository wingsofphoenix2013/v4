# bt_analysis_emastate_mtf.py ‚Äî –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä MTF-—Å–æ—Å—Ç–æ—è–Ω–∏–π EMA –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ close (H1/M15/M5) –ø–æ –∏—Å—Ç–æ—Ä–∏–∏ 12 —Å–≤–µ—á–µ–π (prefetch –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω—É)

import logging
import json
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple
from decimal import Decimal, InvalidOperation

# üî∏ –õ–æ–≥–≥–µ—Ä –º–æ–¥—É–ª—è
log = logging.getLogger("BT_ANALYSIS_EMASTATE_MTF")

# üî∏ –î–µ—Ñ–æ–ª—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ (—Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω—ã —Å –ø—Ä–∏–Ω—è—Ç—ã–º–∏ —Ä–µ—à–µ–Ω–∏—è–º–∏)
DEFAULT_N_BARS = 12
DEFAULT_EPS_K = Decimal("0.0001")          # 0.01% –æ—Ç —Ü–µ–Ω—ã
DEFAULT_MIN_SHARE = Decimal("0.01")

# üî∏ –¢–∞–±–ª–∏—Ü—ã OHLCV –ø–æ TF
OHLCV_TABLES_BY_TF: Dict[str, str] = {
    "m5": "ohlcv_bb_m5",
    "m15": "ohlcv_bb_m15",
    "h1": "ohlcv_bb_h1",
}

# üî∏ –®–∞–≥ –≤—Ä–µ–º–µ–Ω–∏ TF
TF_STEP: Dict[str, timedelta] = {
    "m5": timedelta(minutes=5),
    "m15": timedelta(minutes=15),
    "h1": timedelta(hours=1),
}

# üî∏ –ö–∞—Ç–∞–ª–æ–≥ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π —Å–æ—Å—Ç–æ—è–Ω–∏—è -> bin_idx (0..6)
STATE_TO_BIN_IDX: Dict[str, int] = {
    "ABOVE_AWAY": 0,
    "ABOVE_STAG": 1,
    "ABOVE_APPROACH": 2,
    "NEAR": 3,
    "BELOW_APPROACH": 4,
    "BELOW_STAG": 5,
    "BELOW_AWAY": 6,
}


# üî∏ –ü—É–±–ª–∏—á–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ EMA state MTF (–±–∞—Ç—á-–ø–æ–¥—Ö–æ–¥: prefetch –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω—É)
async def run_emastate_mtf_analysis(
    analysis: Dict[str, Any],
    analysis_ctx: Dict[str, Any],
    pg,
    redis,  # –æ—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–∏–≥–Ω–∞—Ç—É—Ä, –∑–¥–µ—Å—å –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
) -> Dict[str, Any]:
    analysis_id = analysis.get("id")
    family_key = str(analysis.get("family_key") or "").strip()
    analysis_key = str(analysis.get("key") or "").strip()
    name = analysis.get("name")

    params = analysis.get("params") or {}
    scenario_id = analysis_ctx.get("scenario_id")
    signal_id = analysis_ctx.get("signal_id")

    # –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ (–≤ bt_analysis_parameters)
    instance_id_m5 = _get_int_param(params, "instance_id_m5", 0)
    instance_id_m15 = _get_int_param(params, "instance_id_m15", 0)
    instance_id_h1 = _get_int_param(params, "instance_id_h1", 0)
    param_name = _get_str_param(params, "param_name", "").strip()

    n_bars = _get_int_param(params, "n_bars", DEFAULT_N_BARS)
    eps_k = _get_decimal_param(params, "eps_k", DEFAULT_EPS_K)
    min_share = _get_decimal_param(params, "min_share", DEFAULT_MIN_SHARE)

    if analysis_id is None or scenario_id is None or signal_id is None:
        log.debug(
            "BT_ANALYSIS_EMASTATE_MTF: –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–ø—É—â–µ–Ω (–Ω–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö id) analysis_id=%s, scenario_id=%s, signal_id=%s",
            analysis_id,
            scenario_id,
            signal_id,
        )
        return {
            "rows": [],
            "summary": {
                "positions_total": 0,
                "positions_used": 0,
                "positions_skipped": 0,
                "skipped_reason": "missing_ids",
            },
        }

    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏
    if not param_name or instance_id_m5 <= 0 or instance_id_m15 <= 0 or instance_id_h1 <= 0:
        log.debug(
            "BT_ANALYSIS_EMASTATE_MTF: –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–ø—É—â–µ–Ω (–Ω–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤) analysis_id=%s, scenario_id=%s, signal_id=%s, "
            "param_name=%s, instance_id_m5=%s, instance_id_m15=%s, instance_id_h1=%s",
            analysis_id,
            scenario_id,
            signal_id,
            param_name,
            instance_id_m5,
            instance_id_m15,
            instance_id_h1,
        )
        return {
            "rows": [],
            "summary": {
                "positions_total": 0,
                "positions_used": 0,
                "positions_skipped": 0,
                "skipped_reason": "missing_params",
            },
        }

    # –æ–∫–Ω–æ run
    window_from = analysis_ctx.get("window_from")
    window_to = analysis_ctx.get("window_to")

    log.debug(
        "BT_ANALYSIS_EMASTATE_MTF: —Å—Ç–∞—Ä—Ç –∞–Ω–∞–ª–∏–∑–∞ id=%s (family=%s, key=%s, name=%s) scenario_id=%s, signal_id=%s ‚Äî "
        "param_name=%s, n_bars=%s, eps_k=%s, min_share=%s",
        analysis_id,
        family_key,
        analysis_key,
        name,
        scenario_id,
        signal_id,
        param_name,
        n_bars,
        eps_k,
        min_share,
    )

    # –∑–∞–≥—Ä—É–∂–∞–µ–º –ø–æ–∑–∏—Ü–∏–∏ –æ–∫–Ω–∞ run (status=closed + postproc_v2=true) ‚Äî —Å—Ç—Ä–æ–≥–æ –≤ –≥—Ä–∞–Ω–∏—Ü–∞—Ö window_from/window_to
    positions = await _load_positions_for_analysis(pg, int(scenario_id), int(signal_id), window_from, window_to)
    if not positions:
        log.info(
            "BT_ANALYSIS_EMASTATE_MTF: –Ω–µ—Ç –ø–æ–∑–∏—Ü–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ analysis_id=%s scenario_id=%s signal_id=%s",
            analysis_id,
            scenario_id,
            signal_id,
        )
        return {
            "rows": [],
            "summary": {
                "positions_total": 0,
                "positions_used": 0,
                "positions_skipped": 0,
            },
        }

    # –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –Ω–∞—Ä–µ–∑–∫–∞ –ø–æ symbol + –ø–∞—Ä—Å–∏–Ω–≥ anchor_open_time –ø–æ TF
    positions_total = 0
    positions_skipped = 0

    positions_by_symbol: Dict[str, List[Dict[str, Any]]] = {}
    for p in positions:
        positions_total += 1

        position_uid = p["position_uid"]
        symbol = str(p["symbol"] or "").strip()
        direction = str(p["direction"] or "").strip().lower()
        pnl_abs = p["pnl_abs"]
        raw_stat = p["raw_stat"]

        if not position_uid or not symbol:
            positions_skipped += 1
            continue

        anchor_h1 = _extract_anchor_open_time(raw_stat, "h1")
        anchor_m15 = _extract_anchor_open_time(raw_stat, "m15")
        anchor_m5 = _extract_anchor_open_time(raw_stat, "m5")

        # –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ø–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä —è–∫–æ—Ä–µ–π ‚Äî –ø–æ–∑–∏—Ü–∏—é –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        if anchor_h1 is None or anchor_m15 is None or anchor_m5 is None:
            positions_skipped += 1
            continue

        positions_by_symbol.setdefault(symbol, []).append(
            {
                "position_uid": position_uid,
                "symbol": symbol,
                "direction": direction,
                "pnl_abs": pnl_abs,
                "anchor_h1": anchor_h1,
                "anchor_m15": anchor_m15,
                "anchor_m5": anchor_m5,
            }
        )

    # –±–∞–∑–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ (–±–µ–∑ tail): –¥–ª—è –∫–∞–∂–¥–æ–π –ø–æ–∑–∏—Ü–∏–∏ ‚Äî –∏–Ω–¥–µ–∫—Å—ã –±–∏–Ω–Ω–æ–≤ –Ω–∞ H1/M15/M5
    base_list: List[Dict[str, Any]] = []

    # —Å—á—ë—Ç—á–∏–∫–∏ batched-–ø—Ä–æ—Ö–æ–¥–∞
    symbols_total = len(positions_by_symbol)
    symbols_prefetched = 0
    symbols_skipped = 0

    # –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ö–æ–¥ –ø–æ symbol: prefetch –¥–∞–Ω–Ω—ã—Ö –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω—É –∏ —Ä–∞—Å—á—ë—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–π –≤ –ø–∞–º—è—Ç–∏
    for symbol, plist in positions_by_symbol.items():
        if not plist:
            continue

        # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏
        if symbol == "":
            symbols_skipped += 1
            continue

        try:
            # —Å—á–∏—Ç–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω—ã –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è prefetch –ø–æ –∫–∞–∂–¥–æ–º—É TF
            t_from_h1, t_to_h1 = _compute_prefetch_range(plist, "anchor_h1", "h1", n_bars)
            t_from_m15, t_to_m15 = _compute_prefetch_range(plist, "anchor_m15", "m15", n_bars)
            t_from_m5, t_to_m5 = _compute_prefetch_range(plist, "anchor_m5", "m5", n_bars)

            # prefetch OHLCV close –∏ EMA –ø–æ –∫–∞–∂–¥–æ–º—É TF
            closes_h1 = await _prefetch_close_map(pg, "h1", symbol, t_from_h1, t_to_h1)
            closes_m15 = await _prefetch_close_map(pg, "m15", symbol, t_from_m15, t_to_m15)
            closes_m5 = await _prefetch_close_map(pg, "m5", symbol, t_from_m5, t_to_m5)

            emas_h1 = await _prefetch_ema_map(pg, instance_id_h1, symbol, param_name, t_from_h1, t_to_h1)
            emas_m15 = await _prefetch_ema_map(pg, instance_id_m15, symbol, param_name, t_from_m15, t_to_m15)
            emas_m5 = await _prefetch_ema_map(pg, instance_id_m5, symbol, param_name, t_from_m5, t_to_m5)

            symbols_prefetched += 1

        except Exception as e:
            log.error(
                "BT_ANALYSIS_EMASTATE_MTF: –æ—à–∏–±–∫–∞ prefetch symbol=%s analysis_id=%s scenario_id=%s signal_id=%s: %s",
                symbol,
                analysis_id,
                scenario_id,
                signal_id,
                e,
                exc_info=True,
            )
            symbols_skipped += 1
            continue

        # —Å—á–∏—Ç–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–π –ø–æ–∑–∏—Ü–∏–∏ –¥–∞–Ω–Ω–æ–≥–æ symbol
        for rec in plist:
            position_uid = rec["position_uid"]
            direction = rec["direction"]
            pnl_abs = rec["pnl_abs"]

            anchor_h1 = rec["anchor_h1"]
            anchor_m15 = rec["anchor_m15"]
            anchor_m5 = rec["anchor_m5"]

            h1_state = _calc_tf_state_from_maps(
                tf="h1",
                anchor_open_time=anchor_h1,
                ema_map=emas_h1,
                close_map=closes_h1,
                n_bars=n_bars,
                eps_k=eps_k,
            )
            m15_state = _calc_tf_state_from_maps(
                tf="m15",
                anchor_open_time=anchor_m15,
                ema_map=emas_m15,
                close_map=closes_m15,
                n_bars=n_bars,
                eps_k=eps_k,
            )
            m5_state = _calc_tf_state_from_maps(
                tf="m5",
                anchor_open_time=anchor_m5,
                ema_map=emas_m5,
                close_map=closes_m5,
                n_bars=n_bars,
                eps_k=eps_k,
            )

            # –µ—Å–ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω TF –Ω–µ —Å–º–æ–≥ –¥–∞—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ ‚Äî –ø–æ–∑–∏—Ü–∏—é –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            if h1_state is None or m15_state is None or m5_state is None:
                positions_skipped += 1
                continue

            h1_idx = STATE_TO_BIN_IDX.get(h1_state)
            m15_idx = STATE_TO_BIN_IDX.get(m15_state)
            m5_idx = STATE_TO_BIN_IDX.get(m5_state)

            if h1_idx is None or m15_idx is None or m5_idx is None:
                positions_skipped += 1
                continue

            base_list.append(
                {
                    "position_uid": position_uid,
                    "direction": direction,
                    "pnl_abs": pnl_abs,
                    "h1_idx": int(h1_idx),
                    "m15_idx": int(m15_idx),
                    "m5_idx": int(m5_idx),
                }
            )

    positions_used = len(base_list)

    if positions_used == 0:
        log.info(
            "BT_ANALYSIS_EMASTATE_MTF: –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –Ω–µ—Ç –ø–æ–∑–∏—Ü–∏–π analysis_id=%s scenario_id=%s signal_id=%s (total=%s skipped=%s)",
            analysis_id,
            scenario_id,
            signal_id,
            positions_total,
            positions_skipped,
        )
        return {
            "rows": [],
            "summary": {
                "positions_total": positions_total,
                "positions_used": 0,
                "positions_skipped": positions_skipped,
            },
        }

    total_for_share = Decimal(positions_used)

    # –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ H1_bin
    by_h1: Dict[int, List[Dict[str, Any]]] = {}
    for rec in base_list:
        by_h1.setdefault(int(rec["h1_idx"]), []).append(rec)

    rows: List[Dict[str, Any]] = []

    # —Å—á—ë—Ç—á–∏–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    tail_h1_rows = 0
    tail_m15_rows = 0
    full_rows = 0

    # –ø—Ä–æ—Ö–æ–¥–∏–º –ø–æ H1-–≥—Ä—É–ø–ø–∞–º –∏ –ø—Ä–∏–º–µ–Ω—è–µ–º tail (H1 ‚Üí M15 ‚Üí M5)
    for h1_idx, group_h in by_h1.items():
        group_n_h = len(group_h)
        share_h = Decimal(group_n_h) / total_for_share

        # –µ—Å–ª–∏ –¥–æ–ª—è H1-–≥—Ä—É–ø–ø—ã < min_share ‚Äî —Å–∫–ª–∞–¥—ã–≤–∞–µ–º –≤ —Ö–≤–æ—Å—Ç H1_bin_X|M15_0|M5_0
        if share_h < min_share:
            bin_name = f"H1_bin_{h1_idx}|M15_0|M5_0"
            for rec in group_h:
                rows.append(
                    {
                        "position_uid": rec["position_uid"],
                        "timeframe": "mtf",
                        "direction": rec["direction"],
                        "bin_name": bin_name,
                        "value": 0,
                        "pnl_abs": rec["pnl_abs"],
                    }
                )
                tail_h1_rows += 1
            continue

        # –∏–Ω–∞—á–µ ‚Äî –≤–Ω—É—Ç—Ä–∏ H1-–≥—Ä—É–ø–ø—ã –ø—Ä–∏–º–µ–Ω—è–µ–º tail –ø–æ M15 (–¥–æ–ª—è —Å—á–∏—Ç–∞–µ—Ç—Å—è –æ—Ç total_for_share)
        by_m15: Dict[int, List[Dict[str, Any]]] = {}
        for rec in group_h:
            by_m15.setdefault(int(rec["m15_idx"]), []).append(rec)

        for m15_idx, group_m15 in by_m15.items():
            group_n_m15 = len(group_m15)
            share_m15 = Decimal(group_n_m15) / total_for_share

            # –µ—Å–ª–∏ –¥–æ–ª—è (H1,M15) < min_share ‚Äî —Ö–≤–æ—Å—Ç H1_bin_X|M15_bin_Y|M5_0
            if share_m15 < min_share:
                bin_name = f"H1_bin_{h1_idx}|M15_bin_{m15_idx}|M5_0"
                for rec in group_m15:
                    rows.append(
                        {
                            "position_uid": rec["position_uid"],
                            "timeframe": "mtf",
                            "direction": rec["direction"],
                            "bin_name": bin_name,
                            "value": 0,
                            "pnl_abs": rec["pnl_abs"],
                        }
                    )
                    tail_m15_rows += 1
                continue

            # –∏–Ω–∞—á–µ ‚Äî –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–∞—è MTF-–º–∞—Ç—Ä–∏—Ü–∞: H1_bin_X|M15_bin_Y|M5_bin_Z
            for rec in group_m15:
                m5_idx = int(rec["m5_idx"])
                bin_name = f"H1_bin_{h1_idx}|M15_bin_{m15_idx}|M5_bin_{m5_idx}"
                rows.append(
                    {
                        "position_uid": rec["position_uid"],
                        "timeframe": "mtf",
                        "direction": rec["direction"],
                        "bin_name": bin_name,
                        "value": 0,
                        "pnl_abs": rec["pnl_abs"],
                    }
                )
                full_rows += 1

    # –∏—Ç–æ–≥–æ–≤—ã–π summary
    summary = {
        "positions_total": positions_total,
        "positions_used": positions_used,
        "positions_skipped": positions_skipped,
        "rows": len(rows),
        "tail_h1_rows": tail_h1_rows,
        "tail_m15_rows": tail_m15_rows,
        "full_rows": full_rows,
        "h1_groups": len(by_h1),
        "n_bars": n_bars,
        "eps_k": str(eps_k),
        "min_share": str(min_share),
        "param_name": param_name,
        "symbols_total": symbols_total,
        "symbols_prefetched": symbols_prefetched,
        "symbols_skipped": symbols_skipped,
    }

    log.info(
        "BT_ANALYSIS_EMASTATE_MTF: done analysis_id=%s (family=%s, key=%s, name=%s) scenario_id=%s signal_id=%s ‚Äî "
        "param=%s n_bars=%s eps_k=%s min_share=%s pos_total=%s used=%s skipped=%s rows=%s (tail_h1=%s tail_m15=%s full=%s) "
        "symbols_total=%s prefetched=%s skipped=%s",
        analysis_id,
        family_key,
        analysis_key,
        name,
        scenario_id,
        signal_id,
        param_name,
        n_bars,
        eps_k,
        min_share,
        positions_total,
        positions_used,
        positions_skipped,
        len(rows),
        tail_h1_rows,
        tail_m15_rows,
        full_rows,
        symbols_total,
        symbols_prefetched,
        symbols_skipped,
    )

    return {"rows": rows, "summary": summary}


# üî∏ –†–∞—Å—á—ë—Ç –¥–∏–∞–ø–∞–∑–æ–Ω–∞ prefetch –ø–æ —Å–ø–∏—Å–∫—É –ø–æ–∑–∏—Ü–∏–π (min_anchor - (N-1)*step .. max_anchor)
def _compute_prefetch_range(
    positions: List[Dict[str, Any]],
    anchor_key: str,
    tf: str,
    n_bars: int,
) -> Tuple[datetime, datetime]:
    step = TF_STEP.get(tf)
    if step is None:
        raise RuntimeError(f"Unsupported tf: {tf}")

    anchors: List[datetime] = []
    for p in positions:
        t = p.get(anchor_key)
        if isinstance(t, datetime):
            anchors.append(t)

    if not anchors:
        raise RuntimeError(f"No anchors for tf={tf} key={anchor_key}")

    t_min = min(anchors)
    t_max = max(anchors)

    # –∑–∞—Ö–≤–∞—Ç—ã–≤–∞–µ–º N-1 –±–∞—Ä –Ω–∞–∑–∞–¥, –≤–∫–ª—é—á–∞—è —è–∫–æ—Ä—å
    lookback = step * max(int(n_bars) - 1, 0)
    t_from = t_min - lookback
    t_to = t_max

    return t_from, t_to


# üî∏ Prefetch: –∑–∞–≥—Ä—É–∑–∫–∞ close –¥–ª—è symbol+tf –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –≤—Ä–µ–º–µ–Ω–∏
async def _prefetch_close_map(
    pg,
    tf: str,
    symbol: str,
    time_from: datetime,
    time_to: datetime,
) -> Dict[datetime, Decimal]:
    table = OHLCV_TABLES_BY_TF.get(tf)
    if not table:
        return {}

    async with pg.acquire() as conn:
        rows = await conn.fetch(
            f"""
            SELECT open_time, "close"
            FROM {table}
            WHERE symbol = $1
              AND open_time BETWEEN $2 AND $3
            ORDER BY open_time
            """,
            symbol,
            time_from,
            time_to,
        )

    out: Dict[datetime, Decimal] = {}
    for r in rows:
        out[r["open_time"]] = _safe_decimal(r["close"])
    return out


# üî∏ Prefetch: –∑–∞–≥—Ä—É–∑–∫–∞ EMA –¥–ª—è instance_id+symbol+param_name –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –≤—Ä–µ–º–µ–Ω–∏
async def _prefetch_ema_map(
    pg,
    instance_id: int,
    symbol: str,
    param_name: str,
    time_from: datetime,
    time_to: datetime,
) -> Dict[datetime, Decimal]:
    async with pg.acquire() as conn:
        rows = await conn.fetch(
            """
            SELECT open_time, value
            FROM indicator_values_v4
            WHERE instance_id = $1
              AND symbol      = $2
              AND param_name  = $3
              AND open_time BETWEEN $4 AND $5
            ORDER BY open_time
            """,
            int(instance_id),
            symbol,
            param_name,
            time_from,
            time_to,
        )

    out: Dict[datetime, Decimal] = {}
    for r in rows:
        out[r["open_time"]] = _safe_decimal(r["value"])
    return out


# üî∏ –†–∞—Å—á—ë—Ç —Å–æ—Å—Ç–æ—è–Ω–∏—è –Ω–∞ –æ–¥–Ω–æ–º TF –ø–æ –∑–∞—Ä–∞–Ω–µ–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º series map'–∞–º (EMA/close)
def _calc_tf_state_from_maps(
    tf: str,
    anchor_open_time: datetime,
    ema_map: Dict[datetime, Decimal],
    close_map: Dict[datetime, Decimal],
    n_bars: int,
    eps_k: Decimal,
) -> Optional[str]:
    step = TF_STEP.get(tf)
    if step is None:
        return None

    # —Å–æ–±–∏—Ä–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Ä–µ–º–µ–Ω –ø–æ—Å–ª–µ–¥–Ω–∏—Ö N –±–∞—Ä–æ–≤ –≤–∫–ª—é—á–∞—è anchor
    times: List[datetime] = []
    for i in range(int(n_bars) - 1, -1, -1):
        times.append(anchor_open_time - (step * i))

    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏: –≤—Å–µ –≤—Ä–µ–º–µ–Ω–∞ –¥–æ–ª–∂–Ω—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –∏ –≤ EMA, –∏ –≤ close
    ema_series: List[Decimal] = []
    close_series: List[Decimal] = []

    for t in times:
        e = ema_map.get(t)
        c = close_map.get(t)
        if e is None or c is None:
            return None
        ema_series.append(e)
        close_series.append(c)

    ema_last = ema_series[-1]
    close_last = close_series[-1]

    d_last = ema_last - close_last
    a_last = _abs(d_last)

    eps = _safe_decimal(close_last) * _safe_decimal(eps_k)

    # near –∏–º–µ–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞–¥ –≤—Å–µ–º
    if a_last <= eps:
        return "NEAR"

    # —Ä—è–¥ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π |ema-close| –ø–æ –æ–∫–Ω—É
    a_series: List[Decimal] = []
    for i in range(len(ema_series)):
        a_series.append(_abs(ema_series[i] - close_series[i]))

    slope = _linreg_slope(a_series)

    # –ø–æ—Ä–æ–≥ –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ –¥–≤–∏–∂–µ–Ω–∏—è (–¥–µ—Ñ–æ–ª—Ç–Ω–∞—è —Å—Ö–µ–º–∞): thr = eps / N
    thr = eps / Decimal(max(int(n_bars), 1))

    # –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç—Ä–µ–Ω–¥–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
    if slope <= -thr:
        motion = "APPROACH"
    elif slope >= thr:
        motion = "AWAY"
    else:
        motion = "STAG"

    # –Ω–∞–¥/–ø–æ–¥ —Ü–µ–Ω–æ–π –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ç–æ—á–∫–µ –æ–∫–Ω–∞
    if d_last > 0:
        return f"ABOVE_{motion}"
    else:
        return f"BELOW_{motion}"


# üî∏ –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ–∑–∏—Ü–∏–π —Å—Ü–µ–Ω–∞—Ä–∏—è/—Å–∏–≥–Ω–∞–ª–∞ (postproc_v2=true) –≤ –æ–∫–Ω–µ –≤—Ä–µ–º–µ–Ω–∏
async def _load_positions_for_analysis(
    pg,
    scenario_id: int,
    signal_id: int,
    window_from: Optional[Any],
    window_to: Optional[Any],
) -> List[Dict[str, Any]]:
    async with pg.acquire() as conn:
        # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏
        if window_from is None or window_to is None:
            return []

        rows = await conn.fetch(
            """
            SELECT
                position_uid,
                symbol,
                direction,
                pnl_abs,
                raw_stat
            FROM bt_scenario_positions_v2
            WHERE scenario_id = $1
              AND signal_id   = $2
              AND status      = 'closed'
              AND postproc_v2 = true
              AND entry_time BETWEEN $3 AND $4
            ORDER BY entry_time
            """,
            scenario_id,
            signal_id,
            window_from,
            window_to,
        )

    out: List[Dict[str, Any]] = []
    for r in rows:
        raw = r["raw_stat"]

        # –ø—Ä–∏–≤–æ–¥–∏–º jsonb –∫ dict, –µ—Å–ª–∏ –æ–Ω –ø—Ä–∏—à—ë–ª —Å—Ç—Ä–æ–∫–æ–π
        if isinstance(raw, str):
            try:
                raw = json.loads(raw)
            except Exception:
                raw = None

        out.append(
            {
                "position_uid": r["position_uid"],
                "symbol": r["symbol"],
                "direction": r["direction"],
                "pnl_abs": _safe_decimal(r["pnl_abs"]),
                "raw_stat": raw,
            }
        )

    log.debug(
        "BT_ANALYSIS_EMASTATE_MTF: –∑–∞–≥—Ä—É–∂–µ–Ω–æ –ø–æ–∑–∏—Ü–∏–π scenario_id=%s signal_id=%s: %s",
        scenario_id,
        signal_id,
        len(out),
    )
    return out


# üî∏ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —è–∫–æ—Ä–Ω–æ–≥–æ open_time –ø–æ TF –∏–∑ raw_stat
def _extract_anchor_open_time(raw_stat: Any, tf: str) -> Optional[datetime]:
    if raw_stat is None:
        return None

    if isinstance(raw_stat, str):
        try:
            raw_stat = json.loads(raw_stat)
        except Exception:
            return None

    if not isinstance(raw_stat, dict):
        return None

    tf_block = (raw_stat.get("tf") or {}).get(tf)
    if not isinstance(tf_block, dict):
        return None

    open_time_str = tf_block.get("open_time")
    if not open_time_str:
        return None

    try:
        return datetime.fromisoformat(str(open_time_str))
    except Exception:
        return None


# üî∏ –ù–∞–∫–ª–æ–Ω –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ y(t) –ø–æ t=0..n-1 (–≤ –µ–¥–∏–Ω–∏—Ü–∞—Ö y –Ω–∞ –±–∞—Ä)
def _linreg_slope(values: List[Decimal]) -> Decimal:
    n = len(values)
    if n <= 1:
        return Decimal("0")

    xs: List[Decimal] = [Decimal(i) for i in range(n)]
    mean_x = sum(xs) / Decimal(n)
    mean_y = sum(values) / Decimal(n)

    cov = Decimal("0")
    var = Decimal("0")

    for i in range(n):
        dx = xs[i] - mean_x
        dy = values[i] - mean_y
        cov += dx * dy
        var += dx * dx

    if var == 0:
        return Decimal("0")

    return cov / var


# üî∏ –ê–±—Å–æ–ª—é—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ Decimal
def _abs(x: Decimal) -> Decimal:
    return x if x >= 0 else -x


# üî∏ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ Decimal
def _safe_decimal(value: Any) -> Decimal:
    if isinstance(value, Decimal):
        return value
    try:
        return Decimal(str(value))
    except (InvalidOperation, TypeError, ValueError):
        return Decimal("0")


# üî∏ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ —á—Ç–µ–Ω–∏–µ Decimal-–ø–∞—Ä–∞–º–µ—Ç—Ä–∞
def _get_decimal_param(params: Dict[str, Any], name: str, default: Decimal) -> Decimal:
    cfg = params.get(name)
    if cfg is None:
        return default

    raw = cfg.get("value")
    if raw is None:
        return default

    try:
        return Decimal(str(raw))
    except (InvalidOperation, TypeError, ValueError):
        return default


# üî∏ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ —á—Ç–µ–Ω–∏–µ int-–ø–∞—Ä–∞–º–µ—Ç—Ä–∞
def _get_int_param(params: Dict[str, Any], name: str, default: int) -> int:
    cfg = params.get(name)
    if cfg is None:
        return default

    raw = cfg.get("value")
    if raw is None:
        return default

    try:
        return int(str(raw))
    except (TypeError, ValueError):
        return default


# üî∏ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ —á—Ç–µ–Ω–∏–µ str-–ø–∞—Ä–∞–º–µ—Ç—Ä–∞
def _get_str_param(params: Dict[str, Any], name: str, default: str) -> str:
    cfg = params.get(name)
    if cfg is None:
        return default

    raw = cfg.get("value")
    if raw is None:
        return default

    return str(raw).strip()