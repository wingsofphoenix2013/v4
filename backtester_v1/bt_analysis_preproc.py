# bt_analysis_preproc.py ‚Äî –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –∞–Ω–∞–ª–∏–∑–æ–≤ (–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ—Ä–æ–≥–∞ + —Å–æ—Å—Ç–∞–≤–∞ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤, —Ä–∞–∑–º–µ—Ç–∫–∞ –±–∏–Ω–Ω–æ–≤ –∏ –ø—É–±–ª–∏–∫–∞—Ü–∏—è bt:analysis:preproc_ready)

import asyncio
import json
import logging
from datetime import datetime
from decimal import Decimal, InvalidOperation, ROUND_DOWN
from typing import Any, Dict, List, Optional, Tuple

# üî∏ –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã —Å—Ç—Ä–∏–º–æ–≤ –∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞
ANALYSIS_READY_STREAM_KEY = "bt:analysis:ready"
PREPROC_READY_STREAM_KEY = "bt:analysis:preproc_ready"

PREPROC_CONSUMER_GROUP = "bt_analysis_preproc"
PREPROC_CONSUMER_NAME = "bt_analysis_preproc_main"

PREPROC_STREAM_BATCH_SIZE = 10
PREPROC_STREAM_BLOCK_MS = 5000

PREPROC_MAX_CONCURRENCY = 6

# üî∏ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
EPS_THRESHOLD = Decimal("0.00000001")          # —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π eps –¥–ª—è —Å—Ç—Ä–æ–≥–∏—Ö —Å—Ä–∞–≤–Ω–µ–Ω–∏–π (–ø–æ —Ñ–∞–∫—Ç—É winrate —É–∂–µ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω)
MAX_MODEL_ITERS = 20                           # –º–∞–∫—Å–∏–º—É–º –∏—Ç–µ—Ä–∞—Ü–∏–π —É–¥–∞–ª–µ–Ω–∏—è "–≤—Ä–µ–¥–Ω—ã—Ö" –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤
MIN_ANALYZERS_LEFT = 1                         # –Ω–µ –¥–∞—ë–º —É–¥–∞–ª–∏—Ç—å—Å—è –¥–æ 0 (–º–æ–∂–Ω–æ –º–µ–Ω—è—Ç—å –ø–æ–∑–∂–µ)

# üî∏ –ö–µ—à –ø–æ—Å–ª–µ–¥–Ω–∏—Ö source_finished_at –ø–æ (scenario_id, signal_id) –¥–ª—è –æ—Ç—Å–µ—á–∫–∏ –¥—É–±–ª–µ–π
_last_analysis_finished_at: Dict[Tuple[int, int], datetime] = {}

log = logging.getLogger("BT_ANALYSIS_PREPROC")


# üî∏ –ü—É–±–ª–∏—á–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞: –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞
async def run_bt_analysis_preproc_orchestrator(pg, redis):
    log.debug("BT_ANALYSIS_PREPROC: –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –∑–∞–ø—É—â–µ–Ω")

    await _ensure_consumer_group(redis)

    # –æ–±—â–∏–π —Å–µ–º–∞—Ñ–æ—Ä –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞ –ø–æ –ø–∞—Ä–∞–º (scenario_id, signal_id)
    sema = asyncio.Semaphore(PREPROC_MAX_CONCURRENCY)

    while True:
        try:
            entries = await _read_from_stream(redis)
            if not entries:
                continue

            tasks: List[asyncio.Task] = []
            total_msgs = 0

            for stream_key, messages in entries:
                if stream_key != ANALYSIS_READY_STREAM_KEY:
                    continue

                for entry_id, fields in messages:
                    total_msgs += 1
                    task = asyncio.create_task(
                        _process_message(
                            entry_id=entry_id,
                            fields=fields,
                            pg=pg,
                            redis=redis,
                            sema=sema,
                        ),
                        name=f"BT_ANALYSIS_PREPROC_{entry_id}",
                    )
                    tasks.append(task)

            if tasks:
                results = await asyncio.gather(*tasks, return_exceptions=True)
                errors = sum(1 for r in results if isinstance(r, Exception))
                log.info(
                    "BT_ANALYSIS_PREPROC: –æ–±—Ä–∞–±–æ—Ç–∞–Ω –ø–∞–∫–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ bt:analysis:ready ‚Äî —Å–æ–æ–±—â–µ–Ω–∏–π=%s, –æ—à–∏–±–æ–∫=%s",
                    total_msgs,
                    errors,
                )

        except Exception as e:
            log.error(
                "BT_ANALYSIS_PREPROC: –æ—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞: %s",
                e,
                exc_info=True,
            )
            await asyncio.sleep(2)


# üî∏ –ü—Ä–æ–≤–µ—Ä–∫–∞/—Å–æ–∑–¥–∞–Ω–∏–µ consumer group –¥–ª—è —Å—Ç—Ä–∏–º–∞ bt:analysis:ready
async def _ensure_consumer_group(redis) -> None:
    try:
        await redis.xgroup_create(
            name=ANALYSIS_READY_STREAM_KEY,
            groupname=PREPROC_CONSUMER_GROUP,
            id="$",
            mkstream=True,
        )
        log.debug(
            "BT_ANALYSIS_PREPROC: —Å–æ–∑–¥–∞–Ω–∞ consumer group '%s' –¥–ª—è —Å—Ç—Ä–∏–º–∞ '%s'",
            PREPROC_CONSUMER_GROUP,
            ANALYSIS_READY_STREAM_KEY,
        )
    except Exception as e:
        msg = str(e)
        if "BUSYGROUP" in msg:
            log.debug(
                "BT_ANALYSIS_PREPROC: consumer group '%s' –¥–ª—è —Å—Ç—Ä–∏–º–∞ '%s' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç",
                PREPROC_CONSUMER_GROUP,
                ANALYSIS_READY_STREAM_KEY,
            )
        else:
            log.error(
                "BT_ANALYSIS_PREPROC: –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ consumer group '%s': %s",
                PREPROC_CONSUMER_GROUP,
                e,
                exc_info=True,
            )
            raise


# üî∏ –ß—Ç–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ —Å—Ç—Ä–∏–º–∞ bt:analysis:ready
async def _read_from_stream(redis) -> List[Any]:
    entries = await redis.xreadgroup(
        groupname=PREPROC_CONSUMER_GROUP,
        consumername=PREPROC_CONSUMER_NAME,
        streams={ANALYSIS_READY_STREAM_KEY: ">"},
        count=PREPROC_STREAM_BATCH_SIZE,
        block=PREPROC_STREAM_BLOCK_MS,
    )

    if not entries:
        return []

    parsed: List[Any] = []
    for stream_key, messages in entries:
        if isinstance(stream_key, bytes):
            stream_key = stream_key.decode("utf-8")

        stream_entries: List[Any] = []
        for msg_id, fields in messages:
            if isinstance(msg_id, bytes):
                msg_id = msg_id.decode("utf-8")

            str_fields: Dict[str, str] = {}
            for k, v in fields.items():
                key_str = k.decode("utf-8") if isinstance(k, bytes) else str(k)
                val_str = v.decode("utf-8") if isinstance(v, bytes) else str(v)
                str_fields[key_str] = val_str

            stream_entries.append((msg_id, str_fields))

        parsed.append((stream_key, stream_entries))

    return parsed


# üî∏ –†–∞–∑–±–æ—Ä –æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ —Å—Ç—Ä–∏–º–∞ bt:analysis:ready
def _parse_analysis_ready_message(fields: Dict[str, str]) -> Optional[Dict[str, Any]]:
    try:
        scenario_id_str = fields.get("scenario_id")
        signal_id_str = fields.get("signal_id")
        finished_at_str = fields.get("finished_at")

        if not (scenario_id_str and signal_id_str and finished_at_str):
            return None

        scenario_id = int(scenario_id_str)
        signal_id = int(signal_id_str)
        source_finished_at = datetime.fromisoformat(finished_at_str)

        return {
            "scenario_id": scenario_id,
            "signal_id": signal_id,
            "source_finished_at": source_finished_at,
        }
    except Exception as e:
        log.error(
            "BT_ANALYSIS_PREPROC: –æ—à–∏–±–∫–∞ —Ä–∞–∑–±–æ—Ä–∞ —Å–æ–æ–±—â–µ–Ω–∏—è —Å—Ç—Ä–∏–º–∞ bt:analysis:ready: %s, fields=%s",
            e,
            fields,
            exc_info=True,
        )
        return None


# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ bt:analysis:ready —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º —Å–µ–º–∞—Ñ–æ—Ä–æ–º
async def _process_message(
    entry_id: str,
    fields: Dict[str, str],
    pg,
    redis,
    sema: asyncio.Semaphore,
) -> None:
    async with sema:
        ctx = _parse_analysis_ready_message(fields)
        if not ctx:
            await redis.xack(ANALYSIS_READY_STREAM_KEY, PREPROC_CONSUMER_GROUP, entry_id)
            return

        scenario_id = ctx["scenario_id"]
        signal_id = ctx["signal_id"]
        source_finished_at = ctx["source_finished_at"]

        pair_key = (scenario_id, signal_id)
        last_finished = _last_analysis_finished_at.get(pair_key)

        # –æ—Ç—Å–µ—á–∫–∞ –¥—É–±–ª–µ–π –ø–æ —Ä–∞–≤–Ω–æ–º—É source_finished_at
        if last_finished is not None and last_finished == source_finished_at:
            log.debug(
                "BT_ANALYSIS_PREPROC: –¥—É–±–ª–∏–∫–∞—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è scenario_id=%s, signal_id=%s, source_finished_at=%s, stream_id=%s ‚Äî —Ä–∞—Å—á—ë—Ç –Ω–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è",
                scenario_id,
                signal_id,
                source_finished_at,
                entry_id,
            )
            await redis.xack(ANALYSIS_READY_STREAM_KEY, PREPROC_CONSUMER_GROUP, entry_id)
            return

        _last_analysis_finished_at[pair_key] = source_finished_at

        started_at = datetime.utcnow()

        try:
            # –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–∏–≥–Ω–∞–ª–∞
            direction_mask = await _load_signal_direction_mask(pg, signal_id)
            directions = _directions_from_mask(direction_mask)

            # –¥–µ–ø–æ–∑–∏—Ç —Å—Ü–µ–Ω–∞—Ä–∏—è (–¥–ª—è ROI)
            deposit = await _load_scenario_deposit(pg, scenario_id)

            # —Å—á–∏—Ç–∞–µ–º –º–æ–¥–µ–ª—å –æ—Ç–¥–µ–ª—å–Ω–æ –ø–æ –∫–∞–∂–¥–æ–º—É –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—é
            results: Dict[str, Dict[str, Any]] = {}

            for direction in directions:
                # –∫–∞–Ω–¥–∏–¥–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤ –ø–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—é
                initial_analysis_ids = await _load_analysis_ids_for_pair_direction(
                    pg=pg,
                    scenario_id=scenario_id,
                    signal_id=signal_id,
                    direction=direction,
                )

                # –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–∞–≤–∞ + –ø–æ—Ä–æ–≥–∞
                model_result = await _optimize_model_for_direction(
                    pg=pg,
                    scenario_id=scenario_id,
                    signal_id=signal_id,
                    direction=direction,
                    deposit=deposit,
                    direction_mask=direction_mask,
                    initial_analysis_ids=initial_analysis_ids,
                    source_finished_at=source_finished_at,
                )
                results[direction] = model_result

            # —á–∏—Å—Ç–∏–º –ª–∏—à–Ω–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è (–µ—Å–ª–∏ —Ä–∞–Ω–µ–µ –±—ã–ª–∏ –∑–∞–ø–∏—Å–∞–Ω—ã)
            other_dirs = [d for d in ("long", "short") if d not in directions]
            for d in other_dirs:
                await _delete_model_and_threshold_for_direction(pg, scenario_id, signal_id, d)

            # –ø—É–±–ª–∏–∫—É–µ–º —Å–æ–±—ã—Ç–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞
            await _publish_preproc_ready(
                redis=redis,
                scenario_id=scenario_id,
                signal_id=signal_id,
                source_finished_at=source_finished_at,
                direction_mask=direction_mask,
            )

            elapsed_ms = int((datetime.utcnow() - started_at).total_seconds() * 1000)

            # —Å—É–º–º–∞—Ä–Ω—ã–π –ª–æ–≥
            parts: List[str] = []
            for d in directions:
                r = results.get(d) or {}
                parts.append(
                    f"{d} thr={r.get('best_threshold')} roi={r.get('filt_roi')} trades={r.get('filt_trades')} "
                    f"analyses={r.get('selected_cnt')}/{r.get('initial_cnt')} removed_harmful={r.get('harmful_removed_cnt')}"
                )

            log.info(
                "BT_ANALYSIS_PREPROC: scenario_id=%s, signal_id=%s ‚Äî direction_mask=%s, directions=%s, %s, source_finished_at=%s, elapsed_ms=%s",
                scenario_id,
                signal_id,
                direction_mask,
                directions,
                " | ".join(parts) if parts else "no_results",
                source_finished_at,
                elapsed_ms,
            )

        except Exception as e:
            log.error(
                "BT_ANALYSIS_PREPROC: –æ—à–∏–±–∫–∞ —Ä–∞—Å—á—ë—Ç–∞ –¥–ª—è scenario_id=%s, signal_id=%s: %s",
                scenario_id,
                signal_id,
                e,
                exc_info=True,
            )
        finally:
            await redis.xack(ANALYSIS_READY_STREAM_KEY, PREPROC_CONSUMER_GROUP, entry_id)


# üî∏ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è: —Å–æ—Å—Ç–∞–≤ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤ + –ø–æ—Ä–æ–≥ + –∑–∞–ø–∏—Å—å model_opt + bins_labels
async def _optimize_model_for_direction(
    pg,
    scenario_id: int,
    signal_id: int,
    direction: str,
    deposit: Optional[Decimal],
    direction_mask: Optional[str],
    initial_analysis_ids: List[int],
    source_finished_at: datetime,
) -> Dict[str, Any]:
    selected_ids: List[int] = list(initial_analysis_ids)
    harmful_removed: List[Dict[str, Any]] = []

    # –æ—Å–Ω–æ–≤–Ω–æ–π –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–π —Ü–∏–∫–ª
    last_threshold = None
    last_filt_roi = None

    for it in range(MAX_MODEL_ITERS):
        # –µ—Å–ª–∏ —Å–æ–≤—Å–µ–º –Ω–µ—á–µ–≥–æ –≤—ã–±–∏—Ä–∞—Ç—å ‚Äî –≤—Å—ë —Ä–∞–≤–Ω–æ —Å—á–∏—Ç–∞–µ–º –ø–æ—Ä–æ–≥/–º–µ—Ç—Ä–∏–∫–∏ (–±—É–¥—É—Ç 0/–∏—Å—Ö–æ–¥–Ω—ã–µ)
        threshold_result = await _compute_best_threshold_for_direction(
            pg=pg,
            scenario_id=scenario_id,
            signal_id=signal_id,
            direction=direction,
            deposit=deposit,
            analysis_ids=selected_ids,
        )

        best_threshold = threshold_result["best_threshold"]
        filt_roi = threshold_result["filt_roi"]

        # —É—Å–ª–æ–≤–∏—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ (–ø–æ—Ä–æ–≥ –∏ ROI –Ω–µ –º–µ–Ω—è—é—Ç—Å—è)
        if last_threshold is not None and last_filt_roi is not None:
            if best_threshold == last_threshold and filt_roi == last_filt_roi:
                # —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∏—Å—å
                break
        last_threshold = best_threshold
        last_filt_roi = filt_roi

        # –µ—Å–ª–∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤ —É–∂–µ –ø–æ—á—Ç–∏ –Ω–µ—Ç ‚Äî –≤—ã—Ö–æ–¥–∏–º
        if len(selected_ids) <= MIN_ANALYZERS_LEFT:
            break

        # —Å—á–∏—Ç–∞–µ–º –º–∞—Ä–∂–∏–Ω–∞–ª—å–Ω—ã–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —É–¥–∞–ª–µ–Ω–∏—è (–ø–æ —Ç–µ–∫—É—â–µ–º—É threshold –∏ —Ç–µ–∫—É—â–µ–º—É —Å–æ—Å—Ç–∞–≤—É)
        marginal_map = await _load_marginal_unique_removed_map(
            pg=pg,
            scenario_id=scenario_id,
            signal_id=signal_id,
            direction=direction,
            analysis_ids=selected_ids,
            threshold=best_threshold,
        )

        # –≤—ã–±–∏—Ä–∞–µ–º —Å–∞–º—ã–π "–≤—Ä–µ–¥–Ω—ã–π" (—É–Ω–∏–∫–∞–ª—å–Ω–æ —É–¥–∞–ª–∏–ª net winners => positive pnl)
        worst_id = None
        worst_pnl = Decimal("0")
        worst_trades = 0

        # –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: marginal_map —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ —Ç–µ—Ö, —É –∫–æ–≥–æ –µ—Å—Ç—å unique_removed_trades
        for aid, m in marginal_map.items():
            pnl = m.get("unique_removed_pnl_abs", Decimal("0"))
            trades = int(m.get("unique_removed_trades", 0) or 0)
            if trades <= 0:
                continue
            if pnl > worst_pnl:
                worst_pnl = pnl
                worst_id = aid
                worst_trades = trades

        # –µ—Å–ª–∏ –Ω–µ—Ç –≤—Ä–µ–¥–Ω—ã—Ö ‚Äî –∑–∞–≤–µ—Ä—à–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é —Å–æ—Å—Ç–∞–≤–∞
        if worst_id is None or worst_pnl <= 0:
            # –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ —É–∂–µ –µ—Å—Ç—å –≤ threshold_result
            return await _finalize_and_store_model(
                pg=pg,
                scenario_id=scenario_id,
                signal_id=signal_id,
                direction=direction,
                deposit=deposit,
                direction_mask=direction_mask,
                initial_analysis_ids=initial_analysis_ids,
                selected_analysis_ids=selected_ids,
                harmful_removed=harmful_removed,
                threshold_result=threshold_result,
                source_finished_at=source_finished_at,
            )

        # —É–¥–∞–ª—è–µ–º –≤—Ä–µ–¥–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
        if worst_id in selected_ids:
            selected_ids = [x for x in selected_ids if x != worst_id]
            harmful_removed.append(
                {
                    "analysis_id": int(worst_id),
                    "unique_removed_trades": int(worst_trades),
                    "unique_removed_pnl_abs": str(_q_decimal(worst_pnl)),
                }
            )

        # –µ—Å–ª–∏ –æ—Å—Ç–∞–ª–æ—Å—å —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤ ‚Äî –∑–∞–≤–µ—Ä—à–∞–µ–º
        if len(selected_ids) <= MIN_ANALYZERS_LEFT:
            threshold_result = await _compute_best_threshold_for_direction(
                pg=pg,
                scenario_id=scenario_id,
                signal_id=signal_id,
                direction=direction,
                deposit=deposit,
                analysis_ids=selected_ids,
            )
            return await _finalize_and_store_model(
                pg=pg,
                scenario_id=scenario_id,
                signal_id=signal_id,
                direction=direction,
                deposit=deposit,
                direction_mask=direction_mask,
                initial_analysis_ids=initial_analysis_ids,
                selected_analysis_ids=selected_ids,
                harmful_removed=harmful_removed,
                threshold_result=threshold_result,
                source_finished_at=source_finished_at,
            )

    # –µ—Å–ª–∏ —Ü–∏–∫–ª –≤—ã—à–µ–ª –ø–æ –ª–∏–º–∏—Ç—É –∏—Ç–µ—Ä–∞—Ü–∏–π ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ, —á—Ç–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å
    threshold_result = await _compute_best_threshold_for_direction(
        pg=pg,
        scenario_id=scenario_id,
        signal_id=signal_id,
        direction=direction,
        deposit=deposit,
        analysis_ids=selected_ids,
    )
    return await _finalize_and_store_model(
        pg=pg,
        scenario_id=scenario_id,
        signal_id=signal_id,
        direction=direction,
        deposit=deposit,
        direction_mask=direction_mask,
        initial_analysis_ids=initial_analysis_ids,
        selected_analysis_ids=selected_ids,
        harmful_removed=harmful_removed,
        threshold_result=threshold_result,
        source_finished_at=source_finished_at,
    )


# üî∏ –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è: –∑–∞–ø–∏—Å—å bt_analysis_model_opt + bt_analysis_bins_labels + (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) bt_analysis_threshold_opt
async def _finalize_and_store_model(
    pg,
    scenario_id: int,
    signal_id: int,
    direction: str,
    deposit: Optional[Decimal],
    direction_mask: Optional[str],
    initial_analysis_ids: List[int],
    selected_analysis_ids: List[int],
    harmful_removed: List[Dict[str, Any]],
    threshold_result: Dict[str, Any],
    source_finished_at: datetime,
) -> Dict[str, Any]:
    best_threshold = threshold_result["best_threshold"]

    meta_obj = {
        "version": 1,
        "method": "greedy_remove_harmful_unique",
        "threshold_method": "worst_winrate_sweep",
        "eps": str(EPS_THRESHOLD),
        "direction": direction,
        "direction_mask": direction_mask,
        "deposit": str(deposit) if deposit is not None else None,
        "analysis_ids_initial": initial_analysis_ids,
        "analysis_ids_selected": selected_analysis_ids,
        "harmful_removed": harmful_removed,
        "iterations_max": MAX_MODEL_ITERS,
        "harmful_removed_cnt": len(harmful_removed),
        "candidates": threshold_result.get("candidates", 0),
        "removable_positions": threshold_result.get("removable_positions", 0),
    }

    # upsert model_opt –∏ –ø–æ–ª—É—á–∞–µ–º model_id
    model_id = await _upsert_model_opt_return_id(
        pg=pg,
        scenario_id=scenario_id,
        signal_id=signal_id,
        direction=direction,
        best_threshold=best_threshold,
        selected_analysis_ids=selected_analysis_ids,
        threshold_result=threshold_result,
        meta_obj=meta_obj,
        source_finished_at=source_finished_at,
    )

    # —Ä–∞–∑–º–µ—á–∞–µ–º –±–∏–Ω–Ω—ã –¥–ª—è —ç—Ç–æ–π –º–æ–¥–µ–ª–∏
    bins_rows = await _load_bins_stat_rows(
        pg=pg,
        scenario_id=scenario_id,
        signal_id=signal_id,
        direction=direction,
    )
    labels_inserted = await _rebuild_bins_labels(
        pg=pg,
        model_id=model_id,
        scenario_id=scenario_id,
        signal_id=signal_id,
        direction=direction,
        threshold_used=best_threshold,
        selected_analysis_ids=set(selected_analysis_ids),
        bins_rows=bins_rows,
    )

    log.info(
        "BT_ANALYSIS_PREPROC: –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ ‚Äî scenario_id=%s, signal_id=%s, direction=%s, model_id=%s, thr=%s, analyses=%s/%s, harmful_removed=%s, bins_labels=%s, filt_roi=%s, filt_trades=%s",
        scenario_id,
        signal_id,
        direction,
        model_id,
        best_threshold,
        len(selected_analysis_ids),
        len(initial_analysis_ids),
        len(harmful_removed),
        labels_inserted,
        threshold_result.get("filt_roi"),
        threshold_result.get("filt_trades"),
    )

    # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Å—É–º–º–∞—Ä–Ω–æ–≥–æ –ª–æ–≥–∞
    return {
        "model_id": model_id,
        "best_threshold": best_threshold,
        "orig_trades": threshold_result.get("orig_trades"),
        "orig_pnl_abs": threshold_result.get("orig_pnl_abs"),
        "orig_winrate": threshold_result.get("orig_winrate"),
        "orig_roi": threshold_result.get("orig_roi"),
        "filt_trades": threshold_result.get("filt_trades"),
        "filt_pnl_abs": threshold_result.get("filt_pnl_abs"),
        "filt_winrate": threshold_result.get("filt_winrate"),
        "filt_roi": threshold_result.get("filt_roi"),
        "removed_trades": threshold_result.get("removed_trades"),
        "removed_accuracy": threshold_result.get("removed_accuracy"),
        "initial_cnt": len(initial_analysis_ids),
        "selected_cnt": len(selected_analysis_ids),
        "harmful_removed_cnt": len(harmful_removed),
        "bins_labels": labels_inserted,
    }


# üî∏ –†–∞—Å—á—ë—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞ –¥–ª—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–æ –∑–∞–¥–∞–Ω–Ω–æ–º—É –Ω–∞–±–æ—Ä—É –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤ (worst_winrate sweep)
async def _compute_best_threshold_for_direction(
    pg,
    scenario_id: int,
    signal_id: int,
    direction: str,
    deposit: Optional[Decimal],
    analysis_ids: List[int],
) -> Dict[str, Any]:
    positions = await _load_positions_with_worst_winrate(
        pg=pg,
        scenario_id=scenario_id,
        signal_id=signal_id,
        direction=direction,
        analysis_ids=analysis_ids,
    )

    if not positions:
        return {
            "best_threshold": Decimal("0"),
            "orig_trades": 0,
            "orig_pnl_abs": Decimal("0"),
            "orig_winrate": Decimal("0"),
            "orig_roi": Decimal("0"),
            "filt_trades": 0,
            "filt_pnl_abs": Decimal("0"),
            "filt_winrate": Decimal("0"),
            "filt_roi": Decimal("0"),
            "removed_trades": 0,
            "removed_accuracy": Decimal("0"),
            "candidates": 0,
            "removable_positions": 0,
        }

    # –∏—Å—Ö–æ–¥–Ω—ã–µ –∞–≥—Ä–µ–≥–∞—Ç—ã (–¥–æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏)
    orig_trades = len(positions)
    orig_pnl_abs = sum((p["pnl_abs"] for p in positions), Decimal("0"))
    orig_wins = sum(1 for p in positions if p["pnl_abs"] > 0)

    if orig_trades > 0:
        orig_winrate = Decimal(orig_wins) / Decimal(orig_trades)
    else:
        orig_winrate = Decimal("0")

    if deposit and deposit > 0:
        try:
            orig_roi = orig_pnl_abs / deposit
        except (InvalidOperation, ZeroDivisionError):
            orig_roi = Decimal("0")
    else:
        orig_roi = Decimal("0")

    # –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ–∑–∏—Ü–∏–∏ –ø–æ worst_winrate (—Ç–æ–ª—å–∫–æ —Ç–µ, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ —É–¥–∞–ª—è–µ–º—ã)
    groups: Dict[Decimal, Dict[str, Any]] = {}
    removable_count = 0

    for p in positions:
        w = p["worst_winrate"]
        if w is None:
            continue

        removable_count += 1
        g = groups.setdefault(w, {"trades": 0, "pnl": Decimal("0"), "wins": 0, "losers": 0})
        g["trades"] += 1
        g["pnl"] += p["pnl_abs"]
        if p["pnl_abs"] > 0:
            g["wins"] += 1
        if p["pnl_abs"] <= 0:
            g["losers"] += 1

    unique_worst = sorted(groups.keys())
    candidates = 1 + len(unique_worst)

    # —Å—Ç–∞—Ä—Ç–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ: –Ω–∏—á–µ–≥–æ –Ω–µ —É–¥–∞–ª–µ–Ω–æ (threshold=0)
    best_threshold = Decimal("0")
    best_filt_trades = orig_trades
    best_filt_pnl = orig_pnl_abs
    best_filt_winrate = orig_winrate
    best_filt_roi = orig_roi
    best_removed_trades = 0
    best_removed_accuracy = Decimal("0")

    # —Ü–µ–ª–µ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è
    if deposit and deposit > 0:
        best_objective = best_filt_roi
        objective_mode = "roi"
    else:
        best_objective = best_filt_pnl
        objective_mode = "pnl_abs"

    removed_trades = 0
    removed_pnl = Decimal("0")
    removed_wins = 0
    removed_losers = 0

    for v in unique_worst:
        # —É–¥–∞–ª—è–µ–º –≤—Å–µ –ø–æ–∑–∏—Ü–∏–∏ —Å worst_winrate <= v (—ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç winrate <= threshold)
        g = groups[v]

        removed_trades += int(g["trades"])
        removed_pnl += g["pnl"]
        removed_wins += int(g["wins"])
        removed_losers += int(g["losers"])

        filt_trades = orig_trades - removed_trades
        filt_pnl = orig_pnl_abs - removed_pnl
        filt_wins = orig_wins - removed_wins

        if filt_trades > 0:
            filt_winrate = Decimal(filt_wins) / Decimal(filt_trades)
        else:
            filt_winrate = Decimal("0")

        if deposit and deposit > 0:
            try:
                filt_roi = filt_pnl / deposit
            except (InvalidOperation, ZeroDivisionError):
                filt_roi = Decimal("0")
        else:
            filt_roi = Decimal("0")

        if removed_trades > 0:
            removed_accuracy = Decimal(removed_losers) / Decimal(removed_trades)
        else:
            removed_accuracy = Decimal("0")

        threshold = v + EPS_THRESHOLD

        if objective_mode == "roi":
            objective = filt_roi
        else:
            objective = filt_pnl

        # 1) –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π objective
        # 2) –ø—Ä–∏ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ ‚Äî –±–æ–ª—å—à–µ filt_trades
        # 3) –ø—Ä–∏ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ ‚Äî –º–µ–Ω—å—à–∏–π threshold
        if objective > best_objective:
            best_objective = objective
            best_threshold = threshold
            best_filt_trades = filt_trades
            best_filt_pnl = filt_pnl
            best_filt_winrate = filt_winrate
            best_filt_roi = filt_roi
            best_removed_trades = removed_trades
            best_removed_accuracy = removed_accuracy
        elif objective == best_objective:
            if filt_trades > best_filt_trades:
                best_threshold = threshold
                best_filt_trades = filt_trades
                best_filt_pnl = filt_pnl
                best_filt_winrate = filt_winrate
                best_filt_roi = filt_roi
                best_removed_trades = removed_trades
                best_removed_accuracy = removed_accuracy
            elif filt_trades == best_filt_trades and threshold < best_threshold:
                best_threshold = threshold
                best_filt_trades = filt_trades
                best_filt_pnl = filt_pnl
                best_filt_winrate = filt_winrate
                best_filt_roi = filt_roi
                best_removed_trades = removed_trades
                best_removed_accuracy = removed_accuracy

    # –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: –ø–æ—Ä–æ–≥ –∏ –º–µ—Ç—Ä–∏–∫–∏ –∫–≤–∞–Ω—Ç–∏–º –¥–æ 4 –∑–Ω–∞–∫–æ–≤ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ—Å—Ç–∏ (winrate –≤ bins_stat —É–∂–µ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω)
    return {
        "best_threshold": _q_decimal(best_threshold),
        "orig_trades": int(orig_trades),
        "orig_pnl_abs": _q_decimal(orig_pnl_abs),
        "orig_winrate": _q_decimal(orig_winrate),
        "orig_roi": _q_decimal(orig_roi),
        "filt_trades": int(best_filt_trades),
        "filt_pnl_abs": _q_decimal(best_filt_pnl),
        "filt_winrate": _q_decimal(best_filt_winrate),
        "filt_roi": _q_decimal(best_filt_roi),
        "removed_trades": int(best_removed_trades),
        "removed_accuracy": _q_decimal(best_removed_accuracy),
        "candidates": int(candidates),
        "removable_positions": int(removable_count),
    }


# üî∏ –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ–∑–∏—Ü–∏–π —Å worst_winrate (MIN winrate –ø–æ –≤—Å–µ–º –ø–æ–ø–∞–¥–∞–Ω–∏—è–º –ø–æ–∑–∏—Ü–∏–∏) —Å —Ñ–∏–ª—å—Ç—Ä–æ–º –ø–æ analysis_ids
async def _load_positions_with_worst_winrate(
    pg,
    scenario_id: int,
    signal_id: int,
    direction: str,
    analysis_ids: List[int],
) -> List[Dict[str, Any]]:
    # –µ—Å–ª–∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤ –Ω–µ—Ç ‚Äî worst_winrate –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—Å—è
    analysis_ids = analysis_ids or []

    async with pg.acquire() as conn:
        rows = await conn.fetch(
            """
            WITH pos AS (
                SELECT position_uid, pnl_abs
                FROM bt_scenario_positions
                WHERE scenario_id = $1
                  AND signal_id   = $2
                  AND postproc    = true
                  AND direction   = $3
            ),
            worst AS (
                SELECT
                    r.position_uid,
                    MIN(b.winrate) AS worst_winrate
                FROM bt_analysis_positions_raw r
                JOIN bt_analysis_bins_stat b
                  ON b.analysis_id = r.analysis_id
                 AND b.scenario_id = r.scenario_id
                 AND b.signal_id   = r.signal_id
                 AND b.timeframe   = r.timeframe
                 AND b.direction   = r.direction
                 AND b.bin_name    = r.bin_name
                WHERE r.scenario_id = $1
                  AND r.signal_id   = $2
                  AND r.direction   = $3
                  AND (
                        array_length($4::int[], 1) IS NULL
                        OR r.analysis_id = ANY($4::int[])
                      )
                GROUP BY r.position_uid
            )
            SELECT
                p.position_uid,
                p.pnl_abs,
                w.worst_winrate
            FROM pos p
            LEFT JOIN worst w
              ON w.position_uid = p.position_uid
            ORDER BY w.worst_winrate NULLS LAST
            """,
            scenario_id,
            signal_id,
            direction,
            analysis_ids if analysis_ids else None,
        )

    out: List[Dict[str, Any]] = []
    for r in rows:
        out.append(
            {
                "position_uid": r["position_uid"],
                "pnl_abs": _safe_decimal(r["pnl_abs"]),
                "worst_winrate": _safe_decimal_or_none(r["worst_winrate"]),
            }
        )
    return out


# üî∏ –ú–∞—Ä–∂–∏–Ω–∞–ª—å–Ω—ã–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —É–¥–∞–ª–µ–Ω–∏—è –ø–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞–º (unique_removed_pnl_abs) –ø—Ä–∏ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–º threshold –∏ —Å–æ—Å—Ç–∞–≤–µ
async def _load_marginal_unique_removed_map(
    pg,
    scenario_id: int,
    signal_id: int,
    direction: str,
    analysis_ids: List[int],
    threshold: Decimal,
) -> Dict[int, Dict[str, Any]]:
    if not analysis_ids:
        return {}

    async with pg.acquire() as conn:
        rows = await conn.fetch(
            """
            WITH bad_bins AS (
                SELECT analysis_id, timeframe, direction, bin_name
                FROM bt_analysis_bins_stat
                WHERE scenario_id = $1
                  AND signal_id   = $2
                  AND direction   = $3
                  AND analysis_id = ANY($4::int[])
                  AND winrate     <= $5
            ),
            flags AS (
                SELECT DISTINCT
                    r.position_uid,
                    r.analysis_id
                FROM bt_analysis_positions_raw r
                JOIN bad_bins b
                  ON b.analysis_id = r.analysis_id
                 AND b.timeframe   = r.timeframe
                 AND b.direction   = r.direction
                 AND b.bin_name    = r.bin_name
                WHERE r.scenario_id = $1
                  AND r.signal_id   = $2
                  AND r.direction   = $3
                  AND r.analysis_id = ANY($4::int[])
            ),
            pos_agg AS (
                SELECT
                    position_uid,
                    COUNT(DISTINCT analysis_id) AS analyses_cnt,
                    MIN(analysis_id)            AS only_analysis_id
                FROM flags
                GROUP BY position_uid
            ),
            uniq_pos AS (
                SELECT only_analysis_id AS analysis_id, position_uid
                FROM pos_agg
                WHERE analyses_cnt = 1
            )
            SELECT
                u.analysis_id,
                COUNT(*)                                         AS unique_removed_trades,
                COALESCE(SUM(p.pnl_abs), 0)                      AS unique_removed_pnl_abs,
                COUNT(*) FILTER (WHERE p.pnl_abs > 0)            AS unique_removed_wins,
                COUNT(*) FILTER (WHERE p.pnl_abs <= 0)           AS unique_removed_losers
            FROM uniq_pos u
            JOIN bt_scenario_positions p
              ON p.position_uid = u.position_uid
            WHERE p.scenario_id = $1
              AND p.signal_id   = $2
              AND p.direction   = $3
              AND p.postproc    = true
            GROUP BY u.analysis_id
            """,
            scenario_id,
            signal_id,
            direction,
            analysis_ids,
            threshold,
        )

    out: Dict[int, Dict[str, Any]] = {}
    for r in rows:
        aid = int(r["analysis_id"])
        out[aid] = {
            "unique_removed_trades": int(r["unique_removed_trades"]),
            "unique_removed_pnl_abs": _safe_decimal(r["unique_removed_pnl_abs"]),
            "unique_removed_wins": int(r["unique_removed_wins"]),
            "unique_removed_losers": int(r["unique_removed_losers"]),
        }
    return out


# üî∏ Upsert model_opt –∏ –≤–æ–∑–≤—Ä–∞—Ç model_id
async def _upsert_model_opt_return_id(
    pg,
    scenario_id: int,
    signal_id: int,
    direction: str,
    best_threshold: Decimal,
    selected_analysis_ids: List[int],
    threshold_result: Dict[str, Any],
    meta_obj: Dict[str, Any],
    source_finished_at: datetime,
) -> int:
    meta_json = json.dumps(meta_obj, ensure_ascii=False)
    selected_json = json.dumps(selected_analysis_ids, ensure_ascii=False)

    async with pg.acquire() as conn:
        row = await conn.fetchrow(
            """
            INSERT INTO bt_analysis_model_opt (
                scenario_id,
                signal_id,
                direction,
                best_threshold,
                selected_analysis_ids,
                orig_trades,
                orig_pnl_abs,
                orig_winrate,
                orig_roi,
                filt_trades,
                filt_pnl_abs,
                filt_winrate,
                filt_roi,
                removed_trades,
                removed_accuracy,
                meta,
                source_finished_at
            )
            VALUES (
                $1, $2, $3,
                $4,
                $5::jsonb,
                $6, $7, $8, $9,
                $10, $11, $12, $13,
                $14, $15,
                $16::jsonb,
                $17
            )
            ON CONFLICT (scenario_id, signal_id, direction)
            DO UPDATE SET
                best_threshold        = EXCLUDED.best_threshold,
                selected_analysis_ids = EXCLUDED.selected_analysis_ids,
                orig_trades           = EXCLUDED.orig_trades,
                orig_pnl_abs          = EXCLUDED.orig_pnl_abs,
                orig_winrate          = EXCLUDED.orig_winrate,
                orig_roi              = EXCLUDED.orig_roi,
                filt_trades           = EXCLUDED.filt_trades,
                filt_pnl_abs          = EXCLUDED.filt_pnl_abs,
                filt_winrate          = EXCLUDED.filt_winrate,
                filt_roi              = EXCLUDED.filt_roi,
                removed_trades        = EXCLUDED.removed_trades,
                removed_accuracy      = EXCLUDED.removed_accuracy,
                meta                  = EXCLUDED.meta,
                source_finished_at    = EXCLUDED.source_finished_at,
                updated_at            = now()
            RETURNING id
            """,
            scenario_id,
            signal_id,
            direction,
            best_threshold,
            selected_json,
            threshold_result["orig_trades"],
            threshold_result["orig_pnl_abs"],
            threshold_result["orig_winrate"],
            threshold_result["orig_roi"],
            threshold_result["filt_trades"],
            threshold_result["filt_pnl_abs"],
            threshold_result["filt_winrate"],
            threshold_result["filt_roi"],
            threshold_result["removed_trades"],
            threshold_result["removed_accuracy"],
            meta_json,
            source_finished_at,
        )

    return int(row["id"])


# üî∏ –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–æ–∫ bt_analysis_bins_stat –¥–ª—è –ø–∞—Ä—ã –∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
async def _load_bins_stat_rows(
    pg,
    scenario_id: int,
    signal_id: int,
    direction: str,
) -> List[Dict[str, Any]]:
    async with pg.acquire() as conn:
        rows = await conn.fetch(
            """
            SELECT
                analysis_id,
                indicator_param,
                timeframe,
                bin_name,
                trades,
                pnl_abs,
                winrate
            FROM bt_analysis_bins_stat
            WHERE scenario_id = $1
              AND signal_id   = $2
              AND direction   = $3
            """,
            scenario_id,
            signal_id,
            direction,
        )

    out: List[Dict[str, Any]] = []
    for r in rows:
        out.append(
            {
                "analysis_id": int(r["analysis_id"]),
                "indicator_param": r["indicator_param"],
                "timeframe": str(r["timeframe"]),
                "bin_name": str(r["bin_name"]),
                "trades": int(r["trades"]),
                "pnl_abs": _safe_decimal(r["pnl_abs"]),
                "winrate": _safe_decimal(r["winrate"]),
            }
        )
    return out


# üî∏ –ü–µ—Ä–µ—Å–±–æ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ç–∫–∏ –±–∏–Ω–Ω–æ–≤ bt_analysis_bins_labels –¥–ª—è model_id (good/bad/inactive)
async def _rebuild_bins_labels(
    pg,
    model_id: int,
    scenario_id: int,
    signal_id: int,
    direction: str,
    threshold_used: Decimal,
    selected_analysis_ids: set,
    bins_rows: List[Dict[str, Any]],
) -> int:
    async with pg.acquire() as conn:
        # —Å–Ω–∞—á–∞–ª–∞ —É–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—É—é —Ä–∞–∑–º–µ—Ç–∫—É –ø–æ model_id
        await conn.execute(
            """
            DELETE FROM bt_analysis_bins_labels
            WHERE model_id = $1
            """,
            model_id,
        )

        if not bins_rows:
            return 0

        to_insert: List[Tuple[Any, ...]] = []
        for b in bins_rows:
            aid = int(b["analysis_id"])
            winrate = b["winrate"]

            # –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: inactive –¥–ª—è –æ—Ç–∫–ª—é—á–µ–Ω–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤
            if aid not in selected_analysis_ids:
                state = "inactive"
            else:
                # bad –µ—Å–ª–∏ winrate <= threshold
                state = "bad" if winrate <= threshold_used else "good"

            to_insert.append(
                (
                    model_id,
                    scenario_id,
                    signal_id,
                    direction,
                    aid,
                    b["indicator_param"],
                    b["timeframe"],
                    b["bin_name"],
                    state,
                    threshold_used,
                    int(b["trades"]),
                    b["pnl_abs"],
                    b["winrate"],
                )
            )

        await conn.executemany(
            """
            INSERT INTO bt_analysis_bins_labels (
                model_id,
                scenario_id,
                signal_id,
                direction,
                analysis_id,
                indicator_param,
                timeframe,
                bin_name,
                state,
                threshold_used,
                trades,
                pnl_abs,
                winrate
            )
            VALUES (
                $1, $2, $3, $4,
                $5, $6, $7, $8,
                $9, $10,
                $11, $12, $13
            )
            """,
            to_insert,
        )

    return len(to_insert)


# üî∏ –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö —Å—Ç—Ä–æ–∫ –º–æ–¥–µ–ª–∏ –∏ –º–µ—Ç—Ä–∏–∫ –¥–ª—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è (–∫–∞—Å–∫–∞–¥–æ–º —É–¥–∞–ª–∏—Ç bins_labels)
async def _delete_model_and_threshold_for_direction(
    pg,
    scenario_id: int,
    signal_id: int,
    direction: str,
) -> None:
    async with pg.acquire() as conn:
        await conn.execute(
            """
            DELETE FROM bt_analysis_model_opt
            WHERE scenario_id = $1
              AND signal_id   = $2
              AND direction   = $3
            """,
            scenario_id,
            signal_id,
            direction,
        )


# üî∏ –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏—è –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ –≤ bt:analysis:preproc_ready
async def _publish_preproc_ready(
    redis,
    scenario_id: int,
    signal_id: int,
    source_finished_at: datetime,
    direction_mask: Optional[str],
) -> None:
    finished_at = datetime.utcnow()

    try:
        await redis.xadd(
            PREPROC_READY_STREAM_KEY,
            {
                "scenario_id": str(scenario_id),
                "signal_id": str(signal_id),
                "finished_at": finished_at.isoformat(),
                "source_finished_at": source_finished_at.isoformat(),
                "direction_mask": str(direction_mask) if direction_mask is not None else "",
            },
        )
        log.debug(
            "BT_ANALYSIS_PREPROC: –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ —Å–æ–±—ã—Ç–∏–µ preproc_ready –≤ —Å—Ç—Ä–∏–º '%s' –¥–ª—è scenario_id=%s, signal_id=%s, finished_at=%s",
            PREPROC_READY_STREAM_KEY,
            scenario_id,
            signal_id,
            finished_at,
        )
    except Exception as e:
        log.error(
            "BT_ANALYSIS_PREPROC: –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å —Å–æ–±—ã—Ç–∏–µ –≤ —Å—Ç—Ä–∏–º '%s' –¥–ª—è scenario_id=%s, signal_id=%s: %s",
            PREPROC_READY_STREAM_KEY,
            scenario_id,
            signal_id,
            e,
            exc_info=True,
        )


# üî∏ –ó–∞–≥—Ä—É–∑–∫–∞ direction_mask —Å–∏–≥–Ω–∞–ª–∞ –∏–∑ bt_signals_parameters (param_name='direction_mask')
async def _load_signal_direction_mask(pg, signal_id: int) -> Optional[str]:
    async with pg.acquire() as conn:
        row = await conn.fetchrow(
            """
            SELECT param_value
            FROM bt_signals_parameters
            WHERE signal_id  = $1
              AND param_name = 'direction_mask'
            LIMIT 1
            """,
            signal_id,
        )

    if not row:
        return None

    value = row["param_value"]
    if value is None:
        return None

    return str(value).strip().lower() or None


# üî∏ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ direction_mask -> —Å–ø–∏—Å–æ–∫ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π
def _directions_from_mask(mask: Optional[str]) -> List[str]:
    if not mask:
        return ["long", "short"]

    m = mask.strip().lower()

    if m == "long":
        return ["long"]
    if m == "short":
        return ["short"]

    if m in ("both", "all", "any", "long_short", "short_long", "long+short", "short+long", "long|short", "short|long"):
        return ["long", "short"]

    return ["long", "short"]


# üî∏ –ó–∞–≥—Ä—É–∑–∫–∞ analysis_id –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏–∑ bins_stat –ø–æ –ø–∞—Ä–µ –∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—é
async def _load_analysis_ids_for_pair_direction(
    pg,
    scenario_id: int,
    signal_id: int,
    direction: str,
) -> List[int]:
    async with pg.acquire() as conn:
        rows = await conn.fetch(
            """
            SELECT DISTINCT analysis_id
            FROM bt_analysis_bins_stat
            WHERE scenario_id = $1
              AND signal_id   = $2
              AND direction   = $3
            ORDER BY analysis_id
            """,
            scenario_id,
            signal_id,
            direction,
        )
    return [int(r["analysis_id"]) for r in rows]


# üî∏ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–µ–ø–æ–∑–∏—Ç–∞ —Å—Ü–µ–Ω–∞—Ä–∏—è –∏–∑ bt_scenario_parameters (param_name='deposit')
async def _load_scenario_deposit(
    pg,
    scenario_id: int,
) -> Optional[Decimal]:
    async with pg.acquire() as conn:
        row = await conn.fetchrow(
            """
            SELECT param_value
            FROM bt_scenario_parameters
            WHERE scenario_id = $1
              AND param_name  = 'deposit'
            LIMIT 1
            """,
            scenario_id,
        )

    if not row:
        return None

    dep = _safe_decimal(row["param_value"])
    if dep <= 0:
        return None

    return dep


# üî∏ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ Decimal
def _safe_decimal(value: Any) -> Decimal:
    if isinstance(value, Decimal):
        return value
    try:
        return Decimal(str(value))
    except (InvalidOperation, TypeError, ValueError):
        return Decimal("0")


# üî∏ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: Decimal –∏–ª–∏ None (–µ—Å–ª–∏ value is None)
def _safe_decimal_or_none(value: Any) -> Optional[Decimal]:
    if value is None:
        return None
    if isinstance(value, Decimal):
        return value
    try:
        return Decimal(str(value))
    except (InvalidOperation, TypeError, ValueError):
        return None


# üî∏ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è Decimal –¥–æ 4 –∑–Ω–∞–∫–æ–≤ (–≤–Ω–∏–∑ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ—Å—Ç–∏)
def _q_decimal(value: Decimal) -> Decimal:
    return value.quantize(Decimal("0.0001"), rounding=ROUND_DOWN)