# bt_analysis_main.py ‚Äî –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤ backtester_v1

import asyncio
import logging
from datetime import datetime
from decimal import Decimal
from typing import Dict, Any, List, Optional, Callable, Awaitable, Tuple

# üî∏ –ö–æ–Ω—Ñ–∏–≥ –∏ –∫–µ—à–∏ backtester_v1
from backtester_config import (
    get_analysis_connections_for_scenario_signal,
    get_analysis_instance,
)

# üî∏ –¢–∏–ø –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞:
#    (analysis_cfg, analysis_ctx, pg_pool, redis_client) -> {"rows": [...], "summary": {...}}
AnalysisHandler = Callable[
    [Dict[str, Any], Dict[str, Any], Any, Any],
    Awaitable[Dict[str, Any]]
]

# üî∏ –í–æ—Ä–∫–µ—Ä—ã –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤ (–∏–∑ –ø–∞–∫–µ—Ç–∞ analysis/)
from analysis.bt_analysis_rsi_bin import run_rsi_bin_analysis
from analysis.bt_analysis_mfi_bin import run_mfi_bin_analysis
from analysis.bt_analysis_adx_bin import run_adx_bin_analysis
from analysis.bt_analysis_bb_band_bin import run_bb_band_bin_analysis
from analysis.bt_analysis_lr_band_bin import run_lr_band_bin_analysis
from analysis.bt_analysis_lr_angle_bin import run_lr_angle_bin_analysis
from analysis.bt_analysis_atr_bin import run_atr_bin_analysis
from analysis.bt_analysis_dmigap_bin import run_dmigap_bin_analysis


# üî∏ –†–µ–µ—Å—Ç—Ä –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤: (family_key, key) ‚Üí handler
ANALYSIS_HANDLERS: Dict[Tuple[str, str], AnalysisHandler] = {
    ("rsi", "rsi_bin"): run_rsi_bin_analysis,
    ("mfi", "mfi_bin"): run_mfi_bin_analysis,
    ("adx_dmi", "adx_bin"): run_adx_bin_analysis,
    ("bb", "bb_band_bin"): run_bb_band_bin_analysis,
    ("lr", "lr_band_bin"): run_lr_band_bin_analysis,
    ("lr", "lr_angle_bin"): run_lr_angle_bin_analysis,
    ("atr", "atr_bin"): run_atr_bin_analysis,
    ("adx_dmi", "dmigap_bin"): run_dmigap_bin_analysis,
}

# üî∏ –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã —Å—Ç—Ä–∏–º–∞ –∞–Ω–∞–ª–∏–∑–∞
ANALYSIS_STREAM_KEY = "bt:postproc:ready"
ANALYSIS_CONSUMER_GROUP = "bt_analysis"
ANALYSIS_CONSUMER_NAME = "bt_analysis_main"

# üî∏ –°—Ç—Ä–∏–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞
ANALYSIS_READY_STREAM_KEY = "bt:analysis:ready"

# üî∏ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —á—Ç–µ–Ω–∏—è —Å—Ç—Ä–∏–º–∞
ANALYSIS_STREAM_BATCH_SIZE = 10
ANALYSIS_STREAM_BLOCK_MS = 5000

# üî∏ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤
ANALYSIS_MAX_CONCURRENCY = 12

# üî∏ –ö–µ—à –ø–æ—Å–ª–µ–¥–Ω–∏—Ö finished_at –ø–æ (scenario_id, signal_id) –¥–ª—è –æ—Ç—Å–µ—á–∫–∏ –¥—É–±–ª–µ–π
_last_postproc_finished_at: Dict[Tuple[int, int], datetime] = {}

log = logging.getLogger("BT_ANALYSIS_MAIN")


# üî∏ –ü—É–±–ª–∏—á–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞: –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤
async def run_bt_analysis_orchestrator(pg, redis):
    log.debug("BT_ANALYSIS_MAIN: –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤ –∑–∞–ø—É—â–µ–Ω")

    await _ensure_consumer_group(redis)

    # –æ–±—â–∏–π —Å–µ–º–∞—Ñ–æ—Ä –¥–ª—è –≤—Å–µ—Ö –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤
    analysis_sema = asyncio.Semaphore(ANALYSIS_MAX_CONCURRENCY)

    # –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —á—Ç–µ–Ω–∏—è —Å—Ç—Ä–∏–º–∞ –∏ –∑–∞–ø—É—Å–∫–∞ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤
    while True:
        try:
            messages = await _read_from_stream(redis)

            if not messages:
                continue

            total_msgs = 0
            total_pairs = 0
            total_analyses_planned = 0
            total_analyses_ok = 0
            total_analyses_failed = 0
            total_rows_inserted = 0
            total_bins_rows = 0

            for stream_key, entries in messages:
                if stream_key != ANALYSIS_STREAM_KEY:
                    # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º —á—É–∂–∏–µ —Å—Ç—Ä–∏–º—ã
                    continue

                for entry_id, fields in entries:
                    total_msgs += 1

                    ctx = _parse_postproc_message(fields)
                    if not ctx:
                        # –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –ø–æ–ª—è ‚Äî ACK –∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                        await redis.xack(ANALYSIS_STREAM_KEY, ANALYSIS_CONSUMER_GROUP, entry_id)
                        continue

                    scenario_id = ctx["scenario_id"]
                    signal_id = ctx["signal_id"]
                    finished_at = ctx["finished_at"]

                    pair_key = (scenario_id, signal_id)
                    last_finished = _last_postproc_finished_at.get(pair_key)

                    # –æ—Ç—Å–µ—á–∫–∞ –¥—É–±–ª–µ–π –ø–æ —Ä–∞–≤–Ω–æ–º—É finished_at
                    if last_finished is not None and last_finished == finished_at:
                        log.debug(
                            "BT_ANALYSIS_MAIN: –¥—É–±–ª–∏–∫–∞—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è scenario_id=%s, signal_id=%s, "
                            "finished_at=%s, stream_id=%s ‚Äî –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã –Ω–µ –∑–∞–ø—É—Å–∫–∞—é—Ç—Å—è",
                            scenario_id,
                            signal_id,
                            finished_at,
                            entry_id,
                        )
                        await redis.xack(ANALYSIS_STREAM_KEY, ANALYSIS_CONSUMER_GROUP, entry_id)
                        continue

                    _last_postproc_finished_at[pair_key] = finished_at
                    total_pairs += 1

                    log.debug(
                        "BT_ANALYSIS_MAIN: –ø–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ "
                        "scenario_id=%s, signal_id=%s, finished_at=%s, stream_id=%s",
                        scenario_id,
                        signal_id,
                        finished_at,
                        entry_id,
                    )

                    # –ø–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å–≤—è–∑–∫–∏ —Å—Ü–µ–Ω–∞—Ä–∏–π ‚Üî —Å–∏–≥–Ω–∞–ª ‚Üî –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
                    links = get_analysis_connections_for_scenario_signal(scenario_id, signal_id)
                    if not links:
                        log.debug(
                            "BT_ANALYSIS_MAIN: –¥–ª—è scenario_id=%s, signal_id=%s –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–≤—è–∑–æ–∫ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤, "
                            "—Å–æ–æ–±—â–µ–Ω–∏–µ %s –±—É–¥–µ—Ç –ø–æ–º–µ—á–µ–Ω–æ –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ",
                            scenario_id,
                            signal_id,
                            entry_id,
                        )
                        # –ø—É–±–ª–∏–∫—É–µ–º –ø—É—Å—Ç–æ–µ —Å–æ–±—ã—Ç–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞
                        await _publish_analysis_ready(
                            redis=redis,
                            scenario_id=scenario_id,
                            signal_id=signal_id,
                            analyses_total=0,
                            analyses_ok=0,
                            analyses_failed=0,
                            rows_inserted=0,
                            bins_rows=0,
                        )
                        await redis.xack(ANALYSIS_STREAM_KEY, ANALYSIS_CONSUMER_GROUP, entry_id)
                        continue

                    # —Ñ–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤ –¥–ª—è –∑–∞–ø—É—Å–∫–∞
                    analyses_to_run: List[Dict[str, Any]] = []
                    for link in links:
                        analysis_id = link.get("analysis_id")
                        analysis_cfg = get_analysis_instance(analysis_id)
                        if not analysis_cfg:
                            log.warning(
                                "BT_ANALYSIS_MAIN: –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä id=%s –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–µ—à–µ, "
                                "scenario_id=%s, signal_id=%s, —Å–æ–æ–±—â–µ–Ω–∏–µ=%s",
                                analysis_id,
                                scenario_id,
                                signal_id,
                                entry_id,
                            )
                            continue

                        if not analysis_cfg.get("enabled"):
                            log.debug(
                                "BT_ANALYSIS_MAIN: –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä id=%s –æ—Ç–∫–ª—é—á—ë–Ω, "
                                "scenario_id=%s, signal_id=%s, —Å–æ–æ–±—â–µ–Ω–∏–µ=%s",
                                analysis_id,
                                scenario_id,
                                signal_id,
                                entry_id,
                            )
                            continue

                        analyses_to_run.append(analysis_cfg)

                    if not analyses_to_run:
                        log.debug(
                            "BT_ANALYSIS_MAIN: –¥–ª—è scenario_id=%s, signal_id=%s –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤ "
                            "(–ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ –∫–µ—à—É), —Å–æ–æ–±—â–µ–Ω–∏–µ %s –±—É–¥–µ—Ç –ø–æ–º–µ—á–µ–Ω–æ –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ",
                            scenario_id,
                            signal_id,
                            entry_id,
                        )
                        await _publish_analysis_ready(
                            redis=redis,
                            scenario_id=scenario_id,
                            signal_id=signal_id,
                            analyses_total=0,
                            analyses_ok=0,
                            analyses_failed=0,
                            rows_inserted=0,
                            bins_rows=0,
                        )
                        await redis.xack(ANALYSIS_STREAM_KEY, ANALYSIS_CONSUMER_GROUP, entry_id)
                        continue

                    # –∑–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã –¥–ª—è –¥–∞–Ω–Ω–æ–π –ø–∞—Ä—ã —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –ø–æ —Å–µ–º–∞—Ñ–æ—Ä—É
                    tasks: List[asyncio.Task] = []
                    for analysis in analyses_to_run:
                        task = asyncio.create_task(
                            _run_analysis_with_semaphore(
                                analysis=analysis,
                                scenario_id=scenario_id,
                                signal_id=signal_id,
                                pg=pg,
                                redis=redis,
                                sema=analysis_sema,
                            ),
                            name=f"BT_ANALYSIS_{analysis.get('id')}_SC_{scenario_id}_SIG_{signal_id}",
                        )
                        tasks.append(task)

                    results = await asyncio.gather(*tasks, return_exceptions=True)

                    analyses_total = len(analyses_to_run)
                    analyses_ok = 0
                    analyses_failed = 0
                    rows_inserted = 0
                    bins_rows_for_pair = 0

                    for res in results:
                        if isinstance(res, Exception):
                            analyses_failed += 1
                            continue

                        status = res.get("status")
                        inserted = res.get("rows_inserted", 0)
                        bins_rows = res.get("bins_rows", 0)

                        if status == "ok":
                            analyses_ok += 1
                        elif status == "skipped":
                            # —Å—á–∏—Ç–∞–µ–º –∫–∞–∫ "—É—Å–ø–µ—à–Ω–æ, –Ω–æ –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö"
                            analyses_ok += 1
                        else:
                            analyses_failed += 1

                        rows_inserted += inserted
                        bins_rows_for_pair += bins_rows

                    total_analyses_planned += analyses_total
                    total_analyses_ok += analyses_ok
                    total_analyses_failed += analyses_failed
                    total_rows_inserted += rows_inserted
                    total_bins_rows += bins_rows_for_pair

                    log.info(
                        "BT_ANALYSIS_MAIN: scenario_id=%s, signal_id=%s ‚Äî –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤ –≤—Å–µ–≥–æ=%s, "
                        "—É—Å–ø–µ—à–Ω–æ=%s, —Å –æ—à–∏–±–∫–∞–º–∏=%s, —Å—Ç—Ä–æ–∫ –≤ raw=%s, —Å—Ç—Ä–æ–∫ –≤ bins_stat=%s",
                        scenario_id,
                        signal_id,
                        analyses_total,
                        analyses_ok,
                        analyses_failed,
                        rows_inserted,
                        bins_rows_for_pair,
                    )

                    # –ø—É–±–ª–∏–∫—É–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞ –≤ bt:analysis:ready
                    await _publish_analysis_ready(
                        redis=redis,
                        scenario_id=scenario_id,
                        signal_id=signal_id,
                        analyses_total=analyses_total,
                        analyses_ok=analyses_ok,
                        analyses_failed=analyses_failed,
                        rows_inserted=rows_inserted,
                        bins_rows=bins_rows_for_pair,
                    )

                    # –ø–æ–º–µ—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤
                    await redis.xack(ANALYSIS_STREAM_KEY, ANALYSIS_CONSUMER_GROUP, entry_id)

            log.debug(
                "BT_ANALYSIS_MAIN: –ø–∞–∫–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω ‚Äî —Å–æ–æ–±—â–µ–Ω–∏–π=%s, –ø–∞—Ä=%s, "
                "–∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤_–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–ª–æ—Å—å=%s, —É—Å–ø–µ—Ö–æ–≤=%s, –æ—à–∏–±–æ–∫=%s, —Å—Ç—Ä–æ–∫_raw=%s, —Å—Ç—Ä–æ–∫_bins=%s",
                total_msgs,
                total_pairs,
                total_analyses_planned,
                total_analyses_ok,
                total_analyses_failed,
                total_rows_inserted,
                total_bins_rows,
            )
            log.info(
                "BT_ANALYSIS_MAIN: –∏—Ç–æ–≥ –ø–æ –ø–∞–∫–µ—Ç—É ‚Äî —Å–æ–æ–±—â–µ–Ω–∏–π=%s, –ø–∞—Ä=%s, "
                "–∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤ –≤—Å–µ–≥–æ=%s, —É—Å–ø–µ—à–Ω–æ=%s, —Å –æ—à–∏–±–∫–∞–º–∏=%s, —Å—Ç—Ä–æ–∫ –≤ raw=%s, —Å—Ç—Ä–æ–∫ –≤ bins_stat=%s",
                total_msgs,
                total_pairs,
                total_analyses_planned,
                total_analyses_ok,
                total_analyses_failed,
                total_rows_inserted,
                total_bins_rows,
            )

        except Exception as e:
            log.error(
                "BT_ANALYSIS_MAIN: –æ—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞: %s",
                e,
                exc_info=True,
            )
            # –Ω–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π, —á—Ç–æ–±—ã –Ω–µ –∫—Ä—É—Ç–∏—Ç—å CPU –ø—Ä–∏ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–π –æ—à–∏–±–∫–µ
            await asyncio.sleep(2)


# üî∏ –ü—Ä–æ–≤–µ—Ä–∫–∞/—Å–æ–∑–¥–∞–Ω–∏–µ consumer group –¥–ª—è —Å—Ç—Ä–∏–º–∞ –∞–Ω–∞–ª–∏–∑–∞
async def _ensure_consumer_group(redis) -> None:
    try:
        # –ø—ã—Ç–∞–µ–º—Å—è —Å–æ–∑–¥–∞—Ç—å –≥—Ä—É–ø–ø—É; MKSTREAM —Å–æ–∑–¥–∞—Å—Ç —Å—Ç—Ä–∏–º, –µ—Å–ª–∏ –µ–≥–æ –µ—â—ë –Ω–µ—Ç
        await redis.xgroup_create(
            name=ANALYSIS_STREAM_KEY,
            groupname=ANALYSIS_CONSUMER_GROUP,
            id="$",
            mkstream=True,
        )
        log.debug(
            "BT_ANALYSIS_MAIN: —Å–æ–∑–¥–∞–Ω–∞ consumer group '%s' –¥–ª—è —Å—Ç—Ä–∏–º–∞ '%s'",
            ANALYSIS_CONSUMER_GROUP,
            ANALYSIS_STREAM_KEY,
        )
    except Exception as e:
        msg = str(e)
        if "BUSYGROUP" in msg:
            log.debug(
                "BT_ANALYSIS_MAIN: consumer group '%s' –¥–ª—è —Å—Ç—Ä–∏–º–∞ '%s' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç",
                ANALYSIS_CONSUMER_GROUP,
                ANALYSIS_STREAM_KEY,
            )
        else:
            log.error(
                "BT_ANALYSIS_MAIN: –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ consumer group '%s': %s",
                ANALYSIS_CONSUMER_GROUP,
                e,
                exc_info=True,
            )
            raise


# üî∏ –ß—Ç–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ —Å—Ç—Ä–∏–º–∞ bt:postproc:ready
async def _read_from_stream(redis) -> List[Any]:
    entries = await redis.xreadgroup(
        groupname=ANALYSIS_CONSUMER_GROUP,
        consumername=ANALYSIS_CONSUMER_NAME,
        streams={ANALYSIS_STREAM_KEY: ">"},
        count=ANALYSIS_STREAM_BATCH_SIZE,
        block=ANALYSIS_STREAM_BLOCK_MS,
    )

    if not entries:
        return []

    parsed: List[Any] = []
    for stream_key, messages in entries:
        if isinstance(stream_key, bytes):
            stream_key = stream_key.decode("utf-8")

        stream_entries: List[Any] = []
        for msg_id, fields in messages:
            if isinstance(msg_id, bytes):
                msg_id = msg_id.decode("utf-8")

            str_fields: Dict[str, str] = {}
            for k, v in fields.items():
                key_str = k.decode("utf-8") if isinstance(k, bytes) else str(k)
                val_str = v.decode("utf-8") if isinstance(v, bytes) else str(v)
                str_fields[key_str] = val_str

            stream_entries.append((msg_id, str_fields))

        parsed.append((stream_key, stream_entries))

    return parsed


# üî∏ –†–∞–∑–±–æ—Ä –æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ —Å—Ç—Ä–∏–º–∞ bt:postproc:ready
def _parse_postproc_message(fields: Dict[str, str]) -> Optional[Dict[str, Any]]:
    try:
        scenario_id_str = fields.get("scenario_id")
        signal_id_str = fields.get("signal_id")
        finished_at_str = fields.get("finished_at")

        if not (scenario_id_str and signal_id_str and finished_at_str):
            # –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
            return None

        scenario_id = int(scenario_id_str)
        signal_id = int(signal_id_str)
        finished_at = datetime.fromisoformat(finished_at_str)

        # –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è (processed/skipped/errors) —Å–µ–π—á–∞—Å –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º, –Ω–æ –º–æ–∂–µ–º –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
        return {
            "scenario_id": scenario_id,
            "signal_id": signal_id,
            "finished_at": finished_at,
        }
    except Exception as e:
        log.error(
            "BT_ANALYSIS_MAIN: –æ—à–∏–±–∫–∞ —Ä–∞–∑–±–æ—Ä–∞ —Å–æ–æ–±—â–µ–Ω–∏—è —Å—Ç—Ä–∏–º–∞ bt:postproc:ready: %s, fields=%s",
            e,
            fields,
            exc_info=True,
        )
        return None


# üî∏ –û–±—ë—Ä—Ç–∫–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–¥–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ —Å —Å–µ–º–∞—Ñ–æ—Ä–æ–º
async def _run_analysis_with_semaphore(
    analysis: Dict[str, Any],
    scenario_id: int,
    signal_id: int,
    pg,
    redis,
    sema: asyncio.Semaphore,
) -> Dict[str, Any]:
    async with sema:
        try:
            return await _run_single_analysis(
                analysis=analysis,
                scenario_id=scenario_id,
                signal_id=signal_id,
                pg=pg,
                redis=redis,
            )
        except Exception as e:
            analysis_id = analysis.get("id")
            family_key = analysis.get("family_key")
            key = analysis.get("key")
            log.error(
                "BT_ANALYSIS_MAIN: –æ—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ id=%s (family=%s, key=%s) "
                "–¥–ª—è scenario_id=%s, signal_id=%s: %s",
                analysis_id,
                family_key,
                key,
                scenario_id,
                signal_id,
                e,
                exc_info=True,
            )
            return {
                "analysis_id": analysis_id,
                "status": "error",
                "rows_inserted": 0,
                "bins_rows": 0,
            }


# üî∏ –ó–∞–ø—É—Å–∫ –æ–¥–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞: –æ—á–∏—Å—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –∑–∞–ø—É—Å–∫ –≤–æ—Ä–∫–µ—Ä–∞, –∑–∞–ø–∏—Å—å raw –∏ –ø–µ—Ä–µ—Å—á—ë—Ç bin-—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
async def _run_single_analysis(
    analysis: Dict[str, Any],
    scenario_id: int,
    signal_id: int,
    pg,
    redis,
) -> Dict[str, Any]:
    analysis_id = analysis.get("id")
    family_key = str(analysis.get("family_key") or "").strip()
    analysis_key = str(analysis.get("key") or "").strip()
    name = analysis.get("name")
    params = analysis.get("params") or {}

    handler = ANALYSIS_HANDLERS.get((family_key, analysis_key))
    if handler is None:
        log.debug(
            "BT_ANALYSIS_MAIN: –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä id=%s (family=%s, key=%s, name=%s) –ø–æ–∫–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è —Ä–µ–µ—Å—Ç—Ä–æ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤",
            analysis_id,
            family_key,
            analysis_key,
            name,
        )
        return {
            "analysis_id": analysis_id,
            "status": "skipped",
            "rows_inserted": 0,
            "bins_rows": 0,
        }

    # indicator_param ‚Äî –Ω–∞–ø—Ä–∏–º–µ—Ä rsi14 / rsi21 / lr50_angle –∏ —Ç.–ø.
    indicator_param_cfg = params.get("param_name")
    if indicator_param_cfg is not None:
        indicator_param = str(indicator_param_cfg.get("value") or "").strip() or None
    else:
        indicator_param = None

    log.debug(
        "BT_ANALYSIS_MAIN: –∑–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ id=%s (family=%s, key=%s, name=%s, indicator_param=%s) "
        "–¥–ª—è scenario_id=%s, signal_id=%s",
        analysis_id,
        family_key,
        analysis_key,
        name,
        indicator_param,
        scenario_id,
        signal_id,
    )

    # –æ—á–∏—Å—Ç–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –∏ –ø–∞—Ä—ã (—Å—Ü–µ–Ω–∞—Ä–∏–π, —Å–∏–≥–Ω–∞–ª)
    async with pg.acquire() as conn:
        await conn.execute(
            """
            DELETE FROM bt_analysis_positions_raw
            WHERE analysis_id = $1
              AND scenario_id = $2
              AND signal_id = $3
            """,
            analysis_id,
            scenario_id,
            signal_id,
        )
        await conn.execute(
            """
            DELETE FROM bt_analysis_bins_stat
            WHERE analysis_id = $1
              AND scenario_id = $2
              AND signal_id = $3
            """,
            analysis_id,
            scenario_id,
            signal_id,
        )

    # –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
    analysis_ctx: Dict[str, Any] = {
        "scenario_id": scenario_id,
        "signal_id": signal_id,
    }

    # –∑–∞–ø—É—Å–∫–∞–µ–º –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫—É –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
    result: Dict[str, Any] = await handler(analysis, analysis_ctx, pg, redis)
    rows: List[Dict[str, Any]] = (result or {}).get("rows") or []

    if not rows:
        log.debug(
            "BT_ANALYSIS_MAIN: –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä id=%s (family=%s, key=%s) –¥–ª—è scenario_id=%s, signal_id=%s "
            "–Ω–µ –≤–µ—Ä–Ω—É–ª —Å—Ç—Ä–æ–∫ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ (raw)",
            analysis_id,
            family_key,
            analysis_key,
            scenario_id,
            signal_id,
        )
        return {
            "analysis_id": analysis_id,
            "status": "ok",
            "rows_inserted": 0,
            "bins_rows": 0,
        }

    # –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–∞—Å—Å–æ–≤–æ–π –≤—Å—Ç–∞–≤–∫–∏ –≤ bt_analysis_positions_raw
    to_insert: List[Tuple[Any, ...]] = []
    for row in rows:
        position_uid = row.get("position_uid")
        timeframe = row.get("timeframe")
        direction = row.get("direction")
        bin_name = row.get("bin_name")
        value = row.get("value")
        pnl_abs = row.get("pnl_abs")

        if not position_uid or timeframe is None or direction is None or bin_name is None:
            # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
            log.debug(
                "BT_ANALYSIS_MAIN: –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä id=%s (family=%s, key=%s) –≤–µ—Ä–Ω—É–ª –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—É—é —Å—Ç—Ä–æ–∫—É, "
                "–æ–Ω–∞ –±—É–¥–µ—Ç –ø—Ä–æ–ø—É—â–µ–Ω–∞: %s",
                analysis_id,
                family_key,
                analysis_key,
                row,
            )
            continue

        to_insert.append(
            (
                analysis_id,
                position_uid,
                scenario_id,
                signal_id,
                family_key,
                analysis_key,
                timeframe,
                direction,
                bin_name,
                value,
                pnl_abs,
            )
        )

    inserted = 0
    bins_rows = 0

    if to_insert:
        async with pg.acquire() as conn:
            await conn.executemany(
                """
                INSERT INTO bt_analysis_positions_raw (
                    analysis_id,
                    position_uid,
                    scenario_id,
                    signal_id,
                    family_key,
                    "key",
                    timeframe,
                    direction,
                    bin_name,
                    value,
                    pnl_abs
                )
                VALUES (
                    $1, $2, $3, $4,
                    $5, $6, $7, $8,
                    $9, $10, $11
                )
                """,
                to_insert,
            )
        inserted = len(to_insert)

        # –ø–µ—Ä–µ—Å—á—ë—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –±–∏–Ω–Ω–∞–º –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –∏ –ø–∞—Ä—ã
        bins_rows, trades_total = await _recalc_bins_stat(
            pg=pg,
            analysis_id=analysis_id,
            scenario_id=scenario_id,
            signal_id=signal_id,
            indicator_param=indicator_param,
        )

        log.info(
            "BT_ANALYSIS_MAIN: –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä id=%s (family=%s, key=%s, name=%s) "
            "–¥–ª—è scenario_id=%s, signal_id=%s –∑–∞–ø–∏—Å–∞–ª raw —Å—Ç—Ä–æ–∫=%s –∏ bins —Å—Ç—Ä–æ–∫=%s (trades_total=%s)",
            analysis_id,
            family_key,
            analysis_key,
            name,
            scenario_id,
            signal_id,
            inserted,
            bins_rows,
            trades_total,
        )
    else:
        log.debug(
            "BT_ANALYSIS_MAIN: –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä id=%s (family=%s, key=%s, name=%s) –¥–ª—è scenario_id=%s, signal_id=%s "
            "–Ω–µ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–ª –≤–∞–ª–∏–¥–Ω—ã—Ö —Å—Ç—Ä–æ–∫ raw –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏",
            analysis_id,
            family_key,
            analysis_key,
            name,
            scenario_id,
            signal_id,
        )

    return {
        "analysis_id": analysis_id,
        "status": "ok",
        "rows_inserted": inserted,
        "bins_rows": bins_rows,
    }


# üî∏ –ü–µ—Ä–µ—Å—á—ë—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –±–∏–Ω–Ω–∞–º –≤ bt_analysis_bins_stat
async def _recalc_bins_stat(
    pg,
    analysis_id: int,
    scenario_id: int,
    signal_id: int,
    indicator_param: Optional[str],
) -> Tuple[int, int]:
    async with pg.acquire() as conn:
        rows = await conn.fetch(
            """
            SELECT
                timeframe,
                direction,
                bin_name,
                COUNT(*)                                         AS trades,
                COUNT(*) FILTER (WHERE pnl_abs > 0)              AS wins,
                COALESCE(SUM(pnl_abs), 0)                        AS pnl_abs_total
            FROM bt_analysis_positions_raw
            WHERE analysis_id = $1
              AND scenario_id = $2
              AND signal_id   = $3
            GROUP BY timeframe, direction, bin_name
            """,
            analysis_id,
            scenario_id,
            signal_id,
        )

        if not rows:
            log.debug(
                "BT_ANALYSIS_MAIN: –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ id=%s, scenario_id=%s, signal_id=%s –Ω–µ—Ç —Å—Ç—Ä–æ–∫ raw –¥–ª—è –ø–µ—Ä–µ—Å—á—ë—Ç–∞ bins_stat",
                analysis_id,
                scenario_id,
                signal_id,
            )
            return 0, 0

        # —É–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Å—Ç—Ä–æ–∫–∏ bins_stat –¥–ª—è —ç—Ç–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏ –ø–∞—Ä—ã
        await conn.execute(
            """
            DELETE FROM bt_analysis_bins_stat
            WHERE analysis_id = $1
              AND scenario_id = $2
              AND signal_id   = $3
            """,
            analysis_id,
            scenario_id,
            signal_id,
        )

        to_insert: List[Tuple[Any, ...]] = []
        total_trades = 0

        for r in rows:
            timeframe = r["timeframe"]
            direction = r["direction"]
            bin_name = r["bin_name"]
            trades = int(r["trades"])
            wins = int(r["wins"])
            pnl_abs_total = Decimal(str(r["pnl_abs_total"]))

            total_trades += trades

            if trades > 0:
                winrate = Decimal(wins) / Decimal(trades)
            else:
                winrate = Decimal("0")

            # –ª—ë–≥–∫–∞—è –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏
            pnl_abs_q = pnl_abs_total.quantize(Decimal("0.0001"))
            winrate_q = winrate.quantize(Decimal("0.0001"))

            to_insert.append(
                (
                    analysis_id,
                    scenario_id,
                    signal_id,
                    indicator_param,
                    timeframe,
                    direction,
                    bin_name,
                    trades,
                    pnl_abs_q,
                    winrate_q,
                )
            )

        await conn.executemany(
            """
            INSERT INTO bt_analysis_bins_stat (
                analysis_id,
                scenario_id,
                signal_id,
                indicator_param,
                timeframe,
                direction,
                bin_name,
                trades,
                pnl_abs,
                winrate
            )
            VALUES (
                $1, $2, $3, $4,
                $5, $6, $7,
                $8, $9, $10
            )
            """,
            to_insert,
        )

    bins_count = len(to_insert)

    log.debug(
        "BT_ANALYSIS_MAIN: –ø–µ—Ä–µ—Å—á–∏—Ç–∞–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ bins_stat –¥–ª—è analysis_id=%s, scenario_id=%s, signal_id=%s ‚Äî "
        "–±–∏–Ω–æ–≤=%s, trades_total=%s",
        analysis_id,
        scenario_id,
        signal_id,
        bins_count,
        total_trades,
    )
    return bins_count, total_trades


# üî∏ –ü—É–±–ª–∏–∫–∞—Ü–∏—è –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ–±—ã—Ç–∏—è –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞ –≤ bt:analysis:ready
async def _publish_analysis_ready(
    redis,
    scenario_id: int,
    signal_id: int,
    analyses_total: int,
    analyses_ok: int,
    analyses_failed: int,
    rows_inserted: int,
    bins_rows: int,
) -> None:
    finished_at = datetime.utcnow()

    try:
        await redis.xadd(
            ANALYSIS_READY_STREAM_KEY,
            {
                "scenario_id": str(scenario_id),
                "signal_id": str(signal_id),
                "analyses_total": str(analyses_total),
                "analyses_ok": str(analyses_ok),
                "analyses_failed": str(analyses_failed),
                "rows_raw": str(rows_inserted),
                "rows_bins": str(bins_rows),
                "finished_at": finished_at.isoformat(),
            },
        )
        log.debug(
            "BT_ANALYSIS_MAIN: –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ —Å–æ–±—ã—Ç–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞ –≤ —Å—Ç—Ä–∏–º '%s' "
            "–¥–ª—è scenario_id=%s, signal_id=%s, analyses_total=%s, analyses_ok=%s, "
            "analyses_failed=%s, rows_raw=%s, rows_bins=%s, finished_at=%s",
            ANALYSIS_READY_STREAM_KEY,
            scenario_id,
            signal_id,
            analyses_total,
            analyses_ok,
            analyses_failed,
            rows_inserted,
            bins_rows,
            finished_at,
        )
    except Exception as e:
        log.error(
            "BT_ANALYSIS_MAIN: –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å —Å–æ–±—ã—Ç–∏–µ –≤ —Å—Ç—Ä–∏–º '%s' "
            "–¥–ª—è scenario_id=%s, signal_id=%s: %s",
            ANALYSIS_READY_STREAM_KEY,
            scenario_id,
            signal_id,
            e,
            exc_info=True,
        )