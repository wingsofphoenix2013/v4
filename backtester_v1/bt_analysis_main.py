# bt_analysis_main.py ‚Äî –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤ (feature bins) –¥–ª—è backtester_v1

import asyncio
import logging
from datetime import datetime
from typing import Any, Dict, List, Optional

# üî∏ –ö–æ–Ω—Ñ–∏–≥ –∏ –∫–µ—à–∏ backtester_v1 (–∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã –∏ —Å–≤—è–∑–∫–∏)
from backtester_config import (
    get_analysis_instances_for_scenario_signal,
)

# üî∏ –í–æ—Ä–∫–µ—Ä—ã —Å–µ–º–µ–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤
from bt_analysis_rsi import run_analysis_rsi
from bt_analysis_adx import run_analysis_adx
from bt_analysis_ema import run_analysis_ema
from bt_analysis_atr import run_analysis_atr
from bt_analysis_supertrend import run_analysis_supertrend

# üî∏ –†–µ–µ—Å—Ç—Ä –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ —Å–µ–º–µ–π—Å—Ç–≤ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤
FAMILY_ANALYSIS_HANDLERS = {
    "rsi": run_analysis_rsi,
    "adx": run_analysis_adx,
    "ema": run_analysis_ema,
    "atr": run_analysis_atr,
    "supertrend": run_analysis_supertrend,
}

# üî∏ –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã —Å—Ç—Ä–∏–º–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
ANALYSIS_STREAM_KEY = "bt:postproc:ready"
ANALYSIS_CONSUMER_GROUP = "bt_analysis"
ANALYSIS_CONSUMER_NAME = "bt_analysis_main"

# üî∏ –°—Ç—Ä–∏–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞ (–ø–æ—Å–ª–µ –≤—Å–µ—Ö –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤ —Å–µ–º—å–∏)
ANALYSIS_READY_STREAM_KEY = "bt:analysis:ready"

# üî∏ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —á—Ç–µ–Ω–∏—è —Å—Ç—Ä–∏–º–∞ bt:postproc:ready
ANALYSIS_STREAM_BATCH_SIZE = 10      # —Å–∫–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–π —á–∏—Ç–∞–µ–º –∑–∞ –æ–¥–∏–Ω –∑–∞—Ö–æ–¥
ANALYSIS_STREAM_BLOCK_MS = 5000      # –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ —á—Ç–µ–Ω–∏—è (–º—Å)

log = logging.getLogger("BT_ANALYSIS_MAIN")


# üî∏ –ü—É–±–ª–∏—á–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞: –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∏—á
async def run_bt_analysis_orchestrator(pg, redis):
    log.debug("BT_ANALYSIS_MAIN: –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–ø—É—â–µ–Ω")

    # –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º consumer group –¥–ª—è —Å—Ç—Ä–∏–º–∞ bt:postproc:ready
    await _ensure_consumer_group(redis)

    # –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —á—Ç–µ–Ω–∏—è —Å—Ç—Ä–∏–º–∞ –∏ –∑–∞–ø—É—Å–∫–∞ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤
    while True:
        try:
            messages = await _read_from_stream(redis)

            if not messages:
                continue

            total_msgs = 0
            total_tasks_started = 0
            total_pairs = 0

            for stream_key, entries in messages:
                if stream_key != ANALYSIS_STREAM_KEY:
                    # –∑–∞—â–∏—â–∞–µ–º—Å—è –æ—Ç —á—É–∂–∏—Ö —Å—Ç—Ä–∏–º–æ–≤ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
                    continue

                for entry_id, fields in entries:
                    total_msgs += 1

                    ctx = _parse_analysis_message(fields)
                    if not ctx:
                        # –Ω–µ —É–¥–∞–ª–æ—Å—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Äî ACK –∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                        await redis.xack(ANALYSIS_STREAM_KEY, ANALYSIS_CONSUMER_GROUP, entry_id)
                        continue

                    scenario_id = ctx["scenario_id"]
                    signal_id = ctx["signal_id"]

                    log.debug(
                        "BT_ANALYSIS_MAIN: –ø–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ "
                        "scenario_id=%s, signal_id=%s, finished_at=%s, stream_id=%s",
                        scenario_id,
                        signal_id,
                        ctx["finished_at"],
                        entry_id,
                    )

                    # –ø–æ–ª—É—á–∞–µ–º –≤—Å–µ –≤–∫–ª—é—á—ë–Ω–Ω—ã–µ –∏–Ω—Å—Ç–∞–Ω—Å—ã –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤ –¥–ª—è —ç—Ç–æ–π –ø–∞—Ä—ã
                    analysis_instances = get_analysis_instances_for_scenario_signal(
                        scenario_id=scenario_id,
                        signal_id=signal_id,
                    )

                    if not analysis_instances:
                        log.debug(
                            "BT_ANALYSIS_MAIN: –¥–ª—è scenario_id=%s, signal_id=%s –Ω–µ—Ç –≤–∫–ª—é—á—ë–Ω–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤, "
                            "—Å–æ–æ–±—â–µ–Ω–∏–µ %s –ø–æ–º–µ—á–µ–Ω–æ –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ",
                            scenario_id,
                            signal_id,
                            entry_id,
                        )
                        await redis.xack(ANALYSIS_STREAM_KEY, ANALYSIS_CONSUMER_GROUP, entry_id)
                        continue

                    # –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –∏–Ω—Å—Ç–∞–Ω—Å—ã –ø–æ —Å–µ–º—å–µ (family_key)
                    instances_by_family: Dict[str, List[Dict[str, Any]]] = {}
                    for inst in analysis_instances:
                        family_key = inst.get("family_key")
                        if not family_key:
                            continue
                        instances_by_family.setdefault(family_key, []).append(inst)

                    started_for_message = 0

                    for family_key, family_instances in instances_by_family.items():
                        asyncio.create_task(
                            _run_family_worker(
                                family_key=family_key,
                                instances=family_instances,
                                scenario_id=scenario_id,
                                signal_id=signal_id,
                                pg=pg,
                                redis=redis,
                            ),
                            name=f"BT_ANALYSIS_{family_key.upper()}_SC{scenario_id}_SIG{signal_id}",
                        )
                        started_for_message += 1
                        total_tasks_started += 1
                        total_pairs += len(family_instances)

                    # –ø–æ–º–µ—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ
                    await redis.xack(ANALYSIS_STREAM_KEY, ANALYSIS_CONSUMER_GROUP, entry_id)

                    log.debug(
                        "BT_ANALYSIS_MAIN: —Å–æ–æ–±—â–µ–Ω–∏–µ stream_id=%s –¥–ª—è scenario_id=%s, signal_id=%s "
                        "–æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ, —Å–µ–º–µ–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤ –∑–∞–ø—É—â–µ–Ω–æ=%s",
                        entry_id,
                        scenario_id,
                        signal_id,
                        started_for_message,
                    )

            log.debug(
                "BT_ANALYSIS_MAIN: –ø–∞–∫–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω ‚Äî —Å–æ–æ–±—â–µ–Ω–∏–π=%s, —Å–µ–º–µ–π_–∑–∞–ø—É—Å–∫–æ–≤=%s, "
                "–∏–Ω—Å—Ç–∞–Ω—Å–æ–≤_–∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤=%s",
                total_msgs,
                total_tasks_started,
                total_pairs,
            )

        except Exception as e:
            log.error(
                "BT_ANALYSIS_MAIN: –æ—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞: %s",
                e,
                exc_info=True,
            )
            # –Ω–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π, —á—Ç–æ–±—ã –Ω–µ –∫—Ä—É—Ç–∏—Ç—å CPU –ø—Ä–∏ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–π –æ—à–∏–±–∫–µ
            await asyncio.sleep(2)


# üî∏ –ü—Ä–æ–≤–µ—Ä–∫–∞/—Å–æ–∑–¥–∞–Ω–∏–µ consumer group –¥–ª—è —Å—Ç—Ä–∏–º–∞ –∞–Ω–∞–ª–∏–∑–∞
async def _ensure_consumer_group(redis) -> None:
    try:
        # MKSTREAM —Å–æ–∑–¥–∞—Å—Ç —Å—Ç—Ä–∏–º, –µ—Å–ª–∏ –µ–≥–æ –µ—â—ë –Ω–µ—Ç
        await redis.xgroup_create(
            name=ANALYSIS_STREAM_KEY,
            groupname=ANALYSIS_CONSUMER_GROUP,
            id="$",
            mkstream=True,
        )
        log.debug(
            "BT_ANALYSIS_MAIN: —Å–æ–∑–¥–∞–Ω–∞ consumer group '%s' –¥–ª—è —Å—Ç—Ä–∏–º–∞ '%s'",
            ANALYSIS_CONSUMER_GROUP,
            ANALYSIS_STREAM_KEY,
        )
    except Exception as e:
        msg = str(e)
        if "BUSYGROUP" in msg:
            log.debug(
                "BT_ANALYSIS_MAIN: consumer group '%s' –¥–ª—è —Å—Ç—Ä–∏–º–∞ '%s' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç",
                ANALYSIS_CONSUMER_GROUP,
                ANALYSIS_STREAM_KEY,
            )
        else:
            log.error(
                "BT_ANALYSIS_MAIN: –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ consumer group '%s': %s",
                ANALYSIS_CONSUMER_GROUP,
                e,
                exc_info=True,
            )
            raise


# üî∏ –ß—Ç–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ —Å—Ç—Ä–∏–º–∞ bt:postproc:ready
async def _read_from_stream(redis) -> List[Any]:
    entries = await redis.xreadgroup(
        groupname=ANALYSIS_CONSUMER_GROUP,
        consumername=ANALYSIS_CONSUMER_NAME,
        streams={ANALYSIS_STREAM_KEY: ">"},
        count=ANALYSIS_STREAM_BATCH_SIZE,
        block=ANALYSIS_STREAM_BLOCK_MS,
    )

    if not entries:
        return []

    parsed: List[Any] = []
    for stream_key, messages in entries:
        if isinstance(stream_key, bytes):
            stream_key = stream_key.decode("utf-8")

        stream_entries: List[Any] = []
        for msg_id, fields in messages:
            if isinstance(msg_id, bytes):
                msg_id = msg_id.decode("utf-8")

            str_fields: Dict[str, str] = {}
            for k, v in fields.items():
                key_str = k.decode("utf-8") if isinstance(k, bytes) else str(k)
                val_str = v.decode("utf-8") if isinstance(v, bytes) else str(v)
                str_fields[key_str] = val_str

            stream_entries.append((msg_id, str_fields))

        parsed.append((stream_key, stream_entries))

    return parsed


# üî∏ –†–∞–∑–±–æ—Ä –æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ —Å—Ç—Ä–∏–º–∞ bt:postproc:ready
def _parse_analysis_message(fields: Dict[str, str]) -> Optional[Dict[str, Any]]:
    try:
        scenario_id_str = fields.get("scenario_id")
        signal_id_str = fields.get("signal_id")
        finished_at_str = fields.get("finished_at")

        if not (scenario_id_str and signal_id_str and finished_at_str):
            return None

        scenario_id = int(scenario_id_str)
        signal_id = int(signal_id_str)
        finished_at = datetime.fromisoformat(finished_at_str)

        processed_str = fields.get("processed") or "0"
        skipped_str = fields.get("skipped") or "0"
        errors_str = fields.get("errors") or "0"

        try:
            processed = int(processed_str)
        except Exception:
            processed = 0

        try:
            skipped = int(skipped_str)
        except Exception:
            skipped = 0

        try:
            errors = int(errors_str)
        except Exception:
            errors = 0

        return {
            "scenario_id": scenario_id,
            "signal_id": signal_id,
            "finished_at": finished_at,
            "processed": processed,
            "skipped": skipped,
            "errors": errors,
        }
    except Exception as e:
        log.error(
            "BT_ANALYSIS_MAIN: –æ—à–∏–±–∫–∞ —Ä–∞–∑–±–æ—Ä–∞ —Å–æ–æ–±—â–µ–Ω–∏—è —Å—Ç—Ä–∏–º–∞ bt:postproc:ready: %s, fields=%s",
            e,
            fields,
            exc_info=True,
        )
        return None

# üî∏ –î–∏—Å–ø–µ—Ç—á–µ—Ä –≤–æ—Ä–∫–µ—Ä–æ–≤ —Å–µ–º–µ–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤ –ø–æ family_key
async def _run_family_worker(
    family_key: str,
    instances: List[Dict[str, Any]],
    scenario_id: int,
    signal_id: int,
    pg,
    redis,
) -> None:
    log.debug(
        "BT_ANALYSIS_MAIN: –∑–∞–ø—É—Å–∫ —Å–µ–º–µ–π–Ω–æ–≥–æ –≤–æ—Ä–∫–µ—Ä–∞ –¥–ª—è family_key=%s, "
        "scenario_id=%s, signal_id=%s, –∏–Ω—Å—Ç–∞–Ω—Å–æ–≤=%s",
        family_key,
        scenario_id,
        signal_id,
        len(instances),
    )

    try:
        handler = FAMILY_ANALYSIS_HANDLERS.get(family_key)
        if not handler:
            log.debug(
                "BT_ANALYSIS_MAIN: family_key=%s –ø–æ–∫–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –≤–æ—Ä–∫–µ—Ä–æ–º –∞–Ω–∞–ª–∏–∑–∞ "
                "(scenario_id=%s, signal_id=%s)",
                family_key,
                scenario_id,
                signal_id,
            )
            return

        # –∑–∞–ø—É—Å–∫–∞–µ–º —Å–µ–º–µ–π–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
        await handler(
            scenario_id=scenario_id,
            signal_id=signal_id,
            analysis_instances=instances,
            pg=pg,
        )

        # –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Å–µ–º–µ–π—Å—Ç–≤–∞ –ø—É–±–ª–∏–∫—É–µ–º —Å–æ–±—ã—Ç–∏–µ –≤ bt:analysis:ready
        finished_at = datetime.utcnow()
        analysis_ids = [str(inst.get("id")) for inst in instances if inst.get("id") is not None]

        try:
            await redis.xadd(
                ANALYSIS_READY_STREAM_KEY,
                {
                    "scenario_id": str(scenario_id),
                    "signal_id": str(signal_id),
                    "family_key": str(family_key),
                    "analysis_ids": ",".join(analysis_ids),
                    "finished_at": finished_at.isoformat(),
                },
            )
            log.debug(
                "BT_ANALYSIS_MAIN: –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ —Å–æ–±—ã—Ç–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞ –≤ —Å—Ç—Ä–∏–º '%s' "
                "–¥–ª—è scenario_id=%s, signal_id=%s, family=%s, analysis_ids=%s",
                ANALYSIS_READY_STREAM_KEY,
                scenario_id,
                signal_id,
                family_key,
                analysis_ids,
            )
        except Exception as e:
            log.error(
                "BT_ANALYSIS_MAIN: –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å —Å–æ–±—ã—Ç–∏–µ –≤ —Å—Ç—Ä–∏–º '%s' "
                "–¥–ª—è scenario_id=%s, signal_id=%s, family=%s: %s",
                ANALYSIS_READY_STREAM_KEY,
                scenario_id,
                signal_id,
                family_key,
                e,
                exc_info=True,
            )

        log.debug(
            "BT_ANALYSIS_MAIN: family_key=%s —É—Å–ø–µ—à–Ω–æ –æ—Ç—Ä–∞–±–æ—Ç–∞–ª –¥–ª—è scenario_id=%s, signal_id=%s",
            family_key,
            scenario_id,
            signal_id,
        )
    except Exception as e:
        log.error(
            "BT_ANALYSIS_MAIN: –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ —Å–µ–º–µ–π–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ family_key=%s "
            "(scenario_id=%s, signal_id=%s): %s",
            family_key,
            scenario_id,
            signal_id,
            e,
            exc_info=True,
        )