# bt_signals_emacross.py ‚Äî –≤–æ—Ä–∫–µ—Ä backfill –¥–ª—è –ø—Å–µ–≤–¥–æ-—Å–∏–≥–Ω–∞–ª–æ–≤ —Å–µ–º–µ–π—Å—Ç–≤–∞ EMA-cross (—Å —Ñ–∏–∫—Å–∞—Ü–∏–µ–π run_id)

import asyncio
import logging
import uuid
import json
from datetime import datetime, timedelta
from typing import Dict, Any, List, Tuple, Optional, Set

# üî∏ –ö–µ—à–∏ backtester_v1
from backtester_config import get_all_ticker_symbols, get_ticker_info

# üî∏ –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –∏ –ª–æ–≥–≥–µ—Ä
BT_SIGNALS_READY_STREAM = "bt:signals:ready"
log = logging.getLogger("BT_SIG_EMA_CROSS")

# üî∏ –¢–∞–π–º—à–∞–≥–∏ TF (–≤ –º–∏–Ω—É—Ç–∞—Ö) –¥–ª—è decision_time
TF_STEP_MINUTES = {
    "m5": 5,
}


# üî∏ –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ –≤ –≤–∏–¥–µ timedelta
def _get_timeframe_timedelta(timeframe: str) -> timedelta:
    tf = (timeframe or "").lower()
    step_min = TF_STEP_MINUTES.get(tf)
    if not step_min:
        return timedelta(0)
    return timedelta(minutes=step_min)


# üî∏ –ü—É–±–ª–∏—á–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞: backfill –ø–æ –æ–∫–Ω—É backfill_days –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–Ω—Å—Ç–∞–Ω—Å–∞ —Å–∏–≥–Ω–∞–ª–∞
async def run_emacross_backfill(
    signal: Dict[str, Any],
    pg,
    redis,
    run_id: Optional[int] = None,
    window_from_time: Optional[datetime] = None,
    window_to_time: Optional[datetime] = None,
) -> None:
    signal_id = signal.get("id")
    signal_key = signal.get("key")
    name = signal.get("name")
    timeframe = signal.get("timeframe")
    backfill_days = signal.get("backfill_days") or 0
    params = signal.get("params") or {}

    if timeframe != "m5":
        log.warning(
            "BT_SIG_EMA_CROSS: —Å–∏–≥–Ω–∞–ª id=%s ('%s') –∏–º–µ–µ—Ç –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π timeframe=%s, –æ–∂–∏–¥–∞–µ—Ç—Å—è 'm5'",
            signal_id,
            name,
            timeframe,
        )
        return

    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏: decision_time = open_time + TF
    tf_delta = _get_timeframe_timedelta(timeframe)
    if tf_delta <= timedelta(0):
        log.error(
            "BT_SIG_EMA_CROSS: –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π TF –¥–ª—è decision_time (timeframe=%s), signal_id=%s ('%s')",
            timeframe,
            signal_id,
            name,
        )
        return

    # —Å—á–∏—Ç—ã–≤–∞–µ–º –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã EMA-–∏–Ω—Å—Ç–∞–Ω—Å–æ–≤ –∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å–∏–≥–Ω–∞–ª–∞
    try:
        fast_cfg = params["ema_fast_instance_id"]
        slow_cfg = params["ema_slow_instance_id"]
        fast_instance_id = int(fast_cfg["value"])
        slow_instance_id = int(slow_cfg["value"])
    except Exception as e:
        log.error(
            "BT_SIG_EMA_CROSS: —Å–∏–≥–Ω–∞–ª id=%s ('%s') ‚Äî –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã EMA-–∏–Ω—Å—Ç–∞–Ω—Å–æ–≤: %s",
            signal_id,
            name,
            e,
        )
        return

    if backfill_days <= 0 and (window_from_time is None or window_to_time is None):
        log.warning(
            "BT_SIG_EMA_CROSS: —Å–∏–≥–Ω–∞–ª id=%s ('%s') –∏–º–µ–µ—Ç backfill_days=%s –∏ –æ–∫–Ω–æ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω–æ, backfill –ø—Ä–æ–ø—É—â–µ–Ω",
            signal_id,
            name,
            backfill_days,
        )
        return

    # –º–∞—Å–∫–∞ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π: 'long' / 'short' / 'both' (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é both)
    dir_mask_cfg = params.get("direction_mask")
    if dir_mask_cfg:
        mask_val_raw = dir_mask_cfg.get("value") or ""
        mask_val = str(mask_val_raw).strip().lower()
    else:
        mask_val = "both"

    if mask_val == "long":
        allowed_directions: Set[str] = {"long"}
    elif mask_val == "short":
        allowed_directions = {"short"}
    else:
        allowed_directions = {"long", "short"}

    # —Ä–∞–±–æ—á–µ–µ –æ–∫–Ω–æ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    if window_from_time is not None and window_to_time is not None:
        from_time = window_from_time
        to_time = window_to_time
    else:
        now = datetime.utcnow()
        from_time = now - timedelta(days=int(backfill_days))
        to_time = now

    # —Å–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤ –∏–∑ –∫–µ—à–∞
    symbols = get_all_ticker_symbols()
    if not symbols:
        log.debug(
            "BT_SIG_EMA_CROSS: –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏, —Å–∏–≥–Ω–∞–ª id=%s ('%s')",
            signal_id,
            name,
        )
        return

    log.debug(
        "BT_SIG_EMA_CROSS: —Å—Ç–∞—Ä—Ç backfill –¥–ª—è —Å–∏–≥–Ω–∞–ª–∞ id=%s ('%s', key=%s), TF=%s, –æ–∫–Ω–æ=[%s..%s], —Ç–∏–∫–µ—Ä–æ–≤=%s, "
        "direction_mask=%s, ema_fast_instance_id=%s, ema_slow_instance_id=%s, run_id=%s",
        signal_id,
        name,
        signal_key,
        timeframe,
        from_time,
        to_time,
        len(symbols),
        mask_val,
        fast_instance_id,
        slow_instance_id,
        run_id,
    )

    # –∑–∞–≥—Ä—É–∂–∞–µ–º —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–æ–±—ã—Ç–∏—è —Å–∏–≥–Ω–∞–ª–∞ –≤ –æ–∫–Ω–µ, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ª–∏—à–Ω–µ–π —Ä–∞–±–æ—Ç—ã
    existing_events = await _load_existing_events(pg, signal_id, timeframe, from_time, to_time)

    sema = asyncio.Semaphore(5)
    tasks = []
    for symbol in symbols:
        tasks.append(
            _process_symbol(
                signal_id=signal_id,
                signal_key=signal_key,
                name=name,
                timeframe=timeframe,
                symbol=symbol,
                fast_instance_id=fast_instance_id,
                slow_instance_id=slow_instance_id,
                from_time=from_time,
                to_time=to_time,
                existing_events=existing_events,
                pg=pg,
                sema=sema,
                allowed_directions=allowed_directions,
                tf_delta=tf_delta,
                run_id=run_id,
            )
        )

    results = await asyncio.gather(*tasks, return_exceptions=True)

    total_inserted = 0
    total_skipped_existing = 0
    total_skipped_duplicate = 0

    total_long = 0
    total_short = 0

    for res in results:
        if isinstance(res, Exception):
            continue
        ins, longs, shorts, skipped_existing, skipped_duplicate = res
        total_inserted += ins
        total_long += longs
        total_short += shorts
        total_skipped_existing += skipped_existing
        total_skipped_duplicate += skipped_duplicate

    log.info(
        "BT_SIG_EMA_CROSS: –∏—Ç–æ–≥–∏ backfill ‚Äî signal_id=%s, TF=%s, window=[%s..%s], run_id=%s, "
        "inserted=%s (long=%s, short=%s), skipped_existing=%s, skipped_duplicate=%s",
        signal_id,
        timeframe,
        from_time,
        to_time,
        run_id,
        total_inserted,
        total_long,
        total_short,
        total_skipped_existing,
        total_skipped_duplicate,
    )

    # –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤ Redis Stream –æ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Å–∏–≥–Ω–∞–ª–æ–≤ (—Å run_id)
    finished_at = datetime.utcnow()

    try:
        payload = {
            "signal_id": str(signal_id),
            "from_time": from_time.isoformat(),
            "to_time": to_time.isoformat(),
            "finished_at": finished_at.isoformat(),
        }
        if run_id is not None:
            payload["run_id"] = str(int(run_id))

        await redis.xadd(BT_SIGNALS_READY_STREAM, payload)

        log.debug(
            "BT_SIG_EMA_CROSS: –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ —Å–æ–±—ã—Ç–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –≤ —Å—Ç—Ä–∏–º '%s' –¥–ª—è signal_id=%s, run_id=%s, –æ–∫–Ω–æ=[%s .. %s], finished_at=%s",
            BT_SIGNALS_READY_STREAM,
            signal_id,
            run_id,
            from_time,
            to_time,
            finished_at,
        )
    except Exception as e:
        # –æ—à–∏–±–∫–∏ —Å—Ç—Ä–∏–º–∞ –Ω–µ –¥–æ–ª–∂–Ω—ã –ª–æ–º–∞—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π backfill
        log.error(
            "BT_SIG_EMA_CROSS: –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å —Å–æ–±—ã—Ç–∏–µ –≤ —Å—Ç—Ä–∏–º '%s' –¥–ª—è signal_id=%s: %s",
            BT_SIGNALS_READY_STREAM,
            signal_id,
            e,
            exc_info=True,
        )


# üî∏ –ó–∞–≥—Ä—É–∑–∫–∞ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–æ–±—ã—Ç–∏–π —Å–∏–≥–Ω–∞–ª–∞ –≤ –æ–∫–Ω–µ (–¥–ª—è –∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏)
async def _load_existing_events(
    pg,
    signal_id: int,
    timeframe: str,
    from_time: datetime,
    to_time: datetime,
) -> set[Tuple[str, datetime, str]]:
    existing: set[Tuple[str, datetime, str]] = set()
    async with pg.acquire() as conn:
        rows = await conn.fetch(
            """
            SELECT symbol, open_time, direction
            FROM bt_signals_values
            WHERE signal_id = $1
              AND timeframe = $2
              AND open_time BETWEEN $3 AND $4
            """,
            signal_id,
            timeframe,
            from_time,
            to_time,
        )
    for r in rows:
        existing.add((r["symbol"], r["open_time"], r["direction"]))
    log.debug(
        "BT_SIG_EMA_CROSS: —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–æ–±—ã—Ç–∏–π –≤ –æ–∫–Ω–µ [%s .. %s] –¥–ª—è signal_id=%s, TF=%s: %s",
        from_time,
        to_time,
        signal_id,
        timeframe,
        len(existing),
    )
    return existing


# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞: –ø–æ–∏—Å–∫ –∫—Ä–æ—Å—Å–æ–≤ EMA –∏ –∑–∞–ø–∏—Å—å —Å–∏–≥–Ω–∞–ª–æ–≤
async def _process_symbol(
    signal_id: int,
    signal_key: str,
    name: str,
    timeframe: str,
    symbol: str,
    fast_instance_id: int,
    slow_instance_id: int,
    from_time: datetime,
    to_time: datetime,
    existing_events: set[Tuple[str, datetime, str]],
    pg,
    sema: asyncio.Semaphore,
    allowed_directions: Set[str],
    tf_delta: timedelta,
    run_id: Optional[int],
) -> Tuple[int, int, int, int, int]:
    async with sema:
        try:
            return await _process_symbol_inner(
                signal_id=signal_id,
                signal_key=signal_key,
                name=name,
                timeframe=timeframe,
                symbol=symbol,
                fast_instance_id=fast_instance_id,
                slow_instance_id=slow_instance_id,
                from_time=from_time,
                to_time=to_time,
                existing_events=existing_events,
                pg=pg,
                allowed_directions=allowed_directions,
                tf_delta=tf_delta,
                run_id=run_id,
            )
        except Exception as e:
            log.error(
                "BT_SIG_EMA_CROSS: –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–∏–º–≤–æ–ª–∞ %s –¥–ª—è —Å–∏–≥–Ω–∞–ª–∞ id=%s ('%s'): %s",
                symbol,
                signal_id,
                name,
                e,
                exc_info=True,
            )
            return 0, 0, 0, 0, 0


# üî∏ –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –ª–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–∏–º–≤–æ–ª–∞ –±–µ–∑ —Å–µ–º–∞—Ñ–æ—Ä–∞
async def _process_symbol_inner(
    signal_id: int,
    signal_key: str,
    name: str,
    timeframe: str,
    symbol: str,
    fast_instance_id: int,
    slow_instance_id: int,
    from_time: datetime,
    to_time: datetime,
    existing_events: set[Tuple[str, datetime, str]],
    pg,
    allowed_directions: Set[str],
    tf_delta: timedelta,
    run_id: Optional[int],
) -> Tuple[int, int, int, int, int]:
    # –∑–∞–≥—Ä—É–∂–∞–µ–º —Å–µ—Ä–∏–∏ EMA –¥–ª—è fast –∏ slow
    fast_series = await _load_ema_series(pg, fast_instance_id, symbol, from_time, to_time)
    slow_series = await _load_ema_series(pg, slow_instance_id, symbol, from_time, to_time)

    if not fast_series or not slow_series:
        log.debug("BT_SIG_EMA_CROSS: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö EMA –¥–ª—è %s, —Å–∏–≥–Ω–∞–ª id=%s ('%s')", symbol, signal_id, name)
        return 0, 0, 0, 0, 0

    # —Ä–∞–±–æ—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–æ –æ–±—â–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã–º —Ç–æ—á–∫–∞–º
    times = sorted(set(fast_series.keys()) & set(slow_series.keys()))
    if len(times) < 2:
        log.debug("BT_SIG_EMA_CROSS: —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ –æ–±—â–∏—Ö –±–∞—Ä–æ–≤ EMA –¥–ª—è %s, —Å–∏–≥–Ω–∞–ª id=%s ('%s')", symbol, signal_id, name)
        return 0, 0, 0, 0, 0

    # epsilon = 1 * ticksize
    ticker_info = get_ticker_info(symbol) or {}
    ticksize = ticker_info.get("ticksize")
    try:
        epsilon = 1.0 * float(ticksize) if ticksize is not None else 0.0
    except Exception:
        epsilon = 0.0

    # –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏–π –∏ –ø–æ–∏—Å–∫ –∫—Ä–æ—Å—Å–æ–≤
    candidates: List[Tuple[datetime, str]] = []
    prev_state: Optional[str] = None

    for ts in times:
        fast_val = fast_series.get(ts)
        slow_val = slow_series.get(ts)
        if fast_val is None or slow_val is None:
            continue

        diff = fast_val - slow_val
        state = _classify_state(diff, epsilon)

        if state == "neutral":
            # –∑–æ–Ω–∞ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç–∏, —Å–æ—Å—Ç–æ—è–Ω–∏–µ –Ω–µ –º–µ–Ω—è–µ–º
            continue

        if prev_state is None:
            prev_state = state
            continue

        if state != prev_state:
            # —Ñ–∏–∫—Å–∏—Ä—É–µ–º –∫—Ä–æ—Å—Å —Å —É—á—ë—Ç–æ–º —Å–º–µ–Ω—ã —Å–æ—Å—Ç–æ—è–Ω–∏—è
            if prev_state == "below" and state == "above":
                direction = "long"
            elif prev_state == "above" and state == "below":
                direction = "short"
            else:
                prev_state = state
                continue

            # —Ñ–∏–ª—å—Ç—Ä –ø–æ –º–∞—Å–∫–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π
            if direction not in allowed_directions:
                prev_state = state
                continue

            candidates.append((ts, direction))
            prev_state = state

    if not candidates:
        return 0, 0, 0, 0, 0

    # –ø–æ–¥–≥—Ä—É–∂–∞–µ–º —Ü–µ–Ω—ã close –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –±–∞—Ä–æ–≤
    open_times = [ts for ts, _ in candidates]
    prices = await _load_close_prices(pg, symbol, timeframe, open_times)

    # —Ñ–æ—Ä–º–∏—Ä—É–µ–º –≤—Å—Ç–∞–≤–∫–∏, —É—á–∏—Ç—ã–≤–∞—è —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–æ–±—ã—Ç–∏—è –≤ –æ–∫–Ω–µ
    to_insert = []
    long_count = 0
    short_count = 0

    skipped_existing = 0
    skipped_duplicate = 0

    for ts, direction in candidates:
        # –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ü–µ–Ω—ã
        price = prices.get(ts)
        if price is None:
            continue

        # –µ—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å —Å–æ–±—ã—Ç–∏–µ –≤ –æ–∫–Ω–µ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        key = (symbol, ts, direction)
        if key in existing_events:
            skipped_existing += 1
            continue

        # decision_time = close_time –±–∞—Ä–∞, –ø–æ –∫–æ—Ç–æ—Ä–æ–º—É —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω —Å–∏–≥–Ω–∞–ª
        decision_time = ts + tf_delta

        signal_uuid = uuid.uuid4()
        message = "EMA_CROSS_LONG" if direction == "long" else "EMA_CROSS_SHORT"

        raw_message = {
            "signal_key": signal_key,
            "signal_id": signal_id,
            "symbol": symbol,
            "timeframe": timeframe,
            "open_time": ts.isoformat(),
            "decision_time": decision_time.isoformat(),
            "direction": direction,
            "price": float(price),
            "epsilon": epsilon,
        }

        to_insert.append(
            (
                str(signal_uuid),
                signal_id,
                symbol,
                timeframe,
                ts,
                decision_time,
                direction,
                message,
                json.dumps(raw_message),
                int(run_id) if run_id is not None else None,
            )
        )

        if direction == "long":
            long_count += 1
        else:
            short_count += 1

    if not to_insert:
        return 0, 0, 0, skipped_existing, 0

    # –≤—Å—Ç–∞–≤–∫–∞: —Å–æ–±—ã—Ç–∏—è –Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º, —Ñ–∏–∫—Å–∏—Ä—É–µ–º first_backfill_run_id —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –ø–æ—è–≤–ª–µ–Ω–∏–∏
    async with pg.acquire() as conn:
        res = await conn.executemany(
            """
            INSERT INTO bt_signals_values
                (signal_uuid, signal_id, symbol, timeframe, open_time, decision_time, direction, message, raw_message, first_backfill_run_id)
            VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9::jsonb, $10)
            ON CONFLICT (signal_id, symbol, timeframe, open_time, direction)
            DO NOTHING
            """,
            to_insert,
        )

    # executemany –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ—à—Ç—É—á–Ω—ã–π inserted count; —Å—á–∏—Ç–∞–µ–º "–¥—É–±–ª–∏–∫–∞—Ç—ã" –∫–∞–∫ (to_insert - —Ä–µ–∞–ª—å–Ω–æ –≤—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ)
    # —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –≤—Å—Ç–∞–≤–æ–∫ ‚Äî –¥–µ–ª–∞–µ–º INSERT ... RETURNING –Ω–∞ –±–∞—Ç—á–∞—Ö; –Ω–æ —Ç—É—Ç –¥–µ—Ä–∂–∏–º –ø—Ä–æ—Å—Ç–æ–π –≤–∞—Ä–∏–∞–Ω—Ç.
    # –æ—Ü–µ–Ω–∫–∞ duplicate –Ω–∏–∂–µ –±—É–¥–µ—Ç "0", –µ—Å–ª–∏ –Ω–µ —Å—á–∏—Ç–∞—Ç—å ‚Äî –∞ –≤–∞–∂–Ω–µ–µ —Å—É–º–º–∞—Ä–Ω—ã–µ inserted –ø–æ —Å–∏–≥–Ω–∞–ª—É –Ω–∞ —É—Ä–æ–≤–Ω–µ run.
    # –ø–æ—ç—Ç–æ–º—É –Ω–∏–∂–µ —Å—á–∏—Ç–∞–µ–º inserted –∫–∞–∫ len(to_insert), –∞ duplicate=0; —Ä–µ–∞–ª—å–Ω—ã–π duplicate –ø–æ–π–º–∞–µ—Ç—Å—è –∏–Ω–¥–µ–∫—Å–æ–º –∏ –Ω–µ –ø–æ–ª–æ–º–∞–µ—Ç backfill.
    inserted = len(to_insert)

    # –µ—Å–ª–∏ run_id –∑–∞–¥–∞–Ω, —Ç–æ —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç "–ø–µ—Ä–≤–æ–µ –ø–æ—è–≤–ª–µ–Ω–∏–µ –≤ backfill"; –≤ —Å–ª—É—á–∞–µ –¥—É–±–ª–µ–π insert –Ω–µ –ø—Ä–æ–∏–∑–æ–π–¥—ë—Ç
    # –∏ first_backfill_run_id –Ω–µ –±—É–¥–µ—Ç –∑–∞—Ç—ë—Ä—Ç.
    return inserted, long_count, short_count, skipped_existing, skipped_duplicate


# üî∏ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è fast vs slow –ø–æ diff –∏ epsilon
def _classify_state(diff: float, epsilon: float) -> str:
    # –±–µ–∑ epsilon —Å—á–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –∑–Ω–∞–∫
    if epsilon <= 0:
        if diff > 0:
            return "above"
        if diff < 0:
            return "below"
        return "neutral"

    if diff > epsilon:
        return "above"
    if diff < -epsilon:
        return "below"
    return "neutral"


# üî∏ –ó–∞–≥—Ä—É–∑–∫–∞ —Å–µ—Ä–∏–∏ EMA –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–Ω—Å—Ç–∞–Ω—Å–∞ / —Å–∏–º–≤–æ–ª–∞ / –æ–∫–Ω–∞
async def _load_ema_series(
    pg,
    instance_id: int,
    symbol: str,
    from_time: datetime,
    to_time: datetime,
) -> Dict[datetime, float]:
    async with pg.acquire() as conn:
        rows = await conn.fetch(
            """
            SELECT open_time, value
            FROM indicator_values_v4
            WHERE instance_id = $1
              AND symbol = $2
              AND open_time BETWEEN $3 AND $4
            ORDER BY open_time
            """,
            instance_id,
            symbol,
            from_time,
            to_time,
        )

    series: Dict[datetime, float] = {}
    for r in rows:
        series[r["open_time"]] = float(r["value"])
    return series


# üî∏ –ó–∞–≥—Ä—É–∑–∫–∞ —Ü–µ–Ω close –¥–ª—è –Ω–∞–±–æ—Ä–∞ open_time
async def _load_close_prices(
    pg,
    symbol: str,
    timeframe: str,
    open_times: List[datetime],
) -> Dict[datetime, float]:
    if not open_times:
        return {}

    # —Å–µ–π—á–∞—Å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ m5
    if timeframe != "m5":
        return {}

    async with pg.acquire() as conn:
        rows = await conn.fetch(
            """
            SELECT open_time, "close"
            FROM ohlcv_bb_m5
            WHERE symbol = $1
              AND open_time = ANY($2::timestamp[])
            """,
            symbol,
            open_times,
        )

    prices: Dict[datetime, float] = {}
    for r in rows:
        prices[r["open_time"]] = float(r["close"])
    return prices