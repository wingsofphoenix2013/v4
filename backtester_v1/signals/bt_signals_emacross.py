# bt_signals_emacross.py ‚Äî timer-backfill –≤–æ—Ä–∫–µ—Ä RAW (EMA cross) –¥–ª—è m5: –ø–∏—à–µ—Ç events + membership + ready_v2

import asyncio
import logging
import hashlib
import json
import uuid
from datetime import datetime, timedelta
from typing import Dict, Any, List, Tuple, Optional, Set


# üî∏ –ö–µ—à–∏ backtester_v1
from backtester_config import get_all_ticker_symbols, get_ticker_info


# üî∏ –õ–æ–≥–≥–µ—Ä –º–æ–¥—É–ª—è
log = logging.getLogger("BT_SIG_EMA_CROSS")


# üî∏ –°—Ç—Ä–∏–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å–∏–≥–Ω–∞–ª–æ–≤ (v2)
BT_SIGNALS_READY_STREAM_V2 = "bt:signals:ready_v2"


# üî∏ –¢–∞–±–ª–∏—Ü—ã
BT_SIGNAL_EVENTS_TABLE = "bt_signals_values"
BT_SIGNAL_MEMBERSHIP_TABLE = "bt_signals_membership"


# üî∏ –¢–∞–π–º—à–∞–≥–∏ TF (–≤ –º–∏–Ω—É—Ç–∞—Ö)
TF_STEP_MINUTES = {
    "m5": 5,
}


# üî∏ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞ –ø–æ —Ç–∏–∫–µ—Ä–∞–º
SYMBOL_MAX_CONCURRENCY = 5


# üî∏ –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ –≤ –≤–∏–¥–µ timedelta
def _get_timeframe_timedelta(timeframe: str) -> timedelta:
    tf = (timeframe or "").strip().lower()
    step_min = TF_STEP_MINUTES.get(tf)
    if not step_min:
        return timedelta(0)
    return timedelta(minutes=step_min)


# üî∏ –ü—É–±–ª–∏—á–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞: backfill –ø–æ –æ–∫–Ω—É run –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–Ω—Å—Ç–∞–Ω—Å–∞ EMA-cross —Å–∏–≥–Ω–∞–ª–∞
async def run_emacross_backfill(
    signal: Dict[str, Any],
    pg,
    redis,
    run_id: Optional[int] = None,
    window_from_time: Optional[datetime] = None,
    window_to_time: Optional[datetime] = None,
) -> None:
    signal_id = int(signal.get("id") or 0)
    signal_key = str(signal.get("key") or "").strip()
    name = signal.get("name")
    timeframe = str(signal.get("timeframe") or "").strip().lower()
    params = signal.get("params") or {}

    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏
    if signal_id <= 0 or timeframe != "m5":
        return
    if run_id is None or window_from_time is None or window_to_time is None:
        log.warning(
            "BT_SIG_EMA_CROSS: –ø—Ä–æ–ø—É—Å–∫ backfill ‚Äî signal_id=%s ('%s'), run_id/window –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç (run_id=%s, from=%s, to=%s)",
            signal_id,
            name,
            run_id,
            window_from_time,
            window_to_time,
        )
        return

    # decision_time = open_time + TF
    tf_delta = _get_timeframe_timedelta(timeframe)
    if tf_delta <= timedelta(0):
        return

    # —á–∏—Ç–∞–µ–º EMA instance ids (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ)
    try:
        fast_cfg = params["ema_fast_instance_id"]
        slow_cfg = params["ema_slow_instance_id"]
        fast_instance_id = int(fast_cfg["value"])
        slow_instance_id = int(slow_cfg["value"])
    except Exception as e:
        log.error(
            "BT_SIG_EMA_CROSS: —Å–∏–≥–Ω–∞–ª id=%s ('%s') ‚Äî –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã EMA-–∏–Ω—Å—Ç–∞–Ω—Å–æ–≤: %s",
            signal_id,
            name,
            e,
        )
        return

    # –º–∞—Å–∫–∞ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π: 'long' / 'short' / 'both' (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é both)
    dir_mask_cfg = params.get("direction_mask")
    if dir_mask_cfg:
        mask_val_raw = dir_mask_cfg.get("value") or ""
        mask_val = str(mask_val_raw).strip().lower()
    else:
        mask_val = "both"

    if mask_val == "long":
        allowed_directions: Set[str] = {"long"}
    elif mask_val == "short":
        allowed_directions = {"short"}
    else:
        allowed_directions = {"long", "short"}

    from_time = window_from_time
    to_time = window_to_time

    # –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ç–∏–ø–∞ —Å–æ–±—ã—Ç–∏—è (–æ–±—â–∏–π event-layer, –±–µ–∑ signal_id)
    event_key = "emacross_m5"

    # –ø–æ–¥–ø–∏—Å—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ (—Å—Ç–∞–±–∏–ª—å–Ω–∞—è —á–∞—Å—Ç—å –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏ —Å–æ–±—ã—Ç–∏–π)
    event_params_hash = _make_event_params_hash(
        fast_instance_id=fast_instance_id,
        slow_instance_id=slow_instance_id,
        timeframe=timeframe,
    )

    # RAW membership –Ω–µ —Ç—Ä–µ–±—É–µ—Ç scenario/winner
    sys_scenario_id = None
    sys_analysis_id = None

    # —Å–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤ –∏–∑ –∫–µ—à–∞
    symbols = get_all_ticker_symbols()
    if not symbols:
        log.debug("BT_SIG_EMA_CROSS: –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏, signal_id=%s ('%s')", signal_id, name)
        return

    log.debug(
        "BT_SIG_EMA_CROSS: —Å—Ç–∞—Ä—Ç backfill ‚Äî signal_id=%s ('%s', key=%s), run_id=%s, TF=%s, –æ–∫–Ω–æ=[%s..%s], —Ç–∏–∫–µ—Ä–æ–≤=%s, "
        "direction_mask=%s, fast_instance_id=%s, slow_instance_id=%s, event_key=%s, hash=%s",
        signal_id,
        name,
        signal_key,
        int(run_id),
        timeframe,
        from_time,
        to_time,
        len(symbols),
        mask_val,
        fast_instance_id,
        slow_instance_id,
        event_key,
        event_params_hash,
    )

    sema = asyncio.Semaphore(SYMBOL_MAX_CONCURRENCY)
    tasks: List[asyncio.Task] = []

    for symbol in symbols:
        tasks.append(
            asyncio.create_task(
                _process_symbol(
                    pg=pg,
                    sema=sema,
                    run_id=int(run_id),
                    signal_id=signal_id,
                    scenario_id=sys_scenario_id,
                    winner_analysis_id=sys_analysis_id,
                    parent_run_id=int(run_id),
                    parent_signal_id=signal_id,
                    symbol=str(symbol),
                    timeframe=timeframe,
                    from_time=from_time,
                    to_time=to_time,
                    fast_instance_id=fast_instance_id,
                    slow_instance_id=slow_instance_id,
                    allowed_directions=allowed_directions,
                    tf_delta=tf_delta,
                    event_key=event_key,
                    event_params_hash=event_params_hash,
                ),
                name=f"BT_SIG_EMA_CROSS_{signal_id}_{symbol}",
            )
        )

    results = await asyncio.gather(*tasks, return_exceptions=True)

    total_candidates = 0
    total_events_inserted = 0
    total_membership_inserted = 0
    total_long = 0
    total_short = 0
    total_no_data = 0

    for res in results:
        if isinstance(res, Exception):
            continue
        cands, ev_ins, mem_ins, longs, shorts, no_data = res
        total_candidates += cands
        total_events_inserted += ev_ins
        total_membership_inserted += mem_ins
        total_long += longs
        total_short += shorts
        total_no_data += no_data

    finished_at = datetime.utcnow()

    log.info(
        "BT_SIG_EMA_CROSS: backfill –≥–æ—Ç–æ–≤ ‚Äî signal_id=%s run_id=%s TF=%s window=[%s..%s] tickers=%s "
        "candidates=%s (long=%s short=%s) events_inserted=%s membership_inserted=%s no_data=%s",
        signal_id,
        int(run_id),
        timeframe,
        from_time,
        to_time,
        len(symbols),
        total_candidates,
        total_long,
        total_short,
        total_events_inserted,
        total_membership_inserted,
        total_no_data,
    )

    # –ø—É–±–ª–∏–∫—É–µ–º ready_v2: downstream —á–∏—Ç–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç —á–µ—Ä–µ–∑ membership(run_id, signal_id)
    try:
        await redis.xadd(
            BT_SIGNALS_READY_STREAM_V2,
            {
                "signal_id": str(signal_id),
                "run_id": str(int(run_id)),
                "from_time": from_time.isoformat(),
                "to_time": to_time.isoformat(),
                "finished_at": finished_at.isoformat(),
                "dataset_kind": "membership",
                "parent_run_id": str(int(run_id)),
                "parent_signal_id": str(int(signal_id)),
            },
        )
    except Exception as e:
        log.error(
            "BT_SIG_EMA_CROSS: –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å ready_v2 (signal_id=%s run_id=%s): %s",
            signal_id,
            int(run_id),
            e,
            exc_info=True,
        )


# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞: –ø–æ–∏—Å–∫ cross-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ -> upsert events -> insert membership
async def _process_symbol(
    pg,
    sema: asyncio.Semaphore,
    run_id: int,
    signal_id: int,
    scenario_id: int,
    winner_analysis_id: int,
    parent_run_id: int,
    parent_signal_id: int,
    symbol: str,
    timeframe: str,
    from_time: datetime,
    to_time: datetime,
    fast_instance_id: int,
    slow_instance_id: int,
    allowed_directions: Set[str],
    tf_delta: timedelta,
    event_key: str,
    event_params_hash: str,
) -> Tuple[int, int, int, int, int, int]:
    async with sema:
        # –≥—Ä—É–∑–∏–º EMA fast/slow –Ω–∞ m5
        fast_series = await _load_ema_series(pg, fast_instance_id, symbol, from_time, to_time)
        slow_series = await _load_ema_series(pg, slow_instance_id, symbol, from_time, to_time)
        if not fast_series or not slow_series:
            return 0, 0, 0, 0, 0, 1

        # –≥—Ä—É–∑–∏–º OHLCV –¥–ª—è m5 (–¥–ª—è —Ü–µ–Ω)
        ohlcv = await _load_ohlcv_series(pg, symbol, timeframe, from_time, to_time)
        if not ohlcv:
            return 0, 0, 0, 0, 0, 1

        # precision —Ü–µ–Ω—ã + ticksize –¥–ª—è epsilon
        ticker_info = get_ticker_info(symbol) or {}
        try:
            precision_price = int(ticker_info.get("precision_price") or 8)
        except Exception:
            precision_price = 8

        ticksize_raw = ticker_info.get("ticksize")
        try:
            ticksize = float(ticksize_raw) if ticksize_raw is not None else 0.0
        except Exception:
            ticksize = 0.0

        # epsilon = 1 * ticksize (–∫–∞–∫ –≤ —Å—Ç–∞—Ä–æ–º –≤–æ—Ä–∫–µ—Ä–µ)
        epsilon = float(ticksize) if ticksize > 0.0 else 0.0

        # –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º cross-–∫–∞–Ω–¥–∏–¥–∞—Ç—ã (–¥–ª—è —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π)
        candidates, long_count, short_count = _find_emacross_candidates(
            symbol=symbol,
            timeframe=timeframe,
            allowed_directions=allowed_directions,
            precision_price=precision_price,
            epsilon=epsilon,
            fast_instance_id=fast_instance_id,
            slow_instance_id=slow_instance_id,
            fast_series=fast_series,
            slow_series=slow_series,
            ohlcv=ohlcv,
            tf_delta=tf_delta,
        )

        if not candidates:
            return 0, 0, 0, 0, 0, 0

        # –≤—Å—Ç–∞–≤–ª—è–µ–º events (–∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ)
        events_inserted = await _upsert_events(
            pg=pg,
            symbol=symbol,
            timeframe=timeframe,
            event_key=event_key,
            event_params_hash=event_params_hash,
            candidates=candidates,
        )

        # –ø–æ–ª—É—á–∞–µ–º id —Å–æ–±—ã—Ç–∏–π –¥–ª—è membership (–ø–æ open_time+direction)
        event_ids_by_key = await _load_event_ids_for_candidates(
            pg=pg,
            symbol=symbol,
            timeframe=timeframe,
            event_key=event_key,
            event_params_hash=event_params_hash,
            candidates=candidates,
        )

        # —Ñ–æ—Ä–º–∏—Ä—É–µ–º membership rows
        to_membership: List[Tuple[Any, ...]] = []
        for cand in candidates:
            key = (cand["open_time"], cand["direction"])
            ev_id = event_ids_by_key.get(key)
            if not ev_id:
                continue

            to_membership.append(
                (
                    int(run_id),
                    int(signal_id),
                    int(ev_id),
                    None,          # scenario_id
                    int(parent_run_id),
                    int(parent_signal_id),
                    None,          # winner_analysis_id
                    "v1",          # score_version
                    None,          # winner_param
                    "raw",         # bin_name
                    None,          # plugin
                    None,          # plugin_param_name
                    None,          # lr_prefix
                    None,          # length
                    "generate",    # pipeline_mode
                )
            )

        membership_inserted = 0
        if to_membership:
            membership_inserted = await _insert_membership(pg, to_membership)

        return len(candidates), int(events_inserted), int(membership_inserted), int(long_count), int(short_count), 0


# üî∏ –ü–æ–∏—Å–∫ EMA-cross –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (—Ä–µ–∑—É–ª—å—Ç–∞—Ç ‚Äî —Å–ø–∏—Å–æ–∫ dict)
def _find_emacross_candidates(
    symbol: str,
    timeframe: str,
    allowed_directions: Set[str],
    precision_price: int,
    epsilon: float,
    fast_instance_id: int,
    slow_instance_id: int,
    fast_series: Dict[datetime, float],
    slow_series: Dict[datetime, float],
    ohlcv: Dict[datetime, Tuple[float, float, float, float]],
    tf_delta: timedelta,
) -> Tuple[List[Dict[str, Any]], int, int]:
    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏
    if not fast_series or not slow_series or not ohlcv:
        return [], 0, 0

    times = sorted(set(fast_series.keys()) & set(slow_series.keys()) & set(ohlcv.keys()))
    if len(times) < 2:
        return [], 0, 0

    out: List[Dict[str, Any]] = []
    long_count = 0
    short_count = 0

    prev_state: Optional[str] = None

    for ts in times:
        fast_val = fast_series.get(ts)
        slow_val = slow_series.get(ts)
        if fast_val is None or slow_val is None:
            continue

        diff = float(fast_val) - float(slow_val)
        state = _classify_state(diff, float(epsilon))

        # –∑–æ–Ω–∞ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç–∏ ‚Äî —Å–æ—Å—Ç–æ—è–Ω–∏–µ –Ω–µ –º–µ–Ω—è–µ–º
        if state == "neutral":
            continue

        if prev_state is None:
            prev_state = state
            continue

        if state == prev_state:
            continue

        # —Ñ–∏–∫—Å–∏—Ä—É–µ–º –∫—Ä–æ—Å—Å —Å —É—á—ë—Ç–æ–º —Å–º–µ–Ω—ã —Å–æ—Å—Ç–æ—è–Ω–∏—è
        if prev_state == "below" and state == "above":
            direction = "long"
        elif prev_state == "above" and state == "below":
            direction = "short"
        else:
            prev_state = state
            continue

        # —Ñ–∏–ª—å—Ç—Ä –ø–æ –º–∞—Å–∫–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π
        if direction not in allowed_directions:
            prev_state = state
            continue

        # —Ü–µ–Ω–∞ close –¥–ª—è –±–∞—Ä–∞ ts
        ohlcv_curr = ohlcv.get(ts)
        if not ohlcv_curr:
            prev_state = state
            continue

        close_curr = ohlcv_curr[3]
        if close_curr is None or close_curr == 0:
            prev_state = state
            continue

        try:
            close_f = float(close_curr)
        except Exception:
            prev_state = state
            continue

        # –æ–∫—Ä—É–≥–ª—è–µ–º —Ü–µ–Ω—É (–≤–∞–∂–Ω–æ: –Ω–µ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ float, —á—Ç–æ–±—ã –Ω–µ –ø–æ–ª—É—á–∞—Ç—å –¥–ª–∏–Ω–Ω—ã–µ —Ö–≤–æ—Å—Ç—ã –≤ numeric)
        try:
            price_rounded = f"{close_f:.{precision_price}f}"
        except Exception:
            price_rounded = str(close_f)

        decision_time = ts + tf_delta

        # —Å—Ç–∞–±–∏–ª—å–Ω—ã–π payload –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ (–Ω–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç run/winner/bins)
        payload_stable = {
            "pattern": "cross",
            "symbol": symbol,
            "timeframe": timeframe,
            "open_time": ts.isoformat(),
            "decision_time": decision_time.isoformat(),
            "direction": direction,
            "price": price_rounded,
            "fast_instance_id": int(fast_instance_id),
            "slow_instance_id": int(slow_instance_id),
            "fast_value": float(fast_val),
            "slow_value": float(slow_val),
            "diff": float(diff),
            "epsilon": float(epsilon),
            "prev_state": str(prev_state),
            "state": str(state),
        }

        out.append(
            {
                "symbol": symbol,
                "timeframe": timeframe,
                "open_time": ts,
                "decision_time": decision_time,
                "direction": direction,
                "price": price_rounded,
                "pattern": "cross",
                "payload_stable": payload_stable,
            }
        )

        if direction == "long":
            long_count += 1
        else:
            short_count += 1

        prev_state = state

    return out, long_count, short_count


# üî∏ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è fast vs slow –ø–æ diff –∏ epsilon
def _classify_state(diff: float, epsilon: float) -> str:
    # –±–µ–∑ epsilon —Å—á–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –∑–Ω–∞–∫
    if epsilon <= 0.0:
        if diff > 0.0:
            return "above"
        if diff < 0.0:
            return "below"
        return "neutral"

    if diff > float(epsilon):
        return "above"
    if diff < -float(epsilon):
        return "below"
    return "neutral"


# üî∏ Upsert events –≤ bt_signals_values (–æ–±—â–∏–π event-layer)
async def _upsert_events(
    pg,
    symbol: str,
    timeframe: str,
    event_key: str,
    event_params_hash: str,
    candidates: List[Dict[str, Any]],
) -> int:
    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏
    if not candidates:
        return 0

    uuids: List[str] = []
    symbols: List[str] = []
    tfs: List[str] = []
    open_times: List[datetime] = []
    decision_times: List[datetime] = []
    directions: List[str] = []
    prices: List[str] = []
    patterns: List[str] = []
    payloads: List[str] = []
    event_keys: List[str] = []
    hashes: List[str] = []

    for c in candidates:
        uuids.append(str(uuid.uuid4()))
        symbols.append(str(symbol))
        tfs.append(str(timeframe))
        open_times.append(c["open_time"])
        decision_times.append(c["decision_time"])
        directions.append(str(c["direction"]))
        prices.append(str(c.get("price") or ""))
        patterns.append(str(c.get("pattern") or ""))
        payloads.append(json.dumps(c.get("payload_stable") or {}))
        event_keys.append(str(event_key))
        hashes.append(str(event_params_hash))

    async with pg.acquire() as conn:
        rows = await conn.fetch(
            f"""
            INSERT INTO {BT_SIGNAL_EVENTS_TABLE}
                (signal_uuid, symbol, timeframe, open_time, decision_time, direction, price, pattern, payload_stable, event_key, event_params_hash)
            SELECT
                u.signal_uuid,
                u.symbol,
                u.timeframe,
                u.open_time,
                u.decision_time,
                u.direction,
                NULLIF(u.price,'')::numeric,
                NULLIF(u.pattern,''),
                u.payload_stable::jsonb,
                u.event_key,
                u.event_params_hash
            FROM unnest(
                $1::uuid[],
                $2::text[],
                $3::text[],
                $4::timestamp[],
                $5::timestamp[],
                $6::text[],
                $7::text[],
                $8::text[],
                $9::text[],
                $10::text[],
                $11::text[]
            ) AS u(
                signal_uuid,
                symbol,
                timeframe,
                open_time,
                decision_time,
                direction,
                price,
                pattern,
                payload_stable,
                event_key,
                event_params_hash
            )
            ON CONFLICT (event_key, event_params_hash, symbol, timeframe, open_time, direction)
            DO NOTHING
            RETURNING id
            """,
            uuids,
            symbols,
            tfs,
            open_times,
            decision_times,
            directions,
            prices,
            patterns,
            payloads,
            event_keys,
            hashes,
        )

    return len(rows)


# üî∏ –ó–∞–≥—Ä—É–∑–∫–∞ id —Å–æ–±—ã—Ç–∏–π –¥–ª—è –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (–¥–ª—è membership)
async def _load_event_ids_for_candidates(
    pg,
    symbol: str,
    timeframe: str,
    event_key: str,
    event_params_hash: str,
    candidates: List[Dict[str, Any]],
) -> Dict[Tuple[datetime, str], int]:
    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏
    if not candidates:
        return {}

    open_times: List[datetime] = [c["open_time"] for c in candidates]
    directions: List[str] = [str(c["direction"]) for c in candidates]

    async with pg.acquire() as conn:
        rows = await conn.fetch(
            f"""
            SELECT id, open_time, direction
            FROM {BT_SIGNAL_EVENTS_TABLE}
            WHERE event_key = $1
              AND event_params_hash = $2
              AND symbol = $3
              AND timeframe = $4
              AND (open_time, direction) IN (
                    SELECT * FROM unnest($5::timestamp[], $6::text[])
              )
            """,
            str(event_key),
            str(event_params_hash),
            str(symbol),
            str(timeframe),
            open_times,
            directions,
        )

    out: Dict[Tuple[datetime, str], int] = {}
    for r in rows:
        out[(r["open_time"], str(r["direction"]))] = int(r["id"])
    return out


# üî∏ –í—Å—Ç–∞–≤–∫–∞ membership (–∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ)
async def _insert_membership(pg, rows: List[Tuple[Any, ...]]) -> int:
    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏
    if not rows:
        return 0

    run_ids: List[int] = []
    signal_ids: List[int] = []
    value_ids: List[int] = []
    scenario_ids: List[Optional[int]] = []
    parent_run_ids: List[int] = []
    parent_signal_ids: List[int] = []
    winner_ids: List[Optional[int]] = []
    score_versions: List[str] = []
    winner_params: List[Optional[str]] = []
    bin_names: List[str] = []
    plugins: List[Optional[str]] = []
    plugin_params: List[Optional[str]] = []
    lr_prefixes: List[Optional[str]] = []
    lengths: List[Optional[int]] = []
    pipeline_modes: List[str] = []

    for r in rows:
        run_ids.append(int(r[0]))
        signal_ids.append(int(r[1]))
        value_ids.append(int(r[2]))
        scenario_ids.append(r[3] if r[3] is None else int(r[3]))
        parent_run_ids.append(int(r[4]))
        parent_signal_ids.append(int(r[5]))
        winner_ids.append(r[6] if r[6] is None else int(r[6]))
        score_versions.append(str(r[7]))
        winner_params.append(None if r[8] is None else str(r[8]))
        bin_names.append(str(r[9]))
        plugins.append(None if r[10] is None else str(r[10]))
        plugin_params.append(None if r[11] is None else str(r[11]))
        lr_prefixes.append(None if r[12] is None else str(r[12]))
        lengths.append(None if r[13] is None else int(r[13]))
        pipeline_modes.append(str(r[14]))

    async with pg.acquire() as conn:
        inserted_rows = await conn.fetch(
            f"""
            INSERT INTO {BT_SIGNAL_MEMBERSHIP_TABLE}
                (run_id, signal_id, signal_value_id, scenario_id, parent_run_id, parent_signal_id,
                 winner_analysis_id, score_version, winner_param, bin_name,
                 plugin, plugin_param_name, lr_prefix, length, pipeline_mode)
            SELECT
                u.run_id,
                u.signal_id,
                u.signal_value_id,
                u.scenario_id,
                u.parent_run_id,
                u.parent_signal_id,
                u.winner_analysis_id,
                u.score_version,
                u.winner_param,
                u.bin_name,
                u.plugin,
                u.plugin_param_name,
                u.lr_prefix,
                u.length,
                u.pipeline_mode
            FROM unnest(
                $1::bigint[],
                $2::int[],
                $3::int[],
                $4::int[],
                $5::bigint[],
                $6::int[],
                $7::int[],
                $8::text[],
                $9::text[],
                $10::text[],
                $11::text[],
                $12::text[],
                $13::text[],
                $14::int[],
                $15::text[]
            ) AS u(
                run_id,
                signal_id,
                signal_value_id,
                scenario_id,
                parent_run_id,
                parent_signal_id,
                winner_analysis_id,
                score_version,
                winner_param,
                bin_name,
                plugin,
                plugin_param_name,
                lr_prefix,
                length,
                pipeline_mode
            )
            ON CONFLICT (run_id, signal_id, signal_value_id) DO NOTHING
            RETURNING id
            """,
            run_ids,
            signal_ids,
            value_ids,
            scenario_ids,
            parent_run_ids,
            parent_signal_ids,
            winner_ids,
            score_versions,
            winner_params,
            bin_names,
            plugins,
            plugin_params,
            lr_prefixes,
            lengths,
            pipeline_modes,
        )

    return len(inserted_rows)


# üî∏ –ó–∞–≥—Ä—É–∑–∫–∞ EMA-—Å–µ—Ä–∏–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–Ω—Å—Ç–∞–Ω—Å–∞ / —Å–∏–º–≤–æ–ª–∞ / –æ–∫–Ω–∞
async def _load_ema_series(
    pg,
    instance_id: int,
    symbol: str,
    from_time: datetime,
    to_time: datetime,
) -> Dict[datetime, float]:
    async with pg.acquire() as conn:
        rows = await conn.fetch(
            """
            SELECT open_time, value
            FROM indicator_values_v4
            WHERE instance_id = $1
              AND symbol      = $2
              AND open_time  BETWEEN $3 AND $4
            ORDER BY open_time
            """,
            int(instance_id),
            str(symbol),
            from_time,
            to_time,
        )

    series: Dict[datetime, float] = {}
    for r in rows:
        ts = r["open_time"]
        try:
            series[ts] = float(r["value"])
        except Exception:
            continue
    return series


# üî∏ –ó–∞–≥—Ä—É–∑–∫–∞ OHLCV-—Å–µ—Ä–∏–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞ / TF / –æ–∫–Ω–∞
async def _load_ohlcv_series(
    pg,
    symbol: str,
    timeframe: str,
    from_time: datetime,
    to_time: datetime,
) -> Dict[datetime, Tuple[float, float, float, float]]:
    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏
    if timeframe != "m5":
        return {}

    table_name = "ohlcv_bb_m5"

    async with pg.acquire() as conn:
        rows = await conn.fetch(
            f"""
            SELECT open_time, open, high, low, close
            FROM {table_name}
            WHERE symbol = $1
              AND open_time BETWEEN $2 AND $3
            ORDER BY open_time
            """,
            str(symbol),
            from_time,
            to_time,
        )

    series: Dict[datetime, Tuple[float, float, float, float]] = {}
    for r in rows:
        try:
            series[r["open_time"]] = (
                float(r["open"]),
                float(r["high"]),
                float(r["low"]),
                float(r["close"]),
            )
        except Exception:
            continue
    return series


# üî∏ –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ hash –Ω–∞–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ (–¥–ª—è event_params_hash)
def _make_event_params_hash(
    fast_instance_id: int,
    slow_instance_id: int,
    timeframe: str,
) -> str:
    s = f"fast={int(fast_instance_id)}|slow={int(slow_instance_id)}|tf={str(timeframe)}|eps=ticksize*1"
    return hashlib.sha1(s.encode("utf-8")).hexdigest()[:16]