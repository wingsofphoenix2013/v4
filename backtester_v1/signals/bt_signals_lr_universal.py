# bt_signals_lr_universal.py ‚Äî timer-backfill –≤–æ—Ä–∫–µ—Ä RAW (LR bounce) –¥–ª—è m5: –ø–∏—à–µ—Ç events + membership + ready_v2

import asyncio
import logging
import hashlib
import json
import uuid
from datetime import datetime, timedelta
from typing import Dict, Any, List, Tuple, Optional, Set


# üî∏ –ö–µ—à–∏ backtester_v1
from backtester_config import get_all_ticker_symbols, get_ticker_info

# üî∏ –õ–æ–≥–≥–µ—Ä –º–æ–¥—É–ª—è
log = logging.getLogger("BT_SIG_LR_UNI")

# üî∏ –°—Ç—Ä–∏–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å–∏–≥–Ω–∞–ª–æ–≤ (v2)
BT_SIGNALS_READY_STREAM_V2 = "bt:signals:ready_v2"

# üî∏ –¢–∞–±–ª–∏—Ü—ã
BT_SIGNAL_EVENTS_TABLE = "bt_signals_values"
BT_SIGNAL_MEMBERSHIP_TABLE = "bt_signals_membership"
BT_RUNS_TABLE = "bt_signal_backfill_runs"

# üî∏ –¢–∞–π–º—à–∞–≥–∏ TF (–≤ –º–∏–Ω—É—Ç–∞—Ö)
TF_STEP_MINUTES = {
    "m5": 5,
}

# üî∏ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞ –ø–æ —Ç–∏–∫–µ—Ä–∞–º
SYMBOL_MAX_CONCURRENCY = 5


# üî∏ –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ –≤ –≤–∏–¥–µ timedelta
def _get_timeframe_timedelta(timeframe: str) -> timedelta:
    tf = (timeframe or "").strip().lower()
    step_min = TF_STEP_MINUTES.get(tf)
    if not step_min:
        return timedelta(0)
    return timedelta(minutes=step_min)


# üî∏ –ü—É–±–ª–∏—á–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞: backfill –ø–æ –æ–∫–Ω—É run –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–Ω—Å—Ç–∞–Ω—Å–∞ LR-—Å–∏–≥–Ω–∞–ª–∞
async def run_lr_universal_backfill(
    signal: Dict[str, Any],
    pg,
    redis,
    run_id: Optional[int] = None,
    window_from_time: Optional[datetime] = None,
    window_to_time: Optional[datetime] = None,
) -> None:
    signal_id = int(signal.get("id") or 0)
    signal_key = str(signal.get("key") or "").strip()
    name = signal.get("name")
    timeframe = str(signal.get("timeframe") or "").strip().lower()
    params = signal.get("params") or {}

    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏
    if signal_id <= 0 or timeframe != "m5":
        return
    if run_id is None or window_from_time is None or window_to_time is None:
        log.warning(
            "BT_SIG_LR_UNI: –ø—Ä–æ–ø—É—Å–∫ backfill ‚Äî signal_id=%s ('%s'), run_id/window –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç (run_id=%s, from=%s, to=%s)",
            signal_id,
            name,
            run_id,
            window_from_time,
            window_to_time,
        )
        return

    # —á–∏—Ç–∞–µ–º LR instance (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π)
    try:
        lr_cfg = params["indicator"]
        lr_m5_instance_id = int(lr_cfg["value"])
    except Exception as e:
        log.error(
            "BT_SIG_LR_UNI: —Å–∏–≥–Ω–∞–ª id=%s ('%s') ‚Äî –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã indicator (LR instance_id m5): %s",
            signal_id,
            name,
            e,
        )
        return

    # –º–∞—Å–∫–∞ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π: 'long' / 'short' / 'both' (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é both)
    dir_mask_cfg = params.get("direction_mask")
    if dir_mask_cfg:
        mask_val_raw = dir_mask_cfg.get("value") or ""
        mask_val = str(mask_val_raw).strip().lower()
    else:
        mask_val = "both"

    if mask_val == "long":
        allowed_directions: Set[str] = {"long"}
    elif mask_val == "short":
        allowed_directions = {"short"}
    else:
        allowed_directions = {"long", "short"}

    # —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã –ø–æ —Ç—Ä–µ–Ω–¥—É: trend / counter / agnostic
    trend_cfg = params.get("trend_type")
    if trend_cfg:
        trend_raw = trend_cfg.get("value") or ""
        trend_type = str(trend_raw).strip().lower()
    else:
        trend_type = "agnostic"

    if trend_type not in ("trend", "counter", "agnostic"):
        log.warning(
            "BT_SIG_LR_UNI: —Å–∏–≥–Ω–∞–ª id=%s ('%s') –∏–º–µ–µ—Ç –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π trend_type=%s, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 'agnostic'",
            signal_id,
            name,
            trend_type,
        )
        trend_type = "agnostic"

    # —Ñ–ª–∞–≥: –Ω—É–∂–Ω–æ –ª–∏ —Å–ª–µ–¥–∏—Ç—å, —á—Ç–æ–±—ã –ø–æ—Å–ª–µ –æ—Ç—Å–∫–æ–∫–∞ —Ü–µ–Ω–∞ –æ—Å—Ç–∞–≤–∞–ª–∞—Å—å –≤ —Å–≤–æ–µ–π –ø–æ–ª–æ–≤–∏–Ω–µ –∫–∞–Ω–∞–ª–∞
    keep_half_cfg = params.get("keep_half")
    if keep_half_cfg:
        keep_half_raw = keep_half_cfg.get("value") or ""
        keep_half = str(keep_half_raw).strip().lower() == "true"
    else:
        keep_half = False

    # –ø–∞—Ä–∞–º–µ—Ç—Ä –∑–æ–Ω—ã —É –≥—Ä–∞–Ω–∏—Ü—ã –∫–∞–Ω–∞–ª–∞: –¥–æ–ª—è –≤—ã—Å–æ—Ç—ã –∫–∞–Ω–∞–ª–∞ (0.0 .. 0.5)
    zone_k = _get_float_param(params, "zone_k", 0.0)
    if zone_k < 0.0:
        zone_k = 0.0
    if zone_k > 0.5:
        zone_k = 0.5

    # –ø–∞—Ç—Ç–µ—Ä–Ω ‚Äî —Ç–æ–ª—å–∫–æ bounce
    pattern = "bounce"

    from_time = window_from_time
    to_time = window_to_time

    # –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ç–∏–ø–∞ —Å–æ–±—ã—Ç–∏—è (–æ–±—â–∏–π event-layer, –±–µ–∑ signal_id)
    event_key = f"lr_universal_bounce_{timeframe}"

    # –ø–æ–¥–ø–∏—Å—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ (—Å—Ç–∞–±–∏–ª—å–Ω–∞—è —á–∞—Å—Ç—å –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏ —Å–æ–±—ã—Ç–∏–π)
    event_params_hash = _make_event_params_hash(
        lr_instance_id=lr_m5_instance_id,
        timeframe=timeframe,
        trend_type=trend_type,
        zone_k=zone_k,
        keep_half=keep_half,
    )

    # RAW membership –Ω–µ —Ç—Ä–µ–±—É–µ—Ç scenario/winner
    sys_scenario_id = None
    sys_analysis_id = None

    # —Å–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤ –∏–∑ –∫–µ—à–∞
    symbols = get_all_ticker_symbols()
    if not symbols:
        log.debug("BT_SIG_LR_UNI: –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏, signal_id=%s ('%s')", signal_id, name)
        return

    log.debug(
        "BT_SIG_LR_UNI: —Å—Ç–∞—Ä—Ç backfill ‚Äî signal_id=%s ('%s', key=%s), run_id=%s, TF=%s, –æ–∫–Ω–æ=[%s..%s], —Ç–∏–∫–µ—Ä–æ–≤=%s, "
        "direction_mask=%s, lr_m5_instance_id=%s, pattern=%s, trend_type=%s, zone_k=%.3f, keep_half=%s, event_key=%s, hash=%s",
        signal_id,
        name,
        signal_key,
        int(run_id),
        timeframe,
        from_time,
        to_time,
        len(symbols),
        mask_val,
        lr_m5_instance_id,
        pattern,
        trend_type,
        zone_k,
        keep_half,
        event_key,
        event_params_hash,
    )

    sema = asyncio.Semaphore(SYMBOL_MAX_CONCURRENCY)
    tasks: List[asyncio.Task] = []

    for symbol in symbols:
        tasks.append(
            asyncio.create_task(
                _process_symbol(
                    pg=pg,
                    sema=sema,
                    run_id=int(run_id),
                    signal_id=signal_id,
                    scenario_id=sys_scenario_id,
                    winner_analysis_id=sys_analysis_id,
                    parent_run_id=int(run_id),
                    parent_signal_id=signal_id,
                    symbol=str(symbol),
                    timeframe=timeframe,
                    from_time=from_time,
                    to_time=to_time,
                    lr_m5_instance_id=lr_m5_instance_id,
                    allowed_directions=allowed_directions,
                    trend_type=trend_type,
                    zone_k=zone_k,
                    keep_half=keep_half,
                    pattern=pattern,
                    event_key=event_key,
                    event_params_hash=event_params_hash,
                ),
                name=f"BT_SIG_LR_UNI_{signal_id}_{symbol}",
            )
        )

    results = await asyncio.gather(*tasks, return_exceptions=True)

    total_candidates = 0
    total_events_inserted = 0
    total_membership_inserted = 0
    total_long = 0
    total_short = 0
    total_no_data = 0

    for res in results:
        if isinstance(res, Exception):
            continue
        cands, ev_ins, mem_ins, longs, shorts, no_data = res
        total_candidates += cands
        total_events_inserted += ev_ins
        total_membership_inserted += mem_ins
        total_long += longs
        total_short += shorts
        total_no_data += no_data

    finished_at = datetime.utcnow()

    log.debug(
        "BT_SIG_LR_UNI: backfill –≥–æ—Ç–æ–≤ ‚Äî signal_id=%s run_id=%s TF=%s window=[%s..%s] tickers=%s "
        "candidates=%s (long=%s short=%s) events_inserted=%s membership_inserted=%s no_data=%s",
        signal_id,
        int(run_id),
        timeframe,
        from_time,
        to_time,
        len(symbols),
        total_candidates,
        total_long,
        total_short,
        total_events_inserted,
        total_membership_inserted,
        total_no_data,
    )

    # –ø—É–±–ª–∏–∫—É–µ–º ready_v2: downstream —á–∏—Ç–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç —á–µ—Ä–µ–∑ membership(run_id, signal_id)
    try:
        await redis.xadd(
            BT_SIGNALS_READY_STREAM_V2,
            {
                "signal_id": str(signal_id),
                "run_id": str(int(run_id)),
                "from_time": from_time.isoformat(),
                "to_time": to_time.isoformat(),
                "finished_at": finished_at.isoformat(),
                "dataset_kind": "membership",
                "parent_run_id": str(int(run_id)),
                "parent_signal_id": str(int(signal_id)),
            },
        )
    except Exception as e:
        log.error(
            "BT_SIG_LR_UNI: –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å ready_v2 (signal_id=%s run_id=%s): %s",
            signal_id,
            int(run_id),
            e,
            exc_info=True,
        )


# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞: –ø–æ–∏—Å–∫ bounce-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ -> upsert events -> insert membership
async def _process_symbol(
    pg,
    sema: asyncio.Semaphore,
    run_id: int,
    signal_id: int,
    scenario_id: int,
    winner_analysis_id: int,
    parent_run_id: int,
    parent_signal_id: int,
    symbol: str,
    timeframe: str,
    from_time: datetime,
    to_time: datetime,
    lr_m5_instance_id: int,
    allowed_directions: Set[str],
    trend_type: str,
    zone_k: float,
    keep_half: bool,
    pattern: str,
    event_key: str,
    event_params_hash: str,
) -> Tuple[int, int, int, int, int, int]:
    async with sema:
        # –≥—Ä—É–∑–∏–º LR-–∫–∞–Ω–∞–ª –Ω–∞ m5
        lr_series = await _load_lr_series(pg, lr_m5_instance_id, symbol, from_time, to_time)
        if not lr_series or len(lr_series) < 2:
            return 0, 0, 0, 0, 0, 1

        # –≥—Ä—É–∑–∏–º OHLCV –¥–ª—è m5 (–¥–ª—è —Ü–µ–Ω)
        ohlcv = await _load_ohlcv_series(pg, symbol, timeframe, from_time, to_time)
        if not ohlcv:
            return 0, 0, 0, 0, 0, 1

        # precision —Ü–µ–Ω—ã
        ticker_info = get_ticker_info(symbol) or {}
        try:
            precision_price = int(ticker_info.get("precision_price") or 8)
        except Exception:
            precision_price = 8

        tf_delta = _get_timeframe_timedelta(timeframe)
        if tf_delta <= timedelta(0):
            return 0, 0, 0, 0, 0, 1

        # –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º bounce-–∫–∞–Ω–¥–∏–¥–∞—Ç—ã (–¥–ª—è —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π)
        candidates, long_count, short_count = _find_bounce_candidates(
            symbol=symbol,
            allowed_directions=allowed_directions,
            trend_type=trend_type,
            zone_k=zone_k,
            keep_half=keep_half,
            precision_price=precision_price,
            lr_series=lr_series,
            ohlcv=ohlcv,
            tf_delta=tf_delta,
            pattern=pattern,
            lr_m5_instance_id=lr_m5_instance_id,
        )

        if not candidates:
            return 0, 0, 0, 0, 0, 0

        # –≤—Å—Ç–∞–≤–ª—è–µ–º events (–∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ)
        events_inserted = await _upsert_events(
            pg=pg,
            symbol=symbol,
            timeframe=timeframe,
            event_key=event_key,
            event_params_hash=event_params_hash,
            candidates=candidates,
        )

        # –ø–æ–ª—É—á–∞–µ–º id —Å–æ–±—ã—Ç–∏–π –¥–ª—è membership (–ø–æ open_time+direction)
        event_ids_by_key = await _load_event_ids_for_candidates(
            pg=pg,
            symbol=symbol,
            timeframe=timeframe,
            event_key=event_key,
            event_params_hash=event_params_hash,
            candidates=candidates,
        )

        # —Ñ–æ—Ä–º–∏—Ä—É–µ–º membership rows
        to_membership: List[Tuple[Any, ...]] = []
        for cand in candidates:
            key = (cand["open_time"], cand["direction"])
            ev_id = event_ids_by_key.get(key)
            if not ev_id:
                continue

            to_membership.append(
                (
                    int(run_id),
                    int(signal_id),
                    int(ev_id),
                    None,          # scenario_id
                    int(parent_run_id),
                    int(parent_signal_id),
                    None,          # winner_analysis_id
                    "v1",          # score_version
                    None,          # winner_param
                    "raw",         # bin_name
                    None,          # plugin
                    None,          # plugin_param_name
                    None,          # lr_prefix
                    None,          # length
                    "generate",    # pipeline_mode
                )
            )

        membership_inserted = 0
        if to_membership:
            membership_inserted = await _insert_membership(pg, to_membership)

        return len(candidates), int(events_inserted), int(membership_inserted), int(long_count), int(short_count), 0


# üî∏ –ü–æ–∏—Å–∫ bounce-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (–ª–æ–≥–∏–∫–∞ –∫–∞–∫ —Ä–∞–Ω—å—à–µ, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç ‚Äî —Å–ø–∏—Å–æ–∫ dict)
def _find_bounce_candidates(
    symbol: str,
    allowed_directions: Set[str],
    trend_type: str,
    zone_k: float,
    keep_half: bool,
    precision_price: int,
    lr_series: Dict[datetime, Dict[str, float]],
    ohlcv: Dict[datetime, Tuple[float, float, float, float]],
    tf_delta: timedelta,
    pattern: str,
    lr_m5_instance_id: int,
) -> Tuple[List[Dict[str, Any]], int, int]:
    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏
    if not lr_series or not ohlcv:
        return [], 0, 0

    times = sorted(set(lr_series.keys()) & set(ohlcv.keys()))
    if len(times) < 2:
        return [], 0, 0

    out: List[Dict[str, Any]] = []
    long_count = 0
    short_count = 0

    for i in range(1, len(times)):
        prev_ts = times[i - 1]
        ts = times[i]

        lr_prev = lr_series.get(prev_ts)
        lr_curr = lr_series.get(ts)
        if not lr_prev or not lr_curr:
            continue

        ohlcv_prev = ohlcv.get(prev_ts)
        ohlcv_curr = ohlcv.get(ts)
        if not ohlcv_prev or not ohlcv_curr:
            continue

        close_prev = ohlcv_prev[3]
        close_curr = ohlcv_curr[3]
        if close_curr is None or close_curr == 0:
            continue

        angle = lr_curr.get("angle")
        upper_curr = lr_curr.get("upper")
        lower_curr = lr_curr.get("lower")
        upper_prev = lr_prev.get("upper")
        lower_prev = lr_prev.get("lower")
        center_curr = lr_curr.get("center")

        if angle is None or upper_curr is None or lower_curr is None or upper_prev is None or lower_prev is None:
            continue

        # –µ—Å–ª–∏ keep_half –≤–∫–ª—é—á—ë–Ω, –Ω–æ –Ω–µ—Ç center_curr ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        if keep_half and center_curr is None:
            continue

        try:
            angle_f = float(angle)
            upper_prev_f = float(upper_prev)
            lower_prev_f = float(lower_prev)
            upper_curr_f = float(upper_curr)
            lower_curr_f = float(lower_curr)
            close_prev_f = float(close_prev)
            close_curr_f = float(close_curr)
            center_curr_f = float(center_curr) if center_curr is not None else 0.0
        except Exception:
            continue

        H = upper_prev_f - lower_prev_f
        if H <= 0:
            continue

        # —É—Å–ª–æ–≤–∏—è –ø–æ —Ç—Ä–µ–Ω–¥—É
        if trend_type == "trend":
            long_trend_ok = angle_f > 0.0
            short_trend_ok = angle_f < 0.0
        elif trend_type == "counter":
            long_trend_ok = angle_f < 0.0
            short_trend_ok = angle_f > 0.0
        else:
            long_trend_ok = True
            short_trend_ok = True

        direction: Optional[str] = None

        # LONG bounce
        if "long" in allowed_directions and long_trend_ok:
            if zone_k == 0.0:
                in_zone_prev = close_prev_f <= lower_prev_f
            else:
                threshold = lower_prev_f + (float(zone_k) * H)
                in_zone_prev = close_prev_f <= threshold

            if in_zone_prev and close_curr_f > lower_prev_f:
                if keep_half and not (close_curr_f <= center_curr_f):
                    continue
                direction = "long"

        # SHORT bounce
        if direction is None and "short" in allowed_directions and short_trend_ok:
            if zone_k == 0.0:
                in_zone_prev = close_prev_f >= upper_prev_f
            else:
                threshold = upper_prev_f - (float(zone_k) * H)
                in_zone_prev = close_prev_f >= threshold

            if in_zone_prev and close_curr_f < upper_prev_f:
                if keep_half and not (close_curr_f >= center_curr_f):
                    continue
                direction = "short"

        if direction is None:
            continue

        # –æ–∫—Ä—É–≥–ª—è–µ–º —Ü–µ–Ω—É (–≤–∞–∂–Ω–æ: –Ω–µ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ float, —á—Ç–æ–±—ã –Ω–µ –ø–æ–ª—É—á–∞—Ç—å –¥–ª–∏–Ω–Ω—ã–µ —Ö–≤–æ—Å—Ç—ã –≤ numeric)
        try:
            price_rounded = f"{close_curr_f:.{precision_price}f}"
        except Exception:
            price_rounded = str(close_curr_f)

        decision_time = ts + tf_delta

        # —Å—Ç–∞–±–∏–ª—å–Ω—ã–π payload –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ (–Ω–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç run/winner/bins)
        payload_stable = {
            "pattern": pattern,
            "symbol": symbol,
            "timeframe": "m5",
            "open_time": ts.isoformat(),
            "decision_time": decision_time.isoformat(),
            "direction": direction,
            "price": price_rounded,
            "angle_m5": angle_f,
            "upper_prev": upper_prev_f,
            "lower_prev": lower_prev_f,
            "upper_curr": upper_curr_f,
            "lower_curr": lower_curr_f,
            "center_curr": center_curr_f,
            "zone_k": float(zone_k),
            "trend_type": str(trend_type),
            "keep_half": bool(keep_half),
            "lr_m5_instance_id": int(lr_m5_instance_id),
        }

        out.append(
            {
                "symbol": symbol,
                "timeframe": "m5",
                "open_time": ts,
                "decision_time": decision_time,
                "direction": direction,
                "price": price_rounded,
                "pattern": pattern,
                "payload_stable": payload_stable,
            }
        )

        if direction == "long":
            long_count += 1
        else:
            short_count += 1

    return out, long_count, short_count


# üî∏ Upsert events –≤ bt_signals_values (–æ–±—â–∏–π event-layer)
async def _upsert_events(
    pg,
    symbol: str,
    timeframe: str,
    event_key: str,
    event_params_hash: str,
    candidates: List[Dict[str, Any]],
) -> int:
    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏
    if not candidates:
        return 0

    uuids: List[str] = []
    symbols: List[str] = []
    tfs: List[str] = []
    open_times: List[datetime] = []
    decision_times: List[datetime] = []
    directions: List[str] = []
    prices: List[str] = []
    patterns: List[str] = []
    payloads: List[str] = []
    event_keys: List[str] = []
    hashes: List[str] = []

    for c in candidates:
        uuids.append(str(uuid.uuid4()))
        symbols.append(str(symbol))
        tfs.append(str(timeframe))
        open_times.append(c["open_time"])
        decision_times.append(c["decision_time"])
        directions.append(str(c["direction"]))
        prices.append(str(c.get("price") or ""))
        patterns.append(str(c.get("pattern") or ""))
        payloads.append(json.dumps(c.get("payload_stable") or {}))
        event_keys.append(str(event_key))
        hashes.append(str(event_params_hash))

    async with pg.acquire() as conn:
        rows = await conn.fetch(
            f"""
            INSERT INTO {BT_SIGNAL_EVENTS_TABLE}
                (signal_uuid, symbol, timeframe, open_time, decision_time, direction, price, pattern, payload_stable, event_key, event_params_hash)
            SELECT
                u.signal_uuid,
                u.symbol,
                u.timeframe,
                u.open_time,
                u.decision_time,
                u.direction,
                NULLIF(u.price,'')::numeric,
                NULLIF(u.pattern,''),
                u.payload_stable::jsonb,
                u.event_key,
                u.event_params_hash
            FROM unnest(
                $1::uuid[],
                $2::text[],
                $3::text[],
                $4::timestamp[],
                $5::timestamp[],
                $6::text[],
                $7::text[],
                $8::text[],
                $9::text[],
                $10::text[],
                $11::text[]
            ) AS u(
                signal_uuid,
                symbol,
                timeframe,
                open_time,
                decision_time,
                direction,
                price,
                pattern,
                payload_stable,
                event_key,
                event_params_hash
            )
            ON CONFLICT (event_key, event_params_hash, symbol, timeframe, open_time, direction)
            DO NOTHING
            RETURNING id
            """,
            uuids,
            symbols,
            tfs,
            open_times,
            decision_times,
            directions,
            prices,
            patterns,
            payloads,
            event_keys,
            hashes,
        )

    return len(rows)

# üî∏ –ó–∞–≥—Ä—É–∑–∫–∞ id —Å–æ–±—ã—Ç–∏–π –¥–ª—è –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (–¥–ª—è membership)
async def _load_event_ids_for_candidates(
    pg,
    symbol: str,
    timeframe: str,
    event_key: str,
    event_params_hash: str,
    candidates: List[Dict[str, Any]],
) -> Dict[Tuple[datetime, str], int]:
    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏
    if not candidates:
        return {}

    open_times: List[datetime] = [c["open_time"] for c in candidates]
    directions: List[str] = [str(c["direction"]) for c in candidates]

    async with pg.acquire() as conn:
        rows = await conn.fetch(
            f"""
            SELECT id, open_time, direction
            FROM {BT_SIGNAL_EVENTS_TABLE}
            WHERE event_key = $1
              AND event_params_hash = $2
              AND symbol = $3
              AND timeframe = $4
              AND (open_time, direction) IN (
                    SELECT * FROM unnest($5::timestamp[], $6::text[])
              )
            """,
            str(event_key),
            str(event_params_hash),
            str(symbol),
            str(timeframe),
            open_times,
            directions,
        )

    out: Dict[Tuple[datetime, str], int] = {}
    for r in rows:
        out[(r["open_time"], str(r["direction"]))] = int(r["id"])
    return out


# üî∏ –í—Å—Ç–∞–≤–∫–∞ membership (–∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ)
async def _insert_membership(pg, rows: List[Tuple[Any, ...]]) -> int:
    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏
    if not rows:
        return 0

    run_ids: List[int] = []
    signal_ids: List[int] = []
    value_ids: List[int] = []
    scenario_ids: List[Optional[int]] = []
    parent_run_ids: List[int] = []
    parent_signal_ids: List[int] = []
    winner_ids: List[Optional[int]] = []
    score_versions: List[str] = []
    winner_params: List[Optional[str]] = []
    bin_names: List[str] = []
    plugins: List[Optional[str]] = []
    plugin_params: List[Optional[str]] = []
    lr_prefixes: List[Optional[str]] = []
    lengths: List[Optional[int]] = []
    pipeline_modes: List[str] = []

    for r in rows:
        run_ids.append(int(r[0]))
        signal_ids.append(int(r[1]))
        value_ids.append(int(r[2]))
        scenario_ids.append(r[3] if r[3] is None else int(r[3]))
        parent_run_ids.append(int(r[4]))
        parent_signal_ids.append(int(r[5]))
        winner_ids.append(r[6] if r[6] is None else int(r[6]))
        score_versions.append(str(r[7]))
        winner_params.append(None if r[8] is None else str(r[8]))
        bin_names.append(str(r[9]))
        plugins.append(None if r[10] is None else str(r[10]))
        plugin_params.append(None if r[11] is None else str(r[11]))
        lr_prefixes.append(None if r[12] is None else str(r[12]))
        lengths.append(None if r[13] is None else int(r[13]))
        pipeline_modes.append(str(r[14]))

    async with pg.acquire() as conn:
        inserted_rows = await conn.fetch(
            f"""
            INSERT INTO {BT_SIGNAL_MEMBERSHIP_TABLE}
                (run_id, signal_id, signal_value_id, scenario_id, parent_run_id, parent_signal_id,
                 winner_analysis_id, score_version, winner_param, bin_name,
                 plugin, plugin_param_name, lr_prefix, length, pipeline_mode)
            SELECT
                u.run_id,
                u.signal_id,
                u.signal_value_id,
                u.scenario_id,
                u.parent_run_id,
                u.parent_signal_id,
                u.winner_analysis_id,
                u.score_version,
                u.winner_param,
                u.bin_name,
                u.plugin,
                u.plugin_param_name,
                u.lr_prefix,
                u.length,
                u.pipeline_mode
            FROM unnest(
                $1::bigint[],
                $2::int[],
                $3::int[],
                $4::int[],
                $5::bigint[],
                $6::int[],
                $7::int[],
                $8::text[],
                $9::text[],
                $10::text[],
                $11::text[],
                $12::text[],
                $13::text[],
                $14::int[],
                $15::text[]
            ) AS u(
                run_id,
                signal_id,
                signal_value_id,
                scenario_id,
                parent_run_id,
                parent_signal_id,
                winner_analysis_id,
                score_version,
                winner_param,
                bin_name,
                plugin,
                plugin_param_name,
                lr_prefix,
                length,
                pipeline_mode
            )
            ON CONFLICT (run_id, signal_id, signal_value_id) DO NOTHING
            RETURNING id
            """,
            run_ids,
            signal_ids,
            value_ids,
            scenario_ids,
            parent_run_ids,
            parent_signal_ids,
            winner_ids,
            score_versions,
            winner_params,
            bin_names,
            plugins,
            plugin_params,
            lr_prefixes,
            lengths,
            pipeline_modes,
        )

    return len(inserted_rows)
# üî∏ –ó–∞–≥—Ä—É–∑–∫–∞ LR-—Å–µ—Ä–∏–∏ (angle/upper/lower/center) –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–Ω—Å—Ç–∞–Ω—Å–∞ / —Å–∏–º–≤–æ–ª–∞ / –æ–∫–Ω–∞
async def _load_lr_series(
    pg,
    instance_id: int,
    symbol: str,
    from_time: datetime,
    to_time: datetime,
) -> Dict[datetime, Dict[str, float]]:
    async with pg.acquire() as conn:
        rows = await conn.fetch(
            """
            SELECT open_time, param_name, value
            FROM indicator_values_v4
            WHERE instance_id = $1
              AND symbol      = $2
              AND open_time  BETWEEN $3 AND $4
            ORDER BY open_time
            """,
            int(instance_id),
            str(symbol),
            from_time,
            to_time,
        )

    series: Dict[datetime, Dict[str, float]] = {}
    for r in rows:
        ts = r["open_time"]
        pname = str(r["param_name"] or "")
        val = r["value"]

        entry = series.setdefault(ts, {})

        pname_l = pname.lower()
        try:
            fval = float(val)
        except Exception:
            continue

        if pname_l.endswith("_angle"):
            entry["angle"] = fval
        elif pname_l.endswith("_upper"):
            entry["upper"] = fval
        elif pname_l.endswith("_lower"):
            entry["lower"] = fval
        elif pname_l.endswith("_center"):
            entry["center"] = fval

    return series


# üî∏ –ó–∞–≥—Ä—É–∑–∫–∞ OHLCV-—Å–µ—Ä–∏–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞ / TF / –æ–∫–Ω–∞
async def _load_ohlcv_series(
    pg,
    symbol: str,
    timeframe: str,
    from_time: datetime,
    to_time: datetime,
) -> Dict[datetime, Tuple[float, float, float, float]]:
    # —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏
    if timeframe != "m5":
        return {}

    table_name = "ohlcv_bb_m5"

    async with pg.acquire() as conn:
        rows = await conn.fetch(
            f"""
            SELECT open_time, open, high, low, close
            FROM {table_name}
            WHERE symbol = $1
              AND open_time BETWEEN $2 AND $3
            ORDER BY open_time
            """,
            str(symbol),
            from_time,
            to_time,
        )

    series: Dict[datetime, Tuple[float, float, float, float]] = {}
    for r in rows:
        try:
            series[r["open_time"]] = (
                float(r["open"]),
                float(r["high"]),
                float(r["low"]),
                float(r["close"]),
            )
        except Exception:
            continue
    return series


# üî∏ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ —á—Ç–µ–Ω–∏–µ float-–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å–∏–≥–Ω–∞–ª–∞
def _get_float_param(params: Dict[str, Any], name: str, default: float) -> float:
    cfg = params.get(name)
    if cfg is None:
        return default

    raw = cfg.get("value")
    try:
        return float(str(raw))
    except Exception:
        return default


# üî∏ –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ hash –Ω–∞–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ (–¥–ª—è event_params_hash)
def _make_event_params_hash(
    lr_instance_id: int,
    timeframe: str,
    trend_type: str,
    zone_k: float,
    keep_half: bool,
) -> str:
    s = f"lr={int(lr_instance_id)}|tf={str(timeframe)}|trend={str(trend_type)}|zone_k={float(zone_k)}|keep_half={bool(keep_half)}"
    return hashlib.sha1(s.encode("utf-8")).hexdigest()[:16]
