# bt_scenarios_postproc.py ‚Äî –ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –ø–æ–∑–∏—Ü–∏–π —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ (—Å–±–æ—Ä —Å–Ω–∞–ø—à–æ—Ç–æ–≤ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤, run-aware)

import asyncio
import logging
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Tuple
import json

# üî∏ –ö–µ—à–∏ backtester_v1 (–∏–Ω—Å—Ç–∞–Ω—Å—ã –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤)
from backtester_config import get_all_indicator_instances

log = logging.getLogger("BT_SCENARIOS_POSTPROC")

# üî∏ –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã —Å—Ç—Ä–∏–º–∞ –ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
POSTPROC_STREAM_KEY = "bt:scenarios:ready"
POSTPROC_CONSUMER_GROUP = "bt_scenarios_postproc"
POSTPROC_CONSUMER_NAME = "bt_scenarios_postproc_main"

# üî∏ –°—Ç—Ä–∏–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞
POSTPROC_READY_STREAM_KEY = "bt:postproc:ready"

# üî∏ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —á—Ç–µ–Ω–∏—è —Å—Ç—Ä–∏–º–∞
POSTPROC_STREAM_BATCH_SIZE = 10
POSTPROC_STREAM_BLOCK_MS = 5000

# üî∏ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ–∑–∏—Ü–∏–π
POSTPROC_BATCH_SIZE = 200
POSTPROC_MAX_CONCURRENCY = 10

# üî∏ –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã –∏ –∏—Ö —à–∞–≥ –≤ –º–∏–Ω—É—Ç–∞—Ö
TF_STEP_MINUTES = {
    "m5": 5,
    "m15": 15,
    "h1": 60,
}


# üî∏ –ü—É–±–ª–∏—á–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞: –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
async def run_bt_scenarios_postproc(pg, redis) -> None:
    log.debug("BT_SCENARIOS_POSTPROC: –≤–æ—Ä–∫–µ—Ä –ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –∑–∞–ø—É—â–µ–Ω")

    # –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º consumer group –¥–ª—è —Å—Ç—Ä–∏–º–∞
    await _ensure_consumer_group(redis)

    # –∑–∞–≥—Ä—É–∂–∞–µ–º –∏–Ω—Å—Ç–∞–Ω—Å—ã –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –∏ —Ä–∞—Å–∫–ª–∞–¥—ã–≤–∞–µ–º –ø–æ TF
    indicator_by_tf, instances_by_id = _build_indicator_instances_cache()
    log.debug(
        "BT_SCENARIOS_POSTPROC: –∫–µ—à –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω ‚Äî TF=%s",
        {tf: len(instances) for tf, instances in indicator_by_tf.items()},
    )

    # –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —á—Ç–µ–Ω–∏—è —Å—Ç—Ä–∏–º–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
    while True:
        try:
            messages = await _read_from_stream(redis)

            if not messages:
                continue

            total_msgs = 0
            total_scenarios_processed = 0
            total_positions_processed = 0
            total_positions_skipped = 0
            total_positions_errors = 0

            for stream_key, entries in messages:
                if stream_key != POSTPROC_STREAM_KEY:
                    # –∑–∞—â–∏—â–∞–µ–º—Å—è –æ—Ç —á—É–∂–∏—Ö —Å—Ç—Ä–∏–º–æ–≤ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
                    continue

                for entry_id, fields in entries:
                    total_msgs += 1

                    ctx = _parse_ready_message(fields)
                    if not ctx:
                        # –Ω–µ —É–¥–∞–ª–æ—Å—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Äî ACK –∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                        await redis.xack(POSTPROC_STREAM_KEY, POSTPROC_CONSUMER_GROUP, entry_id)
                        continue

                    scenario_id = ctx["scenario_id"]
                    signal_id = ctx["signal_id"]
                    run_id = ctx["run_id"]
                    finished_at = ctx["finished_at"]

                    log.debug(
                        "BT_SCENARIOS_POSTPROC: –ø–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Å—Ü–µ–Ω–∞—Ä–∏—è "
                        "scenario_id=%s, signal_id=%s, run_id=%s, finished_at=%s, stream_id=%s",
                        scenario_id,
                        signal_id,
                        run_id,
                        finished_at,
                        entry_id,
                    )

                    # –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –ø–æ–∑–∏—Ü–∏–π –¥–∞–Ω–Ω–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è
                    processed, skipped, errors = await _process_scenario_positions(
                        pg=pg,
                        scenario_id=scenario_id,
                        signal_id=signal_id,
                        indicator_by_tf=indicator_by_tf,
                        instances_by_id=instances_by_id,
                    )
                    total_scenarios_processed += 1
                    total_positions_processed += processed
                    total_positions_skipped += skipped
                    total_positions_errors += errors

                    log.debug(
                        "BT_SCENARIOS_POSTPROC: summary –¥–ª—è scenario_id=%s, signal_id=%s, run_id=%s ‚Äî processed=%s, skipped=%s, errors=%s",
                        scenario_id,
                        signal_id,
                        run_id,
                        processed,
                        skipped,
                        errors,
                    )

                    # –ø—É–±–ª–∏–∫—É–µ–º —Å–æ–±—ã—Ç–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ –≤ bt:postproc:ready (run-aware)
                    finished_at_postproc = datetime.utcnow()
                    try:
                        await redis.xadd(
                            POSTPROC_READY_STREAM_KEY,
                            {
                                "scenario_id": str(scenario_id),
                                "signal_id": str(signal_id),
                                "run_id": str(run_id),
                                "processed": str(processed),
                                "skipped": str(skipped),
                                "errors": str(errors),
                                "finished_at": finished_at_postproc.isoformat(),
                            },
                        )
                        log.debug(
                            "BT_SCENARIOS_POSTPROC: –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ —Å–æ–±—ã—Ç–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ "
                            "–≤ —Å—Ç—Ä–∏–º '%s' –¥–ª—è scenario_id=%s, signal_id=%s, run_id=%s, finished_at=%s",
                            POSTPROC_READY_STREAM_KEY,
                            scenario_id,
                            signal_id,
                            run_id,
                            finished_at_postproc,
                        )
                    except Exception as e:
                        # –ø—Ä–æ–±–ª–µ–º—ã —Å—Ç—Ä–∏–º–∞ –Ω–µ –¥–æ–ª–∂–Ω—ã –ª–æ–º–∞—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π –≤–æ—Ä–∫–µ—Ä
                        log.error(
                            "BT_SCENARIOS_POSTPROC: –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å —Å–æ–±—ã—Ç–∏–µ –≤ —Å—Ç—Ä–∏–º '%s' "
                            "–¥–ª—è scenario_id=%s, signal_id=%s, run_id=%s: %s",
                            POSTPROC_READY_STREAM_KEY,
                            scenario_id,
                            signal_id,
                            run_id,
                            e,
                            exc_info=True,
                        )

                    # –ø–æ–º–µ—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ
                    await redis.xack(POSTPROC_STREAM_KEY, POSTPROC_CONSUMER_GROUP, entry_id)

            log.debug(
                "BT_SCENARIOS_POSTPROC: –∏—Ç–æ–≥ –ø–æ –ø–∞–∫–µ—Ç—É ‚Äî —Å–æ–æ–±—â–µ–Ω–∏–π=%s, —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤=%s, positions processed=%s, skipped=%s, errors=%s",
                total_msgs,
                total_scenarios_processed,
                total_positions_processed,
                total_positions_skipped,
                total_positions_errors,
            )

        except Exception as e:
            log.error(
                "BT_SCENARIOS_POSTPROC: –æ—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ –≤–æ—Ä–∫–µ—Ä–∞: %s",
                e,
                exc_info=True,
            )
            # –Ω–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π, —á—Ç–æ–±—ã –Ω–µ –∫—Ä—É—Ç–∏—Ç—å CPU –ø—Ä–∏ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–π –æ—à–∏–±–∫–µ
            await asyncio.sleep(2)


# üî∏ –ü—Ä–æ–≤–µ—Ä–∫–∞/—Å–æ–∑–¥–∞–Ω–∏–µ consumer group –¥–ª—è —Å—Ç—Ä–∏–º–∞ –ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞
async def _ensure_consumer_group(redis) -> None:
    try:
        await redis.xgroup_create(
            name=POSTPROC_STREAM_KEY,
            groupname=POSTPROC_CONSUMER_GROUP,
            id="$",
            mkstream=True,
        )
        log.debug(
            "BT_SCENARIOS_POSTPROC: —Å–æ–∑–¥–∞–Ω–∞ consumer group '%s' –¥–ª—è —Å—Ç—Ä–∏–º–∞ '%s'",
            POSTPROC_CONSUMER_GROUP,
            POSTPROC_STREAM_KEY,
        )
    except Exception as e:
        msg = str(e)
        if "BUSYGROUP" in msg:
            log.debug(
                "BT_SCENARIOS_POSTPROC: consumer group '%s' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç ‚Äî —Å–¥–≤–∏–≥–∞–µ–º –∫—É—Ä—Å–æ—Ä –≥—Ä—É–ø–ø—ã –Ω–∞ '$' (SETID) –¥–ª—è –∏–≥–Ω–æ—Ä–∞ –∏—Å—Ç–æ—Ä–∏–∏ –¥–æ —Å—Ç–∞—Ä—Ç–∞",
                POSTPROC_CONSUMER_GROUP,
            )

            await redis.execute_command(
                "XGROUP",
                "SETID",
                POSTPROC_STREAM_KEY,
                POSTPROC_CONSUMER_GROUP,
                "$",
            )

            log.debug(
                "BT_SCENARIOS_POSTPROC: consumer group '%s' SETID='$' –¥–ª—è —Å—Ç—Ä–∏–º–∞ '%s' –≤—ã–ø–æ–ª–Ω–µ–Ω",
                POSTPROC_CONSUMER_GROUP,
                POSTPROC_STREAM_KEY,
            )
        else:
            log.error(
                "BT_SCENARIOS_POSTPROC: –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ consumer group '%s': %s",
                POSTPROC_CONSUMER_GROUP,
                e,
                exc_info=True,
            )
            raise

# üî∏ –ß—Ç–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ —Å—Ç—Ä–∏–º–∞ bt:scenarios:ready
async def _read_from_stream(redis) -> List[Any]:
    try:
        entries = await redis.xreadgroup(
            groupname=POSTPROC_CONSUMER_GROUP,
            consumername=POSTPROC_CONSUMER_NAME,
            streams={POSTPROC_STREAM_KEY: ">"},
            count=POSTPROC_STREAM_BATCH_SIZE,
            block=POSTPROC_STREAM_BLOCK_MS,
        )
    except Exception as e:
        msg = str(e)
        if "NOGROUP" in msg:
            log.warning(
                "BT_SCENARIOS_POSTPROC: NOGROUP –ø—Ä–∏ XREADGROUP ‚Äî –ø–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º/–ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≥—Ä—É–ø–ø—É –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º",
            )
            await _ensure_consumer_group(redis)
            return []
        raise

    if not entries:
        return []

    parsed: List[Any] = []
    for stream_key, messages in entries:
        if isinstance(stream_key, bytes):
            stream_key = stream_key.decode("utf-8")

        stream_entries: List[Any] = []
        for msg_id, fields in messages:
            if isinstance(msg_id, bytes):
                msg_id = msg_id.decode("utf-8")

            str_fields: Dict[str, str] = {}
            for k, v in fields.items():
                key_str = k.decode("utf-8") if isinstance(k, bytes) else str(k)
                val_str = v.decode("utf-8") if isinstance(v, bytes) else str(v)
                str_fields[key_str] = val_str

            stream_entries.append((msg_id, str_fields))

        parsed.append((stream_key, stream_entries))

    return parsed


# üî∏ –†–∞–∑–±–æ—Ä –æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ —Å—Ç—Ä–∏–º–∞ bt:scenarios:ready (run-aware)
def _parse_ready_message(fields: Dict[str, str]) -> Optional[Dict[str, Any]]:
    try:
        scenario_id_str = fields.get("scenario_id")
        signal_id_str = fields.get("signal_id")
        run_id_str = fields.get("run_id")
        finished_at_str = fields.get("finished_at")

        if not (scenario_id_str and signal_id_str and run_id_str and finished_at_str):
            return None

        scenario_id = int(scenario_id_str)
        signal_id = int(signal_id_str)
        run_id = int(run_id_str)
        finished_at = datetime.fromisoformat(finished_at_str)

        return {
            "scenario_id": scenario_id,
            "signal_id": signal_id,
            "run_id": run_id,
            "finished_at": finished_at,
        }
    except Exception as e:
        log.error(
            "BT_SCENARIOS_POSTPROC: –æ—à–∏–±–∫–∞ —Ä–∞–∑–±–æ—Ä–∞ —Å–æ–æ–±—â–µ–Ω–∏—è —Å—Ç—Ä–∏–º–∞ bt:scenarios:ready: %s, fields=%s",
            e,
            fields,
            exc_info=True,
        )
        return None


# üî∏ –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–µ—à–∞ –∏–Ω—Å—Ç–∞–Ω—Å–æ–≤ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –ø–æ TF
def _build_indicator_instances_cache() -> Tuple[Dict[str, Dict[int, Dict[str, Any]]], Dict[int, Dict[str, Any]]]:
    all_instances = get_all_indicator_instances()  # instance_id -> {indicator, timeframe, params, ...}

    indicator_by_tf: Dict[str, Dict[int, Dict[str, Any]]] = {"m5": {}, "m15": {}, "h1": {}}
    instances_by_id: Dict[int, Dict[str, Any]] = {}

    for instance_id, inst in all_instances.items():
        tf = inst.get("timeframe")

        if tf not in indicator_by_tf:
            # –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º TF, —Å –∫–æ—Ç–æ—Ä—ã–º–∏ –ø–æ–∫–∞ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ–º –≤ postproc
            continue

        indicator_by_tf[tf][instance_id] = inst
        instances_by_id[instance_id] = inst

    return indicator_by_tf, instances_by_id


# üî∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –ø–æ–∑–∏—Ü–∏–π –æ–¥–Ω–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è (–ø–æ –æ–¥–Ω–æ–º—É —Å–æ–æ–±—â–µ–Ω–∏—é –∏–∑ —Å—Ç—Ä–∏–º–∞)
async def _process_scenario_positions(
    pg,
    scenario_id: int,
    signal_id: int,
    indicator_by_tf: Dict[str, Dict[int, Dict[str, Any]]],
    instances_by_id: Dict[int, Dict[str, Any]],
) -> Tuple[int, int, int]:
    processed = 0
    skipped = 0
    errors = 0

    # –∑–∞–≥—Ä—É–∂–∞–µ–º –ø–æ–∑–∏—Ü–∏–∏ —ç—Ç–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è/—Å–∏–≥–Ω–∞–ª–∞, –∫–æ—Ç–æ—Ä—ã–µ –µ—â—ë –Ω–µ –ø—Ä–æ—à–ª–∏ –ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥
    async with pg.acquire() as conn:
        rows = await conn.fetch(
            """
            SELECT
                id,
                symbol,
                timeframe,
                entry_time
            FROM bt_scenario_positions
            WHERE scenario_id = $1
              AND signal_id = $2
              AND postproc = false
            ORDER BY entry_time
            """,
            scenario_id,
            signal_id,
        )

    positions: List[Dict[str, Any]] = [
        {
            "id": r["id"],
            "symbol": r["symbol"],
            "timeframe": r["timeframe"],
            "entry_time": r["entry_time"],
        }
        for r in rows
    ]

    if not positions:
        log.debug(
            "BT_SCENARIOS_POSTPROC: –¥–ª—è scenario_id=%s, signal_id=%s –Ω–µ—Ç –ø–æ–∑–∏—Ü–∏–π —Å postproc=false",
            scenario_id,
            signal_id,
        )
        return processed, skipped, errors

    total_positions = len(positions)
    log.debug(
        "BT_SCENARIOS_POSTPROC: —Å—Ü–µ–Ω–∞—Ä–∏–π scenario_id=%s, signal_id=%s ‚Äî –ø–æ–∑–∏—Ü–∏–π –¥–ª—è –ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞=%s",
        scenario_id,
        signal_id,
        total_positions,
    )

    # –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ–∑–∏—Ü–∏–∏ –±–∞—Ç—á–∞–º–∏, –≤–Ω—É—Ç—Ä–∏ –±–∞—Ç—á–∞ –¥–æ POSTPROC_MAX_CONCURRENCY –∑–∞–¥–∞—á –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    for i in range(0, total_positions, POSTPROC_BATCH_SIZE):
        batch = positions[i : i + POSTPROC_BATCH_SIZE]
        sema = asyncio.Semaphore(POSTPROC_MAX_CONCURRENCY)
        tasks = []

        for pos in batch:
            tasks.append(
                _process_position_with_semaphore(
                    pg=pg,
                    position=pos,
                    indicator_by_tf=indicator_by_tf,
                    instances_by_id=instances_by_id,
                    sema=sema,
                )
            )

        results = await asyncio.gather(*tasks, return_exceptions=True)

        for res in results:
            if isinstance(res, Exception):
                errors += 1
                continue
            if res == "processed":
                processed += 1
            elif res == "skipped":
                skipped += 1
            elif res == "error":
                errors += 1

    return processed, skipped, errors


# üî∏ –û–±—ë—Ä—Ç–∫–∞ –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞ –ø–æ –ø–æ–∑–∏—Ü–∏—è–º
async def _process_position_with_semaphore(
    pg,
    position: Dict[str, Any],
    indicator_by_tf: Dict[str, Dict[int, Dict[str, Any]]],
    instances_by_id: Dict[int, Dict[str, Any]],
    sema: asyncio.Semaphore,
) -> str:
    async with sema:
        try:
            return await _process_single_position(pg, position, indicator_by_tf, instances_by_id)
        except Exception as e:
            log.error(
                "BT_SCENARIOS_POSTPROC: –æ—à–∏–±–∫–∞ –ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ –ø–æ–∑–∏—Ü–∏–∏ id=%s: %s",
                position.get("id"),
                e,
                exc_info=True,
            )
            return "error"


# üî∏ –ü–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –æ–¥–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏: —Å–±–æ—Ä –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –ø–æ —Ç—Ä—ë–º TF –∏ –∑–∞–ø–∏—Å—å raw_stat
async def _process_single_position(
    pg,
    position: Dict[str, Any],
    indicator_by_tf: Dict[str, Dict[int, Dict[str, Any]]],
    instances_by_id: Dict[int, Dict[str, Any]],
) -> str:
    pos_id = position["id"]
    symbol = position["symbol"]
    base_tf = position["timeframe"]
    entry_time: datetime = position["entry_time"]

    # –≤—ã—á–∏—Å–ª—è–µ–º –æ–ø–æ—Ä–Ω—ã–µ open_time –¥–ª—è –≤—Å–µ—Ö TF –ø–æ –µ–¥–∏–Ω–æ–º—É –ø—Ä–∞–≤–∏–ª—É "—á—Ç–æ –∏–∑–≤–µ—Å—Ç–Ω–æ –∫ –º–æ–º–µ–Ω—Ç—É —Ä–µ—à–µ–Ω–∏—è"
    open_times = await _resolve_open_times_for_position(pg, symbol, base_tf, entry_time)
    if not open_times:
        log.debug(
            "BT_SCENARIOS_POSTPROC: –ø–æ–∑–∏—Ü–∏—è id=%s, symbol=%s ‚Äî –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å open_time –¥–ª—è –≤—Å–µ—Ö TF, –ø–æ–∑–∏—Ü–∏—è –ø—Ä–æ–ø—É—â–µ–Ω–∞",
            pos_id,
            symbol,
        )
        return "skipped"

    tf_payload: Dict[str, Dict[str, Any]] = {}

    async with pg.acquire() as conn:
        for tf in ("m5", "m15", "h1"):
            tf_instances = indicator_by_tf.get(tf) or {}
            if not tf_instances:
                continue

            tf_open_time = open_times.get(tf)
            if tf_open_time is None:
                log.debug(
                    "BT_SCENARIOS_POSTPROC: –ø–æ–∑–∏—Ü–∏—è id=%s, symbol=%s ‚Äî –Ω–µ—Ç open_time –¥–ª—è TF=%s, –ø–æ–∑–∏—Ü–∏—è –ø—Ä–æ–ø—É—â–µ–Ω–∞",
                    pos_id,
                    symbol,
                    tf,
                )
                return "skipped"

            instance_ids = list(tf_instances.keys())

            rows = await conn.fetch(
                """
                SELECT instance_id, param_name, value
                FROM indicator_values_v4
                WHERE symbol = $1
                  AND open_time = $2
                  AND instance_id = ANY($3::int[])
                """,
                symbol,
                tf_open_time,
                instance_ids,
            )

            by_instance: Dict[int, List[Dict[str, Any]]] = {}
            for r in rows:
                iid = r["instance_id"]
                by_instance.setdefault(iid, []).append(
                    {
                        "param_name": r["param_name"],
                        "value": float(r["value"]),
                    }
                )

            tf_families: Dict[str, Dict[str, float]] = {}

            for iid, records in by_instance.items():
                inst = instances_by_id.get(iid)
                if not inst:
                    continue

                family = inst.get("indicator") or "unknown"
                family_dict = tf_families.setdefault(family, {})

                for rec in records:
                    param_name = rec["param_name"]
                    value = rec["value"]
                    family_dict[param_name] = value

            if not tf_families:
                continue

            tf_payload[tf] = {
                "open_time": tf_open_time.isoformat(),
                "indicators": tf_families,
            }

    if not tf_payload:
        log.debug(
            "BT_SCENARIOS_POSTPROC: –ø–æ–∑–∏—Ü–∏—è id=%s, symbol=%s ‚Äî –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è –∑–∞–ø–∏—Å–∏, –ø–æ–∑–∏—Ü–∏—è –ø—Ä–æ–ø—É—â–µ–Ω–∞",
            pos_id,
            symbol,
        )
        return "skipped"

    raw_stat = {
        "version": "v1",
        "tf": tf_payload,
    }

    raw_stat_json = json.dumps(raw_stat)

    # –∑–∞–ø–∏—Å—ã–≤–∞–µ–º raw_stat –∏ –ø–æ–º–µ—á–∞–µ–º –ø–æ–∑–∏—Ü–∏—é –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—É—é
    async with pg.acquire() as conn:
        await conn.execute(
            """
            UPDATE bt_scenario_positions
            SET raw_stat = $1::jsonb,
                postproc = true
            WHERE id = $2
            """,
            raw_stat_json,
            pos_id,
        )

    return "processed"


# üî∏ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ open_time –¥–ª—è –ø–æ–∑–∏—Ü–∏–∏ –ø–æ –≤—Å–µ–º TF (–µ–¥–∏–Ω–∞—è –ª–æ–≥–∏–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö)
async def _resolve_open_times_for_position(
    pg,
    symbol: str,
    base_tf: str,
    entry_time: datetime,
) -> Optional[Dict[str, datetime]]:
    open_times: Dict[str, datetime] = {}

    base_tf_lower = (base_tf or "").lower()
    base_step_min = TF_STEP_MINUTES.get(base_tf_lower)

    if not base_step_min:
        log.warning(
            "BT_SCENARIOS_POSTPROC: –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –±–∞–∑–æ–≤—ã–π TF '%s' –¥–ª—è –ø–æ–∑–∏—Ü–∏–∏ symbol=%s",
            base_tf,
            symbol,
        )
        return None

    # –º–æ–º–µ–Ω—Ç –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è –ø–æ —Å–¥–µ–ª–∫–µ: –∑–∞–∫—Ä—ã—Ç–∏–µ –±–∞—Ä–∞ –ø–æ–∑–∏—Ü–∏–∏
    decision_time = entry_time + timedelta(minutes=base_step_min)

    async with pg.acquire() as conn:
        # –¥–ª—è –≤—Å–µ—Ö TF –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–¥–∏–Ω–æ–µ –ø—Ä–∞–≤–∏–ª–æ:
        # open_time_TF + Œî_TF <= decision_time (–±–∞—Ä –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–∫—Ä—ã—Ç –∫ –º–æ–º–µ–Ω—Ç—É —Ä–µ—à–µ–Ω–∏—è)
        for tf in ("m5", "m15", "h1"):
            table_name = _ohlcv_table_for_timeframe(tf)
            if not table_name:
                continue

            step_minutes = TF_STEP_MINUTES.get(tf)
            if step_minutes is None:
                continue

            interval_str = f"{step_minutes} minutes"

            tf_row = await conn.fetchrow(
                f"""
                SELECT max(open_time) AS open_time
                FROM {table_name}
                WHERE symbol = $1
                  AND open_time + interval '{interval_str}' <= $2
                """,
                symbol,
                decision_time,
            )

            if not tf_row or tf_row["open_time"] is None:
                return None

            open_times[tf] = tf_row["open_time"]

    required_tfs = {"m5", "m15", "h1"}
    if not required_tfs.issubset(open_times.keys()):
        return None

    return open_times


# üî∏ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã OHLCV –ø–æ TF
def _ohlcv_table_for_timeframe(timeframe: str) -> Optional[str]:
    if timeframe == "m5":
        return "ohlcv_bb_m5"
    if timeframe == "m15":
        return "ohlcv_bb_m15"
    if timeframe == "h1":
        return "ohlcv_bb_h1"
    return None