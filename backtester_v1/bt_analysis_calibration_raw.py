# bt_analysis_calibration_raw.py â€” ÑÐ±Ð¾Ñ€ ÑÑ‹Ñ€Ñ‹Ñ… Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹ Ñ„Ð¸Ñ‡ (ÐºÐ°Ð»Ð¸Ð±Ñ€Ð¾Ð²Ð¾Ñ‡Ð½Ñ‹Ð¹ ÑÐ»Ð¾Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°)

import asyncio
import json
import logging
from collections import defaultdict
from datetime import datetime, timedelta
from decimal import Decimal, ROUND_DOWN, getcontext
from typing import Any, Dict, List, Optional, Tuple

# ðŸ”¸ ÐšÐµÑˆÐ¸ backtester_v1 (Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ñ‹ Ð¸ Ð¸Ð½Ð´Ð¸ÐºÐ°Ñ‚Ð¾Ñ€Ñ‹)
from backtester_config import get_analysis_instance, get_all_indicator_instances

# ðŸ”¸ ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Decimal
getcontext().prec = 28

log = logging.getLogger("BT_ANALYSIS_CALIB_RAW")

# ðŸ”¸ ÐšÐ¾Ð½ÑÑ‚Ð°Ð½Ñ‚Ñ‹ ÑÑ‚Ñ€Ð¸Ð¼Ð¾Ð² Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
ANALYSIS_READY_STREAM_KEY = "bt:analysis:ready"
CALIB_READY_STREAM_KEY = "bt:analysis:calibration:ready"
CALIB_CONSUMER_GROUP = "bt_analysis_calib_raw"
CALIB_CONSUMER_NAME = "bt_analysis_calib_raw_main"

# ðŸ”¸ ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ñ‡Ñ‚ÐµÐ½Ð¸Ñ ÑÑ‚Ñ€Ð¸Ð¼Ð° bt:analysis:ready
CALIB_STREAM_BATCH_SIZE = 10
CALIB_STREAM_BLOCK_MS = 5000

# ðŸ”¸ Ð¢Ð°Ð¹Ð¼ÑˆÐ°Ð³Ð¸ TF (Ð² Ð¼Ð¸Ð½ÑƒÑ‚Ð°Ñ…) Ð´Ð»Ñ Ñ€Ð°ÑÑ‡Ñ‘Ñ‚Ð° Ð¾ÐºÐ¾Ð½ Ð¿Ð¾ Ð±Ð°Ñ€Ð°Ð¼
TF_STEP_MINUTES = {
    "m5": 5,
    "m15": 15,
    "h1": 60,
}


# ðŸ”¸ ÐšÐ²Ð°Ð½Ñ‚Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð´Ð¾ 4 Ð·Ð½Ð°ÐºÐ¾Ð²
def _q4(value: Decimal) -> Decimal:
    return value.quantize(Decimal("0.0001"), rounding=ROUND_DOWN)


# ðŸ”¸ Ð‘ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾Ðµ Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ
def _safe_div(n: Decimal, d: Decimal) -> Decimal:
    if d == 0:
        return Decimal("0")
    return n / d


# ðŸ”¸ Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ RSI Ð¸Ð· raw_stat Ñ ÑƒÑ‡Ñ‘Ñ‚Ð¾Ð¼ TF Ð¸ ÐºÐ»ÑŽÑ‡Ð°
def _extract_rsi_value(
    raw_stat: Any,
    timeframe: str,
    source_key: str,
) -> Optional[float]:
    # ÐµÑÐ»Ð¸ raw_stat Ð¿Ñ€Ð¸ÑˆÑ‘Ð» ÐºÐ°Ðº JSON-ÑÑ‚Ñ€Ð¾ÐºÐ° â€” Ñ€Ð°Ð·Ð±Ð¸Ñ€Ð°ÐµÐ¼
    if isinstance(raw_stat, str):
        try:
            raw_stat = json.loads(raw_stat)
        except Exception:
            return None

    if not isinstance(raw_stat, dict):
        return None

    tf_map = raw_stat.get("tf")
    if not isinstance(tf_map, dict):
        return None

    tf_lower: Dict[str, Any] = {str(k).lower(): v for k, v in tf_map.items()}
    tf_block = tf_lower.get(timeframe.lower())
    if not isinstance(tf_block, dict):
        return None

    indicators = tf_block.get("indicators")
    if not isinstance(indicators, dict):
        return None

    indicators_lower: Dict[str, Any] = {str(k).lower(): v for k, v in indicators.items()}
    rsi_block_raw = indicators_lower.get("rsi")
    if not isinstance(rsi_block_raw, dict):
        return None

    rsi_block: Dict[str, Any] = {str(k).lower(): v for k, v in rsi_block_raw.items()}
    rsi_val_raw = rsi_block.get(source_key.lower())
    if rsi_val_raw is None:
        return None

    try:
        return float(rsi_val_raw)
    except Exception:
        return None


# ðŸ”¸ ÐŸÐ¾Ð¸ÑÐº instance_id Ð´Ð»Ñ RSI Ð¿Ð¾ timeframe Ð¸ source_key (rsi14 â†’ length=14)
def _resolve_rsi_instance_id(timeframe: str, source_key: str) -> Optional[int]:
    all_instances = get_all_indicator_instances()
    length = None

    try:
        if source_key.lower().startswith("rsi"):
            length = int(source_key[3:])
    except Exception:
        length = None

    if length is None:
        return None

    for iid, inst in all_instances.items():
        indicator = (inst.get("indicator") or "").lower()
        tf = (inst.get("timeframe") or "").lower()
        if indicator != "rsi" or tf != timeframe.lower():
            continue
        params = inst.get("params") or {}
        length_raw = params.get("length")
        try:
            length_inst = int(str(length_raw))
        except Exception:
            continue
        if length_inst == length:
            return iid

    return None


# ðŸ”¸ Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ñ€ÑÐ´Ð° RSI Ð¿Ð¾ instance_id Ð´Ð»Ñ Ð²ÑÐµÑ… ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²
async def _load_rsi_history_for_positions(
    pg,
    instance_id: int,
    timeframe: str,
    positions: List[Dict[str, Any]],
    window_bars: int,
) -> Dict[str, List[Tuple[Any, float]]]:
    if window_bars <= 0:
        window_bars = 1

    step_min = TF_STEP_MINUTES.get(timeframe)
    if not step_min:
        step_min = 5

    by_symbol: Dict[str, List[Any]] = defaultdict(list)
    for p in positions:
        symbol = p["symbol"]
        entry_time = p["entry_time"]
        by_symbol[symbol].append(entry_time)

    result: Dict[str, List[Tuple[Any, float]]] = {}

    async with pg.acquire() as conn:
        for symbol, times in by_symbol.items():
            if not times:
                continue

            min_entry = min(times)
            max_entry = max(times)

            delta = timedelta(minutes=step_min * window_bars)
            from_time = min_entry - delta
            to_time = max_entry

            rows = await conn.fetch(
                """
                SELECT open_time, value
                FROM indicator_values_v4
                WHERE instance_id = $1
                  AND symbol      = $2
                  AND open_time  BETWEEN $3 AND $4
                ORDER BY open_time
                """,
                instance_id,
                symbol,
                from_time,
                to_time,
            )

            if not rows:
                continue

            series: List[Tuple[Any, float]] = []
            for r in rows:
                try:
                    series.append((r["open_time"], float(r["value"])))
                except Exception:
                    continue

            if series:
                result[symbol] = series

    return result


# ðŸ”¸ ÐŸÐ¾Ð¸ÑÐº Ð¸Ð½Ð´ÐµÐºÑÐ° Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐ³Ð¾ Ð±Ð°Ñ€Ð° Ñ open_time <= entry_time
def _find_index_leq(series: List[Tuple[Any, float]], entry_time) -> Optional[int]:
    lo = 0
    hi = len(series) - 1
    idx = None

    while lo <= hi:
        mid = (lo + hi) // 2
        t = series[mid][0]
        if t <= entry_time:
            idx = mid
            lo = mid + 1
        else:
            hi = mid - 1

    return idx


# ðŸ”¸ Ð‘Ð¸Ð½Ð½Ð¸Ð½Ð³ Ð´Ð»Ñ rsi_dist_from_50 (Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð´Ð»Ñ Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ð½Ð¸Ñ Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½Ð°, Ð½Ð¾ Ð½Ðµ Ð·Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÐ¼ Ð±Ð¸Ð½)
def _rsi_dist_raw(rsi: float) -> float:
    return abs(rsi - 50.0)


# ðŸ”¸ Ð‘Ð¸Ð½Ð½Ð¸Ð½Ð³ Ð´Ð»Ñ rsi_zone (Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¼ÐµÑ‚ÐºÑƒ, Ñ‡Ð¸ÑÐ»Ð° Ð½Ð°Ñ Ð·Ð´ÐµÑÑŒ Ð½Ðµ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÑƒÑŽÑ‚)
def _bin_rsi_zone(rsi: float) -> Tuple[str, float, float]:
    if rsi < 30.0:
        return "Z1_LT_30", 0.0, 30.0
    if 30.0 <= rsi < 40.0:
        return "Z2_30_40", 30.0, 40.0
    if 40.0 <= rsi <= 60.0:
        return "Z3_40_60", 40.0, 60.0
    if 60.0 < rsi <= 70.0:
        return "Z4_60_70", 60.0, 70.0
    return "Z5_GT_70", 70.0, 100.0


# ðŸ”¸ Ð‘Ð¸Ð½Ð½Ð¸Ð½Ð³ Ð´Ð»Ñ Ð½Ð°ÐºÐ»Ð¾Ð½Ð°/ÑƒÑÐºÐ¾Ñ€ÐµÐ½Ð¸Ñ (Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð´Ð»Ñ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ñ… Ð±Ð¸Ð½Ð¾Ð², Ð½Ð¾ Ð² raw Ð¼Ñ‹ Ð¿Ð¸ÑˆÐµÐ¼ ÑÐ°Ð¼Ð¾ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ)
def _bin_signed_value_5(v: float) -> str:
    if v >= 5.0:
        return "StrongUp"
    if 2.0 <= v < 5.0:
        return "ModerateUp"
    if -2.0 < v < 2.0:
        return "Flat"
    if -5.0 < v <= -2.0:
        return "ModerateDown"
    return "StrongDown"


# ðŸ”¸ Ð‘Ð¸Ð½Ð½Ð¸Ð½Ð³ Ð²Ð¾Ð»Ð°Ñ‚Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸ (Ð´Ð»Ñ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ñ… Ð±Ð¸Ð½Ð¾Ð², Ð² raw Ð¿Ð¸ÑˆÐµÐ¼ vol)
def _bin_volatility(v: float) -> str:
    if v < 3.0:
        return "Vol_VeryLow"
    if v < 6.0:
        return "Vol_Low"
    if v < 10.0:
        return "Vol_Medium"
    if v < 15.0:
        return "Vol_High"
    return "Vol_VeryHigh"


# ðŸ”¸ Ð‘Ð¸Ð½Ð½Ð¸Ð½Ð³ delta RSI vs MA(RSI) (Ð´Ð»Ñ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ñ… Ð±Ð¸Ð½Ð¾Ð², Ð² raw Ð¿Ð¸ÑˆÐµÐ¼ delta)
def _bin_rsi_vs_ma(delta: float) -> str:
    if delta <= -10.0:
        return "StrongBelow"
    if -10.0 < delta <= -3.0:
        return "SlightBelow"
    if -3.0 < delta < 3.0:
        return "Near"
    if 3.0 <= delta < 10.0:
        return "SlightAbove"
    return "StrongAbove"


# ðŸ”¸ Ð‘Ð¸Ð½Ð½Ð¸Ð½Ð³ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð° Ð±Ð°Ñ€Ð¾Ð² Ñ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚Ð° Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐ³Ð¾ ÐºÐ°ÑÐ°Ð½Ð¸Ñ ÑƒÑ€Ð¾Ð²Ð½Ñ
def _bin_bars_since_level(bars: int) -> str:
    if bars == 0:
        return "JustNow"
    if 1 <= bars <= 3:
        return "VeryRecent"
    if 4 <= bars <= 10:
        return "Recent"
    if 11 <= bars <= 30:
        return "Old"
    return "VeryOld"

# ðŸ”¸ ÐŸÑƒÐ±Ð»Ð¸Ñ‡Ð½Ð°Ñ Ñ‚Ð¾Ñ‡ÐºÐ° Ð²Ñ…Ð¾Ð´Ð°: Ð²Ð¾Ñ€ÐºÐµÑ€ ÐºÐ°Ð»Ð¸Ð±Ñ€Ð¾Ð²ÐºÐ¸ ÑÑ‹Ñ€Ñ‹Ñ… Ñ„Ð¸Ñ‡
async def run_bt_analysis_calibration_raw(pg, redis):
    log.info("BT_ANALYSIS_CALIB_RAW: Ð²Ð¾Ñ€ÐºÐµÑ€ ÐºÐ°Ð»Ð¸Ð±Ñ€Ð¾Ð²ÐºÐ¸ ÑÑ‹Ñ€Ñ‹Ñ… Ñ„Ð¸Ñ‡ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½")

    # Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ consumer group Ð´Ð»Ñ ÑÑ‚Ñ€Ð¸Ð¼Ð° bt:analysis:ready
    await _ensure_consumer_group(redis)

    # Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ñ†Ð¸ÐºÐ» Ñ‡Ñ‚ÐµÐ½Ð¸Ñ ÑÑ‚Ñ€Ð¸Ð¼Ð° Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
    while True:
        try:
            messages = await _read_from_stream(redis)

            if not messages:
                continue

            total_msgs = 0
            total_pairs = 0
            total_rows_written = 0

            for stream_key, entries in messages:
                if stream_key != ANALYSIS_READY_STREAM_KEY:
                    continue

                for entry_id, fields in entries:
                    total_msgs += 1

                    ctx = _parse_ready_message(fields)
                    if not ctx:
                        await redis.xack(ANALYSIS_READY_STREAM_KEY, CALIB_CONSUMER_GROUP, entry_id)
                        continue

                    scenario_id = ctx["scenario_id"]
                    signal_id = ctx["signal_id"]
                    family_key = ctx["family_key"]
                    analysis_ids = ctx["analysis_ids"]

                    log.info(
                        "BT_ANALYSIS_CALIB_RAW: Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¾ Ð³Ð¾Ñ‚Ð¾Ð²Ð½Ð¾ÑÑ‚Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° "
                        "scenario_id=%s, signal_id=%s, family=%s, analysis_ids=%s, stream_id=%s",
                        scenario_id,
                        signal_id,
                        family_key,
                        analysis_ids,
                        entry_id,
                    )

                    # Ð¿Ð¾ÐºÐ° Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ RSI
                    if family_key != "rsi" or not analysis_ids:
                        await redis.xack(ANALYSIS_READY_STREAM_KEY, CALIB_CONSUMER_GROUP, entry_id)
                        continue

                    rows_written = await _process_family_raw(
                        pg=pg,
                        scenario_id=scenario_id,
                        signal_id=signal_id,
                        family_key=family_key,
                        analysis_ids=analysis_ids,
                    )
                    total_pairs += 1
                    total_rows_written += rows_written

                    # ðŸ”¸ ÐŸÑƒÐ±Ð»Ð¸ÐºÑƒÐµÐ¼ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ðµ Ð³Ð¾Ñ‚Ð¾Ð²Ð½Ð¾ÑÑ‚Ð¸ ÐºÐ°Ð»Ð¸Ð±Ñ€Ð¾Ð²ÐºÐ¸ Ð² bt:analysis:calibration:ready
                    finished_at = datetime.utcnow()
                    try:
                        await redis.xadd(
                            CALIB_READY_STREAM_KEY,
                            {
                                "scenario_id": str(scenario_id),
                                "signal_id": str(signal_id),
                                "family_key": str(family_key),
                                "analysis_ids": ",".join(str(a) for a in analysis_ids),
                                "rows_written": str(rows_written),
                                "finished_at": finished_at.isoformat(),
                            },
                        )
                        log.info(
                            "BT_ANALYSIS_CALIB_RAW: Ð¾Ð¿ÑƒÐ±Ð»Ð¸ÐºÐ¾Ð²Ð°Ð½Ð¾ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ðµ Ð² '%s' Ð´Ð»Ñ scenario_id=%s, signal_id=%s, "
                            "family=%s, analysis_ids=%s, rows_written=%s, finished_at=%s",
                            CALIB_READY_STREAM_KEY,
                            scenario_id,
                            signal_id,
                            family_key,
                            analysis_ids,
                            rows_written,
                            finished_at,
                        )
                    except Exception as e:
                        log.error(
                            "BT_ANALYSIS_CALIB_RAW: Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¾Ð¿ÑƒÐ±Ð»Ð¸ÐºÐ¾Ð²Ð°Ñ‚ÑŒ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ðµ Ð² ÑÑ‚Ñ€Ð¸Ð¼ '%s' "
                            "Ð´Ð»Ñ scenario_id=%s, signal_id=%s, family=%s: %s",
                            CALIB_READY_STREAM_KEY,
                            scenario_id,
                            signal_id,
                            family_key,
                            e,
                            exc_info=True,
                        )

                    await redis.xack(ANALYSIS_READY_STREAM_KEY, CALIB_CONSUMER_GROUP, entry_id)

                    log.info(
                        "BT_ANALYSIS_CALIB_RAW: ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ stream_id=%s Ð´Ð»Ñ scenario_id=%s, signal_id=%s "
                        "Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð¾, ÑÑ‚Ñ€Ð¾Ðº Ð² bt_position_features_raw Ð·Ð°Ð¿Ð¸ÑÐ°Ð½Ð¾=%s",
                        entry_id,
                        scenario_id,
                        signal_id,
                        rows_written,
                    )

            log.info(
                "BT_ANALYSIS_CALIB_RAW: Ð¿Ð°ÐºÐµÑ‚ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½ â€” ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹=%s, Ð¿Ð°Ñ€_ÑÑ†ÐµÐ½Ð°Ñ€Ð¸Ð¹_ÑÐ¸Ð³Ð½Ð°Ð»=%s, "
                "ÑÑ‚Ñ€Ð¾Ðº_Ð²_bt_position_features_raw=%s",
                total_msgs,
                total_pairs,
                total_rows_written,
            )

        except Exception as e:
            log.error(
                "BT_ANALYSIS_CALIB_RAW: Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð² Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¼ Ñ†Ð¸ÐºÐ»Ðµ Ð²Ð¾Ñ€ÐºÐµÑ€Ð°: %s",
                e,
                exc_info=True,
            )
            await asyncio.sleep(2)

# ðŸ”¸ ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ°/ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ðµ consumer group Ð´Ð»Ñ ÑÑ‚Ñ€Ð¸Ð¼Ð° bt:analysis:ready
async def _ensure_consumer_group(redis) -> None:
    try:
        await redis.xgroup_create(
            name=ANALYSIS_READY_STREAM_KEY,
            groupname=CALIB_CONSUMER_GROUP,
            id="$",
            mkstream=True,
        )
        log.debug(
            "BT_ANALYSIS_CALIB_RAW: ÑÐ¾Ð·Ð´Ð°Ð½Ð° consumer group '%s' Ð´Ð»Ñ ÑÑ‚Ñ€Ð¸Ð¼Ð° '%s'",
            CALIB_CONSUMER_GROUP,
            ANALYSIS_READY_STREAM_KEY,
        )
    except Exception as e:
        msg = str(e)
        if "BUSYGROUP" in msg:
            log.info(
                "BT_ANALYSIS_CALIB_RAW: consumer group '%s' Ð´Ð»Ñ ÑÑ‚Ñ€Ð¸Ð¼Ð° '%s' ÑƒÐ¶Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚",
                CALIB_CONSUMER_GROUP,
                ANALYSIS_READY_STREAM_KEY,
            )
        else:
            log.error(
                "BT_ANALYSIS_CALIB_RAW: Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ consumer group '%s': %s",
                CALIB_CONSUMER_GROUP,
                e,
                exc_info=True,
            )
            raise


# ðŸ”¸ Ð§Ñ‚ÐµÐ½Ð¸Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ Ð¸Ð· ÑÑ‚Ñ€Ð¸Ð¼Ð° bt:analysis:ready
async def _read_from_stream(redis) -> List[Any]:
    entries = await redis.xreadgroup(
        groupname=CALIB_CONSUMER_GROUP,
        consumername=CALIB_CONSUMER_NAME,
        streams={ANALYSIS_READY_STREAM_KEY: ">"},
        count=CALIB_STREAM_BATCH_SIZE,
        block=CALIB_STREAM_BLOCK_MS,
    )

    if not entries:
        return []

    parsed: List[Any] = []
    for stream_key, messages in entries:
        if isinstance(stream_key, bytes):
            stream_key = stream_key.decode("utf-8")

        stream_entries: List[Any] = []
        for msg_id, fields in messages:
            if isinstance(msg_id, bytes):
                msg_id = msg_id.decode("utf-8")

            str_fields: Dict[str, str] = {}
            for k, v in fields.items():
                key_str = k.decode("utf-8") if isinstance(k, bytes) else str(k)
                val_str = v.decode("utf-8") if isinstance(v, bytes) else str(v)
                str_fields[key_str] = val_str

            stream_entries.append((msg_id, str_fields))

        parsed.append((stream_key, stream_entries))

    return parsed


# ðŸ”¸ Ð Ð°Ð·Ð±Ð¾Ñ€ Ð¾Ð´Ð½Ð¾Ð³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð¸Ð· ÑÑ‚Ñ€Ð¸Ð¼Ð° bt:analysis:ready
def _parse_ready_message(fields: Dict[str, str]) -> Optional[Dict[str, Any]]:
    try:
        scenario_id_str = fields.get("scenario_id")
        signal_id_str = fields.get("signal_id")
        family_key = fields.get("family_key")
        analysis_ids_str = fields.get("analysis_ids") or ""
        finished_at_str = fields.get("finished_at")

        if not (scenario_id_str and signal_id_str and family_key and finished_at_str):
            return None

        scenario_id = int(scenario_id_str)
        signal_id = int(signal_id_str)
        finished_at = datetime.fromisoformat(finished_at_str)

        raw_ids = [s.strip() for s in analysis_ids_str.split(",") if s.strip()]
        analysis_ids: List[int] = []
        for s in raw_ids:
            try:
                analysis_ids.append(int(s))
            except Exception:
                continue

        return {
            "scenario_id": scenario_id,
            "signal_id": signal_id,
            "family_key": family_key,
            "analysis_ids": analysis_ids,
            "finished_at": finished_at,
        }
    except Exception as e:
        log.error(
            "BT_ANALYSIS_CALIB_RAW: Ð¾ÑˆÐ¸Ð±ÐºÐ° Ñ€Ð°Ð·Ð±Ð¾Ñ€Ð° ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ ÑÑ‚Ñ€Ð¸Ð¼Ð° bt:analysis:ready: %s, fields=%s",
            e,
            fields,
            exc_info=True,
        )
        return None


# ðŸ”¸ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¾Ð´Ð½Ð¾Ð³Ð¾ ÑÐµÐ¼ÐµÐ¹ÑÑ‚Ð²Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð¾Ð² Ð´Ð»Ñ Ð¿Ð°Ñ€Ñ‹ scenario_id/signal_id
async def _process_family_raw(
    pg,
    scenario_id: int,
    signal_id: int,
    family_key: str,
    analysis_ids: List[int],
) -> int:
    # Ð·Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸ ÑÑ‚Ð¾Ð³Ð¾ ÑÑ†ÐµÐ½Ð°Ñ€Ð¸Ñ/ÑÐ¸Ð³Ð½Ð°Ð»Ð°, Ð¿Ñ€Ð¾ÑˆÐµÐ´ÑˆÐ¸Ðµ Ð¿Ð¾ÑÑ‚Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ¸Ð½Ð³
    async with pg.acquire() as conn:
        rows = await conn.fetch(
            """
            SELECT
                id,
                symbol,
                direction,
                timeframe,
                entry_time,
                raw_stat,
                pnl_abs
            FROM bt_scenario_positions
            WHERE scenario_id = $1
              AND signal_id   = $2
              AND postproc    = true
            """,
            scenario_id,
            signal_id,
        )

    if not rows:
        log.debug(
            "BT_ANALYSIS_CALIB_RAW: Ð½ÐµÑ‚ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¹ Ñ postproc=true Ð´Ð»Ñ scenario_id=%s, signal_id=%s",
            scenario_id,
            signal_id,
        )
        return 0

    positions: List[Dict[str, Any]] = []
    for r in rows:
        positions.append(
            {
                "id": r["id"],
                "symbol": r["symbol"],
                "direction": r["direction"],
                "timeframe": r["timeframe"],
                "entry_time": r["entry_time"],
                "raw_stat": r["raw_stat"],
                "pnl_abs": r["pnl_abs"],
            }
        )

    # ðŸ”¸ ÐŸÐ¾Ð»Ð½Ð°Ñ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ° ÑÑ‹Ñ€Ñ‹Ñ… Ñ„Ð¸Ñ‡ Ð´Ð»Ñ ÑÑ‚Ð¾Ð¹ ÑÐ²ÑÐ·ÐºÐ¸ Ð¸ ÑÐµÐ¼ÑŒÐ¸
    async with pg.acquire() as conn:
        await conn.execute(
            """
            DELETE FROM bt_position_features_raw
            WHERE scenario_id = $1
              AND signal_id   = $2
              AND family_key  = $3
            """,
            scenario_id,
            signal_id,
            family_key,
        )

    total_rows_written = 0

    # Ð·Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ RSI Ð¾Ð´Ð¸Ð½ Ñ€Ð°Ð· Ð´Ð»Ñ Ð²ÑÐµÑ… history-based Ñ„Ð¸Ñ‡ Ð¿Ð¾ ÐºÐ°Ð¶Ð´Ð¾Ð¼Ñƒ (timeframe, source_key)
    # ÑÐ½Ð°Ñ‡Ð°Ð»Ð° Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€ÑƒÐµÐ¼ analysis_instances Ð¿Ð¾ (timeframe, source_key)
    history_needed: Dict[Tuple[str, str], Dict[str, Any]] = {}

    for aid in analysis_ids:
        inst = get_analysis_instance(aid)
        if not inst:
            continue
        if inst.get("family_key") != "rsi":
            continue

        key = inst.get("key")
        params = inst.get("params") or {}
        tf_cfg = params.get("timeframe")
        source_cfg = params.get("source_key")

        timeframe = str(tf_cfg.get("value")).strip() if tf_cfg is not None else "m5"
        source_key = str(source_cfg.get("value")).strip() if source_cfg is not None else "rsi14"

        if key in (
            "rsi_zone_duration",
            "rsi_slope",
            "rsi_accel",
            "rsi_volatility",
            "rsi_avg_window",
            "rsi_since_cross_30",
            "rsi_since_cross_50",
            "rsi_since_cross_70",
            "rsi_vs_ma",
            "rsi_extremum",
        ):
            # Ð´Ð»Ñ history-based Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð¾Ð±Ñ‰ÐµÐµ Ð¾ÐºÐ½Ð¾ Ð¸Ð· params Ð¸Ð»Ð¸ Ð´ÐµÑ„Ð¾Ð»Ñ‚
            cfg_key = (timeframe, source_key)
            if cfg_key not in history_needed:
                history_needed[cfg_key] = {
                    "timeframe": timeframe,
                    "source_key": source_key,
                    "params": params,
                }

    rsi_history_by_key: Dict[Tuple[str, str], Dict[str, List[Tuple[Any, float]]]] = {}

    # Ð·Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ (timeframe, source_key)
    for (timeframe, source_key), info in history_needed.items():
        params = info["params"]

        def _get_int_param(name: str, default: int) -> int:
            cfg = params.get(name)
            if cfg is None:
                return default
            try:
                return int(str(cfg.get("value")))
            except Exception:
                return default

        window_bars = _get_int_param("window_bars", 50)
        instance_id = _resolve_rsi_instance_id(timeframe, source_key)
        if instance_id is None:
            log.warning(
                "BT_ANALYSIS_CALIB_RAW: Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ instance_id RSI Ð´Ð»Ñ timeframe=%s, source_key=%s",
                timeframe,
                source_key,
            )
            continue

        rsi_history = await _load_rsi_history_for_positions(
            pg=pg,
            instance_id=instance_id,
            timeframe=timeframe,
            positions=positions,
            window_bars=window_bars,
        )
        rsi_history_by_key[(timeframe, source_key)] = rsi_history

    # ðŸ”¸ ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ ÐºÐ°Ð¶Ð´Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€ Ð¿Ð¾ Ð²ÑÐµÐ¼ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸ÑÐ¼
    async with pg.acquire() as conn:
        for aid in analysis_ids:
            inst = get_analysis_instance(aid)
            if not inst:
                log.warning(
                    "BT_ANALYSIS_CALIB_RAW: analysis_id=%s Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð² ÐºÐµÑˆÐµ, scenario_id=%s, signal_id=%s",
                    aid,
                    scenario_id,
                    signal_id,
                )
                continue

            inst_family = inst.get("family_key")
            key = inst.get("key")
            params = inst.get("params") or {}

            if inst_family != family_key:
                continue

            tf_cfg = params.get("timeframe")
            source_cfg = params.get("source_key")

            timeframe = str(tf_cfg.get("value")).strip() if tf_cfg is not None else "m5"
            source_key = str(source_cfg.get("value")).strip() if source_cfg is not None else "rsi14"

            feature_name = _resolve_feature_name_for_rsi(key=key, timeframe=timeframe, source_key=source_key)

            log.info(
                "BT_ANALYSIS_CALIB_RAW: ÑÐ±Ð¾Ñ€ ÑÑ‹Ñ€Ñ‹Ñ… Ñ„Ð¸Ñ‡ Ð´Ð»Ñ analysis_id=%s, family=%s, key=%s, "
                "feature_name=%s, timeframe=%s, scenario_id=%s, signal_id=%s",
                aid,
                family_key,
                key,
                feature_name,
                timeframe,
                scenario_id,
                signal_id,
            )

            # Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð²ÑÐ¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð´Ð»Ñ history-based
            slope_k = 3
            if key in ("rsi_slope", "rsi_accel"):
                cfg = params.get("slope_k")
                if cfg is not None:
                    try:
                        slope_k = int(str(cfg.get("value")))
                    except Exception:
                        slope_k = 3

            window_bars = 50
            if key in (
                "rsi_zone_duration",
                "rsi_slope",
                "rsi_accel",
                "rsi_volatility",
                "rsi_avg_window",
                "rsi_since_cross_30",
                "rsi_since_cross_50",
                "rsi_since_cross_70",
                "rsi_vs_ma",
                "rsi_extremum",
            ):
                cfg = params.get("window_bars")
                if cfg is not None:
                    try:
                        window_bars = int(str(cfg.get("value")))
                    except Exception:
                        window_bars = 50

            level_param = params.get("level")

            # Ð¸Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ Ð´Ð»Ñ ÑÑ‚Ð¾Ð³Ð¾ (timeframe, source_key), ÐµÑÐ»Ð¸ Ð½ÑƒÐ¶Ð½Ð¾
            history_series = None
            if key in (
                "rsi_zone_duration",
                "rsi_slope",
                "rsi_accel",
                "rsi_volatility",
                "rsi_avg_window",
                "rsi_since_cross_30",
                "rsi_since_cross_50",
                "rsi_since_cross_70",
                "rsi_vs_ma",
                "rsi_extremum",
            ):
                history_series = rsi_history_by_key.get((timeframe, source_key))
                if history_series is None:
                    log.debug(
                        "BT_ANALYSIS_CALIB_RAW: Ð½ÐµÑ‚ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ RSI Ð´Ð»Ñ key=%s timeframe=%s source_key=%s "
                        "â€” ÑÑ‹Ñ€Ñ‹Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ñ„Ð¸Ñ‡Ð¸ Ð·Ð°Ð¿Ð¸ÑÐ°Ð½Ñ‹ Ð½Ðµ Ð±ÑƒÐ´ÑƒÑ‚",
                        key,
                        timeframe,
                        source_key,
                    )
                    continue

            # ÑÐ¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ batch Ð²ÑÑ‚Ð°Ð²Ð¾Ðº Ð´Ð»Ñ ÑÑ‚Ð¾Ð³Ð¾ analysis_id
            rows_to_insert: List[Tuple[Any, ...]] = []

            for p in positions:
                position_id = p["id"]
                symbol = p["symbol"]
                direction = p["direction"]
                entry_time = p["entry_time"]
                raw_stat = p["raw_stat"]
                pnl_abs_raw = p["pnl_abs"]

                if direction is None or pnl_abs_raw is None:
                    continue

                try:
                    pnl_abs = Decimal(str(pnl_abs_raw))
                except Exception:
                    continue

                is_win = pnl_abs > 0

                feature_value: Optional[float] = None

                # Ñ€Ð°ÑÑ‡Ñ‘Ñ‚ feature_value Ð¿Ð¾ ÐºÐ»ÑŽÑ‡Ñƒ
                if key == "rsi_value":
                    rsi_val = _extract_rsi_value(raw_stat, timeframe, source_key)
                    if rsi_val is None:
                        continue
                    feature_value = rsi_val

                elif key == "rsi_dist_from_50":
                    rsi_val = _extract_rsi_value(raw_stat, timeframe, source_key)
                    if rsi_val is None:
                        continue
                    feature_value = _rsi_dist_raw(rsi_val)

                elif key == "rsi_zone":
                    rsi_val = _extract_rsi_value(raw_stat, timeframe, source_key)
                    if rsi_val is None:
                        continue
                    zone_label, _, _ = _bin_rsi_zone(rsi_val)
                    # Ð´Ð»Ñ ÐºÐ°Ð»Ð¸Ð±Ñ€Ð¾Ð²ÐºÐ¸ Ð¼Ð¾Ð¶Ð½Ð¾ Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ñ‡Ð¸ÑÐ»Ð¾Ð²Ð¾Ð¹ RSI, Ð° Ð·Ð¾Ð½Ñƒ Ð²Ð¾ÑÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ðµ
                    feature_value = rsi_val

                elif key in (
                    "rsi_zone_duration",
                    "rsi_slope",
                    "rsi_accel",
                    "rsi_volatility",
                    "rsi_avg_window",
                    "rsi_since_cross_30",
                    "rsi_since_cross_50",
                    "rsi_since_cross_70",
                    "rsi_vs_ma",
                    "rsi_extremum",
                ):
                    series_for_symbol = history_series.get(symbol) if history_series else None
                    if not series_for_symbol:
                        continue

                    idx = _find_index_leq(series_for_symbol, entry_time)
                    if idx is None:
                        continue

                    rsi_t = series_for_symbol[idx][1]

                    if key == "rsi_zone_duration":
                        # Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð² Ð±Ð°Ñ€Ð°Ñ…, ÑÐºÐ¾Ð»ÑŒÐºÐ¾ RSI Ð±Ñ‹Ð» Ð² Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¹ Ð·Ð¾Ð½Ðµ Ð½Ð°Ð·Ð°Ð´
                        zone_label, _, _ = _bin_rsi_zone(rsi_t)

                        def _in_zone(val: float, label: str) -> bool:
                            if label == "Z1_LT_30":
                                return val < 30.0
                            if label == "Z2_30_40":
                                return 30.0 <= val < 40.0
                            if label == "Z3_40_60":
                                return 40.0 <= val <= 60.0
                            if label == "Z4_60_70":
                                return 60.0 < val <= 70.0
                            if label == "Z5_GT_70":
                                return val > 70.0
                            return False

                            # Ð·Ð´ÐµÑÑŒ Ð½ÐµÐ»ÑŒÐ·Ñ

                        duration = 1
                        j = idx - 1
                        while j >= 0 and duration < window_bars:
                            rsi_prev = series_for_symbol[j][1]
                            if not _in_zone(rsi_prev, zone_label):
                                break
                            duration += 1
                            j -= 1

                        feature_value = float(duration)

                    elif key == "rsi_slope":
                        if idx - slope_k < 0:
                            continue
                        rsi_prev = series_for_symbol[idx - slope_k][1]
                        slope = rsi_t - rsi_prev
                        feature_value = slope

                    elif key == "rsi_accel":
                        if idx - 2 * slope_k < 0:
                            continue
                        rsi_prev = series_for_symbol[idx - slope_k][1]
                        rsi_prev2 = series_for_symbol[idx - 2 * slope_k][1]
                        slope1 = rsi_t - rsi_prev
                        slope2 = rsi_prev - rsi_prev2
                        accel = slope1 - slope2
                        feature_value = accel

                    elif key == "rsi_volatility":
                        start_idx = max(0, idx - window_bars + 1)
                        window_vals = [v for _, v in series_for_symbol[start_idx : idx + 1]]
                        if len(window_vals) < 2:
                            continue
                        mean = sum(window_vals) / len(window_vals)
                        var = sum((v - mean) ** 2 for v in window_vals) / (len(window_vals) - 1)
                        vol = var ** 0.5
                        feature_value = vol

                    elif key == "rsi_avg_window":
                        start_idx = max(0, idx - window_bars + 1)
                        window_vals = [v for _, v in series_for_symbol[start_idx : idx + 1]]
                        if not window_vals:
                            continue
                        avg_val = sum(window_vals) / len(window_vals)
                        feature_value = avg_val

                    elif key in ("rsi_since_cross_30", "rsi_since_cross_50", "rsi_since_cross_70"):
                        if level_param is not None:
                            try:
                                level = float(level_param.get("value"))
                            except Exception:
                                level = float(key.split("_")[-1])
                        else:
                            level = float(key.split("_")[-1])

                        bars_since = 0
                        j = idx - 1
                        while j >= 0 and bars_since < window_bars:
                            rsi_prev = series_for_symbol[j][1]
                            if (rsi_t >= level and rsi_prev <= level) or (rsi_t <= level and rsi_prev >= level):
                                break
                            bars_since += 1
                            j -= 1

                        feature_value = float(bars_since)

                    elif key == "rsi_vs_ma":
                        start_idx = max(0, idx - window_bars + 1)
                        window_vals = [v for _, v in series_for_symbol[start_idx : idx + 1]]
                        if not window_vals:
                            continue
                        ma_val = sum(window_vals) / len(window_vals)
                        delta = rsi_t - ma_val
                        feature_value = delta

                    elif key == "rsi_extremum":
                        start_idx = max(0, idx - window_bars + 1)
                        window_vals = [v for _, v in series_for_symbol[start_idx : idx + 1]]
                        if len(window_vals) < 3:
                            continue
                        current = rsi_t
                        feature_value = current

                    else:
                        continue

                else:
                    # Ð½ÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ key â€” Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼
                    continue

                if feature_value is None:
                    continue

                rows_to_insert.append(
                    (
                        position_id,             # position_id
                        scenario_id,             # scenario_id
                        signal_id,               # signal_id
                        direction,               # direction
                        timeframe,               # timeframe (Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°)
                        family_key,              # family_key ('rsi')
                        key,                     # key ('rsi_value', 'rsi_accel', ...)
                        feature_name,            # feature_name ÐºÐ°Ðº Ð² Ð±Ð¸Ð½Ð°Ñ…
                        feature_value,           # feature_value (numeric)
                        pnl_abs,                 # pnl_abs
                        is_win,                  # is_win
                    )
                )

            if rows_to_insert:
                await conn.executemany(
                    """
                    INSERT INTO bt_position_features_raw (
                        position_id,
                        scenario_id,
                        signal_id,
                        direction,
                        timeframe,
                        family_key,
                        key,
                        feature_name,
                        feature_value,
                        pnl_abs,
                        is_win,
                        created_at
                    )
                    VALUES (
                        $1, $2, $3, $4, $5,
                        $6, $7, $8, $9, $10,
                        $11, now()
                    )
                    """,
                    rows_to_insert,
                )

                total_rows_written += len(rows_to_insert)

                log.info(
                    "BT_ANALYSIS_CALIB_RAW: Ð´Ð»Ñ analysis_id=%s, feature_name=%s Ð·Ð°Ð¿Ð¸ÑÐ°Ð½Ð¾ ÑÑ‹Ñ€Ñ‹Ñ… ÑÑ‚Ñ€Ð¾Ðº=%s",
                    aid,
                    feature_name,
                    len(rows_to_insert),
                )

    return total_rows_written


# ðŸ”¸ Ð Ð°Ð·Ñ€ÑƒÐ»Ð¸Ð²Ð°Ð½Ð¸Ðµ feature_name Ð´Ð»Ñ RSI Ð¿Ð¾ key/timeframe/source_key (ÐºÐ°Ðº Ð² bt_analysis_rsi)
def _resolve_feature_name_for_rsi(key: str, timeframe: str, source_key: str) -> str:
    if key == "rsi_value":
        return f"rsi_value_{timeframe}_{source_key}"
    if key == "rsi_dist_from_50":
        return f"rsi_dist_from_50_{timeframe}_{source_key}"
    if key == "rsi_zone":
        return f"rsi_zone_{timeframe}_{source_key}"
    return f"{key}_{timeframe}_{source_key}"